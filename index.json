[{"content":" If you\u0026rsquo;re a dev: build a side project using ANY modern tool (Opencode, Antigravity etc).\nfrom Gergely Orosz\nWhen AI writes almost all code, what happens to software engineering?\nNo longer a hypothetical question, this is a mega-trend set to hit the tech industry\n","date":"2026-01-19T08:15:30+09:00","permalink":"https://cychong47.github.io/post/2026/2026-just-do-it-now/","summary":"\u003cblockquote\u003e\n\u003cp\u003eIf you\u0026rsquo;re a dev: build a side project using ANY modern tool (Opencode, Antigravity etc).\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003efrom Gergely Orosz\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://newsletter.pragmaticengineer.com/p/when-ai-writes-almost-all-code-what\"\u003eWhen AI writes almost all code, what happens to software engineering?\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eNo longer a hypothetical question, this is a mega-trend set to hit the tech industry\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Just Do It Now"},{"content":"Use iPhone shortcuts actions “Use On-Device Model”, “Summarize” and request to Gemini free account to summarize the highlighted text from When AI writes almost all code, what happens to software engineering?\nLooks to me, On-Device AI model is good enough.\nPrompt Use the same prompt for On-Device model and Gemini\nSummarize the input provided as Shortcut Input. The summary must be shorter than 200 words and formatted in a markdown code block. Ensure that all section titles within the summary are rendered as Level 2 Markdown Headings (starting with ##), not as simple bullet points or numbered lists.\nOn-Device model The Rise of AI in Software Engineering The article explores the transformative impact of AI on software engineering, particularly with the advent of AI-powered coding tools like Claude Code. The author shares their experience building production software on their phone using Claude Code, highlighting the significant changes in the field.\nKey Points Declining Value of Expertise: The expertise of programmers, language polyglots, and specialists in specific stacks may become less valuable as AI can generate code efficiently. Emergence of Tech Lead Traits: Being more product-minded and having strong leadership skills will be in higher demand. Overlap between Product Managers and Software Engineers: The roles of both professionals are expected to overlap more than ever before. AI-Generated Code: AI models like Opus 4.5, GPT-5.2, and Gemini 3 have demonstrated their ability to generate code, making it possible for developers to focus on higher-level tasks. Future of Software Engineering: The profession is being refactored, and developers need to adapt to a new world where AI plays a significant role in code generation and software development. Gemini free Summary of AI\u0026rsquo;s Impact on Software Engineering The Tipping Point and New Paradigm Recent AI model releases (Opus 4.5, GPT-5.2, Gemini 3) are the 【tipping point】, enabling AI to generate nearly all code. Engineers can now build production software from mobile devices, like using Claude Code to create and merge PRs. The cost of software production is 【trending towards zero】, with AI behaving like a senior engineer. Evolving Roles and Skills 【Declining value of expertise】 in prototyping, polyglotism, or stack specialization. Increased demand for 【product-minded tech leads】. Software engineers must master new 【programmable abstraction layers】 involving agents, prompts, and tools. Product managers and engineers will 【overlap more】. Future Implications Expectation for all developers to 【generate concept apps fast】. AI will handle 90%+ of code generation and refactoring. Engineers are ceasing to write code by hand, prioritizing 【leveraging AI for productivity】. A need to continually 【re-adjust expectations】 as AI capabilities advance. Summarize action Use shortcuts action \u0026ldquo;Summarizize\u0026rdquo;\nAI coding tools are becoming so advanced that they can generate most of the code for many developers, significantly impacting the software engineering profession. This shift is leading to a decline in the value of traditional expertise like prototyping and language proficiency, while increasing the demand for tech leads with product-minded skills. As AI takes over coding tasks, software engineers must adapt to a new programmable layer of abstraction and leverage AI tools to remain competitive.\n","date":"2026-01-17T15:40:59+09:00","permalink":"https://cychong47.github.io/post/2026/2026-01-17-summarize-text-in-iphone/","summary":"\u003cp\u003eUse iPhone shortcuts actions “Use On-Device Model”, “Summarize” and request to Gemini free account to summarize the highlighted text from \u003ca href=\"https://newsletter.pragmaticengineer.com/p/when-ai-writes-almost-all-code-what\"\u003eWhen AI writes almost all code, what happens to software engineering?\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eLooks to me, On-Device AI model is good enough.\u003c/p\u003e\n\u003ch2 id=\"prompt\"\u003ePrompt\u003c/h2\u003e\n\u003cp\u003eUse the same prompt for \u003ccode\u003eOn-Device model\u003c/code\u003e and \u003ccode\u003eGemini\u003c/code\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eSummarize the input provided as Shortcut Input. The summary must be shorter than 200 words and formatted in a markdown code block. Ensure that all section titles within the summary are rendered as Level 2 Markdown Headings (starting with ##), not as simple bullet points or numbered lists.\u003c/p\u003e","title":"Compare Summarization with On-Device model and Gemini free "},{"content":"Change the blog theme from mainroad to bearblog which is more minimalist.\nDelete existing submodules\n\u0026gt; git submodule deinit themes/mainroad themes/cleanwhite Add bearblog theme as a submodule\n\u0026gt; git submodule add \u0026lt;theme_repository_url\u0026gt; themes/\u0026lt;theme_name\u0026gt; \u0026gt; git submodule add https://github.com/janraasch/hugo-bearblog themes/hugo-bearblog \u0026gt; cat .gitmodules [submodule \u0026#34;themes/hugo-bearblog\u0026#34;] path = themes/hugo-bearblog url = https://github.com/janraasch/hugo-bearblog Install(update) theme submodule\n\u0026gt; git submodule update Cloning into \u0026#39;/Users/cychong/Developer/blog/another/themes/hugo-bearblog\u0026#39;... Submodule path \u0026#39;themes/hugo-bearblog\u0026#39;: checked out \u0026#39;d44ea2fd106f1bc373e0040dc7da58644638e7f0\u0026#39; \u0026gt; ls themes hugo-bearblog Change GitHub Action to get submodules\njobs: deploy: runs-on: ubuntu-latest steps: - uses: actions/checkout@v2 with: submodules: recursive token: ${{ secrets.TOKEN }} # (Optional)If you have the theme added as submodule, you can pull it and use the most updated version - name: Update theme run: git submodule update --init --recursive --remote ","date":"2026-01-17T14:18:59+09:00","permalink":"https://cychong47.github.io/post/2026/2026-01-17-bearblog-theme/","summary":"\u003cp\u003eChange the blog theme from mainroad to bearblog which is more minimalist.\u003c/p\u003e\n\u003cp\u003eDelete existing submodules\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u0026gt; git submodule deinit themes/mainroad themes/cleanwhite\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eAdd bearblog theme as a submodule\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u0026gt; git submodule add \u0026lt;theme_repository_url\u0026gt; themes/\u0026lt;theme_name\u0026gt;\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u0026gt; git submodule add https://github.com/janraasch/hugo-bearblog themes/hugo-bearblog\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u0026gt; cat .gitmodules\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003e[\u003c/span\u003esubmodule \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;themes/hugo-bearblog\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e]\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        path \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e themes/hugo-bearblog\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        url \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e https://github.com/janraasch/hugo-bearblog\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eInstall(update) theme submodule\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u0026gt; git submodule update\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eCloning into \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;/Users/cychong/Developer/blog/another/themes/hugo-bearblog\u0026#39;\u003c/span\u003e...\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eSubmodule path \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;themes/hugo-bearblog\u0026#39;\u003c/span\u003e: checked out \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;d44ea2fd106f1bc373e0040dc7da58644638e7f0\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u0026gt; ls themes \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ehugo-bearblog\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eChange GitHub Action to get submodules\u003c/p\u003e","title":"Switch to Bearblog Theme"},{"content":"Setup Prometheus and Grafana to scrap Cilium metrics This will create a new namespace cilium-monitoring\nkubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.15.1/examples/kubernetes/addons/prometheus/monitoring-example.yaml Some warnings\u0026hellip; namespace/cilium-monitoring created serviceaccount/prometheus-k8s created configmap/grafana-config created configmap/grafana-cilium-dashboard created configmap/grafana-cilium-operator-dashboard created configmap/grafana-hubble-dashboard created configmap/grafana-hubble-l7-http-metrics-by-workload created configmap/prometheus created clusterrole.rbac.authorization.k8s.io/prometheus created clusterrolebinding.rbac.authorization.k8s.io/prometheus created service/grafana created service/prometheus created Warning: would violate PodSecurity \u0026#34;restricted:latest\u0026#34;: allowPrivilegeEscalation != false (container \u0026#34;grafana-core\u0026#34; must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \u0026#34;grafana-core\u0026#34; must set securityContext.capabilities.drop=[\u0026#34;ALL\u0026#34;]), runAsNonRoot != true (pod or container \u0026#34;grafana-core\u0026#34; must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \u0026#34;grafana-core\u0026#34; must set securityContext.seccompProfile.type to \u0026#34;RuntimeDefault\u0026#34; or \u0026#34;Localhost\u0026#34;) deployment.apps/grafana created Warning: would violate PodSecurity \u0026#34;restricted:latest\u0026#34;: allowPrivilegeEscalation != false (container \u0026#34;prometheus\u0026#34; must set securityContext.allowPrivilegeEscalation=false), unrestricted capabilities (container \u0026#34;prometheus\u0026#34; must set securityContext.capabilities.drop=[\u0026#34;ALL\u0026#34;]), runAsNonRoot != true (pod or container \u0026#34;prometheus\u0026#34; must set securityContext.runAsNonRoot=true), seccompProfile (pod or container \u0026#34;prometheus\u0026#34; must set securityContext.seccompProfile.type to \u0026#34;RuntimeDefault\u0026#34; or \u0026#34;Localhost\u0026#34;) deployment.apps/prometheus created kubectl get all ❯ kubectl get all -n cilium-monitoring NAME READY STATUS RESTARTS AGE pod/grafana-6f4755f98c-8c7sg 1/1 Running 0 57s pod/prometheus-67fdcf4796-vc8hd 1/1 Running 0 57s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/grafana ClusterIP 10.102.147.187 \u0026lt;none\u0026gt; 3000/TCP 57s service/prometheus ClusterIP 10.104.8.139 \u0026lt;none\u0026gt; 9090/TCP 57s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/grafana 1/1 1 1 57s deployment.apps/prometheus 1/1 1 1 57s NAME DESIRED CURRENT READY AGE replicaset.apps/grafana-6f4755f98c 1 1 1 57s replicaset.apps/prometheus-67fdcf4796 1 1 1 57s Change service type to LoadBalancer ❯ kubectl patch svc prometheus -n cilium-monitoring -p \u0026#39;{\u0026#34;spec\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;LoadBalancer\u0026#34;}}\u0026#39; ❯ kubectl patch svc grafana -n cilium-monitoring -p \u0026#39;{\u0026#34;spec\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;LoadBalancer\u0026#34;}}\u0026#39; Now TYPE is LoadBalancer and EXTERNAL-IP is assigned for each service\n❯ kubectl get svc -n cilium-monitoring NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE grafana LoadBalancer 10.102.147.187 192.168.0.131 3000:32230/TCP 19m prometheus LoadBalancer 10.104.8.139 192.168.0.130 9090:31588/TCP 19m Access Grafana web page Access Grafana web page Add Prometheus as a data source Enable metrics from Cilium and Hubble Cilium, Hubble, and Cilium Operator do not expose metrics by default. 9962, 9965, and 9963 Enable metrics during installation with helm Add these options to helm install command\n--set prometheus.enabled=true \\ --set operator.prometheus.enabled=true \\ --set hubble.enabled=true \\ --set hubble.metrics.enableOpenMetrics=true \\ --set hubble.metrics.enabled=\u0026#34;{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip\\,source_namespace\\,source_workload\\,destination_ip\\,destination_namespace\\,destination_workload\\,traffic_direction}\u0026#34; Update existing Cilium helm release helm upgrade cilium cilium/cilium --version 1.15.1 \\ --namespace kube-system \\ --reuse-values \\ --set prometheus.enabled=true \\ --set operator.prometheus.enabled=true \\ --set hubble.enabled=true \\ --set hubble.metrics.enableOpenMetrics=true \\ --set hubble.metrics.enabled=\u0026#34;{dns,drop,tcp,flow,port-distribution,icmp,httpV2:exemplars=true;labelsContext=source_ip\\,source_namespace\\,source_workload\\,destination_ip\\,destination_namespace\\,destination_workload\\,traffic_direction}\u0026#34; Check Prometheus Targets Some targets are already configured\nGrafana dashboard for Cilium metrics ","date":"2024-02-20T00:00:00Z","permalink":"https://cychong47.github.io/post/2024/2024-02-20-cilium-and-hubble-with-prometheus-and-grafana/","summary":"\u003ch2 id=\"setup-prometheus-and-grafana-to-scrap-cilium-metrics\"\u003eSetup Prometheus and Grafana to scrap Cilium metrics\u003c/h2\u003e\n\u003cp\u003eThis will create a new namespace \u003ccode\u003ecilium-monitoring\u003c/code\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ekubectl apply -f https://raw.githubusercontent.com/cilium/cilium/1.15.1/examples/kubernetes/addons/prometheus/monitoring-example.yaml\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"some-warnings\"\u003eSome warnings\u0026hellip;\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003enamespace/cilium-monitoring created\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eserviceaccount/prometheus-k8s created\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003econfigmap/grafana-config created\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003econfigmap/grafana-cilium-dashboard created\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003econfigmap/grafana-cilium-operator-dashboard created\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003econfigmap/grafana-hubble-dashboard created\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003econfigmap/grafana-hubble-l7-http-metrics-by-workload created\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003econfigmap/prometheus created\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eclusterrole.rbac.authorization.k8s.io/prometheus created\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eclusterrolebinding.rbac.authorization.k8s.io/prometheus created\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eservice/grafana created\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eservice/prometheus created\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eWarning: would violate PodSecurity \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;restricted:latest\u0026#34;\u003c/span\u003e: allowPrivilegeEscalation !\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e false \u003cspan style=\"color:#f92672\"\u003e(\u003c/span\u003econtainer \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;grafana-core\u0026#34;\u003c/span\u003e must set securityContext.allowPrivilegeEscalation\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003efalse\u003cspan style=\"color:#f92672\"\u003e)\u003c/span\u003e, unrestricted capabilities \u003cspan style=\"color:#f92672\"\u003e(\u003c/span\u003econtainer \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;grafana-core\u0026#34;\u003c/span\u003e must set securityContext.capabilities.drop\u003cspan style=\"color:#f92672\"\u003e=[\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;ALL\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e])\u003c/span\u003e, runAsNonRoot !\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e true \u003cspan style=\"color:#f92672\"\u003e(\u003c/span\u003epod or container \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;grafana-core\u0026#34;\u003c/span\u003e must set securityContext.runAsNonRoot\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003etrue\u003cspan style=\"color:#f92672\"\u003e)\u003c/span\u003e, seccompProfile \u003cspan style=\"color:#f92672\"\u003e(\u003c/span\u003epod or container \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;grafana-core\u0026#34;\u003c/span\u003e must set securityContext.seccompProfile.type to \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;RuntimeDefault\u0026#34;\u003c/span\u003e or \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Localhost\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003edeployment.apps/grafana created\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eWarning: would violate PodSecurity \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;restricted:latest\u0026#34;\u003c/span\u003e: allowPrivilegeEscalation !\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e false \u003cspan style=\"color:#f92672\"\u003e(\u003c/span\u003econtainer \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;prometheus\u0026#34;\u003c/span\u003e must set securityContext.allowPrivilegeEscalation\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003efalse\u003cspan style=\"color:#f92672\"\u003e)\u003c/span\u003e, unrestricted capabilities \u003cspan style=\"color:#f92672\"\u003e(\u003c/span\u003econtainer \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;prometheus\u0026#34;\u003c/span\u003e must set securityContext.capabilities.drop\u003cspan style=\"color:#f92672\"\u003e=[\u003c/span\u003e\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;ALL\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e])\u003c/span\u003e, runAsNonRoot !\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e true \u003cspan style=\"color:#f92672\"\u003e(\u003c/span\u003epod or container \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;prometheus\u0026#34;\u003c/span\u003e must set securityContext.runAsNonRoot\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003etrue\u003cspan style=\"color:#f92672\"\u003e)\u003c/span\u003e, seccompProfile \u003cspan style=\"color:#f92672\"\u003e(\u003c/span\u003epod or container \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;prometheus\u0026#34;\u003c/span\u003e must set securityContext.seccompProfile.type to \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;RuntimeDefault\u0026#34;\u003c/span\u003e or \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Localhost\u0026#34;\u003c/span\u003e\u003cspan style=\"color:#f92672\"\u003e)\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003edeployment.apps/prometheus created\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"kubectl-get-all\"\u003ekubectl get all\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e❯ kubectl get all -n cilium-monitoring \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eNAME                              READY   STATUS    RESTARTS   AGE\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epod/grafana-6f4755f98c-8c7sg      1/1     Running   \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e          57s\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003epod/prometheus-67fdcf4796-vc8hd   1/1     Running   \u003cspan style=\"color:#ae81ff\"\u003e0\u003c/span\u003e          57s\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eNAME                 TYPE        CLUSTER-IP       EXTERNAL-IP   PORT\u003cspan style=\"color:#f92672\"\u003e(\u003c/span\u003eS\u003cspan style=\"color:#f92672\"\u003e)\u003c/span\u003e    AGE\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eservice/grafana      ClusterIP   10.102.147.187   \u0026lt;none\u0026gt;        3000/TCP   57s\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eservice/prometheus   ClusterIP   10.104.8.139     \u0026lt;none\u0026gt;        9090/TCP   57s\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eNAME                         READY   UP-TO-DATE   AVAILABLE   AGE\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003edeployment.apps/grafana      1/1     \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e            \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e           57s\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003edeployment.apps/prometheus   1/1     \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e            \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e           57s\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003eNAME                                    DESIRED   CURRENT   READY   AGE\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ereplicaset.apps/grafana-6f4755f98c      \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e         \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e         \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e       57s\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003ereplicaset.apps/prometheus-67fdcf4796   \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e         \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e         \u003cspan style=\"color:#ae81ff\"\u003e1\u003c/span\u003e       57s\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch3 id=\"change-service-type-to-loadbalancer\"\u003eChange service type to LoadBalancer\u003c/h3\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-sh\" data-lang=\"sh\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e❯ kubectl patch svc prometheus -n cilium-monitoring -p \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;{\u0026#34;spec\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;LoadBalancer\u0026#34;}}\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e❯ kubectl patch svc grafana -n cilium-monitoring -p \u003cspan style=\"color:#e6db74\"\u003e\u0026#39;{\u0026#34;spec\u0026#34;: {\u0026#34;type\u0026#34;: \u0026#34;LoadBalancer\u0026#34;}}\u0026#39;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003eNow \u003ccode\u003eTYPE\u003c/code\u003e is \u003ccode\u003eLoadBalancer\u003c/code\u003e and \u003ccode\u003eEXTERNAL-IP\u003c/code\u003e is assigned for each service\u003c/p\u003e","title":"Monitoring Cilium and Hubble with Prometheus and Grafana"},{"content":"TL;DR QueueHandler를 사용해서 process-safe logger를 만들고 LoggerAdapter를 활용해서 매 로그 메시지마다 특정 정보가 자동으로 출력. main.py #!/usr/bin/env python3 import logging import logging.handlers import multiprocessing from worker import worker_process from my_logger import logger_process if __name__ == \u0026#34;__main__\u0026#34;: # Configure logging logging.basicConfig(level=logging.DEBUG) # Create a queue for logging log_queue = multiprocessing.Queue() # Create worker processes num_workers = 2 processes = [] for i in range(num_workers): p = multiprocessing.Process(target=worker_process, args=(i, log_queue)) processes.append(p) p.start() # Create a logger process for process-safe loggging p = multiprocessing.Process(target=logger_process, args=(log_queue,)) processes.append(p) p.start() # Wait for all processes to finish try: for p in processes: p.join() except KeyboardInterrupt: print(\u0026#34;Uset interrupt. Stop\u0026#34;) worker.py logger를 직접 사용하는 대신 LoggerAdapter를 사용해서 각 process의 추가 정보를 함께 출력.\n#!/usr/bin/env python3 import time import logging from my_logger import WorkerAdapter def worker_process(worker_index, log_queue): # Configure logger for the worker process worker_logger = logging.getLogger(\u0026#34;main-logger\u0026#34;) worker_logger.addHandler(logging.handlers.QueueHandler(log_queue)) worker_logger.setLevel(logging.DEBUG) adapter = WorkerAdapter(worker_logger, {\u0026#39;worker_index\u0026#39;: worker_index}) count = 0 print(f\u0026#34;Start {worker_index}\u0026#34;) try: while True: adapter.debug(f\u0026#34;Starting work... {count}\u0026#34;) time.sleep(1) count += 1 except KeyboardInterrupt: print(\u0026#34;Uset interrupt. Stop\u0026#34;) my_logger.py Utilize LoggerAdapter to prepend some extra data for each log message. Each instance(worker process) could customize these extra data\n#!/usr/bin/env python3 import logging import logging.handlers import sys class WorkerAdapter(logging.LoggerAdapter): def __init__(self, logger, extra=None): super().__init__(logger, extra or {}) def process(self, msg, kwargs): return f\u0026#34;[Worker {self.extra[\u0026#39;worker_index\u0026#39;]}] {msg}\u0026#34;, kwargs def logger_process(log_queue): queue_logger = logging.getLogger(\u0026#34;queue-logger\u0026#34;) stdout_handler = logging.StreamHandler(sys.stdout) stdout_handler.setFormatter(logging.Formatter(\u0026#34;%(asctime)s | %(message)s\u0026#34;)) stdout_handler.setLevel(logging.DEBUG) queue_logger.addHandler(stdout_handler) # while any(p.is_alive() for p in processes) or not log_queue.empty(): print(\u0026#34;Start QueueHandler\u0026#34;) try: while True: record = log_queue.get() queue_logger.handle(record) except KeyboardInterrupt: print(\u0026#34;Uset interrupt. Stop\u0026#34;) Test ❯ python3 main.py Start 0 Start 1 Start QueueHandler 2024-02-18 21:33:02,238 | [Worker 0] Starting work... 0 2024-02-18 21:33:02,242 | [Worker 1] Starting work... 0 2024-02-18 21:33:03,239 | [Worker 0] Starting work... 1 2024-02-18 21:33:03,244 | [Worker 1] Starting work... 1 2024-02-18 21:33:04,240 | [Worker 0] Starting work... 2 2024-02-18 21:33:04,249 | [Worker 1] Starting work... 2 2024-02-18 21:33:05,241 | [Worker 0] Starting work... 3 2024-02-18 21:33:05,254 | [Worker 1] Starting work... 3 ^CUset interrupt. Stop User interrupt. Stop User interrupt. Stop User interrupt. Stop ","date":"2024-02-18T00:00:00Z","permalink":"https://cychong47.github.io/post/2024/2024-02-18-prepend-data-to-python-logger/","summary":"\u003ch2 id=\"tldr\"\u003eTL;DR\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eQueueHandler\u003c/code\u003e를 사용해서 process-safe logger를 만들고\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eLoggerAdapter\u003c/code\u003e를 활용해서 매 로그 메시지마다 특정 정보가 자동으로 출력.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"mainpy\"\u003emain.py\u003c/h2\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-python\" data-lang=\"python\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#75715e\"\u003e#!/usr/bin/env python3\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e logging\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e logging.handlers\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e multiprocessing\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e worker \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e worker_process\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003efrom\u003c/span\u003e my_logger \u003cspan style=\"color:#f92672\"\u003eimport\u003c/span\u003e logger_process\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#66d9ef\"\u003eif\u003c/span\u003e __name__ \u003cspan style=\"color:#f92672\"\u003e==\u003c/span\u003e \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;__main__\u0026#34;\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e# Configure logging\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    logging\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ebasicConfig(level\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003elogging\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eDEBUG)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e# Create a queue for logging\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    log_queue \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e multiprocessing\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eQueue()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e# Create worker processes\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    num_workers \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e \u003cspan style=\"color:#ae81ff\"\u003e2\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    processes \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e []\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e i \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e range(num_workers):\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        p \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e multiprocessing\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eProcess(target\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003eworker_process, args\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e(i, log_queue))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        processes\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eappend(p)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        p\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estart()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e# Create a logger process for process-safe loggging\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    p \u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e multiprocessing\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eProcess(target\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003elogger_process, args\u003cspan style=\"color:#f92672\"\u003e=\u003c/span\u003e(log_queue,))\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    processes\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003eappend(p)\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    p\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003estart()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#75715e\"\u003e# Wait for all processes to finish\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003etry\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        \u003cspan style=\"color:#66d9ef\"\u003efor\u003c/span\u003e p \u003cspan style=\"color:#f92672\"\u003ein\u003c/span\u003e processes:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e            p\u003cspan style=\"color:#f92672\"\u003e.\u003c/span\u003ejoin()\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#66d9ef\"\u003eexcept\u003c/span\u003e \u003cspan style=\"color:#a6e22e\"\u003eKeyboardInterrupt\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e        print(\u003cspan style=\"color:#e6db74\"\u003e\u0026#34;Uset interrupt. Stop\u0026#34;\u003c/span\u003e)\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003ch2 id=\"workerpy\"\u003eworker.py\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003elogger\u003c/code\u003e를 직접 사용하는 대신 \u003ccode\u003eLoggerAdapter\u003c/code\u003e를 사용해서 각 process의 추가 정보를 함께 출력.\u003c/p\u003e","title":"Add extra data to python log message"},{"content":"Why not Agollia algolla 는 site indexing 을 위해 Algollia 서버로 정보를 보내는 듯 함. 대신 hugo에 아주 seamless 하게 연동이 되는데. 좀 아쉽네. (Privacy 건은 좀 더 확인해 봐야겠다)\nAlgollia를 잘 결합해서 사용하는 사이트 하나 https://inchan.dev Search를 클릭하면 입력 창의 크기가 자동으로 커져서 결과가 보여지는 창도 적당해서 보기 좋다.\nInstall Pagefind 설치는 npx를 이용해서 설치하거나, cargo build하거나. 혹은 github에 올려져 있는 바이너리 다운받아 설치하거나. 이 중에 마지막 방법 선택\nhttps://github.com/CloudCannon/pagefind/releases\nwget https://github.com/CloudCannon/pagefind/releases/download/v0.12.0/pagefind-v0.12.0-x86_64-unknown-linux-musl.tar.gz 이것 보다는 multi-byte 처리를 고려한 이 버전을 받는 게 좋을 듯함\nwget https://github.com/CloudCannon/pagefind/releases/download/v0.12.0/pagefind_extended-v0.12.0-x86_64-unknown-linux-musl.tar.gz How to run ./pagefind_extended --source \u0026#34;public\u0026#34; Configuration File pagefind.toml, pagefind.yml/yaml, pagefind.json 등을 사용할 수 있다고 함. 다만 아래와 같이 기본 값을 그대로 사용하는 경우에는 별도로 설정 파일을 만들 필요 없음. source: public bundle_dir: _pagefind 이 정보들은 환경변수를 이용해 설정할 수도 있음\nPAGEFIND_BUNDLE_DIR=\u0026#34;_pagefind\u0026#34; PAGEFIND_SOURCE=\u0026#34;public\u0026#34; ./pagefind_extended 여기서 _bundle_dir은 indexing된 결과를 저장할 output directory를 의미 ( Configuring the Pagefind CLI 참고 )\nBuild a index 256MB, 1 core를 할당한 LXC 기반의 container에서 github-action을 실행하고 있어, 그 머신에서 pagefind_extended를 이용해서 빌드하라고 시켰는데 오잉. 중간에 pagefind가 kill되었다고 나온다.\n5m 6s \u0026gt; Run pagefind_extended --source public Running Pagefind v0.12.0 (Extended) Running from: \u0026#34;/home/cychong/actions-runner/_work/blog/blog\u0026#34; Source: \u0026#34;public\u0026#34; Bundle Directory: \u0026#34;_pagefind\u0026#34; [Walking source directory] Found 5204 files matching **/*.{html} [Parsing files] /home/cychong/actions-runner/_work/_temp/09bfda6f-b57f-454f-90b5-27d8e95e6908.sh: line 1: 20632 Killed pagefind_extended --source public Error: Process completed with exit code 137. OOM(Out Of Memory) 로 process 가 종료되는 경우를 종종 봐서(고작 16GB를 가진 mini3에서 kubernetes를 실행하다 보니 종종 pod가 OOM으로 종료되는 것을 봐서) 혹시나 하고 action-runner LXC의 메모리를 256MB에서 1024MB로 늘린 후 돌려보니 정상적으로 돌아간다.\n실제 동작 중 system monitor를 보니 1GB를 모두 사용하는 경우가 있는데, 대부분 pagefind가 동작하는 시간이 아닐까 싶다.\n실행 결과는 이렇게 나오는데 마지막에 있는 것 같이 indexing에 37초 가량이 걸린다.\n$ pagefind_extended --source public --verbose Running Pagefind v0.12.0 (Extended) Running in verbose mode Running from: \u0026#34;/home/cychong/actions-runner/_work/blog/blog\u0026#34; Source: \u0026#34;public\u0026#34; Bundle Directory: \u0026#34;_pagefind\u0026#34; [Walking source directory] Found 5204 files matching **/*.{html} [Parsing files] Did not find a data-pagefind-body element on the site. ↳ Indexing all \u0026lt;body\u0026gt; elements on the site. [Reading languages] Discovered 1 language: en * en: 4613 pages [Building search indexes] Language en: Indexed 4613 pages Indexed 82547 words Indexed 0 filters Indexed 0 sorts Total: Indexed 1 language Indexed 4613 pages Indexed 82547 words Indexed 0 filters Indexed 0 sorts Finished in 36.867 seconds 이제 빌드는 잘 되니 검색 결과를 이용할 수 있게 html 파일을 수정하면 될 듯.\nblog에 추가 지금 사용하고 있는 mainroad theme는 sidebar widget을 이용해서 search 기능을 제공하고 있다. config.toml 설정 중 일부\nwidgets = [\u0026#34;search\u0026#34;, \u0026#34;categories\u0026#34;, \u0026#34;series\u0026#34;, \u0026#34;taglist\u0026#34;] 이 search 기능은 google 기능을 이용하는데 현재 블로그가 internal network에서만 접근할 수 있게 되어 있다 보니 검색이 제대로 동작하지 않는다. 외부에서 접근이 가능해도 검색 기능이 그닥 쓸모있지 않았지만.\n이제 할 것은 pagefind documentation 에 있는 search 내용을 처리할 코드를 layouts/partials/widgets/search.html에 만들기. 아래 코드는 pagefind documentation에 있는 내용과 기존에 사용하던 다른 widget의 코드를 합쳐서 기존 mainroad theme과 어울리게 만든 것이다.\n\u0026lt;link href=\u0026#34;/_pagefind/pagefind-ui.css\u0026#34; rel=\u0026#34;stylesheet\u0026#34;\u0026gt; \u0026lt;script src=\u0026#34;/_pagefind/pagefind-ui.js\u0026#34; type=\u0026#34;text/javascript\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;div class=\u0026#34;widget-categories widget\u0026#34;\u0026gt; \u0026lt;h4 class=\u0026#34;widget__title\u0026#34;\u0026gt;Search\u0026lt;/h4\u0026gt; \u0026lt;div id=\u0026#34;search\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script\u0026gt; window.addEventListener(\u0026#39;DOMContentLoaded\u0026#39;, (event) =\u0026gt; { new PagefindUI({ element: \u0026#34;#search\u0026#34; }); }); \u0026lt;/script\u0026gt; \u0026lt;/div\u0026gt; 검색을 하면 이렇게 검색 창 아래에 결과가 나온다. github action 에 추가 자동으로 hugo로 빌드할 때마다 자동으로 indexing을 할 수 있게 github의 action flow 수정한다. 아래의 경우는 local github action runner를에서 미리 설치해 높은 pagefind_extended를 사용하는 경우이고, cat .github/workflows/main.yml\n- name: Build run: | rm -rf public/* hugo -t mainroad - name: indexing with pagefind run: | pagefind_extended --source public - name: Deploy run: | pwd rsync -az public/* cychong@${{ secrets.GH_BLOG_TARGET }}:/home/cychong/public/blog/ github.com이 제공하는 runner를 사용하는 경우에는 이렇게 npx pagefind@latest로 명시했다. pagefind 썰치 문서에 보면 npx pagefind를 실행하면 자동으로 pagefind_extended를 설치한다고\nRunning Pagefind via npx will download the pagefind_extended release, which includes specialized support for indexing Chinese and Japanese pages.\n- name: Run Pagefind run: npm_config_yes=true npx pagefind@latest --source \u0026#34;public\u0026#34; Reference https://www.brycewray.com/posts/2022/07/pagefind-quite-find-site-search/ https://www.brycewray.com/posts/2022/07/impressions-hugoconf-2022/ https://patford12.medium.com/add-search-to-hugo-with-page-find-4e78c9b37541 https://pagefind.app/docs/installation/ ","date":"2023-05-18T00:00:00Z","permalink":"https://cychong47.github.io/post/2023/2023-05-18-add-search-to-hugo/","summary":"\u003ch2 id=\"why-not-agollia\"\u003eWhy not Agollia\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003ealgolla\u003c/code\u003e 는 site indexing 을 위해 Algollia 서버로 정보를 보내는 듯 함.\n대신 hugo에 아주 seamless 하게 연동이 되는데. 좀 아쉽네.\n(Privacy 건은 좀 더 확인해 봐야겠다)\u003c/p\u003e\n\u003cp\u003eAlgollia를 잘 결합해서 사용하는 사이트 하나 \u003ca href=\"https://inchan.dev\"\u003ehttps://inchan.dev\u003c/a\u003e\nSearch를 클릭하면 입력 창의 크기가 자동으로 커져서 결과가 보여지는 창도 적당해서 보기 좋다.\u003c/p\u003e\n\u003ch2 id=\"install-pagefind\"\u003eInstall Pagefind\u003c/h2\u003e\n\u003cp\u003e설치는 \u003ccode\u003enpx\u003c/code\u003e를 이용해서 설치하거나, cargo build하거나. 혹은 github에 올려져 있는 바이너리 다운받아 설치하거나. 이 중에 마지막 방법 선택\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/CloudCannon/pagefind/releases\"\u003ehttps://github.com/CloudCannon/pagefind/releases\u003c/a\u003e\u003c/p\u003e","title":"hugo에 검색 기능 추가하기 - pagefind"},{"content":"homelab 서버로 사용할 PC를 당근마켓을 통해 구입. 제품 사양에 비해 저렴하고,, 구입 과정도 매끄러워서 기분좋게 구입한 제품이다.\n오랜만에 AMD CPU를 사용하는 PC를 사용하게 되었네. 조립 PC를 사본 지가 언제인지. 최근 10년 넘게는 맥만 구입해서 궁금하다. 완성품(특히 애플 노트북)에 비해 좋은 점은 원하는 사양으로 변경할 수 있다는 거 일텐데, 그래서 그 장점을 십분 활용하고자, 중고로 얻어온 제품이 이미 16 GiB 메모리가 실장되어 있지만, 32 GiB를 하나 추가로 구입했다. 다른 건 못해도 RAM Flex라도 해 보자.\n","date":"2022-12-31T00:00:00Z","permalink":"https://cychong47.github.io/post/2022/2022-12-31-homeserver-3rd-gen/","summary":"\u003cp\u003ehomelab 서버로 사용할 PC를 당근마켓을 통해 구입.\n제품 사양에 비해 저렴하고,, 구입 과정도 매끄러워서 기분좋게 구입한 제품이다.\u003c/p\u003e\n\u003cp\u003e오랜만에 AMD CPU를 사용하는 PC를 사용하게 되었네.\n조립 PC를 사본 지가 언제인지. 최근 10년 넘게는 맥만 구입해서 궁금하다.\n완성품(특히 애플 노트북)에 비해 좋은 점은 원하는 사양으로 변경할 수 있다는 거 일텐데, 그래서 그 장점을 십분 활용하고자, 중고로 얻어온 제품이 이미 16 GiB 메모리가 실장되어 있지만, 32 GiB를 하나 추가로 구입했다.\n다른 건 못해도 RAM Flex라도 해 보자.\u003c/p\u003e","title":"Homelab server 3rd gen."},{"content":"서로 다른 pod의 container에서 실행되는 DPDK process들도 다른 경우와 마찬가지로 DPDK runtime config 파일과 hugepage map 파일만 공유하면 hugepage를 공유할 수 있다.\n이 때 서로 다른 pod가 같은 DPDK runtime config 파일들과, hugepage map 파일을 공유하기 위해 두 개 pod가 함께 사용할 수 있는 hostPath 를 이용한다. hostPath는 pod가 실행되는 node의 파일 시스템을 이용하여 volume을 만든다. 그러므로 서로 다른 pod가 동일 node에서 실행되는 경우에만 pod가 hugepage를 공유할 수 있다.\nDPDK runtime config 두 개 pod에서 hostPath 를 이용하여 DPDK runtime config 파일을 공유를 위한 volume을 만든다.\nvolumes: - name: dpdk-config hostPath: path: /tmp/dpdk-config Two containers in a single pod 경우와 마찬가지로, 각 container에서는 위 volume을 /var/run/dpdk 위치에 마운트 시킨다.\n- name: container-1 volumeMounts: - mountPath: /var/run/dpdk name: dpdk-config - name: container-2 volumeMounts: - mountPath: /var/run/dpdk name: dpdk-config hugetlbfs 서로 다른 pod가 hugetlbfs를 공유하기 위해 host의 hostPath 를 사용한다. 이때 emptyDir을 사용하는 경우와 달리 pod간 공유할 hugetlbfs를 hostPath에서 만들기 위해 node에 이미 hugetlbfs로 마운트 된 경우를 사용해야 한다.\n리눅스에서는 boot 인자로 지정한 default hugepage size에 해당하는 hugepage는 /dev/hugepages에 마운트 된다.\n$ cat /proc/cmdline BOOT_IMAGE=/boot/vmlinuz-5.13.0-1021-oracle root=UUID=b69068ad-8c25-4bc9-ae7f-e6f8103b9c97 ro default_hugepagesz=2M hugepagesz=2M hugepages=20 console=tty1 console=ttyS0 nvme.shutdown_timeout=10 libiscsi.debug_libiscsi_eh=1 crash_kexec_post_notifiers 위 경우 default_hugepagesz=2M 옵션을 이용하여 2MB를 default hugepage로 사용한 경우로 이 hugepage 들이 마운트 된 위치를 다음과 같이 확인할 수 있다.\n$ grep hugetlbfs /proc/mounts hugetlbfs /dev/hugepages hugetlbfs rw,relatime,pagesize=2M 0 0 pod에서 node의 hugetlbfs를 사용하기 위해 다음과 같이 node의 /dev/hugepages 사용하는 volume을 만든다. (pod에서 별도로 hugetlbfs를 만들지 않고, node에 이미 마운트 된 hugetlbfs 를 사용하므로, emptyDir을 이용한 hugepage를 만들 필요 없다)\nvolumes: - name: dev-hp hostPath: path: /dev/hugepages 그리고 2개 pod내 container들은 각자 이 volume을 자신의 /dev/hugepages에 마운트 한다.\n- name: container-1 volumeMounts: - mountPath: /dev/hugepages name: dev-hp - name: container-2 volumeMounts: - mountPath: /dev/hugepages name: dev-hp 이제 각 pod 의 container에서 각각 DPDK primary process와 secondary process를 실행시키면 두 개 DPDK process들은 hugepage를 이용하여 DPDK가 제공하는 ring 등을 사용하여 서로 통신할 수 있다.\nroot@hugepage-2c-2p-1:~/dpdk# ./dpdk-simple_mp -l 0-1 -n 1 --proc-type=primary EAL: Detected CPU lcores: 4 EAL: Detected NUMA nodes: 1 EAL: Detected static linkage of DPDK EAL: Multi-process socket /var/run/dpdk/rte/mp_socket EAL: Selected IOVA mode \u0026#39;VA\u0026#39; EAL: No available 32768 kB hugepages reported EAL: No available 64 kB hugepages reported EAL: No available 1048576 kB hugepages reported EAL: Probe PCI driver: net_virtio (1af4:1000) device: 0000:00:03.0 (socket 0) eth_virtio_pci_init(): Failed to init PCI device EAL: Requested device 0000:00:03.0 cannot be used TELEMETRY: No legacy callbacks, legacy socket not created APP: Finished Process Init. simple_mp \u0026gt; Starting core 1 root@hugepage-2c-2p-2:~/dpdk# ./dpdk-simple_mp -l 2-3 -n 1 --proc-type=secondary EAL: Detected CPU lcores: 4 EAL: Detected NUMA nodes: 1 EAL: Detected static linkage of DPDK EAL: Multi-process socket /var/run/dpdk/rte/mp_socket_20_6d504b91042f EAL: Selected IOVA mode \u0026#39;VA\u0026#39; EAL: Probe PCI driver: net_virtio (1af4:1000) device: 0000:00:03.0 (socket 0) Device 0000:00:03.0 is not driven by the primary process EAL: Requested device 0000:00:03.0 cannot be used APP: Finished Process Init. Starting core 3 core 1: Received \u0026#39;hi\u0026#39; simple_mp \u0026gt; simple_mp \u0026gt; send hi simple_mp \u0026gt; 이때 node의 /dev/hugepages 디렉토리를 확인하면 container에서 실행된 DPDK application들이 생성한 hugepage map 파일을 확인할 수 있다.\n$ ls -al /dev/hugepages/ total 4096 drwxr-xr-x 2 root root 0 Mar 14 14:49 . drwxr-xr-x 19 root root 3820 Mar 14 09:29 .. -rw------- 1 root root 2097152 Mar 14 14:50 rtemap_0 -rw------- 1 root root 2097152 Mar 14 14:50 rtemap_1 DPDK process의 실행 인자 --file-prefix를 이용하여 hugepage map 파일의 prefix를 변경해 보면 node의 /dev/hugepages 위치에 생성된 hugepage map 파일이 container가 생성한 것을 확인할 수 있다.\nroot@hugepage-2c-2p-1:~/dpdk# ./dpdk-simple_mp -l 0-1 -n 1 --proc-type=primary --file-prefix=simple_mp EAL: Detected CPU lcores: 4 EAL: Detected NUMA nodes: 1 ... Starting core 1 simple_mp \u0026gt; root@hugepage-2c-2p-2:~/dpdk# ./dpdk-simple_mp -l 2-3 -n 1 --proc-type=secondary --file-prefix=simple_mp EAL: Detected CPU lcores: 4 EAL: Detected NUMA nodes: 1 EAL: Detected static linkage of DPDK EAL: Multi-process socket /var/run/dpdk/simple_mp/mp_socket_45_6d552daffb0f EAL: Selected IOVA mode \u0026#39;VA\u0026#39; EAL: Probe PCI driver: net_virtio (1af4:1000) device: 0000:00:03.0 (socket 0) Device 0000:00:03.0 is not driven by the primary process EAL: Requested device 0000:00:03.0 cannot be used APP: Finished Process Init. simple_mp \u0026gt; $ ls -al /dev/hugepages/ total 8192 drwxr-xr-x 2 root root 0 Mar 14 14:51 . drwxr-xr-x 19 root root 3820 Mar 14 09:29 .. -rw------- 1 root root 2097152 Mar 14 14:50 rtemap_0 -rw------- 1 root root 2097152 Mar 14 14:50 rtemap_1 -rw------- 1 root root 2097152 Mar 14 14:52 simple_mpmap_0 -rw------- 1 root root 2097152 Mar 14 14:52 simple_mpmap_1 $ grep HugePages_ /proc/meminfo HugePages_Total: 20 HugePages_Free: 16 HugePages_Rsvd: 0 HugePages_Surp: 0 단, pod가 모두 삭제되어도 위 hugepage map file이 삭제되지 않으므로, 사용된 hugepage는 해제되지 않는다(해제되는 조건은???)\n$ sudo rm -rf /dev/hugepages/* [sudo] password for cychong: $ grep HugePages_ /proc/meminfo HugePages_Total: 20 HugePages_Free: 20 HugePages_Rsvd: 0 HugePages_Surp: 0 Simplified view Reference https://github.com/cychong47/how-to-share-hugepage-in-k8s/tree/main/one-container-in-each-pod\n#til #dpdk #hugepage\n","date":"2022-03-14T00:00:03+09:00","permalink":"https://cychong47.github.io/post/2022/2022-03-14-one-container-in-each-pod/","summary":"\u003cp\u003e서로 다른 pod의 container에서 실행되는 DPDK process들도 다른 경우와 마찬가지로 DPDK runtime config 파일과 hugepage map 파일만 공유하면 hugepage를 공유할 수 있다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2022/03/2022-03-14-dpdk-hugepage-1c-2p-1.png\" alt=\"2022-03-14-dpdk-hugepage-1c-2p-1.png\"\u003e\u003c/p\u003e\n\u003cp\u003e이 때 서로 다른 pod가 같은 DPDK runtime config 파일들과, hugepage map 파일을 공유하기 위해 두 개 pod가 함께 사용할 수 있는 \u003ccode\u003ehostPath\u003c/code\u003e 를 이용한다. \u003ccode\u003ehostPath\u003c/code\u003e는 pod가 실행되는 node의 파일 시스템을 이용하여 volume을 만든다. 그러므로 서로 다른 pod가 동일 node에서 실행되는 경우에만 pod가 hugepage를 공유할 수 있다.\u003c/p\u003e","title":"How to run DPDK in k8s - One container in each pod"},{"content":"하나의 pod에 2개의 container를 두고, 각각의 container에 primary process, secondary process를 실행하려면 두 개 container에서 실행되는 DPDK process간 runime config 파일과, hugepage map 파일을 공유하는 방법은 다음과 같다.\n하나의 pod에 하나의 container만 두는 경우와 달리 두 개의 container가 /var/run/dpdk 위치를 공유해야 하므로, 각 container가 갖는 기본 파일 시스템이 아니라 명시적으로 pod의 volume을 이용해서 파일을 공유해야 한다.\n이를 위해 pod spec에 다음과 같은 volume spec을 추가한다.\nvolume: - name: dpdk-config emptyDir: emptyDir에 명시적으로 지정하지 않은 경우 tmpfs를 사용하므로, 위 volume은 tmpfs를 사용하여 생성된다.\n생성된 volume은 다음과 같이 각 container에서 /var/run/dpdk 에 마운트해야 한다.\n- name: container-1 ... volumeMounts: - mountPath: /var/run/dpdk name: dpdk-config - name: container-2 ... volumeMounts: - mountPath: /var/run/dpdk name: dpdk-config Simplified view Reference https://github.com/cychong47/how-to-share-hugepage-in-k8s/tree/main/two-containers-in-a-single-pod\n#til #dpdk #hugepage\n","date":"2022-03-14T00:00:02+09:00","permalink":"https://cychong47.github.io/post/2022/2022-03-14-two-containers-in-a-pod/","summary":"\u003cp\u003e하나의 pod에 2개의 container를 두고, 각각의 container에 primary process, secondary process를 실행하려면 두 개 container에서 실행되는 DPDK process간 runime config 파일과, hugepage map 파일을 공유하는 방법은 다음과 같다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2022/03/2022-03-14-dpdk-hugepage-2c-1p-1.png\" alt=\"2022-03-14-dpdk-hugepage-2c-1p-1.png\"\u003e\u003c/p\u003e\n\u003cp\u003e하나의 pod에 하나의 container만 두는 경우와 달리 두 개의 container가 \u003ccode\u003e/var/run/dpdk\u003c/code\u003e 위치를 공유해야 하므로, 각 container가 갖는 기본 파일 시스템이 아니라 명시적으로 pod의 volume을 이용해서 파일을 공유해야 한다.\u003c/p\u003e\n\u003cp\u003e이를 위해 pod spec에 다음과 같은 volume spec을 추가한다.\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003evolume\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e - \u003cspan style=\"color:#f92672\"\u003ename\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003edpdk-config\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e   \u003cspan style=\"color:#f92672\"\u003eemptyDir\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003ccode\u003eemptyDir\u003c/code\u003e에 명시적으로 지정하지 않은 경우 \u003ccode\u003etmpfs\u003c/code\u003e를 사용하므로, 위 volume은 \u003ccode\u003etmpfs\u003c/code\u003e를 사용하여 생성된다.\u003c/p\u003e","title":"How to run DPDK in k8s - Two containers in a pod"},{"content":"How to run DPDK application in Kubernetes environment Kubernetes에서 DPDK application을 실행하기 위해서는 DPDK application이 포함된 container에 runtime config 파일이 저장될 /var/run/dpdk 디렉토리와 hugetlbfs 형태로 hugepage가 존재해야 한다. 이 중 /var/run/dpdk는 container 가 갖는 file system에 생성되는 기본 linux directory인 /var/run 아래 위치하므로, DPDK application이 실행되면서 디렉토리를 생성한다.\n반면, hugetblfs 디렉토리은 kubernetes의 volume 에서 제공하는 emptyDir을 사용하면 Pod와 lifecycle을 함께 하는 hugepage를 만들어 사용할 수 있다.\nContainer에서 hugepage를 할당받기 위해서는 다음과 같이 container spec에 요구하는 hugepage 크기를 명시한다.\ncontainers: resource: limits: hugepage-2Mi: 100Mi 다음과 같이 pod에서만 사용할 emptyDir 종류의 Hugepage volume을 만든다.\nvolume: - name: hugepage emptryDir: medium: HugePages emptyDir 종류의 volume은 위와 같이 명시적으로 medium을 지정하지 않으면 기본값인 tmpfs를 사용한다. (tmpfs는 ram disk 기반)\nhugepage volume을 container에 mount하는 방법은 일반적인 volume mount와 동일하다.\nvolumeMounts: - mountPath: /hugepages name: hugepage 위 예에서는 hugepage volume을 /hugepages 위치에 마운트 시키는 것으로, pod에서 확인하면 다음과 같이 hugetlbfs 파일시스템으로 마운트 된 것을 알 수 있다.\nroot@hugepage-1c-1p:/# grep hugetlbfs /proc/mounts nodev /hugepages hugetlbfs rw,relatime,pagesize=2M 0 0 Two DPDK applications in the same container 두 개의 DPDK process를 하나의 container에서 실행하는 것은 하나의 DPDK process를 하나의 container에서 실행하는 것과 동일하다.\nSimplified view Reference https://github.com/cychong47/how-to-share-hugepage-in-k8s/tree/main/one-container-in-a-single-pod\n#til #dpdk #hugepage #kubernetes\n","date":"2022-03-14T00:00:01+09:00","permalink":"https://cychong47.github.io/post/2022/2022-03-14-a-single-container-in-a-pod/","summary":"\u003ch2 id=\"how-to-run-dpdk-application-in-kubernetes-environment\"\u003eHow to run DPDK application in Kubernetes environment\u003c/h2\u003e\n\u003cp\u003eKubernetes에서 DPDK application을 실행하기 위해서는 DPDK application이 포함된 container에 runtime config 파일이 저장될 \u003ccode\u003e/var/run/dpdk\u003c/code\u003e 디렉토리와 \u003ccode\u003ehugetlbfs\u003c/code\u003e 형태로 hugepage가 존재해야 한다.\n이 중 \u003ccode\u003e/var/run/dpdk\u003c/code\u003e는 container 가 갖는 file system에 생성되는 기본 linux directory인 \u003ccode\u003e/var/run\u003c/code\u003e 아래 위치하므로, DPDK application이 실행되면서 디렉토리를 생성한다.\u003c/p\u003e\n\u003cp\u003e반면, \u003ccode\u003ehugetblfs\u003c/code\u003e 디렉토리은 kubernetes의 \u003ccode\u003evolume\u003c/code\u003e 에서 제공하는 \u003ccode\u003eemptyDir\u003c/code\u003e을 사용하면 Pod와 lifecycle을 함께 하는 hugepage를 만들어 사용할 수 있다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2022/03/2022-03-14-dpdk-hugepage-1c-1p-1.png\" alt=\"2022-03-14-dpdk-hugepage-1c-1p-1.png\"\u003e\u003c/p\u003e\n\u003cp\u003eContainer에서 hugepage를 할당받기 위해서는 다음과 같이 container spec에 요구하는 hugepage 크기를 명시한다.\u003c/p\u003e","title":"How to run DPDK in k8s - A single container in a pod"},{"content":"Basic use of hugepage DPDK application이 hugepage를 사용할 때 다음과 같은 2가지 디렉토리를 사용한다.\nDPDK runtime config files /var/run/dpdk 로 고정된 경로를 사용요 DPDK 에서 hugepage를 어떻게 사용하는 지에 대한 meta data를 저장 hugepage map hugepage를 사용하기 위해 hugetlbfs 를 이용할 때 생성하는 hugepage map 파일들이 위치한 곳. DPDK는 이곳에 hugepage의 단위 크기를 갖는 file을 생성하고, mmap()을 사용하여 hugepage를 접근 만일 시스템에 2개 이상의 hugetlbfs가 마운트된 위치가 있는 경우 DPDK process를 실행할 때 --huge-dir 옵션을 사용하여 특정 위치를 사용하도록 할 수 있다. Multi-process support 각자 virtual address space를 갖는 두 개이상의 DPDK process는 위 두 개 디렉토리를 공유하여 hugepage에 구성된 DPDK resource들(memzone 및 memzone위에 구성되는 DPDK ring 등)을 공유할 수 있다.\n참고로, 위와 같이 두 개의 process가 hugepage를 공유할 때 하나의 DPDK process만 hugepage map 파일을 만들어 DPDK memzone을 생성하고, 나머지 DPDK process들은 이미 생성된 memzone을 사용한다. 이때 hugepage map을 만들고 memzone을 생성하는 DPDK process를 통상 primary process라고 부르고, primary process가 생성한 hugepage를 참조하는 DPDK process들을 secondary process라고 부른다.\nSimplified view #til #dpdk\n","date":"2022-03-14T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2022/2022-03-14-hugepage-in-dpdk-basics/","summary":"\u003ch2 id=\"basic-use-of-hugepage\"\u003eBasic use of hugepage\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/2022/03/2022-03-14-dpdk-hugepage-1.png\" alt=\"2022-03-14-dpdk-hugepage-1.png\"\u003e\u003c/p\u003e\n\u003cp\u003eDPDK application이 hugepage를 사용할 때 다음과 같은 2가지 디렉토리를 사용한다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eDPDK runtime config files\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e/var/run/dpdk\u003c/code\u003e  로 고정된 경로를 사용요\u003c/li\u003e\n\u003cli\u003eDPDK 에서 hugepage를 어떻게 사용하는 지에 대한 meta data를 저장\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ehugepage map\n\u003cul\u003e\n\u003cli\u003ehugepage를 사용하기 위해 \u003ccode\u003ehugetlbfs\u003c/code\u003e 를 이용할 때 생성하는 hugepage map 파일들이 위치한 곳.\u003c/li\u003e\n\u003cli\u003eDPDK는 이곳에 hugepage의 단위 크기를 갖는 file을 생성하고, \u003ccode\u003emmap()\u003c/code\u003e을 사용하여 hugepage를 접근\u003c/li\u003e\n\u003cli\u003e만일 시스템에 2개 이상의 \u003ccode\u003ehugetlbfs\u003c/code\u003e가 마운트된 위치가 있는 경우 DPDK process를 실행할 때 \u003ccode\u003e--huge-dir\u003c/code\u003e 옵션을 사용하여 특정 위치를 사용하도록 할 수 있다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"multi-process-support\"\u003eMulti-process support\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/2022/03/2022-03-14-dpdk-hugepage-2.png\" alt=\"2022-03-14-dpdk-hugepage-2.png\"\u003e\u003c/p\u003e","title":"Hugepage in DPDK - Basics"},{"content":"\n","date":"2022-01-22T21:48:56+09:00","permalink":"https://cychong47.github.io/post/2022/2022-01-22-2022-january-books/","summary":"\u003cp\u003e\u003cimg src=\"/images/2022/01/2022-01-22-IMG_0180.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"2022년 1월 새 책들"},{"content":"문제점 Traefik 로그에 time 정보가 제대로 나오게 하려면\nhelm chart에 환경 변수에 TZ를 설정해도 로그 시간이 제대로 나오지 않음.\n192.168.0.101 - - [06/Jan/2022:1:18:17 +0000] \u0026#34;GET /ping HTTP/1.1\u0026#34; 200 2 \u0026#34;-\u0026#34; \u0026#34;-\u0026#34; 100 \u0026#34;ping@internal\u0026#34; \u0026#34;-\u0026#34; 0ms env: - name: TZ value: Asia/Seoul kubectl describe 명령으로 확인하면 환경변수가 제대로 설정된 것으로 나옴\nEnvironment: TZ: Asia/Seoul 해결책 https://doc.traefik.io/traefik/observability/access-logs/#time-zones 위 페이지를 보니 다음과 같이 몇 가지 설정을 해야 한다고.\nTraefik will timestamp each log line in UTC time by default.\nIt is possible to configure the Traefik to timestamp in a specific timezone by ensuring the following configuration has been made in your environment:\nProvide time zone data to /etc/localtime or /usr/share/zoneinfo (based on your distribution) or set the environment variable TZ to the desired timezone Specify the field StartLocal by dropping the field named StartUTC (available on the default Common Log Format (CLF) as well as JSON) version: \u0026#34;3.7\u0026#34; services: traefik: image: traefik:v2.5 environment: - TZ=US/Alaska command: - --accesslog.fields.names.StartUTC=drop - --providers.docker ports: - 80:80 volumes: - /var/run/docker.sock:/var/run/docker.sock 위 내용을 참고해서 /usr/share/zoneinfo mount 하기위해 yaml 파일 수정\ndeployment: # Additional volumes available for use with initContainers and additionalContainers additionalVolumes: - name: zoneinfo hostPath: path: /usr/share/zoneinfo # Additional volumeMounts to add to the Traefik container additionalVolumeMounts: # For instance when using a logshipper for access logs # - name: traefik-logs # mountPath: /var/log/traefik - name: zoneinfo mountPath: /usr/share/zoneinfo 추가로 acccelog에 옵션을 지정해야 하는데 이걸 어떻게 적용해야 하는 지는 traefik helm chart에 있는 _podtemplate.tpl 파일을 보고 values.yaml파일에 지정한 내용이 어떻게 실행 옵션 accesslog로전달되는 지 이해\n_podtemplate.yaml 이 파일을 보면 아래와 같이 values 파일의 acess.fields.general.fields항목에 기술된 키, 값을 --accesslog.fields.names 옵션으로 변환하고 있는 걸 알 수 있다.\n{{- range $fieldname, $fieldaction := .access.fields.general.names }} - \u0026#34;--accesslog.fields.names.{{ $fieldname }}={{ $fieldaction }}\u0026#34; {{- end }} 로그의 timezone을 변경할 때 필요한 옵션이 바로 위에 있는 accesslog.fields.names.StartUTC 항목이므로 아래와 같이 values 파일에 내용 추가\nlogs: access: fields: general: names: StartUTC: drop 변경된 value파일을 적용한 후 다시 kubectl logs명령어로 로그의 시각 정보를 확인하니 이제 정상적으로 +0900 timezone 정보가 반영되어 나오네\n192.168.0.101 - - [06/Jan/2022:10:18:17 +0900] \u0026#34;GET /ping HTTP/1.1\u0026#34; 200 2 \u0026#34;-\u0026#34; \u0026#34;-\u0026#34; 44 \u0026#34;ping@internal\u0026#34; \u0026#34;-\u0026#34; 0ms 192.168.0.101 - - [06/Jan/2022:10:18:17 +0900] \u0026#34;GET /ping HTTP/1.1\u0026#34; 200 2 \u0026#34;-\u0026#34; \u0026#34;-\u0026#34; 45 \u0026#34;ping@internal\u0026#34; \u0026#34;-\u0026#34; 0ms #homelab #traefik #helm #til\n","date":"2022-01-06T00:00:00Z","permalink":"https://cychong47.github.io/post/2022/2022-01-06-how-to-change-timezone-of-traefik-log/","summary":"\u003ch2 id=\"문제점\"\u003e문제점\u003c/h2\u003e\n\u003cp\u003eTraefik 로그에 time 정보가 제대로 나오게 하려면\u003c/p\u003e\n\u003cp\u003ehelm chart에 환경 변수에 \u003ccode\u003eTZ\u003c/code\u003e를 설정해도 로그 시간이 제대로 나오지 않음.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e192.168.0.101 - - [06/Jan/2022:1:18:17 +0000] \u0026#34;GET /ping HTTP/1.1\u0026#34; 200 2 \u0026#34;-\u0026#34; \u0026#34;-\u0026#34; 100 \u0026#34;ping@internal\u0026#34; \u0026#34;-\u0026#34; 0ms\n\u003c/code\u003e\u003c/pre\u003e\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eenv\u003c/span\u003e: \n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  - \u003cspan style=\"color:#f92672\"\u003ename\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003eTZ\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e    \u003cspan style=\"color:#f92672\"\u003evalue\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003eAsia/Seoul\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cp\u003e\u003ccode\u003ekubectl describe\u003c/code\u003e 명령으로 확인하면 환경변수가 제대로 설정된 것으로 나옴\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e    Environment:\n      TZ:  Asia/Seoul\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"해결책\"\u003e해결책\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://doc.traefik.io/traefik/observability/access-logs/#time-zones\"\u003ehttps://doc.traefik.io/traefik/observability/access-logs/#time-zones\u003c/a\u003e\n위 페이지를 보니 다음과 같이 몇 가지 설정을 해야 한다고.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eTraefik will timestamp each log line in UTC time by default.\u003c/p\u003e","title":"Traefik 로그의 timezone 수정"},{"content":"\n","date":"2021-12-13T19:50:15+09:00","permalink":"https://cychong47.github.io/post/2021/2021-12-13-books-for-november-2021/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/12/2021-12-13-IMG_0350.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"2021년 11월 책 들"},{"content":"홈 블로그에 사용하는 텍스트로 된 포스트와 포스트에서 사용하는 이미지 파일을 각자 다른 github repo에서 관리해 오고 있었다. 혻시나 포스트만 클론해서 글을 수정하고 싶을 때 수 GB에 달하는 이미지를 다운받아야 하는 건 아닌 것 같아서.\n","date":"2021-11-24T13:51:30+09:00","permalink":"https://cychong47.github.io/post/2021/2021-11-24-merge-blog-post-and-image-repos/","summary":"\u003cp\u003e홈 블로그에 사용하는 텍스트로 된 포스트와 포스트에서 사용하는 이미지 파일을 각자 다른 github repo에서 관리해 오고 있었다.\n혻시나 포스트만 클론해서 글을 수정하고 싶을 때 수 GB에 달하는 이미지를 다운받아야 하는 건 아닌 것 같아서.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021/11/2021-11-24-IMG_9266.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021/11/2021-11-24-IMG_9267.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021/11/2021-11-24-IMG_9268.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021/11/2021-11-24-IMG_0505.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"Blog의 text와 image를 합쳤다"},{"content":"https://www.mk.co.kr/opinion/columnists/view/2015/02/135652/\n10년 전 쯤에 부서장은 인품이 참 좋은 분이었다. 그 당시 내 기준으로는 회사 생활을 하면서 만난 몇 안되는 좋은 부서장이었다.(물론 그 당시에 내가 생각하는 \u0026lsquo;좋은\u0026rsquo; 부서장의 기준은 지금과 달라졌다.) 왠만하면 화를 내는 일이 없었고, 문제를 일으켜도 문제를 유발한 사람을 탓하기보다는 문제 해결에 집중하는 바람직한 부서장 상을 실천하던 분이었다.\n그 분께 하루는 술 기운을 빌어 부탁을 한 적이 있었다. 퇴근 일찍 하시고, 주말 근무 하지 마시라고. 우리가 더 회사생활을 하면 가게 될 위치 중 하나가 당신인데, 당신의 지금 회사 생활은 별로 따르고 싶은 모습이 아니라고. 그런 모습을 보고 자랄 후배들을 위해 좀 더 희망적인 모습을 보여달라고.\n그 반술주정 반진담의 말에 그 분은 빙그레 웃기만 하셨다. 기억에는 그 분도 이미 술을 적당히 드신 상태라 제정신으로 그 말을 들으셨는 지는 명확하지 않다. 그렇지만 아마도 내가 했던 말은 제대로 들으셨던 것 같다. 그리고 해주고 싶으신 말이 있으셨던 것 같은데 그 이후의 기억은 남아 있지 않다.\n그때도 물론 그렇게 생각하지는 않았지만, 나중에서야 관리자라는 게 참 할일이 많다는 걸 잠시 관리자 역할을 해 보고 알게 되었다. 눈에 보이는 조직 관리, 업무 관리 외에 남에게 보일 수도, 말해줄 수도 없는 이런 저런 일들을 하고 계신다는 걸. 그리고 특히 그 당시 그 부서장의 상사가 매주 토요일 근무를 요구했다는 것도.\n아마도 그 부서장께서는 좋은 이야기를 해주고 싶으셨을 듯 한데, 그러면서도 \u0026ldquo;쨔샤, 너도 나중에 해봐. 그러면 알게 될거야. 나라고 이렇게 살고 싶어서 그렇겠냐\u0026rdquo; 라고 말을 해주셨을 것 같다.\n어떤 국영수 과목을 가르치는 학원에서 각 학원 강사 중에 뛰어난 실적을 낸 강사에게 \u0026lsquo;책임 강사\u0026rsquo;라는 직위를 주고 있었다.\n그런데 언제가부터 몇 년 째 \u0026lsquo;국어\u0026rsquo; 과목 강사만 \u0026lsquo;책임 강사\u0026rsquo;가 되고 있었다. 분명히 다른 과목의 강사 중에서도 뛰어난 성과를 낸 사람이 있었는데 어쩐 일인지 오직 \u0026lsquo;국어\u0026rsquo; 과목 강사에게만 그 기회가 돌아갔다.\n마침 학원장 역시 \u0026lsquo;국어\u0026rsquo; 강사 출신이라 다른 과목에 비해 시험에서 배점이 낮은 \u0026lsquo;국어\u0026rsquo; 과목에 대한 편애가 있는 것이 아닌가 하는 의심을 하는 강사들이 많았다.\n그래도 한동안 국어 강사와 나머지 과목 강사들의 직위 획득 비율이 적당한 수준으로 유지되고 있었다. 매년 국어 강사 한 명에 다른 과목 강사 한 명 정도의 비율로 \u0026lsquo;책임 강사\u0026rsquo; 정도. 그 결과 국어 과목 출신의 \u0026lsquo;책임 강사\u0026rsquo;의 전체 비율과 영어, 수학 출신의 \u0026lsquo;책임 강사\u0026rsquo;이 그래도 큰 차이가 있는 수준은 아니었는데, 그 비율이 언젠가부터 영어, 수학 강사가 \u0026lsquo;직위\u0026rsquo;를 받는 일이 몇 년째 사라지고, 오직 \u0026lsquo;국어\u0026rsquo;강사만 \u0026lsquo;임원 강사\u0026rsquo;를 받는 일이 생겼다.\n그러나 (평) 영어, 수학 강사들이 수근대기 시작했다. 이 학원은 국어 강의를 하지 않으면 비전이 없구나 라고. 몇 년 째 그런 모습을 보며 나름 뛰어난 실력을 자랑하던 영어, 수학 강사들이 다른 학원으로 자리를 옮기기 시작했다.\n가뜩이나 \u0026lsquo;책임 강사\u0026rsquo;가 될 기회가 적은 영어, 수학 과목의 강사들 중에 뛰어난 강사가 사라지니 더욱더 영어, 수학 과목에서 \u0026lsquo;책임 강사\u0026rsquo;가 되는 횟수가 줄었다.\n하지만 학원장은 \u0026lsquo;우리 학원에는 훌륭한 영어, 수학 강사가 없네요\u0026rsquo;라는 말만 한다.\n과연, 이 학원에 영어, 수학 과목을 듣겠다는 학생이 찾아올까?\n멋진 선배, 그리고 그 선배가 조직에서 대접받는 모습을 보지 못하면 후배들은 그 조직을 신뢰하지 않는다. 조직을 신뢰하지 않는 조직원으로 구성된 조직의 미래는 어떤 모습일까?\n","date":"2021-09-27T00:06:00+09:00","permalink":"https://cychong47.github.io/post/2021/2021-09-27-company-without-future/","summary":"\u003cp\u003e\u003ca href=\"https://www.mk.co.kr/opinion/columnists/view/2015/02/135652/\"\u003ehttps://www.mk.co.kr/opinion/columnists/view/2015/02/135652/\u003c/a\u003e\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003e10년 전 쯤에 부서장은 인품이 참 좋은 분이었다. 그 당시 내 기준으로는 회사 생활을 하면서 만난 몇 안되는 좋은 부서장이었다.(물론 그 당시에 내가 생각하는 \u0026lsquo;좋은\u0026rsquo; 부서장의 기준은 지금과 달라졌다.) 왠만하면 화를 내는 일이 없었고, 문제를 일으켜도 문제를 유발한 사람을 탓하기보다는 문제 해결에 집중하는 바람직한 부서장 상을 실천하던 분이었다.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e그 분께 하루는 술 기운을 빌어 부탁을 한 적이 있었다. 퇴근 일찍 하시고, 주말 근무 하지 마시라고. 우리가 더 회사생활을 하면 가게 될 위치 중 하나가 당신인데, 당신의 지금 회사 생활은 별로 따르고 싶은 모습이 아니라고. 그런 모습을 보고 자랄 후배들을 위해 좀 더 희망적인 모습을 보여달라고.\u003c/p\u003e","title":"미래가 없는 조직"},{"content":"\n","date":"2021-09-25T18:52:54+09:00","permalink":"https://cychong47.github.io/post/2021/2021-09-25-foundation-onair-in-appletvplus/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/09/2021-09-25-IMG_7898.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"소설 Foundation이 드디어 영상으로"},{"content":"\n","date":"2021-09-24T11:24:23+09:00","permalink":"https://cychong47.github.io/post/2021/2021-09-24-power-consumption-of-mini3/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/09/2021-09-24-IMG_7884.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"HP mini PC의 소모전력"},{"content":"\n","date":"2021-09-09T18:06:56+09:00","permalink":"https://cychong47.github.io/post/2021/2021-09-09-new-books-in-this-month/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/09/2021-09-09-IMG_0320.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"8월 구매 도서들"},{"content":"\n","date":"2021-08-31T13:24:15+09:00","permalink":"https://cychong47.github.io/post/2021/2021-08-31-upgrade-devonthink3-pro/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/08/2021-08-31-IMG_7067.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021/08/2021-08-31-IMG_7068.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"Devonthink 3 Pro로 업그레이드 - 의리"},{"content":"\n","date":"2021-08-31T00:33:39+09:00","permalink":"https://cychong47.github.io/post/2021/2021-08-31-note-taking-tips/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/08/2021-08-31-IMG_3731.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"Note-taking Tips from twitter"},{"content":"Go, Rust and Python\nPython은 20년째 하고 있는 것 같은데 어째 2개월 한 사람보다 못하냐.\n","date":"2021-08-24T22:54:41+09:00","permalink":"https://cychong47.github.io/post/2021/2021-08-24-2021-languages-to-learn/","summary":"\u003cp\u003eGo, Rust and Python\u003c/p\u003e\n\u003cp\u003ePython은 20년째 하고 있는 것 같은데 어째 2개월 한 사람보다 못하냐.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021/08/2021-08-24-IMG_0318.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"2021년 관심있는 언어들"},{"content":"\n","date":"2021-08-17T09:22:39+09:00","permalink":"https://cychong47.github.io/post/2021/2021-08-17-remove-meta-data-from-image/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/08/2021-08-17-IMG_6772.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"iOS shortcut - 사진 meta 정보 삭제"},{"content":"\n","date":"2021-05-16T14:59:00+09:00","permalink":"https://cychong47.github.io/post/2021/2021-01-01-i-did-not-expect-this/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/05/2021-05-16-IMG_0139.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"책 - 이렇게 될 줄 몰랐습니다"},{"content":"\n","date":"2021-05-13T08:53:00+09:00","permalink":"https://cychong47.github.io/post/2021/2021-05-13-i-know-but-it-is-not-that-easy/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/05/2021-05-13-IMG_4303.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"알지만 쉽지 않은 일"},{"content":"특정 서비스를 외부에 공개하고 싶지 않고, 내부 망에서만 접근하게 하려면 Traefik의 middleware가 제공하는 ipWhilteList 기능을 활용할 수 있다.\n(이름은 요즘 추세에 맞게 ipAllowList 정도로 변경되어야 할 것 같은데..)\n전체적인 동작은 IpWhitelist - Traefik 페이지에 있는 그림으로 간단하게 요약이 가능할 듯. 사이트에 접근하려는 client가 미리 정의된 list에 있는 경우에만 접근을 허용한다는.\nmiddleware 정의 접근을 허용할 client들의 CIDR을 정의한다. 특정 subnet을 정의하거나, 특정 host를 정의할 수 있다. 당연히 복수 정의도 가능하고.\n아래 예는 192.168.0.0/16 에서의 접근만 허용하는 설정이다.\napiVersion: traefik.containo.us/v1alpha1 kind: Middleware metadata: name: ipwhitelist spec: ipWhiteList: sourceRange: - 192.168.0.0/16 ingress route 정의 Middleware가 특정 match마다 적용할 수 있으므로, 위에서 정의한 접근 목록 역시 특정 site 마다 정의할 수 있다. 아래는 / 페이지에 접근하는 client를 list에서 확인해서 포함된 경우에만 허용한다.\n- match: PathPrefix(`/`) kind: Rule services: - name: jellyfin port: 80 middlewares: - name: ipwhitelist namespace: default 이제 / 경로의 접근은 192.168.0.0/16에서만 허용되고, 그 외부에서의 접근은 허용되지 않게 된다.\n","date":"2021-05-08T23:16:00+09:00","permalink":"https://cychong47.github.io/post/2021/2021-05-08-access-control-with-traefik-middleware/","summary":"\u003cp\u003e특정 서비스를 외부에 공개하고 싶지 않고, 내부 망에서만 접근하게 하려면 Traefik의 middleware가 제공하는 \u003ccode\u003eipWhilteList\u003c/code\u003e 기능을 활용할 수 있다.\u003c/p\u003e\n\u003cp\u003e(이름은 요즘 추세에 맞게 \u003ccode\u003eipAllowList\u003c/code\u003e  정도로 변경되어야 할 것 같은데..)\u003c/p\u003e\n\u003cp\u003e전체적인 동작은 \u003ca href=\"https://doc.traefik.io/traefik/middlewares/ipwhitelist/\"\u003eIpWhitelist - Traefik\u003c/a\u003e 페이지에 있는 그림으로 간단하게 요약이 가능할 듯. 사이트에 접근하려는 client가 미리 정의된 list에 있는 경우에만 접근을 허용한다는.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://doc.traefik.io/traefik/assets/img/middleware/ipwhitelist.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch2 id=\"middleware-정의\"\u003emiddleware 정의\u003c/h2\u003e\n\u003cp\u003e접근을 허용할 client들의 CIDR을 정의한다. 특정 subnet을 정의하거나, 특정 host를 정의할 수 있다. 당연히 복수 정의도 가능하고.\u003c/p\u003e\n\u003cp\u003e아래 예는 \u003ccode\u003e192.168.0.0/16\u003c/code\u003e 에서의 접근만 허용하는 설정이다.\u003c/p\u003e","title":"Traefik middleware를 이용한 접근 제한"},{"content":"\n","date":"2021-04-24T18:19:49+09:00","permalink":"https://cychong47.github.io/post/2021/2021-04-24-upgrade-icloud-storage-option/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/04/2021-04-23-IMG_3813.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021/04/2021-04-24-IMG_3921.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021/04/2021-04-24-IMG_3923.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021/04/2021-04-24-IMG_3924.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"iCloud 2TB 서비스로 업그레이드"},{"content":"mini1에서 mini3로의 이전을 준비 중. 기존에 mini3에는 재미삼아 k3s를 설치해 놓았는데 왠지 새로운 설정 방식을 알아야 할 필요가 있나 하는 생각이 들어 이전처럼 다시 vanilla kubernetes 를 설치하기로 했다. minkkube처럼 VM을 만들어야 설치가 되는 것도 아니고 그냥 host OS에 설치하면 되니까 설치도 간단하고(물론 바이너리 하나 설치하면 되는 k3s와는 비교하기 어렵지만) 부하를 감당하기 어려운 정도의 CPU도 아니라서.\nInstalling kubeadm | Kubernetes\n# /etc/modules-load.d/k8s.conf br_netfilter # /etc/sysctl.d/k8s.conf net.bridge.bridge-nf-call-ip6tables = 1 net.bridge.bridge-nf-call-iptables = 1 $ sudo sysctl --system Install Containerd as a Container Runtime docker를 CRI로 사용하는 것은 곧 deprecated예정이니까 containerd를 사용해 보자.\nhttps://kubernetes.io/docs/setup/production-environment/container-runtimes\n하지만 위 문서에서는 containerd 자체에 대한 내용은 없고, 별도 문서에서 설치 과정을 언급하고 있지만, docker를 사용하여 설치하는 것으로 기술하고 있어 별도의 링크를 참고하여 설치 중\nhttps://www.techrepublic.com/article/how-to-install-kubernetes-on-ubuntu-server-without-docker\n# /etc/modules-load.d/containerd.conf overlay br_netfilter # /etc/sysctl.d/99-kubernetes-cri.conf net.bridge.bridge-nf-call-iptables = 1 net.ipv4.ip_forward = 1 net.bridge.bridge-nf-call-ip6tables = 1 $ sudo sysctl --ystem 이제 Containerd 를 패키지로 설치. github에 있는 Containerd는 최신 버전이 1.4.4지만 아직 Ubuntu repository에 있는 버전은 1.3.3라 좀 아쉽지만 일단 설치를 해 보자. 아니면 직접 빌드해서 설치하면 되긴한데, 그러면 앞으로 업데이트도 매번 빌드를 해야 할 것 같아서.\n$ sudo apt search containerd ... containerd/focal-updates,focal-security,now 1.3.3-0ubuntu2.3 amd64 daemon to control runC $ sudo apt install containerd -y $ sudo mkdir -p /etc/containerd $ containerd config default | sudo tee /etc/containerd/config.toml $ sudo systemctl restart containerd Install kubeadm, kubelet and kubectl kubeadm 등 k8s 관련 앱 들을 설치를 하기 위해 repo 추가\n$ curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add OK $ sudo apt-add-repository ‘deb http://apt.kubernetes.io/ kubernetes-xenial main’ Hit:2 http://kr.archive.ubuntu.com/ubuntu focal InRelease Get:3 http://kr.archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB] Get:4 http://kr.archive.ubuntu.com/ubuntu focal-backports InRelease [101 kB] Get:5 http://kr.archive.ubuntu.com/ubuntu focal-security InRelease [109 kB] Get:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease [9,383 B] Get:6 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 Packages [45.5 kB] Fetched 378 kB in 5s (77.5 kB/s) Reading package lists... Done $ sudo apt-get install kubeadm kubelet kubectl -y Disable swap Reboot후에도 swap을 만들지 않도록 조치하고\n# /etc/fstab ... #/swap.img 현재 활성화된 swap도 끄고\n$ free -h total used free shared buff/cache available Mem: 15Gi 292Mi 2.7Gi 2.0Mi 12Gi 14Gi Swap: 4.0Gi 0.0Ki 4.0Gi $ sudo swapoff -a $ free -h total used free shared buff/cache available Mem: 15Gi 282Mi 2.7Gi 2.0Mi 12Gi 14Gi Swap: 0B 0B 0B Setup Cluster 이제 준비가 되었으니 kubeadm으로 설치 시작. mini1에 k8s 설치할 때 kubeadm을 사용해서 이번에는 다른 방법으로 해 보려고 찾아봤는데 딱히 마음에 드는 게 없어서 그냥 이번에도 kubeadm으로 진행. Terraform으로 어떻게 할 수 있지 않을까 했는데 자료를 찾지 못했다는. Public cloud 환경에 cluster를 구성하거나, 이미 구성되어 있는 cluster에 namespace를 추가하고, 툴을 설치하는 등의 예제는 많은데 내가 원하는 on-premise 환경에 kubernetes cluster를 구성하는 내용에 대한 자료는 의의로 많이 없었다는. 그래서 k8s홈페이지에서도 여전히 kubeadm, Kubespray, kops 정도만 소개하고 있는 걸까?\n$ sudo kubeadm config images pull [config/images] Pulled k8s.gcr.io/kube-apiserver:v1.21.0 [config/images] Pulled k8s.gcr.io/kube-controller-manager:v1.21.0 [config/images] Pulled k8s.gcr.io/kube-scheduler:v1.21.0 [config/images] Pulled k8s.gcr.io/kube-proxy:v1.21.0 [config/images] Pulled k8s.gcr.io/pause:3.4.1 [config/images] Pulled k8s.gcr.io/etcd:3.4.13-0 [config/images] Pulled k8s.gcr.io/coredns/coredns:v1.8.0 $ sudo kubeadm init --pod-network-cidr=10.245.0.0/16 [init] Using Kubernetes version: v1.21.0 [preflight] Running pre-flight checks [preflight] Pulling images required for setting up a Kubernetes cluster [preflight] This might take a minute or two, depending on the speed of your internet connection [preflight] You can also perform this action in beforehand using \u0026#39;kubeadm config images pull\u0026#39;[certs] Using certificateDir folder \u0026#34;/etc/kubernetes/pki\u0026#34; [certs] Generating \u0026#34;ca\u0026#34; certificate and key [certs] Generating \u0026#34;apiserver\u0026#34; certificate and key [certs] apiserver serving cert is signed for DNS names [kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local mini3] and IPs [10.96.0.1 192.168.0.101][certs] Generating \u0026#34;apiserver-kubelet-client\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-ca\u0026#34; certificate and key [certs] Generating \u0026#34;front-proxy-client\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/ca\u0026#34; certificate and key [certs] Generating \u0026#34;etcd/server\u0026#34; certificate and key [certs] etcd/server serving cert is signed for DNS names [localhost mini3] and IPs [192.168.0.101 127.0.0.1 ::1] [certs] Generating \u0026#34;etcd/peer\u0026#34; certificate and key [certs] etcd/peer serving cert is signed for DNS names [localhost mini3] and IPs [192.168.0.101 127.0.0.1 ::1] [certs] Generating \u0026#34;etcd/healthcheck-client\u0026#34; certificate and key [certs] Generating \u0026#34;apiserver-etcd-client\u0026#34; certificate and key [certs] Generating \u0026#34;sa\u0026#34; key and public key [kubeconfig] Using kubeconfig folder \u0026#34;/etc/kubernetes\u0026#34; [kubeconfig] Writing \u0026#34;admin.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;kubelet.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;controller-manager.conf\u0026#34; kubeconfig file [kubeconfig] Writing \u0026#34;scheduler.conf\u0026#34; kubeconfig file [kubelet-start] Writing kubelet environment file with flags to file \u0026#34;/var/lib/kubelet/kubeadm-flags.env\u0026#34; [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [kubelet-start] Starting the kubelet [control-plane] Using manifest folder \u0026#34;/etc/kubernetes/manifests\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-apiserver\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-controller-manager\u0026#34; [control-plane] Creating static Pod manifest for \u0026#34;kube-scheduler\u0026#34; [etcd] Creating static Pod manifest for local etcd in \u0026#34;/etc/kubernetes/manifests\u0026#34; [wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \u0026#34;/etc/kubernetes/manifests\u0026#34;. This can take up to 4m0s 1분 정도(아래 로그를 보니 73초) 아무런 진행이 없다 다시 설치가 진행되고, 마지막에 성공했다는 메시지가 짠. 언제나 설치 성공은 기쁜 일이지.\n[kubelet-check] Initial timeout of 40s passed. [apiclient] All control plane components are healthy after 73.009593 seconds [upload-config] Storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace [kubelet] Creating a ConfigMap \u0026#34;kubelet-config-1.21\u0026#34; in namespace kube-system with the configuration for the kubelets in the cluster [upload-certs] Skipping phase. Please see --upload-certs [mark-control-plane] Marking the node mini3 as control-plane by adding the labels: [node-role.kubernetes.io/master(deprecated) node-role.kubernetes.io/control-plane node.kubernetes.io/exclude-from-external-load-balancers] [mark-control-plane] Marking the node mini3 as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule] [bootstrap-token] Using token: rc93da.7cseyuwmnfvhgyyx [bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [bootstrap-token] Creating the \u0026#34;cluster-info\u0026#34; ConfigMap in the \u0026#34;kube-public\u0026#34; namespace [kubelet-finalize] Updating \u0026#34;/etc/kubernetes/kubelet.conf\u0026#34; to point to a rotatable kubelet client certificate and key [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.0.101:6443 --token qs9eij.pm7l5jzihbk2rmvs \\ --discovery-token-ca-cert-hash sha256:754b224773ada603d486d3e6652437539a847323dee6fa011ae472e85b3bcdbc 시키는 대로 kube configuration 파일을 홈 디렉토리에 복사해주고. 이 파일만 있으면 어느 머신에서든 kubectl이나 k9s같은 툴을 이용해서 cluster의 상태를 확인하고, 변경할 수 있다는.\n$ mkdir -p $HOME/.kube $ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config $ sudo chown $(id -u):$(id -g) $HOME/.kube/config Cluster 접근에 필요한 certificate등의 정보가 저장되어 있는 파일이라 파일 퍼미션은 저렇게 600으로 되어 있는 듯.\n$ ls -al $HOME/.kube/config -rw------- 1 cychong cychong 5597 Apr 12 14:02 /home/cychong/.kube/config Install Calico 기본 CNI인 flannel을 사용해도 되지만, 이번에도 익숙한(?) Calico를 굳이 설치.\n이전(v3.8) 설치 때와 달리 지금 Calico버전은 Operator를 이용해서 설치 https://docs.projectcalico.org/getting-started/kubernetes/quickstart\n$ kubectl create -f https://docs.projectcalico.org/manifests/tigera-operator.yaml customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org createdcustomresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ kubecontrollersconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/imagesets.operator.tigera.io created customresourcedefinition.apiextensions.k8s.io/installations.operator.tigera.io created customresourcedefinition.apiextensions.k8s.io/tigerastatuses.operator.tigera.io created namespace/tigera-operator created Warning: policy/v1beta1 PodSecurityPolicy is deprecated in v1.21+, unavailable in v1.25+ podsecuritypolicy.policy/tigera-operator created serviceaccount/tigera-operator created clusterrole.rbac.authorization.k8s.io/tigera-operator created clusterrolebinding.rbac.authorization.k8s.io/tigera-operator created deployment.apps/tigera-operator created tigera-operator 라는 namespace가 생성되고, 거기에 tigera-operator pod가 하나 실행된다.\n$ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-558bd4d5db-7qm2n 0/1 Pending 0 7m3s kube-system coredns-558bd4d5db-vrhmk 0/1 Pending 0 7m3s kube-system etcd-mini3 1/1 Running 0 7m7s kube-system kube-apiserver-mini3 1/1 Running 0 7m7s kube-system kube-controller-manager-mini3 1/1 Running 0 7m7s kube-system kube-proxy-ll97z 1/1 Running 0 7m3s kube-system kube-scheduler-mini3 1/1 Running 0 7m7s tigera-operator tigera-operator-675ccbb69c-fg4k9 1/1 Running 0 2m27s 이제 나머지 Calico를 설치하는데, IP subnet을 변경했으니 설정파일을 받아서 수정한 후 설치하는 걸로.\n$ wget https://docs.projectcalico.org/manifests/custom-resources.yaml --2021-04-12 14:20:49-- https://docs.projectcalico.org/manifests/custom-resources.yaml Resolving docs.projectcalico.org (docs.projectcalico.org)... 3.0.239.142, 104.248.158.121, 2406:da18:880:3802:371c:4bf1:923b:fc30, ... Connecting to docs.projectcalico.org (docs.projectcalico.org)|3.0.239.142|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 545 [text/yaml] Saving to: ‘custom-resources.yaml’ custom-resources.yaml 100%[============================\u0026gt;] 545 --.-KB/s in 0s 2021-04-12 14:20:50 (3.36 MB/s) - ‘custom-resources.yaml’ saved [545/545] 파일에서 “CIDR” 필드 값을 변경한다.\n$ vi custom-resource.yaml 앞에서 kubeadm init할때 사용했던 subnet과 같은 값으로 변경.\n$ grep cidr custom-resources.yaml cidr: 10.245.0.0/16 $ kubectl apply -f custom-resources.yaml installation.operator.tigera.io/default created Wait for all Calico pods are in RUNNING state\n# watch -n2 kubectl get pods -n calico-system Every 2.0s: kubectl get pods -n calico-system NAME READY STATUS RESTARTS AGE calico-kube-controllers-5cbf59cb6f-lg9xq 1/1 Running 0 3m7s calico-node-dglfb 1/1 Running 0 3m8s calico-typha-d798686b4-hf6bb 1/1 Running 0 3m8s 이제 모든 namespaces 해 보면,\n$ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGEcalico-system calico-kube-controllers-5cbf59cb6f-lg9xq 1/1 Running 0 8m18s calico-system calico-node-dglfb 1/1 Running 0 8m19s calico-system calico-typha-d798686b4-hf6bb 1/1 Running 0 8m19s kube-system coredns-558bd4d5db-2wgvk 1/1 Running 0 18mkube-system coredns-558bd4d5db-sxmnq 1/1 Running 0 18mkube-system etcd-mini3 1/1 Running 0 18mkube-system kube-apiserver-mini3 1/1 Running 0 18m kube-system kube-controller-manager-mini3 1/1 Running 0 18mkube-system kube-proxy-bnsv7 1/1 Running 0 18m kube-system kube-scheduler-mini3 1/1 Running 0 18m tigera-operator tigera-operator-675ccbb69c-z9hrz 1/1 Running 0 11m Single node cluster 로 사용하기 위해\n$ kubectl taint nodes --all node-role.kubernetes.io/master- node/mini3 untainted $ kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME mini3 Ready control-plane,master 14m v1.21.0 192.168.0.101 \u0026lt;none\u0026gt; Ubuntu 20.04.2 LTS 5.4.0-66-generic containerd://1.3.3-0ubuntu2.3 이전과 달리 CONTAINER-RUNTIME 에 docker가 아닌 containerd가 표시된 걸 보니 Containerd 설치가 제대로 된 듯\n$ kubectl describe node mini3 Name: mini3 Roles: control-plane,master Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux kubernetes.io/arch=amd64 kubernetes.io/hostname=mini3 kubernetes.io/os=linux node-role.kubernetes.io/control-plane= node-role.kubernetes.io/master= node.kubernetes.io/exclude-from-external-load-balancers= Annotations: kubeadm.alpha.kubernetes.io/cri-socket: /run/containerd/containerd.sock node.alpha.kubernetes.io/ttl: 0 projectcalico.org/IPv4Address: 192.168.0.101/24 projectcalico.org/IPv4VXLANTunnelAddr: 10.245.211.0 volumes.kubernetes.io/controller-managed-attach-detach: true CreationTimestamp: Mon, 12 Apr 2021 14:12:49 +0900 Taints: \u0026lt;none\u0026gt; Unschedulable: false Lease: HolderIdentity: mini3 AcquireTime: \u0026lt;unset\u0026gt; RenewTime: Mon, 12 Apr 2021 14:32:28 +0900 Conditions: Type Status LastHeartbeatTime LastTransitionTime Reason Message ---- ------ ----------------- ------------------ ------ ------- NetworkUnavailable False Mon, 12 Apr 2021 14:24:14 +0900 Mon, 12 Apr 2021 14:24:14 +0900 CalicoIsUp Calico is running on this node MemoryPressure False Mon, 12 Apr 2021 14:30:07 +0900 Mon, 12 Apr 2021 14:12:47 +0900 KubeletHasSufficientMemory kubelet has sufficient memory available DiskPressure False Mon, 12 Apr 2021 14:30:07 +0900 Mon, 12 Apr 2021 14:12:47 +0900 KubeletHasNoDiskPressure kubelet has no disk pressure PIDPressure False Mon, 12 Apr 2021 14:30:07 +0900 Mon, 12 Apr 2021 14:12:47 +0900 KubeletHasSufficientPID kubelet has sufficient PID available Ready True Mon, 12 Apr 2021 14:30:07 +0900 Mon, 12 Apr 2021 14:23:56 +0900 KubeletReady kubelet is posting ready status. AppArmor enabled Addresses: InternalIP: 192.168.0.101 Hostname: mini3 Capacity: cpu: 2 ephemeral-storage: 114336932Ki hugepages-1Gi: 0 hugepages-2Mi: 0 memory: 16311204Ki pods: 110 Allocatable: cpu: 2 ephemeral-storage: 105372916357 hugepages-1Gi: 0 hugepages-2Mi: 0 memory: 16208804Ki pods: 110 System Info: Machine ID: 7369831895a5443e9806a29d674b929b System UUID: a61d4c15-ad23-4b7c-9f11-c07cd13f6216 Boot ID: 7bbad4d9-72fc-4bdf-8604-26cb6fb2bc99 Kernel Version: 5.4.0-66-generic OS Image: Ubuntu 20.04.2 LTS Operating System: linux Architecture: amd64 Container Runtime Version: containerd://1.3.3-0ubuntu2.3 Kubelet Version: v1.21.0 Kube-Proxy Version: v1.21.0 PodCIDR: 10.245.0.0/24 PodCIDRs: 10.245.0.0/24 Non-terminated Pods: (11 in total) Namespace Name CPU Requests CPU Limits Memory Requests Memory Limits Age --------- ---- ------------ ---------- --------------- ------------- --- calico-system calico-kube-controllers-5cbf59cb6f-lg9xq 0 (0%) 0 (0%) 0 (0%) 0 (0%) 9m14s calico-system calico-node-dglfb 0 (0%) 0 (0%) 0 (0%) 0 (0%) 9m15s calico-system calico-typha-d798686b4-hf6bb 0 (0%) 0 (0%) 0 (0%) 0 (0%) 9m15s kube-system coredns-558bd4d5db-2wgvk 100m (5%) 0 (0%) 70Mi (0%) 170Mi (1%) 19m kube-system coredns-558bd4d5db-sxmnq 100m (5%) 0 (0%) 70Mi (0%) 170Mi (1%) 19m kube-system etcd-mini3 100m (5%) 0 (0%) 100Mi (0%) 0 (0%) 19m kube-system kube-apiserver-mini3 250m (12%) 0 (0%) 0 (0%) 0 (0%) 19m kube-system kube-controller-manager-mini3 200m (10%) 0 (0%) 0 (0%) 0 (0%) 19m kube-system kube-proxy-bnsv7 0 (0%) 0 (0%) 0 (0%) 0 (0%) 19m kube-system kube-scheduler-mini3 100m (5%) 0 (0%) 0 (0%) 0 (0%) 19m tigera-operator tigera-operator-675ccbb69c-z9hrz 0 (0%) 0 (0%) 0 (0%) 0 (0%) 12m Allocated resources: (Total limits may be over 100 percent, i.e., overcommitted.) Resource Requests Limits -------- -------- ------ cpu 850m (42%) 0 (0%) memory 240Mi (1%) 340Mi (2%) ephemeral-storage 100Mi (0%) 0 (0%) hugepages-1Gi 0 (0%) 0 (0%) hugepages-2Mi 0 (0%) 0 (0%) Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal NodeHasNoDiskPressure 21m (x5 over 21m) kubelet Node mini3 status is now: NodeHasNoDiskPressure Normal NodeHasSufficientPID 21m (x5 over 21m) kubelet Node mini3 status is now: NodeHasSufficientPID Normal NodeHasSufficientMemory 20m (x6 over 21m) kubelet Node mini3 status is now: NodeHasSufficientMemory Normal Starting 19m kubelet Starting kubelet. Warning InvalidDiskCapacity 19m kubelet invalid capacity 0 on image filesystem Normal NodeHasSufficientMemory 19m kubelet Node mini3 status is now: NodeHasSufficientMemory Normal NodeHasNoDiskPressure 19m kubelet Node mini3 status is now: NodeHasNoDiskPressure Normal NodeHasSufficientPID 19m kubelet Node mini3 status is now: NodeHasSufficientPID Normal NodeAllocatableEnforced 19m kubelet Updated Node Allocatable limit across pods Normal Starting 19m kube-proxy Starting kube-proxy. Normal NodeReady 8m40s kubelet Node mini3 status is now: NodeReady 기본 설치 끝.\n그런데 docker를 설치하지 않았으니 docker 명령어를 사용할 수 없네. 흠.. podman을 설치할까 그냥 docker를 설치할까. podman으로 docker-compose를 사용할 수 있던가\u0026hellip;\n","date":"2021-04-13T11:26:01+09:00","permalink":"https://cychong47.github.io/post/2021/2021-04-13-install-kubernetes-on-mini3/","summary":"\u003cp\u003emini1에서 mini3로의 이전을 준비 중.\n기존에 mini3에는 재미삼아 k3s를 설치해 놓았는데 왠지 새로운 설정 방식을 알아야 할 필요가 있나 하는 생각이 들어 이전처럼 다시 vanilla kubernetes 를 설치하기로 했다. minkkube처럼 VM을 만들어야 설치가 되는 것도 아니고 그냥 host OS에 설치하면 되니까 설치도 간단하고(물론 바이너리 하나 설치하면 되는 k3s와는 비교하기 어렵지만) 부하를 감당하기 어려운 정도의 CPU도 아니라서.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/\"\u003eInstalling kubeadm | Kubernetes\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e# /etc/modules-load.d/k8s.conf\nbr_netfilter\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e# /etc/sysctl.d/k8s.conf\nnet.bridge.bridge-nf-call-ip6tables = 1\nnet.bridge.bridge-nf-call-iptables = 1\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo sysctl --system\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"install-containerd-as-a-container-runtime\"\u003eInstall Containerd as a Container Runtime\u003c/h1\u003e\n\u003cp\u003edocker를 CRI로 사용하는 것은 곧 deprecated예정이니까 containerd를 사용해 보자.\u003c/p\u003e","title":"Install kubernetes on mini3"},{"content":"Traefik을 이용한 Ingress/Ingress Controller를 이용해서 nginx 기반 Pod를 cluster 외부에서 접속할 수 있도록 설정했는데 곰곰히 생각해 보니 그렇다면 nginx service에 굳이 NodePort를 사용해야 하나 라는 생각이 들었다. 이제 외부로부터의 요청은 든든한 Traefik이 처리해 줄 테니 직접 각 pod가 서비스를 NodePort를 이용해서 외부에 오픈할 필요가 없어 보였다.\n이를 위해 기존에 사용하던 nginx의 value 파일을 다음과 같이 수정했다. NodePort를 위해 필요했던 정보들이 사라지고, 수신하고 싶은 Port만 지정하면 되니설정 파일이 무척 깔끔해졌다.\nservice: # type: NodePort # targetPort: 80 # container app. itself # port: 8099 # pod # nodePort: 8099 # cluster-wise # externalTrafficPolicy: Local # externalIPs: [192.168.0.100] type: ClusterIP port: 80 변경된 value 파일을 이용해서 다시 deploy.\n$ kubectl get pod -o wide |grep podcast podcast-nginx-659bcb6485-dxqm5 1/1 Running 0 2m29s 10.244.51.105 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; Service 정보에서 EXTERNAL-IP 항목이 이제 none으로 나오고, TYPE도 Cluster IP로 변경되었다.\n$ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ... podcast-nginx ClusterIP 10.96.100.155 \u0026lt;none\u0026gt; 80/TCP 2m20s ... 다만 IngressRoute 규칙은 다시 설정했어야 하는데, ingress rule의 port정보를 기존에 8099에서 80으로 변경한 후에 helm을 이용해서 backend service/deployment를 설치했는데도 제대로 동작하지 않아서 다시 IngressRoute를 적용했더니 그제서야 정상 동작 했다는.\n아무튼 이제 Traefik으로 처리하는 서비스는 더 이상 외부에서 port를 이용해서 서비스되지 않도록 했다. 이제 공유기에 설정했던 port forwarding 내용도 하나 줄일 수 있겠네. ","date":"2021-04-03T22:00:00+09:00","permalink":"https://cychong47.github.io/post/2021/2021-03-31-change-nodeport-to-clusterip/","summary":"\u003cp\u003eTraefik을 이용한 Ingress/Ingress Controller를 이용해서 nginx 기반 Pod를 cluster 외부에서 접속할 수 있도록 설정했는데 곰곰히 생각해 보니 그렇다면 nginx service에 굳이 \u003ccode\u003eNodePort\u003c/code\u003e를 사용해야 하나 라는 생각이 들었다. 이제 외부로부터의 요청은 든든한 Traefik이 처리해 줄 테니 직접 각 pod가 서비스를 NodePort를 이용해서 외부에 오픈할 필요가 없어 보였다.\u003c/p\u003e\n\u003cp\u003e이를 위해 기존에 사용하던 nginx의 value 파일을 다음과 같이 수정했다. NodePort를 위해 필요했던 정보들이 사라지고, 수신하고 싶은 Port만 지정하면 되니설정 파일이 무척 깔끔해졌다.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eservice:\n        #  type: NodePort\n        #  targetPort: 80               # container app. itself\n        #  port: 8099                   # pod\n        #  nodePort: 8099               # cluster-wise\n        #  externalTrafficPolicy: Local\n        #  externalIPs: [192.168.0.100]\n  type: ClusterIP\n  port: 80\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e변경된 value 파일을 이용해서 다시 deploy.\u003c/p\u003e","title":"Replace NodePort with ClsuterIP - Thx to Traefik"},{"content":"Ingress Controller 를 설치(Helm으로 Traefik 설치하기)했으니 이제 Ingress를 설정해서 실제 cluster 외부로부터의 http/https 메시지를 nginx pod에 전달되게 해 본다.\nIngress Ingress는 Cluster 외부에서 접근하는 http/https request에 대한 라우팅을 제어하는 기능을 제공한다. Ingress | Kubernetes\ningress.yaml 파일을 다음과 같이 작성한다. . 아래는 두 가지 rule을 설정하고 있는데 host가 ‘mini1’이고, URL path가 /ost면 podcast-nginx라는 서비스로 전달하게 하는 것과 host는 상관없이 path가 /ost면 역시 같은 podcast-nginx로 보내는 것이다.\nkind: Ingress apiVersion: extensions/v1beta1 metadata: name: \u0026#34;test\u0026#34; namespace: default spec: rules: - host: mini1 http: paths: - path: /ost backend: serviceName: podcast-nginx servicePort: 8099 - http: paths: - path: /ost backend: serviceName: podcast-nginx servicePort: 8099 Kubectl 명령을 이용해 적용해 본다.\n$ kubectl apply -f ingress.yaml ingress.extensions/test created 확인은 여느 resource와 마찬가지로 get 명령어 사용\n$ kubectl get ingress NAME CLASS HOSTS ADDRESS PORTS AGE test \u0026lt;none\u0026gt; mini1 80 8s 상세 내용을 보려면 역시 describe 명령을 사용한다.\n$ kubectl describe ingress test Name: test Namespace: default Address: Default backend: default-http-backend:80 (\u0026lt;error: endpoints \u0026#34;default-http-backend\u0026#34; not found\u0026gt;) Rules: Host Path Backends ---- ---- -------- mini1 /ost podcast-nginx:8099 () * /ost podcast-nginx:8099 () Annotations: Events: \u0026lt;none\u0026gt; YAML 파일에 기술한 대로 2가지 rule이 설정되었다. {mini1, /ost} -\u0026gt; podcast-nginx:8099 {*,/ost} -\u0026gt; podcast-nginx:8099\n404 Not Found 이전에는 NodePort에 설정한 IP 주소와 NodePort 조합으로 http://192.168.0.100:8099로 접근했는데 이번에는 http://192.168.0.100/ost로 접근을 시도했다. 그렇지만 별로 만나고 싶은 않은 404 에러만 덩그러니…\n404 Not Found nginx/1.19.0 Pod logs 그래도 nginx 에러가 나왔다는 건 적어도 Traefik을 거쳐 nginx가 동작하고 있는 pod까지는 request가 왔다는 걸로 보인다. 즉 이건 Ingress 설정이나 Traefik 동작에는 문제가 없다는 거.\n그래서 nginx가 동작하고 있는 Pod의 로그를 보기로 했다. GitHub - derailed/k9s: 🐶 Kubernetes CLI To Manage Your Clusters In Style!를 이용해서 attach 명령을 이용하면 편리하게 로그를 볼 수 있다(심지어? kubeconfig 파일을 이용해서 다른 머신에서 cluster에 원격으로 접속할 수 있다는. k9s --kubeconfig ~/.kube/config_mini1\nUnable to use a TTY - container nginx did not allocate one If you don\u0026#39;t see a command prompt, try pressing enter. 10.244.51.100 - - [30/Mar/2021:14:11:54 +0000] \u0026#34;GET /ost HTTP/1.1\u0026#34; 404 153 \u0026#34;-\u0026#34; \u0026#34;Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_6) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/14.0.3 Safari/605.1.15\u0026#34; \u0026#34;192.168.0.100\u0026#34; 2021/03/30 14:11:54 [error] 28#28: *793087 open() \u0026#34;/usr/share/nginx/html/ost\u0026#34; failed (2: No such file or directory), client: 10.244.51.100, server: localhost, request: \u0026#34;GET /ost HTTP/1.1\u0026#34;, host: \u0026#34;192.168.0.100\u0026#34; 혹시나 했는데 예상대로 요청하는 html 파일의 경로가 /usr/share/nginx/html/ost 다. 하지만 nginx는 모두 subpath 없이 / 에 파일을 두고 있으므로 /를 찾도록 redirect 시켜야 하는데.\nIngress | Kubernetes 를 보면 rewrite-target이라는 annotation을 사용하는 듯 한데, 해당 annotation의 prefix를 보니 아무래도 nginx만 지원이되는 게 아닌가 싶다.\n$ kubectl describe ingress test Name: test Namespace: default Address: 178.91.123.132 Default backend: default-http-backend:80 (10.8.2.3:8080) Rules: Host Path Backends ---- ---- -------- foo.bar.com /foo service1:80 (10.8.0.90:80) Annotations: nginx.ingress.kubernetes.io/rewrite-target: / Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal ADD 35s loadbalancer-controller default/test 그래서 Traefik이 path rewriting을 지원하는 지 검색해 보니 당연하게도 동일한 기능을 제공한다고. docker - Rewriting paths with Traefik - Stack Overflow\n위 글에 있는 예제는 http://monitor.app.com/service-one 를 http://service-one/monitor로 rewriting하는 경우이다.\napiVersion: v1 kind: Service metadata: name: service-one spec: selector: k8s-app: service-one-app ports: - port: 80 targetPort: 8080 --- kind: Ingress metadata: name: monitor.app annotations: kubernetes.io/ingress.class: traefik traefik.ingress.kubernetes.io/rewrite-target: /monitor # set path to result request spec: rules: - host: monitor.app.com http: paths: - path /service-one # path for routing, it will be removed because of PathPrefixStrip settings backend: serviceName: service-one servicePort: 80 그런데 또 찾아 보니 위의 내용은 Traefik v1에만 해당하는 거라고. v2에서는 PathPrefixStrip 기능이 Middleware의 기능으로 옮겨졌다고 한다.\nIn the v2, the “modifiers” became middleware: https://docs.traefik.io/v2.0/middlewares/stripprefix/ \u0026gt;\nSource : https://github.com/traefik/traefik/issues/5004\nMiddleware `Middleware라니 이건 또 뭔가. Overview - Traefik | Site | v2.0\nAttached to the routers, pieces of middleware are a mean of tweaking the requests before they are sent to your service (or before the answer from the services are sent to the clients)\nRoute 동작 중에 수행할 수 있는 여러가지 작업을 정의한 것이 Middleware라고 이해된다. 확장성을 위해 단순히 경로를 차는 Routing과 경로를 조작(?)하는 등의 작업을 분리해서 Middleware라고 부르는 것 같다.\nMiddleware를 위한 CRD가 정의되어 있는데, Helm으로 설치하면 이미 middleware가 설치되어 있다\nk get CustomResourceDefinition |grep traefik ingressroutes.traefik.containo.us 2021-01-25T13:25:26Z ingressroutetcps.traefik.containo.us 2021-01-25T13:25:26Z ingressrouteudps.traefik.containo.us 2021-01-25T13:25:26Z middlewares.traefik.containo.us 2021-01-25T13:25:26Z serverstransports.traefik.containo.us 2021-01-25T13:25:26Z tlsoptions.traefik.containo.us 2021-01-25T13:25:26Z tlsstores.traefik.containo.us 2021-01-25T13:25:27Z traefikservices.traefik.containo.us 2021-01-25T13:25:27Z 이제 원하는 작업인 /ost를 request path에서 제거하려면 stripPrefix 기능을 이용하면 된다. StripPrefix - Traefik | Site | v2.0 위 페이지에 있는 예제인데 쉽게 예상되는 것처럼 /foobar, /filibar라는 경로가 있으면 제거하라는 의미이다.\n# Strip prefix /foobar and /fiibar apiVersion: traefik.containo.us/v1alpha1 kind: Middleware metadata: name: test-stripprefix spec: stripPrefix: prefixes: - /foobar - /fiibar 적용해 보기 위 예제를 참조해서 다음과 같이 Middleware 를 설정한다.\n$ cat traefik-pathstrip.yaml apiVersion: traefik.containo.us/v1alpha1 kind: Middleware metadata: name: stripprefix spec: stripPrefix: prefixes: - /ost $ kubectl apply -f traefik-pathstrip.yaml middleware.traefik.containo.us/stripprefix created 다만, middleware를 route rule에 적용하려면 kubernetes의 기본 object인 ingress가 아니라 ingressRoute를 사용해야 하는 듯 하다. IngressRoute는 또 뭔지.\nIngressRoute vs. Ingress Ingress is a standard kubernetes object while IngressRoute is CRD of Traefik\nAn ingressRoute is specific to Traefik. It’s not native to Kubernetes. It is a Custom Resource Definition which allows you to take advantage of Traefik features not exposed in the Kubernetes ingress resource\nSource : What is the difference between a Kubernetes Ingress and a IngressRoute? - Stack Overflow\nIngressRoute 예제의 내용에서 Routing rule과 Middleware를 내가 필요한 대로 수정한다.\n$ cat ingress-route.yaml kind: IngressRoute apiVersion: traefik.containo.us/v1alpha1 metadata: name: ingressroutebar namespace: default spec: entryPoints: - web routes: #- match: Host(`bar.com`) \u0026amp;\u0026amp; PathPrefix(`/stripit`) - match: PathPrefix(`/ost`) kind: Rule services: - name: podcast-nginx port: 8099 middlewares: - name: stripprefix namespace: default 그 결과는\n흠…\n일단 웹 페이지 자체는 잘 보이니 routing은 잘 된 듯 한데, 스타일이 이상한 걸 보니 CSS 파일들이 제대로 적용되지 않은 듯 하다. 그리고 제일 위 쪽에 이미지가 보여지지 않는 걸 보니 CSS 파일 외에 다른 파일들의 경로가 안 맞는 듯 하다. 위 페이지에서 링크를 클릭하면 링크도 제대로 동작하지 않는다는. 결국 `URL/ost/index.html’만 제대로 라우팅이 되서 화면에 보이고 나머지는 모두 제대로 동작하지 않는 모양이ㅏㄷ.\n이미지 파일의 경로들을 이전에 잘 동작할 때와 지금 상황을 비교하니 이렇다.\n# 이전 http://192.168.0.100:8099/ http://192.168.0.100:8099/images/logo.png http://192.168.0.100:8099/podcast/cinema-2021-03-30/ # 지금 http://192.168.0.100/ http://192.168.0.100/images/logo.png http://192.168.0.100/podcast/cinema-2021-03-30/ 즉 8099 포트 지정하는 부분만 달라진 형태다.\n그런데 생각해 보니 위 두 번째 경로들은 다음과 같아야 할 것 같다. 경로에 /ost가 있어야 nginx pod로 전달이 될 텐데 그게 없어서 nginx pod로 전달이 되지 않아서 web browser에 표시가 안된 것이다.\nhttp://192.168.0.100/ost http://192.168.0.100/ost/images/logo.png http://192.168.0.100/ost/podcast/cinema-2021-03-30/ 아무래도 이건 nginx에서 설정을 변경해야 하는 것 같은데…\n$ wget http://192.168.0.100/ost/index.html --2021-03-30 23:50:44-- http://192.168.0.100/ost/index.html Connecting to 192.168.0.100:80... connected. HTTP request sent, awaiting response... 200 OK Length: 34351 (34K) [text/html] Saving to: ‘index.html’ index.html 100%[================================================================================================\u0026gt;] 33.55K --.-KB/s in 0s 2021-03-30 23:50:44 (155 MB/s) - ‘index.html’ saved [34351/34351] $ wget http://192.168.0.100:8099/index.html --2021-03-30 23:50:53-- http://192.168.0.100:8099/index.html Connecting to 192.168.0.100:8099... connected. HTTP request sent, awaiting response... 200 OK Length: 34351 (34K) [text/html] Saving to: ‘index.html.1’ index.html.1 100%[================================================================================================\u0026gt;] 33.55K --.-KB/s in 0s 2021-03-30 23:50:53 (179 MB/s) - ‘index.html.1’ saved [34351/34351] $ diff index.html index.html.1 $ 해결 예상대로 해결책은 nginx 의 설정을 변경하는 간단한 수정으로 충분했다. nginx가 hosting하는 사이트는 SSG(Static Site Generator)인 hugo를 이용해서 생성한 파일들로 구성되는데, 그 site의 root에 /ost를 추가하는 것이다. 즉 hugo 설정 파일에서 baseURL에 /ost를 추가하는 거\n$ cat config.yaml --- ... baseURL: \u0026#34;http://sosa0sa.com/ost/\u0026#34; \u0026lt;\u0026lt; 이전 값\u001e \u0026#34;http://sosa0sa.com:8099\u0026#34; 새로 site 파일을 빌드해서 nginx에 밀어넣었더니 다음과 같이 제대로 경로가 바뀌었다.\nhttp://192.168.0.100/ost http://192.168.0.100/ost/images/logo.png http://192.168.0.100/ost/podcast/cinema-2021-03-30/ 짜잔. 이젠 잘 동작한다. 당연히 집 내가 아니라 외부에서도 접속이 잘 되고. ","date":"2021-03-31T23:00:00+09:00","permalink":"https://cychong47.github.io/post/2021/2021-03-31-setup-ingress-with-traefik/","summary":"\u003cp\u003eIngress Controller 를 설치(\u003ca href=\"https://cychong47.github.io/post/2021/2021-03-30-install-traefik-with-helm/\"\u003eHelm으로 Traefik 설치하기\u003c/a\u003e)했으니 이제 Ingress를 설정해서 실제 cluster 외부로부터의 http/https 메시지를 nginx pod에 전달되게 해 본다.\u003c/p\u003e\n\u003ch1 id=\"ingress\"\u003eIngress\u003c/h1\u003e\n\u003cp\u003eIngress는 Cluster 외부에서 접근하는 http/https request에 대한 라우팅을 제어하는 기능을 제공한다.\n\u003ca href=\"https://kubernetes.io/docs/concepts/services-networking/ingress/\"\u003eIngress | Kubernetes\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eingress.yaml 파일을 다음과 같이 작성한다. . 아래는 두 가지 rule을 설정하고 있는데 host가 ‘mini1’이고, URL path가 \u003ccode\u003e/ost\u003c/code\u003e면 podcast-nginx라는 서비스로 전달하게 하는 것과 host는 상관없이 path가 \u003ccode\u003e/ost\u003c/code\u003e면 역시 같은 podcast-nginx로 보내는 것이다.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekind: Ingress\napiVersion: extensions/v1beta1\nmetadata:\n  name: \u0026#34;test\u0026#34;\n  namespace: default\n\nspec:\n  rules:\n    - host: mini1\n      http:\n        paths:\n          - path: /ost\n            backend:\n              serviceName: podcast-nginx\n              servicePort: 8099\n    - http:\n        paths:\n          - path: /ost\n            backend:\n              serviceName: podcast-nginx\n              servicePort: 8099\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eKubectl 명령을 이용해 적용해 본다.\u003c/p\u003e","title":"Setup Ingress with Traefik"},{"content":"지금 집에 있는 서버(mac mini 2009)에서 nginx를 이용해서 블로그를 호스팅하는데 port를 구분해서 외부에 노출하고 있다. 외부에서의 \u0026gt;접근을 위해 NodePort를 사용하고, 각 nginx instance는 서로 다른 port를 이용하고 있는데 port번호가 아니라 URL 경로를 이용해서 서로 다른 서비스를 이용할 수 있는 reverse proxy 기능을 사용하면 좀 더 깔끔할 듯 하다. Kubernetes에서는 ingress와 ingress controller를 이용해서 이 reverse proxy를 구현할 수 있다고 한다. Kubernetes에서는 ingress는 기본적으로 제공하는 object 지만, ingress controller는 제공하고 있지 않아, 별도로 설치해야 한다.\nIngress와 Ingress controller의 차이에 대해 헷갈렸는데 Ingress는 결국 route rule만 설정하고, 실제로 외부에서의 request를 받아 적 \u0026gt;절한 service, pod로 전달하는 역할은 ingress controller가 담당한다. Ingress Controller로 유명한 것은 Kubernets가 알려지기 전 부터 reverse proxy로 잘 알려진 nginx외에 HA Proxy Ingess Controller 등이 있다. Kubernetes.io - Ingress Controller Ingress Controller는 실제 메시지를 받아 처리해야 하므로 Service/Pod형태로 deploy된다. Ingress가 입으로 일을 하면 Ingress Controller가 실제 손, 발로 뛰면서 일을 하는 듯한?\n처음 kubernetes를 설치한 후 블로그를 띄우기 위해 nginx docker image와 Helm chart를 찾아 다닐 때 nginx web server가 아니라 nginx-ingress만 보여서 이게 뭔가 한 적이 있었는데 이제야 조금 이해를 하겠다는.\nIngress controller로 nginx-ingress가 아닌 Traefik을 설치해 보기로 했다. 그냥 에전부터 들었는데 뭐 하는 건지 이해를 하지 못해한참 바라만 보고 있던 터라 한번 사용해 보기로 마음 먹었다.\nhelm repo 추가하기 가급적 모든 app은 helm을 이용해서 설치하려고 하고 있어 Traefik역시 Helm chart를 찾는 것이 첫번째 단계다.\n$ helm repo add traefik https://helm.traefik.io/traefik \u0026#34;traefik\u0026#34; has been added to your repositories $ helm repo update Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \u0026#34;myhelmrepo\u0026#34; chart repository ...Successfully got an update from the \u0026#34;nextcloud\u0026#34; chart repository ...Successfully got an update from the \u0026#34;infracloudio\u0026#34; chart repository ...Successfully got an update from the \u0026#34;influxdata\u0026#34; chart repository ...Successfully got an update from the \u0026#34;grafana\u0026#34; chart repository ...Successfully got an update from the \u0026#34;traefik\u0026#34; chart repository Update Complete. ⎈Happy Helming!⎈ default 값을 사용하여 test deploy $ helm install traefik traefik/traefik NAME: traefik LAST DEPLOYED: Mon Jan 25 22:25:30 2021 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None Exposing Traefik dashboard Traefik의 상태를 확인할 수 있는 dashboard가 있다고 하는데 기본적으로 disable된 상태라 port-forward 명령으로 동작시킬 수 있다고.\n$ kubectl port-forward $(kubectl get pods --selector \u0026#34;app.kubernetes.io/name=traefik\u0026#34; --output=name) 9000:9000 Forwarding from 127.0.0.1:9000 -\u0026gt; 9000 Forwarding from [::1]:9000 -\u0026gt; 9000 다만 helm chart 페이지에 있는 대로만 하면 위의 로그처럼 listen하는 IP 주소가 localhost(127.0.0.1)을 사용하므로 같은 머신에서만 접근이 가능하다. 다른 머신에서도 접근할 수 있게 하려면 --address 옵션을 사용해서 listen 하는 IP 주소를 외부와의 통신이 가능한 IP를 지정하거나, 0.0.0.0과 같이 어느 IP로 접근해도 허용하겠다고 지정한다.(머신에 interface가 여러 개가 있는 경우 특정 interface에 할당된 IP를 지정하면, 해당 IP로 접근하는 것만 허용)\n$ kubectl port-forward --address 0.0.0.0 $(kubectl get pods --selector \u0026#34;app.kubernetes.io/name=traefik\u0026#34; --output=name) 9000:9000 Forwarding from 0.0.0.0:9000 -\u0026gt; 9000 Handling connection for 9000 Try again with value.yaml from Traefik 동작시키는 환경에 맞게 옵션을 변경하기 위해 helm chart value.yaml 파일을 사용한다. values.yaml 파일은 helm chart가 위치한 git repo에서 받을 수 있다. traefik-helm-chart/traefik at master · traefik/traefik-helm-chart · GitHub\n$ helm install -f value.yaml traefik traefik/traefik NAME: traefik LAST DEPLOYED: Tue Jan 26 19:04:47 2021 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None $ helm list | grep traefik traefik default 1 2021-01-26 19:04:47.633224266 +0900 KST\tdeployed\ttraefik-9.13.0 2.4.0 pod는 정상적으로 동작하는 것처럼 보이는데\n$ kubectl get pods NAME READY STATUS RESTARTS AGE ... traefik-6fd6fbd4ff-v96bk 1/1 Running 0 21s Service가 제대로 동작하고 있지 않네. EXTERNAL-IP이 pending 상태라는 건 거의 대부분(100%?) Service type을 LoadBalancer 로 되어 있어서 그렇다는.\n$ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ... traefik LoadBalancer 10.98.42.130 \u0026lt;pending\u0026gt; 80:32480/TCP,443:32398/TCP 24s service.type을 NodePort로 변경 Value파일을 수정해서 LoadBalancer 대신 NodePort를 사용하도록 한다. On-premise환경에서는 MetalLB같은 Load Balancer를 설치하지 않는 이상 NodePort를 사용해야 외부로부터의 접근이 가능하다.\nservice: ... type: NodePort #LoadBalancer .. 수정된 value 파일을 helm upgrade 명령으로 적용해 본다.\n$ vi value.yaml $ helm upgrade -f value.yaml traefik traefik/traefik Release \u0026#34;traefik\u0026#34; has been upgraded. Happy Helming! NAME: traefik LAST DEPLOYED: Tue Jan 26 19:19:06 2021 NAMESPACE: default STATUS: deployed REVISION: 2 TEST SUITE: None 다시 Pod 확인해 보고. Pod 설정에는 변경된 것이 없어 이전에 만들어진 pod가 그대로 동작하고 있다.\n$ kubectl get pods NAME READY STATUS RESTARTS AGE ... traefik-6fd6fbd4ff-v96bk 1/1 Running 0 14m Service는 설정을 변경한 대로 더 이상 Pending 상태가 아니라 None으로. 가만. None이 아니라 host의 IP 주소가 나와야 하는데. NodePort를 사용할 때는 그냥 service type만 변경하는 것이 아니라 명시적으로 IP 주소도 지정해야 한다.\n$ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ... traefik NodePort 10.98.42.130 \u0026lt;none\u0026gt; 80:32480/TCP,443:32398/TCP 14m service.externalIPs 설정 아래와 같이 IP 주소를 지정하고, 이전과 같은 방법으로 helm upgrade로 변경사항을 적용한다.\nservice: ... externalIPs: [192.168.0.100] $ helm upgrade -f value.yaml traefik traefik/traefik Release \u0026#34;traefik\u0026#34; has been upgraded. Happy Helming! NAME: traefik LAST DEPLOYED: Tue Jan 26 19:20:20 2021 NAMESPACE: default STATUS: deployed REVISION: 3 TEST SUITE: None 이젠 Service의 EXTERNAL-IP의 값이 제대로 보여진다.\n$ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ... traefik NodePort 10.98.42.130 192.168.0.100 80:32480/TCP,443:32398/TCP 15m $ kubectl get pods --selector \u0026#34;app.kubernetes.io/name=traefik\u0026#34; --output=name pod/traefik-6fd6fbd4ff-v96bk dashboard expose 설정 변경 Dashboard를 접근하기 위해 매번 port-forward 명령을 실행하는 것이 번거롭고, value 파일을 이용해서 customize 할 수 있는 상황이 되었으므로, values 파일에 있는 설정을 변경한다.\nports: # You SHOULD NOT expose the traefik port on production deployments. # If you want to access it from outside of your cluster, # use `kubectl port-forward` or create a secure ingress expose: true #false 위 코멘트대로 외부 네트워크에서의 접근은 보안상 이유로 권장하지 않긴 한데, 어차피 집 내에서만 접근하도록 설정할 거라 문제는 없을 듯.\n$ helm upgrade -f value.yaml traefik traefik/traefik Release \u0026#34;traefik\u0026#34; has been upgraded. Happy Helming! NAME: traefik LAST DEPLOYED: Tue Jan 26 22:13:04 2021 NAMESPACE: default STATUS: deployed REVISION: 4 TEST SUITE: None 다시 service 를 확인해 보면 이전과 다른 점이 보인다.\n$ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ... traefik NodePort 10.98.42.130 192.168.0.100 9000:31769/TCP,80:32480/TCP,443:32398/TCP 3h8m 이전의 PORT 필드와 비교해 보면 없던 9000 번 포트를 포워딩 하는 내용이 추가되었다.\n변경 전 : 80:32480/TCP,443:32398/TCP 변경 후 : 9000:31769/TCP,80:32480/TCP,443:32398/TCP Value 파일에서 9000 포트의 expose 항목을 true로 설정하면 아래와 같이 port-forward를 별도로 실행할 필요는 없다. 이미 9000번 포트를 kube-proxy가 listen하고 있는 상황이라…\n$ kubectl port-forward --address 0.0.0.0 $(kubectl get pods --selector \u0026#34;app.kubernetes.io/name=traefik\u0026#34; --output=name) 9000:9000 Unable to listen on port 9000: Listeners failed to create with the following errors: [unable to create listener: Error listen tcp4 0.0.0.0:9000: bind: address already in use] error: unable to listen on any of the requested ports: [{9000 9000}] 실행 옵션 변경 Traefik의 실행 옵션을 변경하려면 value 파일에서 다음 항목에 원하는 내용을 추가한다.\nadditionalArguments: - \u0026#34;--providers.kubernetesingress.ingressclass=traefik-internal\u0026#34; - \u0026#34;--log.level=DEBUG\u0026#34; Dashboard is now working - Mar 30, 2021 4:23 PM 이전에 동작하지 않은 이유는 어이없게도 URL 마지막에 / 을 넣지 않아서 라는… 헐..\nFail to access dashboard · Issue #320 · traefik/traefik-helm-chart · GitHub\nHello @Yalafeg ,\nDid you try with a trailing slash / at the end of your URL ? /dashboard/\nWithout this slash, Traefik also gives me 404 page not found\nIf it is still not working, can you provide logs of your Traefik pod ?\n역시 해결책은 본진부터 확인을 해 보는 게 가장 빠른 방법인 듯. (Traefik helm chart의 GitHub repo에 있는 Issue 목록을 뒤져서 찾아냈다는. 역시 이런 실수는 나만 하는게 아니었어 라고 위안도 얻고)\nvalues.yaml 수정 사항 151c151 \u0026lt; level: ERROR --- \u0026gt; level: DEBUG 225c225 \u0026lt; # hostPort: 9000 --- \u0026gt; hostPort: 9000 243c243 \u0026lt; expose: false --- \u0026gt; expose: true \u0026lt;\u0026lt; dashboard을 외부에 expose 할 지 말지 판단 300c300 \u0026lt; type: LoadBalancer --- \u0026gt; type: NodePort \u0026lt;\u0026lt; NodePort 사용 307,308c307,308 \u0026lt; spec: {} \u0026lt; # externalTrafficPolicy: Cluster --- \u0026gt; spec: \u0026gt; externalTrafficPolicy: Local 314c314 \u0026lt; externalIPs: [] --- \u0026gt; externalIPs: [192.168.0.100] \u0026lt;\u0026lt; NodePort 사용을 위해 Host IP 지정 install Traefik in its own namespace kubectl create ns traefik-v2 # Install in the namespace “traefik-v2” helm install -—namespace=traefik-v2 \\ traefik traefik/traefik reference GitHub - traefik/traefik-helm-chart: Traefik v2 helm chart Install And Configure Traefik with Helm ","date":"2021-03-30T09:00:00+09:00","permalink":"https://cychong47.github.io/post/2021/2021-03-30-install-traefik-with-helm/","summary":"\u003cp\u003e지금 집에 있는 서버(mac mini 2009)에서 nginx를 이용해서 블로그를 호스팅하는데 port를 구분해서 외부에 노출하고 있다. 외부에서의 \u0026gt;접근을 위해 NodePort를 사용하고, 각 nginx instance는 서로 다른 port를 이용하고 있는데 port번호가 아니라 URL 경로를 이용해서 서로\n다른 서비스를 이용할 수 있는 reverse proxy 기능을 사용하면 좀 더 깔끔할 듯 하다.\nKubernetes에서는 ingress와 ingress controller를 이용해서 이 reverse proxy를 구현할 수 있다고 한다. Kubernetes에서는 ingress는 기본적으로 제공하는 object 지만, ingress controller는 제공하고 있지 않아, 별도로 설치해야 한다.\u003c/p\u003e","title":"Helm으로 Traefik 설치하기"},{"content":"\n","date":"2021-03-13T18:16:05+09:00","permalink":"https://cychong47.github.io/post/2021/2021-03-13-i-should-have-this-one/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/03/2021-03-13-IMG_3101.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"I should have this one"},{"content":"P17\n나는 일이 계획대로 돌아가지 않을 때 그다지 걱정하지 않는 편이다. 그리고 나쁜 소식도 그저 내게 일어나고 있는 무엇이 아니라 부딛쳐서 해결할 수 있는 문제, 즉 내가 통제할 수 있는 무엇으로 보고 접근한다.\nP30\n첫째, 리스크를 감수하고 창의성을 장려하는 것\n둘째, 신뢰의 문화를 구축하는 것\n셋째, 자신에 대한 깊고 지속적인 호기심을 배양해 주변 사람들에게 영감을 불어넣는 것\n넷째, 변화를 거부하지 않고 수용하는 것\n다섯째, 항상 정직하고 고결하게 세상을 살아가는 것(그럼으로써 힘겨운 상황에 직면하게 될 것이 분명할 때조차도)\n낙관주의 - 사람들은 비관론자에게서 동기를 부여받거나 활력을 얻지 못한다. 용기 - 창의적인 의사결정에 용기는 필수다. 실패에 대한 두려움은 늘 창의성을 파괴한다. 명확한 초점 - 우선순위를 자주, 명확하게 알리는 것이 필수적이다. 결단력 - 리더는 견해의 다양성을 장려하되 결정을 내리고 실행에 옮겨야 한다. 리더가 늘 우유부단하면 효율과 생산성이 떨어질 뿐만 아니라 조직의 사기가 크게 저하된다. 호기심 - 혁신의 길은 호기심에서 시작된다. 공정성 - 자신이 저지른 실수를 정직하게 인정하고 반성했다면, 그에게는 마땅히 두 번째 기회를 주어야 한다. 사려 깊음 진정성 완벽주의 - 어떤 경우라도 완벽을 추구하라는 것이 아니라 평범함을 거부하라는 의미. 무언가가 더 나아길 수 있다고 믿는다면, 그에 걸맞은 노력을 기울여야 한다. 특히 당신이 무언가를 만드는 비즈니스에 몸담고 있다면, 그것을 최고로 위대하게 만들어야 한다. 고결함 - 품질, 고결함 P41\n나는 미래에 대해 그다지 걱정하지 않고, 무언가를 시도하고 실패하는 것에 대해서도 그다지 두려워하지 않는다.\nP42\n1,000여 개에 달하는 책상의 껌을 제거하다 보면 적어도 단조로움을 참아내는 인내심은 단련된다.\n나의 경력에 도움이 되었던 많은 특성들은 아버지와 함께 시작되었다는 것, 아버지도 그 점을 알아주셨으면 좋겠다.\nP44\n오늘날까지 나는 거의 매일 새벽 4시 15분에 일어나는 생활를 하고 있지만, 지금은 순전히 이기적인 이유 때문에 그렇게 하고 있다. 하루의 과업을 수행하기 전에 사색하고 독서하고 운동할 시간을 갖기 위해서다. 일상적으로 그런 시간을 가지면 일의 중압감에서 잠시 벗어나 생각을 좀 더 자유롭게 전개할 수 있다. 훨씬 더 창의적이고 자유로운 방식으로 문제에 접근할 수 있고, 상황을 뒤집어볼 수도 있다. 그래서 나에게는 더 없이 소중한 시간이다.\nP50\n나는 룬이 왜 그렇게 했는 지 당시에는 이해하지 못했지만, 나중에 ‘웬만큼 괜찮은 것’을 받아들이지 않는 태도, 자기가 맡은 일을 최고로 위대하게 만들기 위해서라면 옴짝달싹할 수 없는 데드라인 앞에서도 대담하게 밀어붙이는 것이 전형적인 룬의 방식임을 알게 되었다.\nP57\n룬이 내게 준 금언이 하나 있다. 그것은 이후 내가 맡은 모든 직무에 길잡이가 되었다.\n‘혁신 아니면 죽음이다. 새로운 것이나 검증되지 않음을 두려워하면 혁신은 없다.\n룬에게는 너무 사소해서 무시해도 좋은 세부사항이라는 게 없었다. 그가 생각하는 완벽은 모든 사소한 것들을 바로 잡아서 얻어내 결과였다.\n리더십의 특징 중 하나인 이것을 나는 ‘완벽에 대한 집요한 추구’라고 표현한다.\n적어도 내가 내면화한 바로 그것은 ‘어떤 것을 희생하더라도 반드시 달성해야 하는 완벽주의’가 아니다.\n평범함을 받아들이기를 거부하는 환경을 조성하는 것이 핵심이다. 사람들은 본능적으로 ‘시간이 충분하지 않아서’, ‘의욕이 없어서’, ‘그러려면 곤란한 대화를 나눠야 해서’ 같은 핑계를 먼저 댄다. 그러면서 ‘그저 적당한 수준’임에도 불구하고 ‘이만하면 괜찮지’하며 스스로를 납득시키기 위해 많은 방법을 동원한다.\nP65\n나는 룬이 자신의 권위를 행사하는 방식을 편안하게 받아들일 수 있었고, 그의 좋은 면에 대해서는 동기를 부여받고 나쁜 면에 대해서는 사적으로 상처받지 않기 위해 노력했다.\n…\n그래서 나는 룬의 기분에 휘둘리는 대신 내가 하는 일과 내가 몸담은 직장의 긍정적인 면에 초점을 맞추었다.\nP75\n나는 곧 내가 그를 완전히 잘못 평가하고 있었다는 사실을 알게 되었다. 그는 정감이 넘치고 재미있는 사람이었다. 그의 에너지와 낙관주의는 전염성이 있었다. 그리고 결정적으로 그는 자신이 무엇을 모르는지 알았을 분 아니라 자모른다는 것을 인정할 줄도 아는 사람이었다.\nP76\n그들의 사업전략은 매우 단순했다. 비용관리에 고도로 주의를 기울이면서 중앙집권형이 아닌 분산형 조직의 가치를 믿었다. 모든 핵심적인 결정을 반드시 최고위경영진이나 본사의 소규모 전략가들이 내려야 한다고 생각하지 앉혔다는 뜻이다. 그들은 똑똑하고 품위 있고 열심히 일하는 사람들을 고용해 막중한 책임을 져야 하는 자리에 앉혔고, 대신 자율성을 보장하며 일하는 데 필요한 지원을 아끼지 않았다. 또한 직원들이 항상 쉽고 편하게 다가갈 수 있도록 시간을 엄청나게 후하게 내주었다. 때문에 경영진을 비롯한 구성원 대부분이 그들의 우선순위가 무엇인지 명확히 이해하고 있었고, 언제나 중요한 일에 집중할 수 있었다.\nP79\n상황은 확실히 끔찍했지만, 나는 그것을 재앙이 아니라 풀어야 할 퍼즐로 보고 우리 팀이 이러한 문제를 해결하고 멋진 무언가를 도출해낼 만큼 재능 있고 민첩하다는 점을 모두에게 인지시킬 필요가 있었다.\nP82\n경력 전반에 걸쳐 나는 항상 모든 기회에 본능적으로 ‘예스’라고 답했다. 어느 정도는 흔해 빠진 야망 때문일 수도 있다. 나는 위로 올라 가 더 많은 것을 배우고 실행해보고 싶었고, 그렇게 할 수 이는 어떤 기회든 포기하고 싶지 않았다. 하지만 그와 더불어 익숙하지 않ㅇ는 일도 잘 해낼 수 있다는 것을 나 자신에게 증명해 보이고 싶었다.\nP86\n“인생은 모험이야” 아내는 말했다. “모험의 길을 선택하지 않으면 저대로 사는 게 아니지”\nP90\n나의 무경헙은 실패의 변명이 될 수 없다.\nP96\n주변의 모든 것이 바뀌고 있는데 우리만 그저 예전과 동일한 자세를 취하고 안주할 수는 없었다. 다시 한번 룬의 교훈이 절절하게 울리던 시점이었다. “혁신 아니면 죽음이다”\nP105\n나는 안전지대에 머물길 원치 않았다. 위대함을 만들어낼 가능성 있는 작업에 몰두하고 싶었다. 실패를 편안하게 받아들일 필요성, 그것이 황금시간대를 맡은 그 첫해에 내가 배운 모든 교훈 중에서 가장 심오한 것이었다. 이는 결실이 부족한 것에 대한 변명이 아니라 불가피한 진리에 대한 강조다. 혁신을 원한다면(반드시 언제나 혁신을 원해야만 한다), 실패를 받아들일 필요가 있다.\nP109\n진정한 성취에 대한 영예를 받아들이는 것과 외부의 과찬에 너무 빠져들지 않는 것 사이에서 균형을 찾는 것 역시 중요했다.\nP126\n사업가로서 그들은 비용관리와 수익증대에 열정적으로 초점을 맞추면서 마찬가지의 원칙을 고수하기만 하면 원하는 만큼 오래 그들을 위해 일할 수 있는 임원들을 주변에 두었다.\n그들은 또한 분산형 기업구조의 가치를 믿었다. 만약 어떤 임원이 윤리적으로 행동하는 가운데 특정 예산에 대한 타당성을 주장하면 그들은 그에게 재량권을 주었다. CFO와 법률자문위원을 제외하고 본사임원을 따로 두지 않았으며, 따라서 중앙집중적인 관료조직도 없었다. 그들은 그렇게 각 사업부분에 대한 간섭을 최소화했다.\n하지만 디즈니는 모든 것이 정반대였다. 마이클 아이즈너와 프랭크 웰스는 회사 경영을 맡은 초기부터 ‘전략기획실’이라는 중앙부서를 조직해 교육수준이 높고 극단적인 일단의 임원들을 그곳에 배치했다(그들 모두 MBA를 보유했고, 다수가 하버드나 스탠퍼드 출신이었다) 그들은 주로 분석작업을 수행했고, 마이클이 필요로 하는 데이터와 ‘통찰’을 제공했다. 마이클은 회사가 내리는 모든 사업적 결정의 안정성 여부를 판단하기 위해 그런 통찰을 필요로 했으며, 창작과 관련된 결정은 모두 본인이 직접 내렸다. 전략기획실은 회사의 나머지 부분에 대해 상당한 권한을 행사했으며, 다양한 사업부문을 운영하는 디즈니의 모든 고위임원들을 상대로 스스럼없이 권력을 휘둘렀다.\nP130\n그러나 여기서 되새겨볼 것은, 당신을 위해 일하는 사람들을 신뢰하고, 그들에게 기업가정신을 갖게끔 독려하는 것이 중요하다는 교훈이다.\nP134\n나는 늘 회의 전에 미리 자료를 준비해 그(오비츠)에게 주곤 했는데, 다음 날 그는 자료를 하나도 읽지 않고 나타나 “팩트를 제시해보세요”라고 말한 다음 빠르게 자신의 의견을 개진하곤 했다. 그가 모든 정보를 완벽하게 숙지했기 때문에 빠르게 움직이는 게 아니었다. 실상은 그 반대였다. 아무것도 준비되어 있지 않다는 사실을 은폐하려 애쓸 뿐이다.\nP172\n물론 마이클은 비관론을 견지할 만한 정당하고도 충분한 이유가 있었다. 하지만 리더는 그런 비관주의를 주면 사람들에게 퍼뜨려서는 안 된다. 구성원들의 사기를 떨어뜨리고 에어지와 영감을 얼어붙게 만들며 방어적인 의사결정을 낳기 때문이다.\nP195\n그것에 관해서는 꽤 많은 시간 동안 고심했던 터라 나는 즉각적으로 항목을 나열하기 시작했다. 대여섯 개 쯤 짚어나가자 그는 고개를 저으며 이렇게 말했다.\n“스톱. 그렇게 많으면 우선사항이라고 할 수 없잖아요”\n우선사항이란 많은 시간과 큰 자본을 투입할 극소수의 대상이어야 한다. 그 목록이 지나치게 길면 중용성이 떨어질 뿐만 아니라 아무도 그것을 기억하지 못한다.\n“산만해 보일 뿐입니다” 스콧이 말했다. “딱 3가지만 선택하세요”\nP196\n기업의 조직문화는 많은 요소들에 의해 그 형태를 갖춘다. 그중에서 가장 중요한 것이 바로 리더가 ‘우선사항’을 반복적으로 명확하게 전달하는 일이다. 내가 경험한 바에 의하면, 그것이 바로 위대한 경영자와 나머지를 가르는 요건이다. 리더가 우선사항을 명확하게 제시하지 못하면 주변 사람들은 일할 때 무엇에 우선순위를 두어야 하는 지 알지 못한다. 시간과 에너지, 자본이 낭비되고 마는 것이다. 또한 구성원들은 어디에 집중해야 할지 모르기 때문에 불필요한 불안감에 시달리게 된다. 결국 비효율이 만연하고 불만이 쌓이며 사기는 곤두박질치는 것이다.\nP200\n구성원들로부터 존경받지 못하는 기업이 외부의 존중이나 대중의 인정을 바라는 것은 어불성설입니다. 직원들이 회사를 자랑스러워하며 미래에 대한 확신을 갖고 일하도록 만드는 방법은 그들이 자랑스러워할 만한 제품을 만들어내는 것입니다. 그렇게 간단한 일입니다.\n직원들의 사기와 관련해 내가 언급한 좀 더 현실적인 문제들도 있었다. 지난 세월 디즈니의 거의 모든 비창작 업무에 대한 결정은 중앙의 관리감독 그룹에서 내렸다. 앞서 언급한 그’ 전략기획실’ 말이다. 전략기획실은 최고의 경영대학원에서 MBA를 딴 65명의 분석 전문가들로 구성되었으며 본사 건물의 4층을 점령하고 있었다. 회사가 확장되어감에 따라 그에 대한 마이클의 의존도는 점점 더 높아졌다. 마이클은 모든 의사결정에 대한 분석작업을 거기에 맡기며 다양한 사업에 대한 전략을 요청했다.\n그들은 자신들의 업무 분야에서는 최고였기에 많은 측면에서 합당한 방법이었다. 그러나 2가지 문제점이 대두되었다. 하나는 앞서 언급한 바와 같이 중앙집중적 의사결정이 각 사업부문을 이끄는 고위경영진의 의욕을 저하시킨다는 것이었다. 자신이 리더로서 책임을 맡은 사업부문의 의사결정을 실질적으로 전략기획실이 하는 셈이니 사기가 저하될 수 밖에 없었다. 또 다른 하나는 과도하게 분석적인 그들의 의사결정 과정이 너무 고되고 느리다는 점이었다.\n“세상은 불과 2년 전과 비교하더라도 그 속도의 차이를 실감할 수 있을 정도로 빠르게 돌아가고 있습니다.” 이사회의 임원들을 향해 내가 말했다. “세상의 변화 속도는 앞으로 계속 발라질 겁니다. 그러므로 우리의 의사결정 과정은 더욱 즉각적이고 신속해질 필요가 있습니다. 저는 그렇게 만들 방법을 찾아야만 한다고 봅니다”\n각 사업부문의 리더들이 스스로 의사결정 과정에 보다 깊이 참여하고 있다고 느낀다면, 그것은 곧 조직 전체의 사기 진작에 긍정적 영향을 미치는 낙수효과로 이어질 터였다. 당시에는 나 자신조차 그 효과가 얼마나 극적이고 즉각적일 지 가늠할 수 없었다.\nP210\n돌이켜 생각해 보면 그것은 나에게 끈기와 인내심의 중요성 그리고 스스로 통제할 수 없는 것에 대한 분노와 불안을 피해야 할 필요성을 동시에 일깨운, 실로 힘겹게 얻은 교훈이었다. 자존심을 지키되 거기에 과도하게 정신적 에어지를 낭비하지 말라야 한다(종종 그런 일이 벌어진다) 이 점은 아무리 강조해도 지나치지 않다 모든 사람이 나를 훌륭하다고 평가할 때 긍정적인 생각을 갖는 것은 어렵지 않다. 하지만 자신의 정체성을 침범당할 때, 그것도 그렇게 공개적인 방식으로 도전을 받을 때, 긍정적인 생각을 갖기란 결코 쉽지 않다. 하지만 그럴 때일수록 필요한 것이기도 하다.\n나에 대한 수근거림을 완전히 걸러내는 일은 물론이고 내가 그 자리에 얼마나 부적합한지에 대해 매우 공개적으로 이루어지는 대화들로부터 상처받지 않는 일도 불가능했다. 그러나 강한 자제력과 가족의 사랑에 힘입어 나는 그것을 있는 그대로 인식하고(나라는 사람의 본질과는 무관한 것이었으므로) 적절히 묻어두어야 한다는 것을 배웠다. 어떤 행동을 하고 어떻게 스스로를 위로하는가 하는 부분은 내가 통제할 수 있었다. 그 외의 다른 모든 것들은 내가 통제할 수 있는 범위에서 벗어난 것들이었다. 모든 순간 그런 시각을 견지할 수는 없었지만, 할 수 있는 최대한 그렇게 하고자 노력했고, 나는 지나친 불안감에 휩싸이지 않을 수 있었다.\nP220\n조직을 재편해 전략적 책임을 각 비즈니스 부문으로 옮겨 놓는 일을 시작해야만 했다. 그것도 가급적 빨리 말이다. 사업부문 전반에 걸친 전략기획실의 장악력을 감소시키면 느리게나마 조직 전체의 사기가 진작될 것이었다. 그것이 나의 바람이었다.\nP232\n나는 전략기획실이 기여한 가치도 분명 인정했다. 하지만 해가 갈수록 부서의 규모가 너무 확장되었고 권한 또한 너무 강력해진 것이 문제였다. 그들이 더 큰 영향력을 휘두르면서 개별 사업부문을 맡은 임직원의 권한은 점점 줄어들 수 밖에 없었다. 마이클이 나를 COO로 임명했을 무렵 전략기획실에 소속된 직원 수는 무려 65명이었고, 회사 전반에 걸쳐 주요한 의사결정 권한의 거의 전부를 장악하고 있었다.\nP235\n전략기획실의 재편은 정식취임을 앞둔 6개월 기간에 내가 한 일 중 가장 중요한 성과로 입증되었다. 즉각적이고 실질적인 효과가 나타날 것으로 예상했지만, 실제는 기대 이상이었다. 전략기획실의 비즈니스의 모든 측면에서 막강한 권한을 휘두르는 일이 더 이상 없을 것이라는 공식발표가 나가자마자 조직 전체의 사기가 실로 놀라울 정도로 진작되었다. 마치 굳게 닫혔던 창문들이 일시에 열려 신선한 공기가 내부로 밀려들어오는 것과 같았다. 당시 한 고위임원은 나에게 이렇게 말했다.\n“디즈니 전역에 교회 종들이 있다면 그것들이 일제히 울리고 있는 셈입니다”\nP250\n나에게 스스로에 대한 기대치를 현실적 수준으로 갖는 게 좋지 않겠느냐는 의미였다. 하지만 그날 밤 아내가 재차 상기시킨 그 말에는 어차피 잃을 것도 거의 없는 마당이니 신속하게 움직이는 게 좋겠다는 의미가 함축되어 있었다. 아내가 준 조언의 핵심은 “과감하게 움직이라”는 것이었다.\nP252\n때때로 사람들은 대대적인 변화를 기피하려 든다. 첫발자국을 떼어놓기도 전에 무언가에 대한 시도가 승산이 있는 지 판단하고 부정적 결과를 부각시키기 때문이다. 내가 언제나 직감적으로 느끼는 무언가가 있다면, 그것은 아무리 승산이 없어 보여도 대개는 그렇게 절망적이지는 않다는 것이다.\n충만한 에너지와 신중함 그리고 헌신적인 마음만 있다면 아무리 과감한 아이디어일지라도 반드시 실행에 옮길 수 있다고 믿었다. 나는 이후 스티브와의 대화에서 그런 사고방식을 갖추려고 노력했다.\nP254\n“견실한 장점 한두 가지가 수십 가지 단점보다 강력한 법이지요”\n스티브 잡스\nP256\n몇 명씩 모여 미팅을 하거나 서성거리며 한담을 나누는 모습이 영화제작사라기보다는 대학의 학생회관을 연상케 했다. 창의적인 에너지와 활기가 넘치는 장소였다. 모두가 그곳에 있다는 사실에 만족스러워하는 것처럼 보였다.\nP260\n다른 모든 일도 마찬가지겠지만 상황에 대한 정확한 인지가 핵심이다. 주변의 평가에 귀를 기울이고 자신의 동기화 자신이 신뢰하는 사람들의 조언, 면밀한 조사와 분석의 결과 그리고 분석을 통해 알 수 없는 것에 이르기까지 모든 요소를 따져봐야 한다. 어떤 상황도 서로 같을 수 없다는 사실을 이해하며 이 모든 요소를 신중하게 고려하고 나면 리더의 직감이 궁극적 잣대로 작용하는 순간이 찾아온다. 이것은 과연 올바른 결정인가 아니면 그렇지 않은가? 확실은 것은 아무것도 없다. 그러나 적어도 큰 리스크를 기꺼이 감수할 필요는 있따. 큰 리스크를 감수하지 않으면 그만큼 빛나는 성과도 없다.\nP261\n픽사가 보유한 탁월한 조직문화와 그들의 넘치는 의욕이 바람직한 방식으로 조직 전방에 반향을 불러일으킬 것이다.\n최종적으로 이사회의 승인을 받지 못할 수도 있었다. 그러나 그게 두려워서 이런 좋은 기회를 놓칠 수는 없었다.\nP263\n인수작업을 진행하는 기업들은 정작 자신들이 무엇을 인수하는 지와 관련해서 세심한 주의를 기울이지 못하는 경우가 많다. 단순히 유형재산이나 제조자산 혹은 지적재산권을 획득하는 것으로 인식하기 때문이다. 하지만 대부분의 경우 그들이 실제로 인수하는 것은 사람들이다. 창의성을 기반으로 하는 비즈니스에서는 바로 사람들에게 기업의 진정한 가치가 있는 것이다.\nP271\n시어도어 루즈벨트의 유명한 연설문인 ‘경기장 안에 있는 사람 The Man in the Arena’을 다시 한번 훝어보기도 했다. 오랜 기간 나에게 영감을 준 연설문이었다. “중요한 것은 비평가가 아니다. 어떻게 하면 강자가 휘청거리는지, 어떻게 하면 더 잘할 수 있었는지 지적하는 사람도 아니다. 영광은 먼지와 함께 피로 범벅된 채 실제로 경기장 안에서 뛰고 있는 자의 몫이다”\nP305\n“일을 잘하는 것에 더하여 인성도 바른 사람들로 주변을 채우라”\nP342\n우리가 풀어야 할 문제는 다음과 같았다. 우리는 그 목표를 달성하는데 필요한 기술을 찾아 변화의 선두에 설 수 있는가? 새로운 모델을 구축하기 위해 여전히 수익성이 있는 기존 사업을 축소시킬 배짱이 있는가? 우리는 우리 자신을 파괴할 수 있는가? 우리가 회사를 진정으로 현대화하고 변혁하는 과정에서 불가피하게 발생하는 손실을 과연 월스트리트는 용인할 것인가?\nP344\n우리는 2017년 전체 세션의 주체를 ‘파괴 disruption’로 잡고 각 사업부문의 리더에게 그들이 목도하고 있는 파괴의 수준과 그것이 각 사업의 건전성에 미칠 영향에 대한 예측을 이사회에서 프레젠테이션하도록 지시했다.\nP346\n이사회는 이 계획을 지지했을 뿐 아니라 ‘속도가 핵심’이라고 강조하며 가능한 한 빨리 움직일 것을 촉구했다(이것이 바로 분명한 견해를 가진 현명한 사람들, 시장의 역학에 직접적으로 관련된 사람들로 이사회를 구성해야 하는 이유이다. 각자의 업계에서 심오한 파괴를 경험하고 있는터라 신속하게 변화에 적응하지 못할 경우 처하게 될 위험을 예리하게 인식하고 있었다)\nP353\n“기업이 혁신을 꾀하지 못하는 이유를 알고 있습니까?” 내가 말했다. “전통 때문입니다. 전통이 매 단계에서 마찰을 일으키기 때문이지요”\n나는 투자업계에 대해서도 이야기했다. 투자업게는 어떤 상황에서든 수익이 줄어든 기업에 벌을 주려고 든다. 그래서 기업들이 종종 장기적인 성장을 도모하거나 변화에 적응하기 위해 자본을 쓰는 대신 기존 방식을 고수하며 안전지대에 머물려 하는 것이다.\nP380\n그것은 나에게 그리 어려운 결정이 아니었다. 프로그램을 폐지함으로 인해 발생할 수 있는 재무적 여파가 무엇인지 알아보지도 않았을 뿐더러 그에 대해서는 신경도 쓰지 않았다. 그런 상황에서는 사람과 제품의 품질, 진실성이 다른 무엇보다 중요하다는 원칙이 우선적이었고, 모든 것은 그 원칙을 얼마나 철저하게 고수하느냐에 달려 있었기 때문이다.\nP395\n사소한 것들로부터 바뀌기 시작한다. 자신감이 자신에 대한 과도한 신뢰로 바뀌고 결국 장애가 되기도 한다. 이미 모든 것을 안다고 느끼기 시작하면, 인내심이 사라지고 타인의 의견을 묵살할 수도 있다. 물론 의도적인 것은 아니겠지만 대개는 그렇게 된다는 말이다. 그래서 주변 사람들의 말에 더욱 귀를 기울이고 다양한 의견에 관심을 보이고자 의식적으로 노력해야 한다.\nHigh-quality contents\nTechnology\nGlobal business\n","date":"2021-03-10T23:36:30+09:00","permalink":"https://cychong47.github.io/post/2021/2021-03-10-the-ride-of-a-lifetime/","summary":"\u003cp\u003eP17\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e나는 일이 계획대로 돌아가지 않을 때 그다지 걱정하지 않는 편이다. 그리고 나쁜 소식도 그저 내게 일어나고 있는 무엇이 아니라 부딛쳐서 해결할 수 있는 문제, 즉 내가 통제할 수 있는 무엇으로 보고 접근한다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eP30\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e첫째, 리스크를 감수하고 창의성을 장려하는 것\u003cbr\u003e\n둘째, 신뢰의 문화를 구축하는 것\u003cbr\u003e\n셋째, 자신에 대한 깊고 지속적인 호기심을 배양해 주변 사람들에게 영감을 불어넣는 것\u003cbr\u003e\n넷째, 변화를 거부하지 않고 수용하는 것\u003cbr\u003e\n다섯째, 항상 정직하고 고결하게 세상을 살아가는 것(그럼으로써 힘겨운 상황에 직면하게 될 것이 분명할 때조차도)\u003c/p\u003e","title":"디즈니만이 하는 것(The ride of a lifetime)"},{"content":"어쩌다 출근의 IT개발자의 일상을 보고 여의도 고층 사무실에 있는 핀테크 스타트업에 다니는 청년의 하루를 보여준다.\n미국 대학을 졸업하고 페이스북에서 5년간 일하고 국내에 들어온 친구가 회사의 Data Foundation team이라는 곳의 팀장 업무를 담당하고 있다. 직접 코딩도 하고, 팀원들도 챙기고, CEO와 미팅도 하고.\n특이한 건 랩탑을 2개 사용하고 있었다는. 하나는 문서 작업 용, 다른 하나는 코딩 용이라고 하는데 왜 그렇게 나눠서 사용하는 지는 잘 모르겠지만…\n암튼 문득 생각이 들었다. 절대로 이 회사는 저런 회사를 따라갈 수 없다고.\n저긴 랩탑을 가지고 출퇴근 한다. 이 회사가 걱정하는 보안 걱정을 어떻게 해결하는 지는 알 수 없다.\n다만 확실한 건, 적어도 이 회사에서 걱정하는 것처럼 누군가 회사 직원이 회사의 기밀을 빼돌려서 피해를 주는 걸 덜 걱정할 거라고. 그 회사라고 기밀이 없을리 없다. 그렇다고 이 회사처럼 물리적으로 그리고 시스템 측면에서 보안을 구비하기는 쉽지 않을 것이다. 이 또한 많은 비용이 들어갈 터라.\n그럼 그 회사는 뭘 믿고 저렇게 허술해 보이는 보안체계를 가지는 걸까?\n입사할 때 모두 충성도를 시험이라도 보나?\n아니면 신통한 점쟁이를 데리고 와서 보안 문제를 일으키지 않을 사람들을 골라서 뽑는 걸까?\n그런 건 아닐 거다.\n회사의 성공이 개인에게 주는 의미의 차이 아마도 그 회사의 직원들이 그러지 않을 거라는 생각을 가지고 있을 것 같다.\n이 순진한 생각이 그럴듯 한 것처럼 느껴지는 건 회사의 성장이 곧 직원들 자신들에게 이득으로 돌아온다는 걸 알기 때문이 아닐까 싶다.\n지금 이 회사에서는 일을 열심히 한다고 해서 그 성과가 사업의 성공과 연결되는 것은 쉽지 않다. 개개인에게 맡겨지는 역할은 사업중 대부분 아주 작은 부분인 경우가 많고, ‘의미’가 보일 정도의 비중을 갖는 역할은 대개 임원급에게 맡겨진다. 그런 상황에서 사업의 성공, 회사의 성공과 ‘나’와의 관계는 아주 약한 고리 만을 갖는다.\n당연히 내가 비록 작은 부분이라도 참여하는 제품의 성공, 사업의 성공이 내게 불이익으로 돌아올 일은 전혀 없으므로 일을 열심히 안할 이유는 결코 없다. 하다못해 성과금이라도 덜 나오지는 않을 거라.\n하지만 그렇다고 해서 정말 열심히 해야 할 이유도 분명하지 않다. 어차피 내가 열심히 해서 내가 맡은 부분이 완벽하게 만들어졌다 해도 그 완벽함이 사업에 어떤 기여를 하는 지 측정하는 것은 거의 불가능에 가깝다.\n사업이 성공하고, 좋은 평가를 갖는 경우에 그저 ‘나도 이 성공에 기여했지.’라는 뿌듯함을 갖는 걸로 끝이다.\n하지만 저런 회사는 다르다. 규모가 작은 덕에, 개개인의 제품, 사업 그리고 회사에서 차지하는 비중이 상대적으로 크다. 그리고 내가 하는 업무의 성패가 제품에 사업에 그리고 회사에 더 큰 영향을 미친다. 그리고 그 만큼 그 성패는 내게 직접적인 보상으로 돌아온다. 대부분 스톡옵션으로 대표되겠지만, 금전적으로 그리고 그 만큼 중요한 업계에서의 평판으로 활용될 수 있는 경험을 쌓을 기회가 된다.\n이런 환경에서는 결코 나 하나의 욕심을 채우기 위해 보안 사고를 쳐서 내가 속한 조직을 망가뜨릴 사람은 많지 않을 것이다. 혹시 그럴 지 모르는 의직증(의부증, 의처증 처럼 ‘직원들을 의심하는 증’)을 풀기 위해 직원들의 일하는 환경을 제한하고, 효율을 떨어트리는 것보다는 직원들과 회사의 공동체 운명을 더 강하게 만들어 직원들로 하여금 보안에 대한 제약없이 일하는 대신 그 만큼의 동료들과 회사에 대해 충성하길 만드는 똘똘한 선택을 한 것이 아닌 가 싶다.\n결국 한 문장으로 말하면 그런 회사는 자의건 타의건 직원들을 공동운명체로 보지만, 이 회사는 그렇지 않다. 언제든지 조직을 배신할 수 있고, 보안 허점을 이용해서 회사의 소중한(?) 기밀을 빼돌릴 수 있는 잠재적인 위험요소로 보는 것이다. 그렇기에 워라벨이라는 허울좋은 말을 내세우면서 회사와 직원간에 눈에 보이는 장벽을 치고, 울타리에서만 일하라고 요구하는 것이다.\n그러니 이 두가지 회사는 결코 같을 수 없고, 특히 이 회사는 저런 회사와 경쟁할 수 없다. 정말 대규모 투자가 필요한 경우가 아니라면 절대 경쟁이 되지 않는다. 하지만 어차피 그런 분야는 현명하게 저런 회사들이 정면승부를 하지 않거나, 그런 분야는 신경 쓰지 않는다.\n다만, 경쟁 분야에서는 비교가 되지 않을 것이다. 확보할 수 있는 인력 수준이나 그들이 일하는 속도, 효율은 비교 불가다.\n정말 20년 전에 일하던 회사 환경과 지금을 생각해 보면 별다르게 달라진 게 없다. 달라진 건 컴퓨터 사양이 근래(그나마 늘 최신 사양보다는 뒤쳐지는) 걸로 바뀐 거 정도. 책상 폭은 오히려 좁아지고 여전히 일자 형태의 닭장 같은\n과연 달라질까 정말 틀렸다는 걸 모르는 걸까…\n왜 예전과 달리 점점 저런 회사들에 좋은 친구들이 몰리는 지.\n그게 이 회사에 어떤 영향을 미치게 될 지.\n하긴 관심이 없을 수도 있을 지 모른다. 어차피 그들도 이 회사를 위해서 일하는 건 아닐 테니..\n","date":"2021-03-07T00:07:15+09:00","permalink":"https://cychong47.github.io/post/2021/2021-03-07-how-can-they-trust-employees/","summary":"\u003ch3 id=\"어쩌다-출근의-it개발자의-일상을-보고\"\u003e어쩌다 출근의 IT개발자의 일상을 보고\u003c/h3\u003e\n\u003cp\u003e여의도 고층 사무실에 있는 핀테크 스타트업에 다니는 청년의 하루를 보여준다.\u003cbr\u003e\n미국 대학을 졸업하고 페이스북에서 5년간 일하고 국내에 들어온 친구가 회사의 Data Foundation team이라는 곳의 팀장 업무를 담당하고 있다. 직접 코딩도 하고, 팀원들도 챙기고, CEO와 미팅도 하고.\u003cbr\u003e\n특이한 건 랩탑을 2개 사용하고 있었다는. 하나는 문서 작업 용, 다른 하나는 코딩 용이라고 하는데 왜 그렇게 나눠서 사용하는 지는 잘 모르겠지만…\u003cbr\u003e\n암튼 문득 생각이 들었다. 절대로 이 회사는 저런 회사를 따라갈 수 없다고.\u003cbr\u003e\n저긴 랩탑을 가지고 출퇴근 한다. 이 회사가 걱정하는 보안 걱정을 어떻게 해결하는 지는 알 수 없다.\u003cbr\u003e\n다만 확실한 건, 적어도 이 회사에서 걱정하는 것처럼 누군가 회사 직원이 회사의 기밀을 빼돌려서 피해를 주는 걸 덜 걱정할 거라고. 그 회사라고 기밀이 없을리 없다. 그렇다고 이 회사처럼 물리적으로 그리고 시스템 측면에서 보안을 구비하기는 쉽지 않을 것이다. 이 또한 많은 비용이 들어갈 터라.\u003cbr\u003e\n그럼 그 회사는 뭘 믿고 저렇게 허술해 보이는 보안체계를 가지는 걸까?\u003cbr\u003e\n입사할 때 모두 충성도를 시험이라도 보나?\u003cbr\u003e\n아니면 신통한 점쟁이를 데리고 와서 보안 문제를 일으키지 않을 사람들을 골라서 뽑는 걸까?\u003cbr\u003e\n그런 건 아닐 거다.\u003c/p\u003e","title":"How can they trust employees"},{"content":"\n","date":"2021-03-07T00:04:22+09:00","permalink":"https://cychong47.github.io/post/2021/2021-03-07-i-love-akmu/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/03/2021-03-07-IMG_3010.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"I love AKMU"},{"content":"\n","date":"2021-03-06T17:12:50+09:00","permalink":"https://cychong47.github.io/post/2021/2021-03-06-stool-under-the-desk/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/03/2021-03-06-IMG_3009.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"책상 아래 stool"},{"content":"$ sudo apt install -y cockpit sssd-dbus $ sudo ufw allow 9090/tcp ; sudo systemctl start cockpit` $ ss -tunlp |grep 9090 tcp LISTEN 0 4096 *:9090 *:* CPU load 정보가 주기적으로 100%까지 튀네. 거의 10초 단위로. 뭘까 여러 개의 리눅스 서버가 있는 경우 한 곳에 추가해서 single glass of pane을 만들 수도 있다. 추가된 서버들은 dashboard에서 drop list로 보여지므로 원하는 대상을 선택 ","date":"2021-03-04T22:06:00+09:00","permalink":"https://cychong47.github.io/post/2021/2021-03-04-install-cockpit/","summary":"\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo apt install -y cockpit sssd-dbus\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo ufw allow 9090/tcp ; sudo systemctl start cockpit`\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ ss -tunlp |grep 9090\ntcp   LISTEN 0      4096                       *:9090             *:*\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"/images/2021/03/2021-03-04-cockpit-web.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eCPU load 정보가 주기적으로 100%까지 튀네. 거의 10초 단위로. 뭘까\n\u003cimg src=\"/images/2021/03/2021-03-04-cockpit-cpu.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e여러 개의 리눅스 서버가 있는 경우 한 곳에 추가해서 single glass of pane을 만들 수도 있다.\n\u003cimg src=\"/images/2021/03/2021-03-04-cockpit-add-another-host.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e추가된 서버들은 dashboard에서 drop list로 보여지므로 원하는 대상을 선택\n\u003cimg src=\"/images/2021/03/2021-03-04-cockpit-show-another-host.png\" alt=\"\"\u003e\u003c/p\u003e","title":"Install cockpit - linux server manager"},{"content":"How to change IP address of k3s By default, as k3s operates in the local host, it is not possible to connect from other host.\nTo get the server Ip address,\n$ kubectl config view --raw |grep server server: https://127.0.0.1:6443 The listening server IP address can be specified by giving parameter in running the k3s binary.\nK3s configuration is on /etc/systemd/system/k3s.service\n$ cat /etc/systemd/system/k3s.service [Unit] Description=Lightweight Kubernetes Documentation=https://k3s.io Wants=network-online.target After=network-online.target [Install] WantedBy=multi-user.target [Service] Type=notify EnvironmentFile=/etc/systemd/system/k3s.service.env KillMode=process Delegate=yes # Having non-zero Limit*s causes performance problems due to accounting overhead # in the kernel. We recommend using cgroups to do container-local accounting. LimitNOFILE=1048576 LimitNPROC=infinity LimitCORE=infinity TasksMax=infinity TimeoutStartSec=0 Restart=always RestartSec=5s ExecStartPre=-/sbin/modprobe br_netfilter ExecStartPre=-/sbin/modprobe overlay ExecStart=/usr/local/bin/k3s \\ server \\ \u0026#39;--write-kubeconfig-mode\u0026#39; \\ \u0026#39;644\u0026#39; \\ Append server IP address of ExecStart option\nExecStart=/usr/local/bin/k3s \\ server \\ \u0026#39;--write-kubeconfig-mode\u0026#39; \\ \u0026#39;644\u0026#39; \\ --bind-address 0.0.0.0 \\ Refer to the additional options Rancher Docs: K3s Server Configuration Reference\nThen restart the k3s service\n$ sudo systemctl restart k3s $ sudo systemctl daemon-reload Check again\n$ kubectl config view --raw |grep server server: https://0.0.0.0:6443 To use the kube configuration from other host, change the server IP address of result of kubectl config view —raw to the host IP address of node.\n#kubernetes/k3s\n","date":"2021-03-03T13:17:28+09:00","permalink":"https://cychong47.github.io/post/2021/2021-03-03-change-the-server-ip-address-of-k3s/","summary":"\u003ch1 id=\"how-to-change-ip-address-of-k3s\"\u003eHow to change IP address of k3s\u003c/h1\u003e\n\u003cp\u003eBy default, as k3s operates in the local host, it is not possible to connect from other host.\u003c/p\u003e\n\u003cp\u003eTo get the server Ip address,\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ kubectl config view --raw |grep server\n    server: https://127.0.0.1:6443\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThe listening server IP address can be specified by giving parameter in running the k3s binary.\u003c/p\u003e\n\u003cp\u003eK3s configuration is on \u003ccode\u003e/etc/systemd/system/k3s.service\u003c/code\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ cat /etc/systemd/system/k3s.service\n[Unit]\nDescription=Lightweight Kubernetes\nDocumentation=https://k3s.io\nWants=network-online.target\nAfter=network-online.target\n\n[Install]\nWantedBy=multi-user.target\n\n[Service]\nType=notify\nEnvironmentFile=/etc/systemd/system/k3s.service.env\nKillMode=process\nDelegate=yes\n# Having non-zero Limit*s causes performance problems due to accounting overhead\n# in the kernel. We recommend using cgroups to do container-local accounting.\nLimitNOFILE=1048576\nLimitNPROC=infinity\nLimitCORE=infinity\nTasksMax=infinity\nTimeoutStartSec=0\nRestart=always\nRestartSec=5s\nExecStartPre=-/sbin/modprobe br_netfilter\nExecStartPre=-/sbin/modprobe overlay\nExecStart=/usr/local/bin/k3s \\\n    server \\\n\t\u0026#39;--write-kubeconfig-mode\u0026#39; \\\n\t\u0026#39;644\u0026#39; \\\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eAppend server IP address of \u003ccode\u003eExecStart\u003c/code\u003e option\u003c/p\u003e","title":"Change the server IP address of k3s"},{"content":"\n","date":"2021-03-01T14:24:44+09:00","permalink":"https://cychong47.github.io/post/2021/2021-03-01-memory/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/03/2021-03-01-IMG_2951.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"Memory"},{"content":"\n","date":"2021-02-18T09:48:36+09:00","permalink":"https://cychong47.github.io/post/2021/2021-02-18-dttg-web-archive-results/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/02/2021-02-18-IMG_2677.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021/02/2021-02-18-IMG_2678.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"DTTG web archive results"},{"content":"Devonthink To Go 3.0과 함께 추가된 iCloud CloudKit 을 이용한 싱크 기능. 기존 iCloud 보다 2배 빠르다고 해서 바꿔봤다. 바꾸는 방법이 명확하지 않아 보였는데 다행히 devonthink discussion forum에 공식 가이드가 올라와서 따라해 봤는데 별 문제없이 잘 적용되었다. 속도도 정말 빠른 듯. Mac에서 동기화하는데 정말 수 분 내 1.7G짜리 데이터베이스 파일이 동기화되었고, iPad나 iPhone에서도 금방 처리가 되었다. 썩 괜찮네.\n","date":"2021-02-12T23:52:00+09:00","permalink":"https://cychong47.github.io/post/2021/2021-02-12-change-devonthink-sync/","summary":"\u003cp\u003eDevonthink To Go 3.0과 함께 추가된 \u003ccode\u003eiCloud CloudKit\u003c/code\u003e 을 이용한 싱크 기능. 기존 iCloud 보다 2배 빠르다고 해서 바꿔봤다.\n바꾸는 방법이 명확하지 않아 보였는데 다행히 devonthink discussion forum에 \u003ca href=\"https://discourse.devontechnologies.com/t/moving-from-icloud-to-cloudkit-syncing/61774\"\u003e공식 가이드\u003c/a\u003e가 올라와서 따라해 봤는데 별 문제없이 잘 적용되었다.\n속도도 정말 빠른 듯. Mac에서 동기화하는데 정말 수 분 내 1.7G짜리 데이터베이스 파일이 동기화되었고, iPad나 iPhone에서도 금방 처리가 되었다. 썩 괜찮네.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021/02/2021-02-12-devonthink-sync-change-to-icloud-cloudkit.png\" alt=\"\"\u003e\u003c/p\u003e","title":"Devonthink - iCloud CloudKit sync"},{"content":"Devonthink To Go 3이 나왔다는.\n1.0에서 2.0으로 업그레이드는 무료였지만, 이번에는 유로 업그레이드라고. 그래도 그냥 새로 구입하는 거에 비하면 반값 정도고, 기존 2.0 사용자는 7월 말까지 무료로 사용할 수 있고, 기존 앱하고도 함께 사용할 수 있다고(Tweetbot도 그렇지만, 요금제가 변경되다 보니 기존 것을 무조건 업그레이드 해버리는 짓은 하지 않네)\n당연히 손해 볼 게 없으니 바로 설치.\n여러가지 기능이 추가되었다고는 하는데 잘 모르겠네. 속도가 빨라진 것 같긴 한데 그 외에는 아직\u0026hellip; 그리고 iCloud 싱크 방법도 기존대비 달라진 새로운 방법을 추가로 지원하는데 언제나 그렇듯이 그다지 친절하지 않다. 기존 것을 migration하는 기능이 있는 것도 아니고, 제품 discussion forum에 올라온 글을 보고 해야 하는\u0026hellip; 은근 user friendly하다는 느낌은 별로 없는 앱.\n사용해 보다 업그레이드를 할 지 말 지 판단해야겠다.\n얼마전에 처음으로 subscription 모델로 변경된 Tweetbot은 당장 업그레이드는 포기했는데(왠만하면 ‘의리’로라도 업그레이드를 했을 텐데 구독제는 선뜻 손이 나가질 않는다. 기능이 그렇게 늘어난 것도 아니고\u0026hellip;) Things, Tweetbot, Mindnode 등과 함께 유료 업그레이드를 그래도 쭉 따라오던 앱이었는데 좀 두과 봐야겠다.\n","date":"2021-02-11T15:11:27+09:00","permalink":"https://cychong47.github.io/post/2021/2021-02-11-devonthink-to-go-3-/","summary":"\u003cp\u003eDevonthink To Go 3이 나왔다는.\u003c/p\u003e\n\u003cp\u003e1.0에서 2.0으로 업그레이드는 무료였지만, 이번에는 유로 업그레이드라고.\n그래도 그냥 새로 구입하는 거에 비하면 반값 정도고, 기존 2.0 사용자는 7월 말까지 무료로 사용할 수 있고, 기존 앱하고도 함께 사용할 수 있다고(Tweetbot도 그렇지만, 요금제가 변경되다 보니 기존 것을 무조건 업그레이드 해버리는 짓은 하지 않네)\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021/02/2021-02-11-IMG_2475.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e당연히 손해 볼 게 없으니 바로 설치.\u003cbr\u003e\n여러가지 기능이 추가되었다고는 하는데 잘 모르겠네. 속도가 빨라진 것 같긴 한데 그 외에는 아직\u0026hellip; 그리고 iCloud 싱크 방법도 기존대비 달라진 새로운 방법을 추가로 지원하는데 언제나 그렇듯이 그다지 친절하지 않다. 기존 것을 migration하는 기능이 있는 것도 아니고, 제품 discussion forum에 올라온 글을 보고 해야 하는\u0026hellip; 은근 user friendly하다는 느낌은 별로 없는 앱.\u003c/p\u003e","title":"Devonthink To Go 3"},{"content":"m1은 전문가 직원의 의견이 무시되지 않고 관철된 결과로 봐야겠지?\n이런 배포(?)를 가진 이도 없고,\n이런 혜안/실력을 가진 이도 없고,\n이런 말을 할 수 있는 분위기는 뭐 말할 것도 없고.\n물론 저 당시 애플이라고 많이 달랐을까 하는 의문은 있긴 하지만\u0026hellip;\n그냥 지금 내 주변을 생각하면 많이 안타깝다는 마음만 든다.\n문장에 담긴 의미나 기술적으로 맞고 틀림에는 별 관심이 없고, 문장으로의 적확성만 따지는 분위기가 팽배한\u0026hellip; ","date":"2021-02-11T14:17:38+09:00","permalink":"https://cychong47.github.io/post/2021/2021-02-11-what-if-jobs-does-not-listen-voice-of-employee/","summary":"\u003cp\u003em1은 전문가 직원의 의견이 무시되지 않고 관철된 결과로 봐야겠지?\u003c/p\u003e\n\u003cp\u003e이런 배포(?)를 가진 이도 없고,\u003cbr\u003e\n이런 혜안/실력을 가진 이도 없고,\u003cbr\u003e\n이런 말을 할 수 있는 분위기는 뭐 말할 것도 없고.\u003c/p\u003e\n\u003cp\u003e물론 저 당시 애플이라고 많이 달랐을까 하는 의문은 있긴 하지만\u0026hellip;\u003cbr\u003e\n그냥 지금 내 주변을 생각하면 많이 안타깝다는 마음만 든다.\u003c/p\u003e\n\u003cp\u003e문장에 담긴 의미나 기술적으로 맞고 틀림에는 별 관심이 없고, 문장으로의 적확성만 따지는 분위기가 팽배한\u0026hellip;\n\u003cimg src=\"/images/2021/02/2021-02-11-IMG_2474.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"What if Jobs does not listen voice of employee"},{"content":"\n","date":"2021-02-09T07:20:46+09:00","permalink":"https://cychong47.github.io/post/2021/2021-02-09-moon-in-the-sky/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/02/2021-02-09-IMG_2437.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"Moon in the sky"},{"content":"\n","date":"2021-02-06T09:20:00+09:00","permalink":"https://cychong47.github.io/post/2021/2021-02-06-true-for-the-motivation/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/02/2021-02-06-IMG_2222.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"True for the Motivation"},{"content":"\n","date":"2021-02-06T09:12:00+09:00","permalink":"https://cychong47.github.io/post/2021/2021-02-06-100-tips-for-a-better-life/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/02/2021-02-06-IMG_0296.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"100 Tips for a better life"},{"content":"macstories.net에서 추천 글을 보고 구입했던 Goodlinks app. 구입까지 하면서 까지 기대했던 기능은 그간 pocket을 이용하던 read-it-later 용도였는데 아쉽게도 추천글에 비해 부족한 점이 많았다. 무엇보다 이건 앱을 설치하자 마자 부푼 기대감에 그간 pocket에 모아둔 2만개가 넘는 글들을 모두 한번에 옮겨서 그런 듯 하다. 무려 2014년부터 모았던 글들인데 그 덕분인지 여러가지 예상하지 못했던 문제점이 눈에 띄었다.\n가장 큰 문제는 앱에서 글을 다운로드 하는데 너무 데이터를 많이 사용한다는 점. 앱 특성상 저장된 글의 내용 자체를 다운로드 해서 보여주는데 어떤 문제가 있는 지 불과 몇 시간 만에 1GB의 데이터를 사용해 버렸다. 마침 월 말이라 다행히 여유가 좀 있었지만 그 속도대로 가면 며칠 남은 월말까지 데이터를 모두 사용해 버릴 것 같아서 결국 셀룰러르 데이터를 사용하지 못하게 설정을 변경해야 했다.\n이 과정에서 글 목록 스크롤의 속도가 기대했던 것처럼 빠르지 않은 점도 보였다(실은 왠만한 iOS앱에서 스크롤이 느린 걸 본적이 별로 없었는데\u0026hellip;).\n또 다른 문제는 2014년 부터 저장한 글들을 한꺼번에 가져온 덕에 더 이상 관심없는 글들은 삭제하고 싶었는데 앱에서 삭제하는 작업이 너무 불편했다. 글 목록에서 일일이 하나씩 context menu를 이용해서 삭제해야 했다는\u0026hellip; 내가 기대한 건 일반적인 방법처럼 edit 모드로 들어가면 적어도 삭제할 항목을 선택한 후 일괄 삭제하는 것인데 그런 기능은 전혀 없었다.\n마침 앱에서 일부 글을 선택해서 글 목록만 export하는 iOS shortcut을 사용해 보려 했는데 그럴 때마다 shortcut이 비정상 종료되는 문제가 있어 앱 제작자에게 해당 문제점을 보고한 적이 있다. 기왕 연락을 한 김에 bulk edit 기능을 추가해 달라고 요청을 했다. 아니면 export하는 기능만이라도 추가해 달라고. 이미 import하는 기능은 제공하고 있어, 적절한 파일 형식(json을 기대)으로 export만 해주면 그걸 편집해서 내가 원하는 글만 남겨서 다시 import할 수 있을 거라고 생각했다.\n그래서인가? 아니면 원래 계획에 있었던 건 지는 모르지만, 이번 업데이트가 되면서 export 기능이 추가되었다.\nexport하면 iCloud Drive에 이런 json파일이 생긴다.\njson 형식을 보니 해당 글을 추가한 시간(addedAt)과읽은 시간(readedAt)등이 있었다. 간단하게 각 글의 addedAt 필드 값을 이용해서 2020년에 모은 글만 goodlinks 앱에 다시 import 했다. 그 전에 앱에 있던 모든 글은 삭제하고.\ngoodlinks_split_json.py\n이때도 sync에 이슈가 있는 지 아이패드에서 iCloud에 저장된 모든 글을 삭제한 후 iPhone에서 강제 동기화를 시켰는데(이번에 추가된 기능) 잘 동작하지 않는 듯 했다(나중에 생각해 보이 이 문제는 앱이 아니라 iCloud의 문제일지도) 결국 iPhone, iPad, Mac OS에서 각각 앱을 삭제해서 강제로 데이터를 초기화 시킨 후 에서야 정상적으로 3개 디바이스 글 상태가 정상적으로 동기화 되었다.\n이제 좀 기대했던 앱의 모습이 된 듯 한데\u0026hellip; 이제 글만 읽으면 되는데 본질에 집중하지 못하고 엄하게(?) 주변(툴)만 신경쓰는 듯한 느낌이\u0026hellip;\n","date":"2021-02-05T23:25:00+09:00","permalink":"https://cychong47.github.io/post/2021/2021-02-05-goodlinks-supports-export-finally/","summary":"\u003cp\u003emacstories.net에서 추천 글을 보고 구입했던 Goodlinks app.\n구입까지 하면서 까지 기대했던 기능은 그간 pocket을 이용하던 read-it-later 용도였는데 아쉽게도 추천글에 비해 부족한 점이 많았다.\n무엇보다 이건 앱을 설치하자 마자 부푼 기대감에 그간 pocket에 모아둔 2만개가 넘는 글들을 모두 한번에 옮겨서 그런 듯 하다. 무려 2014년부터 모았던 글들인데 그 덕분인지 여러가지 예상하지 못했던 문제점이 눈에 띄었다.\u003c/p\u003e\n\u003cp\u003e가장 큰 문제는 앱에서 글을 다운로드 하는데 너무 데이터를 많이 사용한다는 점. 앱 특성상 저장된 글의 내용 자체를 다운로드 해서 보여주는데 어떤 문제가 있는 지 불과 몇 시간 만에 1GB의 데이터를 사용해 버렸다. 마침 월 말이라 다행히 여유가 좀 있었지만 그 속도대로 가면 며칠 남은 월말까지 데이터를 모두 사용해 버릴 것 같아서 결국 셀룰러르 데이터를 사용하지 못하게 설정을 변경해야 했다.\u003c/p\u003e","title":"goodlinks supports export finally"},{"content":"\n","date":"2021-02-04T18:45:55+09:00","permalink":"https://cychong47.github.io/post/2021/2021-02-04-esr-magsafe-car-charger/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/02/2021-02-04-IMG_2333.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021/02/2021-02-04-IMG_2334.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"ESR magsafe car charger"},{"content":"\n","date":"2021-02-03T17:37:52+09:00","permalink":"https://cychong47.github.io/post/2021/2021-02-03-something-is-broken/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/02/2021-02-03-IMG_2318.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"Something is broken"},{"content":"망가져서(이렇게 제대로 망가진 아이폰은 처음인) 사용할 수 없는 X. 어제까지 사용하던 SE 2 그리고 이번에 새로 구입한 12 Pro Max.\n아이폰에서는 처음으로 큰 크기의 제품을 사용해 보는 데(X 전까지는 늘 플러스 모델이 아니라 기본 크기의 모델을 사용) 늘 비슷한 폼팩터를 사용하는 것도 지겹고, 노안 때문에 화면이 좀 더 컸으면 좋겠다는 생각 그리고 카메라가 제일 좋은 게 Pro Max라 이번에는 과감히 제일 큰 모델로 구입. 그냥 Pro보다 가격은 비싸지만, 그래도 카메라를 제일 쓰는 게 분명히(?) 도움이 될 거라고 세뇌 중.\n","date":"2021-01-26T22:41:15+09:00","permalink":"https://cychong47.github.io/post/2021/2021-01-26-welcome-iphone-12-pro-max/","summary":"\u003cp\u003e망가져서(이렇게 제대로 망가진 아이폰은 처음인) 사용할 수 없는 X. 어제까지 사용하던 SE 2 그리고 이번에 새로 구입한 12 Pro Max.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2021/01/2021-01-26-IMG_0111.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e아이폰에서는 처음으로 큰 크기의 제품을 사용해 보는 데(X 전까지는 늘 플러스 모델이 아니라 기본 크기의 모델을 사용) 늘 비슷한 폼팩터를 사용하는 것도 지겹고, 노안 때문에 화면이 좀 더 컸으면 좋겠다는 생각 그리고 카메라가 제일 좋은 게 Pro Max라 이번에는 과감히 제일 큰 모델로 구입. 그냥 Pro보다 가격은 비싸지만, 그래도 카메라를 제일 쓰는 게 분명히(?) 도움이 될 거라고 세뇌 중.\u003c/p\u003e","title":"Welcome iPhone 12 Pro Max"},{"content":"\n맥미니의 팬이 동작하지 않는 걸 고쳤다. 간단한 문제였는데 팬 전원 케이블이 연결되지 않아서 그랬다는. 팬 문제를 고친 김에 모니터를 연결해 보니 사과 마크 아래 진행바가 20%에서 멈춰 진행이 되질 않는다. 그래서 OS가 문제인가 싶어 Ubuntu를 설치하려고 부팅 디스크를 만들었는데 부팅할 때 Alt 키를 눌러서 부팅 미디어 선택 화면이 나오질 않는다.\nhttps://www.clien.net/service/board/cm_mac/9288775\n그러나 위의 글을 발견했다. ㅜ 얼마전에 2011 미니로 같은 증상 겪었습니다. 저는 수명다한 ssd가 문제였습니다. 있던 ssd를 빼고 진행하니 다시 제대로 동작하더라구요. 이걸 몰라서 센터에도 한번 갔는데 기사님이 맥미니는 하드아니면 보드문젠데 보드문제면 차라리 하나 새로 사라고 권하시더군요 =_= 검색해보면 아마존 기존으로 기본형이 350달러쯤 하는것 같네요.\n마침 맥미니가 이 상태가 되기 전의 마지막 현상이 내장 하드가 인식되지 않는 거라 그 하드디스크가 부팅을 방해하나 싶어 예전에 맥미니에 두 번째 디스크를 설치하기 위해 구입했던 iFixIt의 도구를 이용해서 맥미니를 분해했다. 2011년 제품은 내구성이 떨어지는 부품을 사용해서 그런지 플라스틱 부품에 손을 대자 부스러진다. 2009년 제품에서는 이런 적이 없었는데.\n그래도 무사히 하드디스크를 빼내낸데 성공했는데 문제는 역순의 조립에서.. 분해 과정에서 디스크에 연결된 부품 하나를 분리하면서 문제를 만들었다. 결국 재조립은 실패하고, 그냥 이 녀석을 보내주기로 했다. 2011년에 구입해서 2021년 그것도 1월 1일에 결국 망가지다니. 그래도 10년을 함께 있었구나.\n지금도 현역 디자인(적어도 첫번째 M1 기반 맥미니도 같은 디자인이라)인데. 이제 사용할 수 없는 내부는 버리더라도 외부 알류미튬 케이스는 남기고 싶은데 요즘 보는 신박한 정리의 철학(?)을 따른다면 이것 역시 버려야 할 듯. 추억은 사진으로 남겨놨으니. ","date":"2021-01-02T20:30:19+09:00","permalink":"https://cychong47.github.io/post/2021/2021-01-02-farewell-mac-mini-2011/","summary":"\u003cp\u003e\u003cimg src=\"/images/2021/01/2021-01-01-IMG_0048.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e맥미니의 팬이 동작하지 않는 걸 고쳤다. 간단한 문제였는데 팬 전원 케이블이 연결되지 않아서 그랬다는.\n팬 문제를 고친 김에 모니터를 연결해 보니 사과 마크 아래 진행바가 20%에서 멈춰 진행이 되질 않는다.\n그래서 OS가 문제인가 싶어 Ubuntu를 설치하려고 부팅 디스크를 만들었는데 부팅할 때 Alt 키를 눌러서 부팅 미디어 선택 화면이 나오질 않는다.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.clien.net/service/board/cm_mac/9288775\"\u003ehttps://www.clien.net/service/board/cm_mac/9288775\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e그러나 위의 글을 발견했다. ㅜ\n얼마전에 2011 미니로 같은 증상 겪었습니다. 저는 수명다한 ssd가 문제였습니다. 있던 ssd를 빼고 진행하니 다시 제대로 동작하더라구요. 이걸 몰라서 센터에도 한번 갔는데 기사님이 맥미니는 하드아니면 보드문젠데 보드문제면 차라리 하나 새로 사라고 권하시더군요 =_= 검색해보면 아마존 기존으로 기본형이 350달러쯤 하는것 같네요.\u003c/p\u003e","title":"Farewell Mac-mini 2011"},{"content":"AWS 에서의 인스턴스 CPU market share 변화 (Intel vs AMD vs Graviton)\n최근 Intel이 몇 번(몇 년간의) 삽질을 반복하고 있는 사이, AMD가 온 세상이 주목할 정도로 경쟁력있는 제품을 내놓아 시장에서 인정을 받아가고 있고, 수 년 전에 한번 세간의 이목을 잠시 받았다 이내 사그러들었던 ARM processor 기반의 컴퓨터들이 주목받고 있다. ARM은 특히 Apple의 결단이 큰 계기가 될 듯 한데, 적어도 MAC을 사용하는 사용자들의 사용 머신을 Intel에서 모두 ARM으로 옮길 것이고, Intel이나 AMD에서 M1과 대적할 수 있는 x86 프로세스를 내놓지 못하면 많은 사람들이 Apple의 M1과 그 후속 프로세서를 이용한 제품 사용자로 넘어갈 것 같다. 현재 기준으로 workalod 마다 다르긴 하지만, 대부분의 경우 x86에서 돌리는 app보다 성능은 물론 가성비도 좋은 편이라 x86에서 어떤 대응책을 가지고 나올 지 궁금할 따름이다.\n그렇지만 모든 사용자가 Apple의 생태계로 이주할 수 있는 것은 아닌데 특히나 우리 나라 같은 경우도 Microsoft Windows 기반만 지원하는 많은 서비스가 존재하고 있어 성능이 좋고, 가성비가 좋아도 애플 컴퓨터로 넘어가지 못하는 사용자도 분명 많이 있을 것이다. 트 ARM 프로세스를 이용한 consumer market은 애플의 이번 맥 제품이 명실상부한 첫 번째 제품이 아닌가 싶다. 그 전까지 ARM processor는 주로 단말기나 RasberrryPi 등의 저전력 장비에서 많이 사용되어 왔다고 알려져 있다. 하지만 일반 사용자들은 모르는 통신 장비에는 ARM architecture를 기반으로 한 processor를 사용하는 경우는 아주 많다. Cavium(지금은 Marvell에 인수된 상태)에서 Octeon TX 시리즈부터 기존 MIPS archtiecture 대신 ARM architecture로 전환한 지 오래되었고, Huawei의 Kirin processor도 ARM architecture 기반의 SoC 제품이다.\n하지만 위에서 언급한 단말기, RasberryPi, 통신 장비 등 외에 ARM을 이용한 제품이 눈에 띄게 늘어나고 있다. 지난 번에 기사를 봤을 때는 \u0026lsquo;그렇구나\u0026rsquo; 하고 넘어갔던 세계 최고 성능의 SuperComputer인 Fujitsu의 Fugaku도 ARM64FX라는 프로세스를 사용하는데 이것도 ARM architecture를 사용한다고 한다. ARM에서 HPC(High Performance Computing) 시장에 도전하기 위해 만든 Neoverse 계열에서 나온 N1 architecture를 기반으로 하고 있고, ARM이 설계한 SVE(Scalable Vector Extension)을 512bit까지 구현한 최초의 ARM 프로세서다. SVE는 ARM에서 x86의 AVX512 뜽에 대응하기 위해 나온 vector processing instruction으로 설계자체가 128비트에서 2048비트까지 지원할 수있도록 설계되었다. 기존에 많이 사용되고 있는 x86의 SSE/AVX나 ARM의 NEON 대비 차이점은 하나의 instruction set을 사용하여 서로 다른 길이의 SVE를 지원하는 ARM processor에서 동작하다는 것이다. 예를 들어 x86에서는 AVX, AVX2, AVX512 가 모두 다른 명령어를 가지고 있어 각각에 맞게 코딩을 다시 해야 한다. 그 덕에 AVX512를 사용하여 작성한 프로그램을 AVX2까지만 지원하는 CPU에서 실행하면 illegal instruction error를 내고 비정상 종료된다. 반면 SVE는 한번 작성한 코드는 SVE 128bit만 지원할 Neoverse N2나 256bit를 지원할 Neoverse V1 혹은 512bit를 지원하는 A64FX에서 모두 실행이 가능하다고 한다. 개발효율측면에서는 하나의 목적을 수행하기 위해 단 한 번만 구현하면 되므로 코드 유지보수나 활용도 측면에서 큰 장점으로 보이낟.\nARM이 특히 고성능 서버 시장에서 좋은 성과를 내고 있어도 아직 그건 특정 영역에서만 의미가 있는 것 또한 현실이다. 예를 들어 AWS의 Graviton2 instance를 사용해서 서비스를 제공하는 일을 한다고 했을 때 그 일을 할 때 사용하는 머신이 m1 기반이 아니면 여전히 ARM processor의 고성능을 직접 체감하기 쉽지 않다.\nTBD\n","date":"2020-12-27T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-12-27-go-go-ms-for-arm/","summary":"\u003cp\u003e\u003ca href=\"https://www.clien.net/service/board/park/15705253\"\u003eAWS 에서의 인스턴스 CPU market share 변화 (Intel vs AMD vs Graviton)\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e최근 Intel이 몇 번(몇 년간의) 삽질을 반복하고 있는 사이, AMD가 온 세상이 주목할 정도로 경쟁력있는 제품을 내놓아 시장에서 인정을 받아가고 있고, 수 년 전에 한번 세간의 이목을 잠시 받았다 이내 사그러들었던 ARM processor 기반의 컴퓨터들이 주목받고 있다.\nARM은 특히 Apple의 결단이 큰 계기가 될 듯 한데, 적어도 MAC을 사용하는 사용자들의 사용 머신을 Intel에서 모두 ARM으로 옮길 것이고, Intel이나 AMD에서 M1과 대적할 수 있는 x86 프로세스를 내놓지 못하면 많은 사람들이 Apple의 M1과 그 후속 프로세서를 이용한 제품 사용자로 넘어갈 것 같다. 현재 기준으로 workalod 마다 다르긴 하지만, 대부분의 경우 x86에서 돌리는 app보다 성능은 물론 가성비도 좋은 편이라 x86에서 어떤 대응책을 가지고 나올 지 궁금할 따름이다.\u003c/p\u003e","title":"ARM processor를 기다리며"},{"content":"이젠 추억이 되어 버린. 한동안 장롱 속에 품고 있다 얼마전에 사진 한 장 찍어놓고, 재활용 함으로 보냈다.\nKLDPWiki: Linuxdoc Sgml/Kerneld KLDPWiki: Linuxdoc Sgml/IP-Subnetworking KLDPWiki: Linuxdoc Sgml/Sendmail-Address-Rewrite ","date":"2020-12-25T17:36:52+09:00","permalink":"https://cychong47.github.io/post/2020/2020-12-25-kldp-t-shirts/","summary":"\u003cp\u003e이젠 추억이 되어 버린.\n한동안 장롱 속에 품고 있다 얼마전에 사진 한 장 찍어놓고, 재활용 함으로 보냈다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/12/2020-12-25-IMG_1697.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://wiki.kldp.org/wiki.php/LinuxdocSgml/Kerneld\"\u003eKLDPWiki: Linuxdoc Sgml/Kerneld\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://wiki.kldp.org/wiki.php/LinuxdocSgml/IP-Subnetworking\"\u003eKLDPWiki: Linuxdoc Sgml/IP-Subnetworking\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://wiki.kldp.org/wiki.php/LinuxdocSgml/Sendmail-Address-Rewrite\"\u003eKLDPWiki: Linuxdoc Sgml/Sendmail-Address-Rewrite\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"KLDP T-shirts"},{"content":"\n","date":"2020-12-21T16:09:48+09:00","permalink":"https://cychong47.github.io/post/2020/2020-12-21-cloud-of-one-fine-day/","summary":"\u003cp\u003e\u003cimg src=\"/images/2020/12/2020-12-21-IMG_1638.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"Cloud of one fine day"},{"content":"역사는 반복된다. 2005년 PowerPC processor에서 Intel CPU로의 전환 발표 후 2006년 첫 제품을 내 놓은 후 다시 15년 만에 이번에는 ARM 기반 자체 CPU인 Apple Silicon으로의 전환을 발표하고, 11월 제품 발표회에서 첫번째 Apple Silicon인 M1 칩 기반의 Apple Macbook Air, Macbook Pro 그리고 Mac mini 제품을 출시했다.\n대학 다닐 때 Apple이 자사 제품에 사용하던 processor를 기존 Motorola 68xxx 시리즈에서 Apple, IBM 그리고 Motorola(나중에 processor division만 분리해서 Freescale로 분사)가 합작해서 만든 RISC 기반의 PowerPC processor로 전환해서 제품 경쟁력 강화를 꾀했던 게 기억난다. 아쉽지만 그렇게 만들어진 PowerPC는 시장에서 이미 시장에서 절대 강자로 굴림하던 x86 호환 제품에 비해 시장성이 높지 않았다. 대부분의 컴퓨터 사용자는 MS-DOS를 사용하고, 새로 출시된 MS Windows로 넘어가고 있던 상황이라 x86 instruction set을 지원하지 않는 다른 architecture 기반의 processor는 시장에서 그다지 환영받지 못했다. 기존에 Motolora processor + Apple 혹은 IBM 메인프레임등에서 동작하던 SW 사용자 정도가 새로 나온 PowerPC 기반의 제품을 사용했다.\nSteve Job가 Apple로 돌아온 후에도 한동안 PowerPC processor를 사용하다 결국 processor가 제품 경쟁력의 발목을 잡는 상황을 타개하기 위해 오랫동안 사용해 온 RISC 기반의 processor 사용을 포기하고 CISC 기반의 x86 으로 이전하는 모험을 하게 된다. 상대적으로 폐쇄적인 HW platform을 통제할 수 있었던 애플이기에, 그리고 OS를 직접 만드는 업체이기에 가능했을 것이다. 기존 PowerPC용으로 개발된 SW를 x86 기반 시스템에서 실행할 수 있도록 Rosseta라는 emulation SW를 제공하는 등 많은 준비를 한 덕에 생각보다 부드럽게 CPU architecture를 바꾸는 이사가 큰 무리없이 완료되었다. 사실 이미 당시에도 애플 컴퓨터를 사용하는 사람들도 당시만 해도 매년 더 좋은 성능의 processor를 시장에서 만날 수 있는 x86을 부러워했기에 사용자 입장에서도 치러야 하는 비용이 있는 이 이전을 박수로 환영하는 분위기였다.\n(아마도 아쉬움을 토로한 사람은 이런 줄 모르고 마지막 세대의 PowerPC 기반 맥을 산 사람이 아닐까 싶다. 바로 나\u0026hellip;. 이렇게 될 줄도 모르고, 난생 처음 노트북을 구입한 것이 이제는 역사에 남아 버린 Powerbook 15인치 마지막 세대. 지금도 책장에 있는데..)\n그 후 15년 가량을 Intel Processor의 성장에 올라탄 애플 맥은 다양한 형태의 제품을 만들어낸다. 인텔의 Core 2 Duo architecture 기반 CPU등을 활용해서 Macbook Air와 같이 누구도 만들지 못한 두께를 가진 노트북도 만들었고, Macbook Pro와 같이가장 강력한 성능의 Windows PC로 불린 제품도 만들었다.\n하지만 Intel processor를 사용하는 MacPro 제품에서 보인 것처럼 High-end 제품의 경우 성능 제약이나 발열에 대한불만이 많았다. 특히 발열 측면에서 취약점을 가졌던 Intel Processor 였기에 쿨링에 제약이 많았던 랩탑 제품에서는 애플 입장에서 아쉬움이많았을 것이다. 더군다나 최근 몇 년 간은 Intel의 processor가 예전과 같은 성능 향상을 보이지 못하고 특히 PC용 시장보다는 상대적으로 고수익을 낼 수 있는 Data center 용 서버 processor에 집중해서 덩달아 애플의 제품 경쟁력도 떨어지는 문제가 발생했다(이 문제는 같은 Intel processor를 사용하는 PC 경쟁업체들도 같은 상황이었겠지만, 해당 업체들은 대부분 processor를 만들 능력이 없고, OS도 Microsoft에 의존해야 하는 상황이라 달리 대안도 없는 상황이라 상황에 대한 인식이 달랐을 듯 싶다). 특히 올해부터는 PC 시장에서도 AMD에 비해 Intel processor의 제품 경쟁력이 떨어진다는 평을 받아 많은 일반 사용자들이 PC를 조립할 때 AMD CPU를 추천하는 상황이 되어 버렸다(오래전에도 AMD processor를 Intel processor보다 추천하는 사람들이 있었지만 당시에는 대부분 제품의 성능 보다는 가성비만을 기준으로 한 경우였는데 요즘은 성능면에서도 Intel processor보다 뛰어나게 되었으니)\n그 와중에 Apple은 이미 iPhone, iPad 등에서 사용하기 위해 ARM기반의 자체 processor를 만들어 매년 성능을 높이며, multimedia, Machine learning 등을 위한 IP를 추가하여 자사 제품의 경쟁력을 높이는 작업을 성공적으로 이루어 내고 있었다.\n그리고 이제는 충분이 때가 되었다는 판단에서 인지 자체 processor를 이용해서 Mac을 만들겠다는 발표를 하기에 이러렀다. 더 이상 자사 제품의 경쟁력을 발목잡는 외부 요인을 두지 않겠다는 의지의 표명인지\u0026hellip; 아마도 이건 SOC를 만들기 위한 chip 설계 능력부터, 해당 chip을 제대로 사용하기 위한 OS, compiler 등을 확보하고 있어 가능한 점일 것이다. Apple은 SW 회사가 아니라 HW 회사라고 부르는 경우도 많지만, 이런 transision을 이렇게 전격적으로 할 수 있는 것 역시 chip 설계 능력 외에 OS를 만들 수 있는 SW 능력과, SW 개발을 위한 compiler를 개발할 수 있는 능력을 가졌기에 가능한 것이다. 이런 회사를 단순히 HW회사가 아니라 충분한 SW 능력과 HW 개발 능력을 모두 가지고 거기에 Service 개발 운영 능력까지 보유한 회사로 보는 것이 맞아 보인다.\n이번 제품 발표회에서 인상 깊었던 몇 가지 CPU, GPU, ML processor 외에 LPDDR5 스펙의 메모리도 함께 SoC에 패키징했다고 한다(memory도 chip에 넣었다는 이야기가 있었는데 그건 아니고, 패키징만 같이 한 거라고)\n덕분에 통상 메모리가 망가지면 어떻게 하나, 메모리의 수명이 processor보다 짧은 건 아닌지 하는질문이 나오기도 했는데.\n하긴 PC 조립하다 보면 메모리 불량으로 문제가 되기도 했는데 이런 경우는 어떻게 되는 걸까? 특히 보증기간이 지난 후에 메모리에 불량이 생길 수는 없는 걸까 라는 생각이 들기도. 그런데 생각해 보면 지금도 요 근래 나오는 애플 랩탑은 메모리를 보드에 부착하는 형태(soldering)로 나오고 있어 A/S 측면에서는 별반 차이가 없겠다는 생각이 들기도 한다. 즉 A/S는 생각하지 말아야 할 것 같은\nGPU의 스펙은 아래 그림. 요즘 NVIDIA GPU 구조를 보다 보니 spec 차이가 궁금하다. 어떤 기준으로 측정하는 지에 따라 다르겠지만, NVIDIA의 V100(2018년 출시) 제품은 Tensor performance는 100 TFLOPS를 넘는다고\n또 하나 특이한 점은 Unified Memory Architecture. CPU, GPU 그리고 메모리가 모두 SoC 안에 함께 있다 보니 CPU와 GPU간 데이터를 복사할 필요가 없다고 한다. NVIDIA도 유사한 UVA(Unified Virtual Addressing) 혹은 Unified Memory라는 개념을 사용하긴 하지만, Addressing만을 하나로 보게 해서 SW coding할 때 편리하지만 실제 동작에서는 필요한 경우 데이터 복사가 이루어지는 걸로 알고 있다. 아무래도 CPU, CPU Host memory 그리고 GPU, GPU device memory가 모두 별도의 부품이라 이렇게 내부적으로 복사가 필요한 것으로 이해된다. 그런 면에서 CPU, GPU 그리고 Memory가 모두 함께 있는 통합 구조는 성능 면에서 큰 장점을 가질 듯 하다. 대신 궁금한 것은 이번에 발표한 모든 제품은 8G 혹은 16GB 메모리를 가진 제품이던데 이미 Intel processor 기반의 Macbook Pro 16 인치는 64GB의 메모리를 갖는 구성도 가능한데 이렇게 높은 용량의 메모리는 어떻게 제공할 까? 그리고 이번에 출시한 모든 low-end 제품군 외에 더 많은 core를 가진 iMac이나 Mac Pro 그리고 Macbook Pro 상위 모델은 어떻게 구성할 까 궁금하다. 일반적인 computer architecture에서는 processor들과 memory가 각각 독립적인 부품이라 어느 정도까지는 각자 용량을 늘이는 것이 가능했는데, Apple Silicon도 이 이슈를 NUMA와 같은 방식으로 해결할까? 다음 제품이 궁금해진다.\n이벤트 전까지는 전혀 관심이 없었는데 이렇게 내부 구조를 듣고 나니 괜스리 관심이 간다. 마침 오늘 맛이 간 Mac mini 2011랑 같은 모양을 가진 M1 칩 사용 Mac mini는 $899 (16GB Unified memory, 256G SSD 기준)\nhttps://www.apple.com/shop/buy-mac/mac-mini/apple-m1-chip-with-8-core-cpu-and-8-core-gpu-256gb#\n하지만 당장은 docker가 동작하지 않는다는 이슈도 있고, 첫 세대는 믿고 걸러야 한다는 말도 있고 하니. 만일 지금 사용하는 맥북프로가 없었으면 모를까\u0026hellip;\n몇 개의 기사글 Source : How Apple\u0026rsquo;s M1 uses high-bandwidth memory to run like the clappers\nHigh-bandwidth memory (HBM) avoids the traditional CPU socket-memory channel design by pooling memory connected to a processor via an interposer layer. HBM combines memory chips and gives them closer and faster access to the CPU as the distance to the processor is only a few micrometer units. This on its own speeds data transfers.\nInterposer layer\nThe SoC has access to 16GB of unified memory. This uses 4266 MT/s LPDDR4X SDRAM (synchronous DRAM) and is mounted with the SoC using a system-in-package (SiP) design. A SoC is built from a single semiconductor die whereas a SiP connects two or more semiconductor dies.\nIn other words, this memory is shared between the three different compute engines and their cores. The three don\u0026rsquo;t have their own individual memory resources, which would need data moved into them. This would happen when, for example, an app executing in the CPU needs graphics processing – meaning the GPU swings into action, using data in its memory\nThe 2020 Mac Mini Unleashed: Putting Apple Silicon M1 To The Test ","date":"2020-11-15T22:12:44+09:00","permalink":"https://cychong47.github.io/post/2020/2020-11-13-apple-m1-soc/","summary":"\u003ch2 id=\"역사는-반복된다\"\u003e역사는 반복된다.\u003c/h2\u003e\n\u003cp\u003e2005년 PowerPC processor에서 Intel CPU로의 전환 발표 후 2006년 첫 제품을 내 놓은 후 다시 15년 만에 이번에는 ARM 기반 자체 CPU인 Apple Silicon으로의 전환을 발표하고, 11월 제품 발표회에서 첫번째 Apple Silicon인 M1 칩 기반의 Apple Macbook Air, Macbook Pro 그리고 Mac mini 제품을 출시했다.\u003c/p\u003e\n\u003cp\u003e대학 다닐 때 Apple이 자사 제품에 사용하던 processor를 기존 Motorola 68xxx 시리즈에서 Apple, IBM 그리고 Motorola(나중에 processor division만 분리해서 Freescale로 분사)가 합작해서 만든 RISC 기반의 PowerPC processor로 전환해서 제품 경쟁력 강화를 꾀했던 게 기억난다. 아쉽지만 그렇게 만들어진 PowerPC는 시장에서 이미 시장에서 절대 강자로 굴림하던 x86 호환 제품에 비해 시장성이 높지 않았다. 대부분의 컴퓨터 사용자는 MS-DOS를 사용하고, 새로 출시된 MS Windows로 넘어가고 있던 상황이라 x86 instruction set을 지원하지 않는 다른 architecture 기반의 processor는 시장에서 그다지 환영받지 못했다. 기존에 Motolora processor + Apple 혹은 IBM 메인프레임등에서 동작하던 SW 사용자 정도가 새로 나온 PowerPC 기반의 제품을 사용했다.\u003c/p\u003e","title":"Apple Silicon - M1 Soc"},{"content":"갑자기 V40에서 냉각수 부족 경고가\u0026hellip;.\n그럴 때는 근처 약국에 가서 증류수를 사서 보충하면 된다고. 수돗물도 괜찮지만, 겨울철에 얼어 붙을 수가 있어 가장 좋은 건 증류수.\n절대 생수는 안된다고.\n","date":"2020-11-07T20:12:21+09:00","permalink":"https://cychong47.github.io/post/2020/2020-11-07-emergency-in-volvo/","summary":"\u003cp\u003e갑자기 V40에서 냉각수 부족 경고가\u0026hellip;.\u003c/p\u003e\n\u003cp\u003e그럴 때는 근처 약국에 가서 증류수를 사서 보충하면 된다고.\n수돗물도 괜찮지만, 겨울철에 얼어 붙을 수가 있어 가장 좋은 건 증류수.\u003cbr\u003e\n절대 생수는 안된다고.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/11/2020-11-07-IMG_0009.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"냉각수 부족 경고가 뜨면"},{"content":"2. CUDA Memory Management Most of the application’s performance will be bottlecked by memory-related constraints GPU RAM BW : 900GB/s (DDR3 ?) NV Visual Profiler Global memory is a staging area where all of the date gets copied from CPU memory. Global Memory(device memory) is visible to all of the threads in the kernel and also visible to CPu. Coalesced vs. uncoalesced global memory access coalesced global memory access : Sequential memory access is adjacent Warp Warp is a unit of thread scheduling/execution in SMs. Once a block has been assigned to an SM, it is divided into a 32-threads unit known as a warp Among all of the available warps, the ones with operands that are ready for the next instruction become eligible for execution. All of the threads in a warp execute the same instruction when selected. AOS vs. SOA AOS : Array of Structure. A[0].a, A[1].a, ... SOA : Structure of Array. Each member of structure is array S.a[0], S[1], ... Suitable for SIMT - same operation for the same member with different array index. In this case, the threads of the same block access adjacent memory spaces in turn increase the spatial locality. As a GPU is latency-hiding architecture, it becomes important to saturate the memory bandwidth. Shared Memory User-Managed Cache Shared memory is only visible to the threads in the same block. All of the threads in a block see the same version of shared memory. Threads in other SM can not see this shared memory Another block has its own shared memory Even in the same SM, different block has different share memory. Key usage of shared memory comes from that threads within a block can share memory access Shared variable can be located in the shared memory to be accessed multiple times. CDUA 9.0 provides inter-thread communication between ones in the different SMs Bank Shared memory is organized into banks to achieve higher bandwidth. Each bank can serve one address per cycle. Volta GPU has 32 banks each 4 bytes wide. 128 Bytes at one cycle Bank Conflict If multiple threads access the same Bank, the access to the shared memory is serialized. This should be avoid if possible. Read-only Cache Referred to as texture cache const __restrict__ Ideally used when the entire warp to read the same address/data Registers Scope : a single thread. Each thread has its own registers Local variables are stored in the registers Too many local variable can cause performance issue as the data should be reside in L1 or L2 cache or device memory register spills Pinned-memory Recommendations to reduce host/device memory copy Minimize amount of data to be transferred Use the pinned memory Batch small transfers into one large transfer Asynchronous data transfer malloc allocates pageable memory Device including GPU can not access the pageable memory. When the device access the pageable memory, the driver allocate temporary pinned memory and copy the data from the pageable memory and do DMA This introduce additional latency cudaMallocHost allocates pinned memory from the system memory. Too much use of pinned memory impact on the system performance as non-pageable memory is also used by the system(OS) Unified Memory Provide a single memory space accessible from CPU and GPU - easy programming and porting the CPU application to GPU Allow over-subscription A single pointer is used by the CPU and GPU while non-unified memory case, each has to have its own pointer as host memory and device memory are different. cudaMallocManaged does not allocate the physical memory when it is called but it allocate when the data is touch for the first time. This requires page migration and introduce additional time. Workaround 1 : define an initialization kernel on the GPU which touch the unified memory space on behalf of the workload kernel. Workaround 2: Prefetch Initialization kernel 왜 page fault 횟수가 줄어드는 지 잘 이해가 안되네\u0026hellip;. 그리고 여러 thread가 동시에 접근하는 건 page fault 회수가 1번인가?? 예제가 잘 이해가 안됨\u0026hellip; Prefetch cudaMemPrefetchAsync\ncudaMemAdviseSetReadyMostly\ncudaMemAdviseSetPreferredLocation\ncudaMemAdviseSetAccessedBy\nVolta combines the shared memory and L1 cache\nTotal 128KB Shared memory can be allocated up to 96KB #cuda #book/learn-cuda-programming\n","date":"2020-11-02T08:56:16+09:00","permalink":"https://cychong47.github.io/post/2020/2020-11-02-chapter-2.-cuda-memory-management/","summary":"\u003ch1 id=\"2-cuda-memory-management\"\u003e2. CUDA Memory Management\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eMost of the application’s performance will be bottlecked by memory-related constraints\u003c/li\u003e\n\u003cli\u003eGPU RAM BW : 900GB/s (DDR3 ?)\u003c/li\u003e\n\u003cli\u003eNV Visual Profiler\u003c/li\u003e\n\u003cli\u003eGlobal memory is a \u003cstrong\u003estaging area\u003c/strong\u003e where all of the date gets copied from CPU memory.\u003c/li\u003e\n\u003cli\u003eGlobal Memory(device memory) is visible to all of the threads in the kernel and also visible to CPu.\u003c/li\u003e\n\u003cli\u003eCoalesced vs. uncoalesced global memory access\n\u003cul\u003e\n\u003cli\u003ecoalesced global memory access : Sequential memory access is adjacent\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"warp\"\u003eWarp\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eWarp is a unit of thread scheduling/execution in SMs. Once a block has been assigned to an SM, it is divided into a 32-threads unit known as a \u003cstrong\u003ewarp\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eAmong all of the available warps, the ones with operands that are ready for the next instruction become \u003cstrong\u003eeligible\u003c/strong\u003e for execution.\u003c/li\u003e\n\u003cli\u003eAll of the threads in a warp execute the same instruction when selected.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"aos-vs-soa\"\u003eAOS vs. SOA\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eAOS : Array of Structure. \u003ccode\u003eA[0].a, A[1].a, ...\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eSOA : Structure of Array. Each member of structure is array \u003ccode\u003eS.a[0], S[1], ...\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003eSuitable for SIMT - same operation for the same member with different array index. In this case, the threads of the same block access adjacent memory spaces in turn increase the spatial locality.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eAs a GPU is latency-hiding architecture, it becomes important to saturate the memory bandwidth.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"shared-memory\"\u003eShared Memory\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eUser-Managed Cache\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eShared memory is only visible to the threads \u003cstrong\u003ein the same block\u003c/strong\u003e.\n\u003cul\u003e\n\u003cli\u003eAll of the threads in a block see the same version of shared memory.\u003c/li\u003e\n\u003cli\u003eThreads in other SM can not see this shared memory\u003c/li\u003e\n\u003cli\u003eAnother block has its own shared memory\u003c/li\u003e\n\u003cli\u003eEven in the same SM, different block has different share memory.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eKey usage of shared memory comes from that threads within a block can share memory access\n\u003cul\u003e\n\u003cli\u003eShared variable can be located in the shared memory to be accessed multiple times.\u003c/li\u003e\n\u003cli\u003eCDUA 9.0 provides inter-thread communication between ones in the different SMs\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eBank\n\u003cul\u003e\n\u003cli\u003eShared memory is organized into banks to achieve higher bandwidth.\u003c/li\u003e\n\u003cli\u003eEach bank can serve one address per cycle.\u003c/li\u003e\n\u003cli\u003eVolta GPU has 32 banks each 4 bytes wide. 128 Bytes at one cycle\u003c/li\u003e\n\u003cli\u003eBank Conflict\n\u003cul\u003e\n\u003cli\u003eIf multiple threads access the same Bank, the access to the shared memory is serialized. This should be avoid if possible.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"read-only-cache\"\u003eRead-only Cache\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eReferred to as \u003cstrong\u003etexture cache\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003econst __restrict__\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eIdeally used when the entire warp to read the same address/data\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"registers\"\u003eRegisters\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eScope : a single thread. Each thread has its own registers\u003c/li\u003e\n\u003cli\u003eLocal variables are stored in the registers\n\u003cul\u003e\n\u003cli\u003eToo many local variable can cause performance issue as the data should be reside in L1 or L2 cache or device memory\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eregister spills\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"pinned-memory\"\u003ePinned-memory\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eRecommendations to reduce host/device memory copy\n\u003cul\u003e\n\u003cli\u003eMinimize amount of data to be transferred\u003c/li\u003e\n\u003cli\u003eUse the \u003cstrong\u003epinned memory\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eBatch small transfers into one large transfer\u003c/li\u003e\n\u003cli\u003eAsynchronous data transfer\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003emalloc\u003c/code\u003e allocates pageable memory\n\u003cul\u003e\n\u003cli\u003eDevice including GPU can not access the pageable memory.\u003c/li\u003e\n\u003cli\u003eWhen the device access the pageable memory, the driver allocate temporary pinned memory and copy the data from the pageable memory  and do DMA\u003c/li\u003e\n\u003cli\u003eThis introduce additional latency\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecudaMallocHost\u003c/code\u003e allocates pinned memory from the system memory.\n\u003cul\u003e\n\u003cli\u003eToo much use of pinned memory impact on the system performance as non-pageable memory is also used by the system(OS)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"unified-memory\"\u003eUnified Memory\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eProvide a single memory space accessible from CPU and GPU - easy programming and porting the CPU application to GPU\u003c/li\u003e\n\u003cli\u003eAllow over-subscription\u003c/li\u003e\n\u003cli\u003eA single pointer is used by the CPU and GPU while non-unified memory case, each has to have its own pointer as host memory and device memory are different.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecudaMallocManaged\u003c/code\u003e does not allocate the physical memory when it is called but it allocate when the data is touch for the first time. This requires \u003ccode\u003epage migration\u003c/code\u003e and introduce additional time.\n\u003cul\u003e\n\u003cli\u003eWorkaround 1 : define an initialization kernel on the GPU which \u003cstrong\u003etouch\u003c/strong\u003e the unified memory space on behalf of the workload kernel.\u003c/li\u003e\n\u003cli\u003eWorkaround 2: Prefetch\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"initialization-kernel\"\u003eInitialization kernel\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e왜 page fault 횟수가 줄어드는 지 잘 이해가 안되네\u0026hellip;. 그리고 여러 thread가 동시에 접근하는 건 page fault 회수가 1번인가?? 예제가 잘 이해가 안됨\u0026hellip;\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"prefetch\"\u003ePrefetch\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003ccode\u003ecudaMemPrefetchAsync\u003c/code\u003e\u003c/p\u003e","title":"Chapter 2. CUDA Memory Management"},{"content":"1. Introduction to CUDA Programming CPU Architecture is optimized for low latency accessing while GPU architecture is optimized for data parallel throughput compution CPU hides latency of data by frequently stroring used data in caches and utilize the temporal locality In CUDA, the execution unit is a warp not a thread. Context switching is happens between the warps and not threads. GPU has lots of registers, all the thread context switching information is already present in the registers.(No context switching overhead unlike the CPU) Host code vs. Device code. Host memory vs. Device memory The return type of device function is always void. Data-parallel portions of an algorithm are executed on the device are kernels. All the kernels in CUDA are asynchronous in nature. Host need to wait for the device to finish. cudaDeviceSynchronize Software X runs on/as HW Y CUDA thread \u0026lt;-\u0026gt; CUDA core/SIMD code CUDA block \u0026lt;-\u0026gt; SM Grid/kenrel \u0026lt;-\u0026gt; GPU device One block runs on a single SM. All the threads within one block can only execute on cores in one SM. \u0026lt;\u0026lt; BlockDim, ThreadDim \u0026gt;\u0026gt; blockIdx, threadIdx : Index blockDim, threadDim : Dimension (==Size) blockDim is the number of threads per block Threads have mechanism to communicate and synchronize efficiently. The CUDA programming model allows this communication for threads whiten the same block The therads communicate with each other in the same block using a special memory shared memory Threads belonging to different block cannot communicate/synchronize with each other during the execution of the kernel. cudaError_t e. cudaGetLastError. Even for the multiple error, only the last one is returned. a\u0026lt;\u0026lt;\u0026lt; , \u0026gt;\u0026gt;\u0026gt;; cudaDeviceSynchronize(); e = cudaGetLastError(); Backlink [[Learn CUDA Programming]]\nDate Oct 19, 2020 4:03 PM\n#cuda #book/learn-cuda-programming\n","date":"2020-11-02T08:55:34+09:00","permalink":"https://cychong47.github.io/post/2020/2020-11-02-chapter-1-introduction-to-cuda-programming/","summary":"\u003ch1 id=\"1-introduction-to-cuda-programming\"\u003e1. Introduction to CUDA Programming\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eCPU Architecture is optimized for low latency accessing while GPU architecture is optimized for data parallel throughput compution\u003c/li\u003e\n\u003cli\u003eCPU hides latency of data by frequently stroring used data in caches and utilize the temporal locality\u003c/li\u003e\n\u003cli\u003eIn CUDA, the execution unit is a warp not a thread. Context switching is happens between the warps and not threads.\u003c/li\u003e\n\u003cli\u003eGPU has lots of registers, all the thread context switching information is already present in the registers.(No context switching overhead unlike the CPU)\u003c/li\u003e\n\u003cli\u003eHost code vs. Device code.\u003c/li\u003e\n\u003cli\u003eHost memory vs. Device memory\u003c/li\u003e\n\u003cli\u003eThe return type of device function is always \u003ccode\u003evoid\u003c/code\u003e.\u003c/li\u003e\n\u003cli\u003eData-parallel portions of an algorithm are executed on the device are kernels.\u003c/li\u003e\n\u003cli\u003eAll the kernels in CUDA are asynchronous in nature. Host need to wait for the device to finish. \u003ccode\u003ecudaDeviceSynchronize\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eSoftware X runs on/as HW Y\n\u003cul\u003e\n\u003cli\u003eCUDA thread \u0026lt;-\u0026gt; CUDA core/SIMD code\u003c/li\u003e\n\u003cli\u003eCUDA block \u0026lt;-\u0026gt; SM\u003c/li\u003e\n\u003cli\u003eGrid/kenrel \u0026lt;-\u0026gt; GPU device\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eOne block runs on a single SM. All the threads within one block can only execute on cores in one SM.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e\u0026lt;\u0026lt; BlockDim, ThreadDim \u0026gt;\u0026gt;\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eblockIdx\u003c/code\u003e, \u003ccode\u003ethreadIdx\u003c/code\u003e : Index\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eblockDim\u003c/code\u003e, \u003ccode\u003ethreadDim\u003c/code\u003e : Dimension (==Size)\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eblockDim\u003c/code\u003e is the number of \u003cstrong\u003ethreads per block\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eThreads have mechanism to communicate and synchronize efficiently.\n\u003cul\u003e\n\u003cli\u003eThe CUDA programming model allows this communication for threads whiten the same block\u003c/li\u003e\n\u003cli\u003eThe therads communicate with each other \u003cstrong\u003ein the same block\u003c/strong\u003e using a special memory \u003cstrong\u003eshared memory\u003c/strong\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eThreads belonging to different block cannot communicate/synchronize with each other during the execution of the kernel.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ecudaError_t e\u003c/code\u003e.  \u003ccode\u003ecudaGetLastError\u003c/code\u003e. Even for the multiple error, only the last one is returned. \u003ccode\u003ea\u0026lt;\u0026lt;\u0026lt; , \u0026gt;\u0026gt;\u0026gt;; cudaDeviceSynchronize(); e = cudaGetLastError();\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"backlink\"\u003eBacklink\u003c/h2\u003e\n\u003cp\u003e[[Learn CUDA Programming]]\u003c/p\u003e","title":"Chapter 1. Introduction to CUDA Programming"},{"content":"Python을 이용해서 손 쉽게 CPU 사용량 정보를 알아낼 수 있는 방법. Physical core 별, logical core 별(Hyper-threading을 켠 경우), 각 core 별 사용량 정보 등을 쉽게 알아낼 수 있다. 이거 C로 짜려면 은근 귀찮은데. 어떻게 해당 정보들을 알아내는 지 궁금하네. 코드를 한번 봐야겠군.\n","date":"2020-10-22T05:46:49+09:00","permalink":"https://cychong47.github.io/post/2020/2020-10-22-how-to-get-cpu-utilization-data-with-python/","summary":"\u003cp\u003ePython을 이용해서 손 쉽게 CPU 사용량 정보를 알아낼 수 있는 방법.\nPhysical core 별, logical core 별(Hyper-threading을 켠 경우), 각 core 별 사용량 정보 등을 쉽게 알아낼 수 있다. 이거 C로 짜려면 은근 귀찮은데.\n어떻게 해당 정보들을 알아내는 지 궁금하네. 코드를 한번 봐야겠군.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/10/2020-10-22-IMG_1027.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"How to get CPU utilization data with python"},{"content":"Use the Secret and ConfigMaps $ cat my-secret.yaml apiVersion: v1 kind: Secret metadata: name: mysecret type: Opaque stringData: WSO2_CLOUD_ORG_KEY: \u0026#34;mycompany\u0026#34; WSO2_CLOUD_EMAIL: \u0026#34;sample-email@wso2.com\u0026#34; WSO2_CLOUD_PASSWORD: \u0026#34;password\u0026#34; $ kubectl apply -f my-secret.yaml secret/mysecret created From Using Kubernetes Secrets as Environment Variables\nspec: containers: - env: - name: WSO2_CLOUD_ORG_KEY valueFrom: secretKeyRef: name: mysecret key: WSO2_CLOUD_ORG_KEY ... apiVersion: v1 kind: Secret metadata: name: my-tokens type: Opaque stringData: pinboard_key: \u0026#34;FIXME\u0026#34; pocket_consumer_key: \u0026#34;FIXME\u0026#34; pocket_access_token: \u0026#34;FIXME\u0026#34; slack_api_token: \u0026#34;FIXME\u0026#34; slack_events_token: \u0026#34;FIXME\u0026#34; slack_verification_token: \u0026#34;FIXME\u0026#34; slack_signing_secret: \u0026#34;FIXME\u0026#34; telegram_token: \u0026#34;FIXME\u0026#34; telegram_api_id: \u0026#34;FIXME\u0026#34; telegram_api_hash: \u0026#34;FIXME\u0026#34; $ kubectl apply -f my-tokens.yaml secret/my-tokens created $ kubectl get secrets NAME TYPE DATA AGE default-token-57nq8 kubernetes.io/service-account-token 3 395d grafana Opaque 3 2d23h grafana-test-token-88vrz kubernetes.io/service-account-token 3 2d23h grafana-token-zc79r kubernetes.io/service-account-token 3 2d23h influxdb-token-bjb5d kubernetes.io/service-account-token 3 4d12h my-secret kubernetes.io/dockerconfigjson 1 269d my-tokens Opaque 7 4s sh.helm.release.v1.grafana.v1 helm.sh/release.v1 1 2d23h sh.helm.release.v1.influxdb.v1 helm.sh/release.v1 1 4d12h sh.helm.release.v1.podcast.v1 helm.sh/release.v1 1 4d13h sh.helm.release.v1.sosa0sa.v1 helm.sh/release.v1 1 4d13h $ kubectl get secrets my-tokens NAME TYPE DATA AGE my-tokens Opaque 7 7s $ kubectl describe secret my-tokens Name: my-tokens Namespace: default Labels: \u0026lt;none\u0026gt; Annotations: Type: Opaque Data ==== pinboard_key: 30 bytes slack_signing_secret: 32 bytes telegram_api_id: 7 bytes verification_token: 24 bytes pocket_access_token: 30 bytes pocket_consumer_key: 30 bytes slack_api_token: 56 bytes slack_events_token: 32 bytes telegram_api_hash: 32 bytes telegram_token: 46 bytes #fun-for-life #kubernetes #TIL #publish\n","date":"2020-10-19T14:21:03+09:00","permalink":"https://cychong47.github.io/post/2020/2020-10-19-use-the-secret-and-configmaps/","summary":"\u003ch1 id=\"use-the-secret-and-configmaps\"\u003eUse the Secret and ConfigMaps\u003c/h1\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ cat my-secret.yaml\napiVersion: v1\nkind: Secret\nmetadata:\n  name: mysecret\ntype: Opaque\nstringData:\n    WSO2_CLOUD_ORG_KEY: \u0026#34;mycompany\u0026#34;\n    WSO2_CLOUD_EMAIL: \u0026#34;sample-email@wso2.com\u0026#34;\n    WSO2_CLOUD_PASSWORD: \u0026#34;password\u0026#34;\n\n$ kubectl apply -f my-secret.yaml\nsecret/mysecret created\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eFrom \u003ca href=\"https://medium.com/faun/using-kubernetes-secrets-as-environment-variables-5ea3ef7581ef\"\u003eUsing Kubernetes Secrets as Environment Variables\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e    spec: \n      containers: \n        - \n          env: \n            - \n              name: WSO2_CLOUD_ORG_KEY\n              valueFrom:\n                secretKeyRef:\n                  name: mysecret\n                  key: WSO2_CLOUD_ORG_KEY\n    ...\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003cimg src=\"Use%20the%20Secret%20and%20ConfigMaps/bear_sketch@2x.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cdiv class=\"highlight\"\u003e\u003cpre tabindex=\"0\" style=\"color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;\"\u003e\u003ccode class=\"language-yaml\" data-lang=\"yaml\"\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003eapiVersion\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003ev1\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003ekind\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003eSecret\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003emetadata\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003ename\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003emy-tokens\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003etype\u003c/span\u003e: \u003cspan style=\"color:#ae81ff\"\u003eOpaque\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e\u003cspan style=\"color:#f92672\"\u003estringData\u003c/span\u003e:\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003epinboard_key\u003c/span\u003e: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;FIXME\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003epocket_consumer_key\u003c/span\u003e: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;FIXME\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003epocket_access_token\u003c/span\u003e: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;FIXME\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003eslack_api_token\u003c/span\u003e: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;FIXME\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003eslack_events_token\u003c/span\u003e: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;FIXME\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003eslack_verification_token\u003c/span\u003e: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;FIXME\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003eslack_signing_secret\u003c/span\u003e: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;FIXME\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003etelegram_token\u003c/span\u003e: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;FIXME\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003etelegram_api_id\u003c/span\u003e: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;FIXME\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003cspan style=\"display:flex;\"\u003e\u003cspan\u003e  \u003cspan style=\"color:#f92672\"\u003etelegram_api_hash\u003c/span\u003e: \u003cspan style=\"color:#e6db74\"\u003e\u0026#34;FIXME\u0026#34;\u003c/span\u003e\n\u003c/span\u003e\u003c/span\u003e\u003c/code\u003e\u003c/pre\u003e\u003c/div\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ kubectl apply -f my-tokens.yaml \nsecret/my-tokens created\n\n$ kubectl get secrets\nNAME                             TYPE                                  DATA   AGE\ndefault-token-57nq8              kubernetes.io/service-account-token   3      395d\ngrafana                          Opaque                                3      2d23h\ngrafana-test-token-88vrz         kubernetes.io/service-account-token   3      2d23h\ngrafana-token-zc79r              kubernetes.io/service-account-token   3      2d23h\ninfluxdb-token-bjb5d             kubernetes.io/service-account-token   3      4d12h\nmy-secret                        kubernetes.io/dockerconfigjson        1      269d\nmy-tokens                        Opaque                                7      4s\nsh.helm.release.v1.grafana.v1    helm.sh/release.v1                    1      2d23h\nsh.helm.release.v1.influxdb.v1   helm.sh/release.v1                    1      4d12h\nsh.helm.release.v1.podcast.v1    helm.sh/release.v1                    1      4d13h\nsh.helm.release.v1.sosa0sa.v1    helm.sh/release.v1                    1      4d13h\n\n$ kubectl get secrets my-tokens\nNAME        TYPE     DATA   AGE\nmy-tokens   Opaque   7      7s\n\n$ kubectl describe secret my-tokens\nName:         my-tokens\nNamespace:    default\nLabels:       \u0026lt;none\u0026gt;\nAnnotations:\nType:         Opaque\n\nData\n====\npinboard_key:          30 bytes\nslack_signing_secret:  32 bytes\ntelegram_api_id:       7 bytes\nverification_token:    24 bytes\npocket_access_token:   30 bytes\npocket_consumer_key:   30 bytes\nslack_api_token:       56 bytes\nslack_events_token:    32 bytes\ntelegram_api_hash:     32 bytes\ntelegram_token:        46 bytes\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e#fun-for-life #kubernetes #TIL  #publish\u003c/p\u003e","title":"Use the Secret and ConfigMaps"},{"content":"Problem CronJob이 지정된 시간에 잘 동작했는 지 확인해 본 결과 이상한 점을 발견했다.\n오후 2시 32분에 CronJob 의 동작을 확인했는데 이전에 실행된 시간이 4시간 32분 전이라고, 즉 새벽 1시가 아니라 오전 10시에 실행이 되었다는 나오는 것이다.\n$ date Sat Oct 10 14:32:36 KST 2020 $ kubectl get cronjob NAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGE pocket-stat 0 1 * * * False 0 4h32m 14h 혹시 10시를 1시로 잘못 설정했나 하고 kubectl describe cronjob 명령으로 확인해 봤지만 schedule 정보는 정상적으로 설정되어 있었다는.\nSchedule: 0 1 * * *\n하지만 kubectl describe cronjob 명령으로 확인한 실제 실행된 시간은 역시 오전 10시 Last Schedule Time: Sat, 10 Oct 2020 10:00:00 +0900\n아래는 kubectl describe cronjob 명령의 전체 결과.\n$ kubectl describe cronjob pocket-stat Name: pocket-stat Namespace: default Labels: app.kubernetes.io/managed-by=Helm Annotations: meta.helm.sh/release-name: pocket-stat meta.helm.sh/release-namespace: default Schedule: 0 1 * * * Concurrency Policy: Allow Suspend: False Successful Job History Limit: 3 Failed Job History Limit: 1 Starting Deadline Seconds: \u0026lt;unset\u0026gt; Selector: \u0026lt;unset\u0026gt; Parallelism: \u0026lt;unset\u0026gt; Completions: \u0026lt;unset\u0026gt; Pod Template: Labels: app.kubernetes.io/instance=pocket-stat app.kubernetes.io/name=pocket-stat Service Account: pocket-stat Containers: pocket-stat: Image: ghcr.io/cychong47/pocket-stat:0.1 Port: 32769/TCP Host Port: 0/TCP Environment: INFLUXDB_HOST: influxdb.default INFLUXDB_PORT: 8086 POCKET_CONSUMER_KEY: \u0026lt;set to the key \u0026#39;pocket_consumer_key\u0026#39; in secret \u0026#39;my-tokens\u0026#39;\u0026gt; Optional: false POCKET_ACCESS_TOKEN: \u0026lt;set to the key \u0026#39;pocket_access_token\u0026#39; in secret \u0026#39;my-tokens\u0026#39;\u0026gt; Optional: false TZ: Asia/Seoul Mounts: \u0026lt;none\u0026gt; Volumes: \u0026lt;none\u0026gt; Last Schedule Time: Sat, 10 Oct 2020 10:00:00 +0900 Active Jobs: \u0026lt;none\u0026gt; Events: \u0026lt;none\u0026gt; 이상하다, 이게 무슨 조화일까?\n시간을 내서 원인을 확인해 봐야겠다 싶었는데 다른 일을 하다 9시간 차이라는 게 뇌리에 남았다. 9 이라는 숫자가 왠지 낯익은데. 개발한 SW를 국내에서만 사용하면 문제가 없지만, 해외에 판매해서 우리와 다른 Timezone에서 실행하면 한번 쯤은 겪어 봤을 수 있는 UTC+9 .\n그래서 검색을 해 보니 아니나 다를 까 CronJob이 Timezone을 지원하지 않는다고.구글링 결과에서 한글로 된 자료가 별로 없었는데 아마도 다른 Timezone, kubernetes 그리고 CronJob이라는 조합이 그리 흔한 경우가 아니라서 그런 듯 하다.\nCronJob을 설명하는 공식 문서에는 이에 대해 다음과 같이 명시하고 있다.\nFrom CronJob | Kubernetes\nCaution:\nAll CronJob schedule: times are based on the timezone of the kube-controller-manager\nIf your control plane runs the kube-controller-manager in Pods or bare containers, the timezone set for the kube-controller-manager container determines the timezone that the cron job controller uses.\nQuestion : is this possible to customize the kube-controller-manager manifest ? · Issue #7827 · kubernetes/kops · GitHub Oct 26, 2019\nTimezone 는 우리나라에서만 사용하는 것도 아니고, 미국 같은 경우에는 특히나 동부, 서부도 다른 Timezone을 사용하고 있으니 관련 이슈가 이미 제기되었을 것 같고. 유럽만 해도 서로 다른 Timezone에 위치한 나라가 모여있는 곳이라 같은 문제가 있을 텐데. 확인해 보니 Kubernetes 커뮤너티에서도 이미 이슈화가 되어 검토를 했지만, 지원하지 않는 걸로 정리를 했다고 한다. Daylight Saving Time(DST)이라고 하는 Summer Time 도 고려해야 하고 kubernetes 내 다른 component들과의 시간 동기화도 고려해야 하는 등 고려해야 할 게 너무 많다고. 그래서 그냥 UTC로 고수하겠다고.\nResolutions Python의 경우도 그렇지만 환경변수 TZ을 설정하는 방법이 많이 시도된 듯 한데 Kube-controller-manager의 경우에는 해당 container의 TZ를 변경하는 건 소용이 없다고. 대신 /etc/localtime을 설정하면 된다고 한다.(참고로, 해당 파일이 없는 경우 기본 설정이 UTC)\nAfter testing today, the solution based on TZ environment variable in the kube-controller-manager pod doesn’t work.\nTo make timezone work we have to mount a volume inside the pod at /etc/localtime as is described here kubernetes/kubernetes#80577 (comment)\n변경해야 할 파일은 /etc/kubernetes/manifests/kube-controller-manager.yaml 인데, 설정 변경 후에는 자동적으로 kube-controller-manager-(hostname) pod를 다시 배포 하므로 파일만 수정하고 저장하면 된다.(restart count가 0인 걸 봐서는 단순히 restart가 아니라 기존 deployment를 제거하고 새로 deploy하는 듯 하다)\n추가 해야 할 내용은 다음과 같이 host OS의 /etc/localtime 파일을 container에 마운트하는 것이다.\n- mountPath: /etc/localtime name: localtime readOnly: true - hostPath: path: /etc/localtime type: FileOrCreate name: localtime 다시 배포된 kube-controller-manager에 제대로 mount되었는 지 확인해 본다.\n$ kubectl describe pod kube-controller-manager-mini1 -n kube-system ... Mounts: ... /etc/localtime from localtime (ro) ... ... 이제 kube-controller-manager pod와 host OS의 시간을 확인해 보면 다음과 같이 같은 시간 대 임을 알 수 있다.\n$ kubectl exec kube-controller-manager-mini1 -n kube-system -- /bin/date Tue Oct 13 22:54:26 KST 2020 $ date Tue Oct 13 22:54:27 KST 2020 이제 시간이 지나서 CronJob이 실행된 시간을 다시 확인해 보면 이제는 설정한 대로 01:00 AM 임을 확인할 수 있다.\n$ kubectl describe cronjob pocket-stat ... Last Schedule Time: Wed, 14 Oct 2020 01:00:00 +0900 ... Alternatives Kubernetes 커뮤니티에서 주로 추천하는 방법은 CronJob의 schedule을 그냥 UTC 기준으로 설정하라고. 이 경우 01:00은 전날 16:00과 같다고 하니 이렇게 설정하라는 (http://timeanddate.com/worldclock/converter.html)\nReference IBM Knowledge Center kube-controller-manager가 CronJob을 실행시키는 주체인데, kube-controller-manager container가 UTC 시간 기준으로 동작해서 Timezone을 고려하지 않으므로, 해당 container에 master node의 timezone 정보를 추가하면 될 거라고 Cron Jobs migration to Kubernetes tips |It’s my SRE life GitHub - hiddeco/cronjobber: Cronjobber is a cronjob controller for Kubernetes with support for time zones CronJob 대신 Timezone을 지원하는 resource 를 정의 ","date":"2020-10-19T14:16:45+09:00","permalink":"https://cychong47.github.io/post/2020/2020-10-19-how-to-fix-no-timezone-support-of-cronjob/","summary":"\u003ch2 id=\"problem\"\u003eProblem\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eCronJob\u003c/code\u003e이 지정된 시간에 잘 동작했는 지 확인해 본 결과 이상한 점을 발견했다.\u003c/p\u003e\n\u003cp\u003e오후 2시 32분에 \u003ccode\u003eCronJob\u003c/code\u003e 의 동작을 확인했는데 이전에 실행된 시간이 4시간 32분 전이라고, 즉 새벽 1시가 아니라 오전 10시에 실행이 되었다는  나오는 것이다.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ date\nSat Oct 10 14:32:36 KST 2020\n\n$ kubectl get cronjob\nNAME          SCHEDULE    SUSPEND   ACTIVE   LAST SCHEDULE   AGE\npocket-stat   0 1 * * *   False     0        4h32m           14h\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e혹시 10시를 1시로 잘못 설정했나 하고 \u003ccode\u003ekubectl describe cronjob\u003c/code\u003e 명령으로 확인해 봤지만 \u003ccode\u003eschedule\u003c/code\u003e 정보는 정상적으로 설정되어 있었다는.\u003c/p\u003e","title":"How to make cronjob to support timezone"},{"content":"서재 방을 뒤집으면서 이참에 책상 밑, 뒤 등에 숨겨(?)놨던 맥미니, 공유기, 나스 등을 나름 랙에 모아놓고, 랜선이 나오는 바로 벽 바로 옆에 뒀다. 그 덕에 벽에서 책상쪽으로 건너가기 위해 바닥에 있던 선 들이 이제 1개로 줄었다. 이전에는 전원선 2개, 유선 랜 2개 였는데 이제는 전원선 하나만 보냈다는.\n덕분에 바닥이 깔끔해 지긴 했는데 랙이 너무 비좁다.\nIKEA 칼락스가 하나 있으면 딱 일 것 같은데. 당근에서 저렴하게 하나 안 나오나?\n","date":"2020-10-19T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-10-19-new-homelab-rack/","summary":"\u003cp\u003e서재 방을 뒤집으면서 이참에 책상 밑, 뒤 등에 숨겨(?)놨던 맥미니, 공유기, 나스 등을 나름 랙에 모아놓고, 랜선이 나오는 바로 벽 바로 옆에 뒀다. 그 덕에 벽에서 책상쪽으로 건너가기 위해 바닥에 있던 선 들이 이제 1개로 줄었다. 이전에는 전원선 2개, 유선 랜 2개 였는데 이제는 전원선 하나만 보냈다는.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/10/2020-10-19-IMG_0007.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e덕분에 바닥이 깔끔해 지긴 했는데 랙이 너무 비좁다.\u003c/p\u003e\n\u003cp\u003eIKEA 칼락스가 하나 있으면 딱 일 것 같은데. 당근에서 저렴하게 하나 안 나오나?\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/10/2020-10-20-ikea-kallax-4x4.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"New homelab rack"},{"content":"\n","date":"2020-10-17T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-10-17-too-cute-to-me/","summary":"\u003cp\u003e\u003cimg src=\"/images/2020/10/2020-10-17-IMG_0002.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/10/2020-10-17-IMG_0003.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"Too cute to me"},{"content":"만일 job을 일정 주기 혹은 특정 시간에 실행시키려면 CronJob resource를 만들어 사용하면 된다.\nJob과 CronJob간의 관계는? CronJob에 대한 설명에 따르면 CronJob정의에 기술한 특정 시간이 되면 CronJob이 Job을 실행한다고. 그리고 그 Job이 Pod를 실행한다.\n그럼 Job을 위한 resource 정의와 CronJob을 위한 resource 정의를 각각 정의해야 하나? 그렇지는 않은 듯. CronJob의 정의 파일을 보면 JobTemplate 항목이 Job에서 볼 수 있는 Template과 유사한 container spec 등을 가지고 있다. 물론 CronJob 에서만 유효한 schedule spec 등을 추가로 가지고 있긴 하지만.\njob.yaml 과 cronjob.yaml을 둘 다 가진 경우 실제로 job.yaml과 cron.yaml 을 모두 가지고 있는 mysqldump의 helm chart를 확인하면 다음과 같다. charts/stable/mysqldump at master · helm/charts · GitHub\n$ head -n 4 cron.yaml {{- if ne .Values.schedule \u0026#34;now\u0026#34; -}} apiVersion: batch/v1beta1 kind: CronJob metadata: $ head -n 4 job.yaml {{- if eq .Values.schedule \u0026#34;now\u0026#34; -}} apiVersion: batch/v1 kind: Job metadata: 즉, Value 파일에 정의한 schedule 값이 now인 경우에는 Job을 deploy하고, 그렇지 않으면 CronJob을 deploy한다. 그러므로 하나의 Helm chart 의 templates 디렉토리에서 한 시점에 deploy될 resource type이 Job이나 CronJob 중 하나만 있어야 하는 듯. 같은 맥락에서 Job/CronJob이 아닌 Deployment가 있어도 Helm install 명령이 어떤 resource를 deploy할 지 판단할 수 없으므로 YAML 파일의 if문 등을 적절히 이용해서 한 번에 하나의 resource 만 deploy되도록 해야 한다(아마도)\nCronJob 배포 Helm을 이용한 deploy는 여느 Deployment, Job과 동일한 방법으로 진행한다.\n$ helm install -f pocket-stat-value.yaml pocket-stat helm-chart/charts/pocket-stat NAME: pocket-stat LAST DEPLOYED: Fri Oct 9 22:57:09 2020 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services pocket-stat) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT 일단 Helm 명령으로 Helm install 명령 자체는 잘 처리되었는 지 확인해 본다. 아래 pocket-stat chart가 deployed로 나오므로 최소한의 단계는 넘어간 듯\n$ helm list NAME NAMESPACE\tREVISION\tUPDATED STATUS CHART APP VERSION grafana default 1 2020-10-04 23:01:12.99628996 +0900 KST deployed\tgrafana-5.7.0 7.2.0 influxdb default 1 2020-10-03 10:22:32.033591453 +0900 KST\tdeployed\tinfluxdb-4.8.5 1.8.0 pocket-stat\tdefault 1 2020-10-09 22:57:09.385381052 +0900 KST\tdeployed\tpocket-stat-0.1.0\t1.16.0 podcast default 1 2020-10-03 08:57:19.676194777 +0900 KST\tdeployed\tnginx-0.2.0 1.0 sosa0sa default 1 2020-10-03 08:48:33.124989027 +0900 KST\tdeployed\tnginx-0.2.0 1.0 Job이나 Deployment에서와 같이 Pod 상태를 확인해 보면 없다\n$ kubectl get pods | grep pocket-stat 혹시나 하고 CronJob 항목을 확인해 보니 뭔가 있다. Value에서 지정한 Schedule대로 매일 00:10 AM에 동작하도록 정보(10 0 * * *)가 나오는 거 보면 정상적으로 배포가 된 듯\ncychong@mini1:~/work/Helm$ kubectl get cronjob NAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGE pocket-stat 10 0 * * * False 0 \u0026lt;none\u0026gt; 4m10s 앞에서 적은 대로 CronJob은 Deployment나 Job과 달리 일단 Pod를 생성하는 게 아니라 지정된 시간이 되면 Job을 만들고, 해당 Job에 의해 Pod가 배포되는 방식이므로 아직 Pod가 생성되지 않는 것이다. 내일 밤 00:10 이 지난 후에 다시 kubectl get cronjob 명령으로 LAST SCHEDULE, ‘ACTIVE` 등의 항목이 어떻게 변경되는 지 확인하면 실제로 동작했는 지 확인할 수 있을 듯.\nCronJob 삭제 CronJob 삭제는 delete cronjob 명령을 사용한다.\n$ kubectl delete cronjob pocket-stat cronjob.batch \u0026#34;pocket-stat\u0026#34; deleted $ kubectl get cronjob No resources found in default namespace. 그런데 여전히 helm에는 남아있네\n$ helm list NAME NAMESPACE\tREVISION\tUPDATED STATUS CHART APP VERSION grafana default 1 2020-10-04 23:01:12.99628996 +0900 KST deployed\tgrafana-5.7.0 7.2.0 influxdb default 1 2020-10-03 10:22:32.033591453 +0900 KST\tdeployed\tinfluxdb-4.8.5 1.8.0 pocket-stat\tdefault 1 2020-10-09 22:57:09.385381052 +0900 KST\tdeployed\tpocket-stat-0.1.0\t1.16.0 podcast default 1 2020-10-03 08:57:19.676194777 +0900 KST\tdeployed\tnginx-0.2.0 1.0 sosa0sa default 1 2020-10-03 08:48:33.124989027 +0900 KST\tdeployed\tnginx-0.2.0 1.0 $ helm uninstall pocket-stat release \u0026#34;pocket-stat\u0026#34; uninstalled 이제 helm repo에 반영. 이제 Cronjob으로 사용할 chart를 github에 만든 helm chart repo에 반영하고 다시 CronJob을 배포해 본다.\n$ helm repo update Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \u0026#34;influxdata\u0026#34; chart repository ...Successfully got an update from the \u0026#34;infracloudio\u0026#34; chart repository ...Successfully got an update from the \u0026#34;myhelmrepo\u0026#34; chart repository ...Successfully got an update from the \u0026#34;grafana\u0026#34; chart repository Update Complete. ⎈Happy Helming!⎈ $ helm search repo pocket-stat NAME CHART VERSION\tAPP VERSION\tDESCRIPTION myhelmrepo/pocket-stat\t0.1.0 1.16.0 A Helm chart for Kubernetes 이제 local filesystem에 있는 chart가 아니라 myhelmrepo에 있는 chart를 이용해서 deploy해 본다.\n$ helm install -f pocket-stat-value.yaml pocket-stat myhelmrepo/pocket-stat NAME: pocket-stat LAST DEPLOYED: Fri Oct 9 23:38:15 2020 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services pocket-stat) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT helm 배포가 정상적으로 되었는 지 확인해 보고\n$ helm list |grep pocket-stat pocket-stat\tdefault 1 2020-10-09 23:38:15.375862343 +0900 KST\tdeployed\tpocket-stat-0.1.0\t1.16.0 CronJob도 잘 배포 되었는 지 확인해 본다.\n$ kubectl get cronjob NAME SCHEDULE SUSPEND ACTIVE LAST SCHEDULE AGE pocket-stat 10 0 * * * False 0 \u0026lt;none\u0026gt; 16s 아직 한번 도 실행이 되지 않은 상태라 LAST SCHEDULE 항목이 none으로 출력되는데 나중에 한번이라도 실행이 되면, 해당 시간과 현재 시각과의 차이를 보여줄 듯\n","date":"2020-10-09T02:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-10-09-cronjob-in-kubernetes/","summary":"\u003cp\u003e만일 \u003ccode\u003ejob\u003c/code\u003e을 일정 주기 혹은 특정 시간에 실행시키려면 \u003ccode\u003eCronJob\u003c/code\u003e resource를 만들어 사용하면 된다.\u003c/p\u003e\n\u003ch2 id=\"job과-cronjob간의-관계는\"\u003e\u003ccode\u003eJob\u003c/code\u003e과 \u003ccode\u003eCronJob\u003c/code\u003e간의 관계는?\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003eCronJob\u003c/code\u003e에 대한 설명에 따르면 \u003ccode\u003eCronJob\u003c/code\u003e정의에 기술한 특정 시간이 되면 \u003ccode\u003eCronJob\u003c/code\u003e이 \u003ccode\u003eJob\u003c/code\u003e을 실행한다고. 그리고 그 \u003ccode\u003eJob\u003c/code\u003e이 \u003ccode\u003ePod\u003c/code\u003e를 실행한다.\u003c/p\u003e\n\u003cp\u003e그럼 \u003ccode\u003eJob\u003c/code\u003e을 위한 resource 정의와 \u003ccode\u003eCronJob\u003c/code\u003e을 위한 resource 정의를 각각 정의해야 하나?\n그렇지는 않은 듯. \u003ccode\u003eCronJob\u003c/code\u003e의 정의 파일을 보면 \u003ccode\u003eJobTemplate\u003c/code\u003e 항목이 \u003ccode\u003eJob\u003c/code\u003e에서 볼 수 있는 \u003ccode\u003eTemplate\u003c/code\u003e과 유사한 container spec 등을 가지고 있다. 물론 \u003ccode\u003eCronJob\u003c/code\u003e 에서만 유효한 \u003ccode\u003eschedule\u003c/code\u003e spec 등을 추가로 가지고 있긴 하지만.\u003c/p\u003e","title":"주기적으로 실행되는 앱은 CronJob으로"},{"content":"한 번 실행되면 데몬 처럼 계속해서 동작하는 앱이 아니라 필요한 일을 수행하고 종료되는 앱도 있다. 실행된 시점에 필요한 일을 수행하고 종료하는 형태로 예를 들면 특정 위치에 있는 파일을 처리하고 종료한다거나, 실행된 시점에 외부 서비스에서 필요한 정보를 가져와 어딘가 저장하는 등의 일을 하는. 이런 종류의 앱을 kubernetes에서 Deployment로 배포한 경우 해당 앱은 자신이 해야 할 일을 정상적으로 수행하고 종료되지만, kubernetes scheduler 입장에서는 해당 container가 (의도하지 않게) 종료된 것으로 판단하여 다시 복구하는 절차를 수행한다. 이는 Deployment로 배포된 container는 scheduler를 통해 배포된 것처럼 scheduler를 통해 제거되지 않으면 비정상이라고 판단하기 때문이다.\n이때 만일 복구하는데 한도를 두지 않으면 계속해서 앱이 실행되었다 종료되고, 다시 복구되는 작업을 반복하게 되는데 이는 불필요한 에러 로그만 지속적으로 생산하는 상황이 된다.\nUse Job instead of Deployment 만일 앱이 실행된 후 필요한 일을 모두 마치고 종료되는 것이 의도된 동작이라면 해당 Pod의 kind를 Deployment가 아니라 Job 형태로 정의한다.\n다만 Job을 이용한 chart를 준비할 때 사소한 이슈라면 helm create 명령으로 만들어진 helm chart template는 기본적으로 Deployment와 Service등만 만들어 Job 을 위한 YAML 파일을 만들 쉬운 방법이 없다는 점이다.(helm create 명령의 도움말이나 구글링 결과, 2020.10월 기준)\n대부분 Job에 대해 설명하는 문서에서는 간단한 YAML 파일을 기준으로 설명하고 있어, helm chart를 사용해서 배포하려는 경우에는 어떻게 chart를 만들어야 할 지 난감하다.\nmysqldump vs. mysql 다행히 github에 있는 공식 helm chart를 보면 많은 기여자들이 만든 좋은 예제를 참조할 수 있다.(이것도 역시 open-source가 주는 장점) 그래서 Job 키워드로 검색을 해 보니 몇 개의 chart가 이를 사용하는 것으로 확인되었다. 그 중에 하나 고른 것이 mysqldump. 이름 그래도 mysql의 database를 백업하는 툴 같은데, mysql shell을 이용하거나 API를 이용해서 DB에 연결해서 정보를 백업하는 형태일 것 같다.\n이때 서버 역할을 할 mysql은 당연히 늘 실행되어 있는 형태일 거라 일반적인 Deployment를 사용할 듯 하고. 그래서 Job을 사용하는 mysqldump chart와 Deployment를 사용하는 mysql의 chart를 비교해 보면 Job을 사용하는 chart를 어떻게 만들면 되는 지 감을 잡을 수 있을 듯 하다.\njob.yaml instead of deployment.yaml mysqldump의 경우 deployment.yaml 대신 job.yaml 파일과 cron.yaml 파일을 가지고 있었다. 그 외 configmap은 mysql과 mysqldump에서 파일 이름만 다를 뿐 양쪽에서 모두 사용하고 있으므로 차이점은 아니고.\ncychong@mini1:~/work/Helm/reference/official-helm-charts/stable/mysqldump/templates$ ls -al total 44 drwxrwxr-x 2 cychong cychong 4096 Oct 9 09:12 . drwxrwxr-x 4 cychong cychong 4096 Sep 20 2019 .. -rw-rw-r-- 1 cychong cychong 1934 Sep 20 2019 NOTES.txt -rw-rw-r-- 1 cychong cychong 1869 Sep 20 2019 _helpers.tpl -rwxrwxr-x 1 cychong cychong 5478 Sep 20 2019 configmap.yaml -rw-rw-r-- 1 cychong cychong 806 Sep 20 2019 cron.yaml -rw-rw-r-- 1 cychong cychong 691 Sep 20 2019 gcpserviceaccount.yaml -rw-rw-r-- 1 cychong cychong 298 Sep 20 2019 job.yaml -rw-rw-r-- 1 cychong cychong 625 Sep 20 2019 pvc.yaml -rw-rw-r-- 1 cychong cychong 1238 Sep 20 2019 secret.yaml cychong@mini1:~/work/Helm/reference/official-helm-charts/stable/mysq/templates/ls -al total 52 drwxrwxr-x 3 cychong cychong 4096 Sep 20 2019 . drwxrwxr-x 3 cychong cychong 4096 Sep 20 2019 .. -rw-rw-r-- 1 cychong cychong 1797 Sep 20 2019 NOTES.txt -rw-rw-r-- 1 cychong cychong 989 Sep 20 2019 _helpers.tpl -rw-rw-r-- 1 cychong cychong 292 Sep 20 2019 configurationFiles-configmap.yaml -rw-rw-r-- 1 cychong cychong 8137 Sep 20 2019 deployment.yaml -rw-rw-r-- 1 cychong cychong 295 Sep 20 2019 initializationFiles-configmap.yaml -rw-rw-r-- 1 cychong cychong 868 Sep 20 2019 pvc.yaml -rwxrwxr-x 1 cychong cychong 1245 Sep 20 2019 secrets.yaml -rw-rw-r-- 1 cychong cychong 800 Sep 20 2019 servicemonitor.yaml -rw-rw-r-- 1 cychong cychong 1104 Sep 20 2019 svc.yaml drwxrwxr-x 2 cychong cychong 4096 Sep 20 2019 tests job.yaml 한번 실행되면 명시적으로 중지시키지 않는 이상 계속해서 실행되는 deployment와 달리 한번 실행되어 필요한 작업을 완료한 후 종료되는 app은 kind를 Deployment가 아닌 Job으로 지정한다.\n$ helm install -f pocket-stat-value.yaml pocket-stat helm-chart/charts/pocket-stat NAME: pocket-stat LAST DEPLOYED: Fri Oct 9 16:24:22 2020 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services pocket-stat) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT Job 타입의 정보는 kubectl get jobs 명령으로 확인할 수 있다.\n$ kubectl get jobs NAME COMPLETIONS DURATION AGE pocket-stat 0/1 6s 6s 그리고 해당 Job에서 생성했던 Pod 역시 아래와 같이 kubectl get pods명령으로 확인이 가능한데, 다른 Deployment 형태의 Pod와 달리 STATUS가 Completed임을 알 수 있다. 즉 필요한 일을 마치 종료되었는데 이를 말 그대로 “Complete” 된 것으로 판단하고, 다시 재실행시키지 않는다는 의미이다.\n$ kubectl get pods NAME READY STATUS RESTARTS AGE grafana-6b66fb5758-gmvgf 1/1 Running 1 4d17h influxdb-0 1/1 Running 1 6d6h pocket-stat-ksrvr 0/1 Completed 0 12s podcast-nginx-659bcb6485-ps7qq 1/1 Running 1 6d7h sosa0sa-nginx-87fc9949c-wb4jp 1/1 Running 1 6d7h Pod의 실행 결과는 여느 Pod 와 동일하게 kubectl logs 명령으로 확인 가능.\n$ kubectl logs pocket-stat-ksrvr Check articles added since 2020-10-08 00:00:00 16 are collected in yesterday ","date":"2020-10-09T01:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-10-09-job-instead-of-deployment/","summary":"\u003cp\u003e한 번 실행되면 데몬 처럼 계속해서 동작하는 앱이 아니라 필요한 일을 수행하고 종료되는 앱도 있다. 실행된 시점에 필요한 일을 수행하고 종료하는 형태로 예를 들면 특정 위치에 있는 파일을 처리하고 종료한다거나, 실행된 시점에 외부 서비스에서 필요한 정보를 가져와 어딘가 저장하는 등의 일을 하는. 이런 종류의 앱을 kubernetes에서 \u003ccode\u003eDeployment\u003c/code\u003e로 배포한 경우 해당 앱은 자신이 해야 할 일을 정상적으로 수행하고 종료되지만, kubernetes scheduler 입장에서는 해당 container가 (의도하지 않게) 종료된 것으로 판단하여 다시 복구하는 절차를 수행한다. 이는 \u003ccode\u003eDeployment\u003c/code\u003e로 배포된 container는 scheduler를 통해 배포된 것처럼 scheduler를 통해 제거되지 않으면 비정상이라고 판단하기 때문이다.\u003c/p\u003e","title":"일회성 앱은 Deployment가 아닌 Job으로"},{"content":"Install InfluxDB with helm GitHub - influxdata/helm-charts: Official Helm Chart Repository for InfluxData Applications 가 helm chart를 이용한 설치법을 제공하는 공식 페이지.\nhelm repo add influxdata https://helm.influxdata.com/ $ helm repo list WARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /home/cychong/.kube/config WARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /home/cychong/.kube/config NAME URL myhelmrepo https://cychong47.github.io/helm-chart/ infracloudio\thttps://infracloudio.github.io/charts influxdata https://helm.influxdata.com/ $ helm search repo influxdata NAME CHART VERSION\tAPP VERSION\tDESCRIPTION influxdata/chronograf 1.1.17 1.8.0 Open-source web application written in Go and R... influxdata/influxdb 4.8.5 1.8.0 Scalable datastore for metrics, events, and rea... influxdata/influxdb-enterprise\t0.1.10 1.8.0 Run InfluxDB Enterprise on Kubernetes influxdata/influxdb2 1.0.7 2.0.0-beta A Helm chart for InfluxDB v2 influxdata/kapacitor 1.3.1 1.5.4 InfluxDB\u0026#39;s native data processing engine. It ca... influxdata/telegraf 1.7.25 1.14 Telegraf is an agent written in Go for collecti... influxdata/telegraf-ds 1.0.16 1.14 Telegraf is an agent written in Go for collecti... influxdata/telegraf-operator 1.1.3 v1.1.0 A Helm chart for Kubernetes to deploy telegraf-... $ helm upgrade --install -f influxdb-value.yaml influxdb influxdata/influxdb Release \u0026#34;influxdb\u0026#34; does not exist. Installing it now. NAME: influxdb LAST DEPLOYED: Sat Oct 3 10:22:32 2020 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: InfluxDB can be accessed via port 8086 on the following DNS name from within your cluster: http://influxdb.default:8086 You can connect to the remote instance with the influx CLI. To forward the API port to localhost:8086, run the following: kubectl port-forward --namespace default $(kubectl get pods --namespace default -l app=influxdb -o jsonpath=\u0026#39;{ .items[0].metadata.name }\u0026#39;) 8086:8086 You can also connect to the influx CLI from inside the container. To open a shell session in the InfluxDB pod, run the following: kubectl exec -i -t --namespace default $(kubectl get pods --namespace default -l app=influxdb -o jsonpath=\u0026#39;{.items[0].metadata.name}\u0026#39;) /bin/sh To view the logs for the InfluxDB pod, run the following: kubectl logs -f --namespace default $(kubectl get pods --namespace default -l app=influxdb -o jsonpath=\u0026#39;{ .items[0].metadata.name }\u0026#39;) $ kubectl get pods NAME READY STATUS RESTARTS AGE influxdb-0 1/1 Running 0 87s podcast-nginx-659bcb6485-ps7qq 1/1 Running 0 86m sosa0sa-nginx-87fc9949c-wb4jp 1/1 Running 0 95m $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE influxdb ClusterIP 10.110.66.138 \u0026lt;none\u0026gt; 8086/TCP,8088/TCP 92s kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 390d podcast-nginx NodePort 10.108.15.141 192.168.1.100 8099:30912/TCP 86m sosa0sa-nginx NodePort 10.100.21.119 192.168.1.100 80:31806/TCP 95m InfluxDB container에 접속해서 CLI확인 kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead. bash-4.4# influx Connected to http://localhost:8086 version 1.8.0 InfluxDB shell version: 1.8.0 \u0026gt; show databases name: databases name ---- _internal $ helm install -f pocket-stat-value.yaml pocket-stat helm-chart/charts/pocket-stat/ NAME: pocket-stat LAST DEPLOYED: Sun Oct 4 20:40:11 2020 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services pocket-stat) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT pocket-stat container를 이용해서 임시 데이터 입력 $ helm install -f pocket-stat-value.yaml pocket-stat ./helm-chart/charts/pocket-stat NAME: pocket-stat LAST DEPLOYED: Sun Oct 4 22:46:26 2020 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services pocket-stat) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT $ kubectl get pods NAME READY STATUS RESTARTS AGE influxdb-0 1/1 Running 0 36h pocket-stat-5b86fbc8f7-xpf9j 1/1 Running 0 20s podcast-nginx-659bcb6485-ps7qq 1/1 Running 0 37h sosa0sa-nginx-87fc9949c-wb4jp 1/1 Running 0 37h pocket-stat example app은 5초 주기로 임의의 데이터를 influxdb에 저장하는 동작 수행\n이제 influxdb에 접속해서 database에 데이터가 입력되고 있는 지 확인\n$ kubectl exec -it influxdb-0 /bin/bash kubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead. bash-4.4# influx Connected to http://localhost:8086 version 1.8.0 InfluxDB shell version: 1.8.0 \u0026gt; show databases name: databases name ---- _internal example \u0026gt; use example Using database example \u0026gt; show field keys; name: throughput fieldKey fieldType -------- --------- dl_tp integer ul_tp integer \u0026gt; select * from throughput; name: throughput time dl_tp host region ul_tp ---- ----- ---- ------ ----- 1601819189000000000 192 server01 us-west 52 1601819194000000000 156 server01 us-west 53 1601819199000000000 189 server01 us-west 62 1601819204000000000 168 server01 us-west 55 1601819209000000000 191 server01 us-west 54 1601819214000000000 182 server01 us-west 51 1601819219000000000 181 server01 us-west 60 1601819224000000000 166 server01 us-west 58 1601819229000000000 198 server01 us-west 69 1601819234000000000 190 server01 us-west 55 Install Grafana with helm GitHub - grafana/helm-charts 의 내용을 참고한다.\n$ helm repo add grafana https://grafana.github.io/helm-charts \u0026#34;grafana\u0026#34; has been added to your repositories $ helm search repo grafana NAME CHART VERSION\tAPP VERSION\tDESCRIPTION grafana/grafana\t5.7.0 7.2.0 The leading tool for querying and visualizing t... ClusterIP를\nservice: # type: ClusterIP # port: 80 # targetPort: 3000 # # targetPort: 4181 To be used with a proxy extraContainer type: NodePort targetPort: 3000 # container app. itself port: 3000 # pod nodePort: 3000 # cluster-wise externalTrafficPolicy: Local externalIPs: [192.168.1.100] annotations: {} labels: {} portName: service $ helm install -f grafana-value.yaml grafana grafana/grafana Error: Service \u0026#34;grafana\u0026#34; is invalid: spec.ports[0].nodePort: Invalid value: 3000: provided port is not in the valid range. The range of valid ports is 30000-32767 흠.. 다른 경우에 이렇게 사용했는데 뭔가 제대로 확인하는 것 같은 느낌.. 일단 다음과 같이 수정했다.\nservice: # type: ClusterIP # port: 80 # targetPort: 3000 # # targetPort: 4181 To be used with a proxy extraContainer type: NodePort targetPort: 3000 # container app. itself port: 80 # pod nodePort: 30000 # cluster-wise externalTrafficPolicy: Local externalIPs: [192.168.1.100] annotations: {} labels: {} portName: service $ helm install -f grafana-value.yaml grafana grafana/grafana NAME: grafana LAST DEPLOYED: Sun Oct 4 23:01:12 2020 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: 1. Get your \u0026#39;admin\u0026#39; user password by running: kubectl get secret --namespace default grafana -o jsonpath=\u0026#34;{.data.admin-password}\u0026#34; | base64 --decode ; echo 2. The Grafana server can be accessed via port 80 on the following DNS name from within your cluster: grafana.default.svc.cluster.local Get the Grafana URL to visit by running these commands in the same shell: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services grafana) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT 3. Login with the password from step 1 and the username: admin ################################################################################# ###### WARNING: Persistence is disabled!!! You will lose your data when ##### ###### the Grafana pod is terminated. ##### ################################################################################# $ kubectl get secret --namespace default grafana -o jsonpath=\u0026#34;{.data.admin-password}\u0026#34; | base64 --decode ; echo !@#!$!@!%!$ $ export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services grafana) $ echo $NODE_PORT 30000 이제 web을 통해 접속하면. 로그인 ID는 Grafana를 deploy했을 때 나온 안내에 있는 대로 admin 이고, 암호는 위의 명령을 통해 찾은 값을 사용해서 로그인한다.\n로그인하면 이상한(?) 기본 데이터가 보이는데 뭔가 의미있는 정보겠지. 아마도 Grafana자체가 가지고 있는 어떤 metric이 아닌가 싶은데.\n원하는 것은 influxdb에 저장된 데이터를 사용하는 것이므로, 아래 화면과 같이 “Data Sources”를 선택해서 Influxdb를 연결한다.\n어렴풋이 예전에 했던 기억이 살짝 나려고 한다.\ninfluxdb container에 대한 정보를 넣어주고 Save \u0026amp; Test를 누르니 한번에 OK가 뜬다. 이런 경우는 잘 없었는데 …. 역시 이전에 했던 기억을 되살려 데이터를 지정해 보는데 이제 3개 pod가 연동하는 걸 봤으니 test app은 삭제하고, 실제 의미있는 데이터를 넣어봐야겠다.\n$ helm uninstall pocket-stat release \u0026#34;pocket-stat\u0026#34; uninstalled Reference GitHub - influxdata/helm-charts: Official Helm Chart Repository for InfluxData Applications influxdb를 helm으로 설치하기 helm-charts/charts/influxdb at master · influxdata/helm-charts · GitHub Grafana, influxDB and python - Keep calm and write something GitHub - grafana/helm-charts Grafana를 helm으로 설치하기 #fun-for-life #helm #publish\n","date":"2020-10-04T23:36:26+09:00","permalink":"https://cychong47.github.io/post/2020/2020-10-04-install-influxdb-grafana-with-helm/","summary":"\u003ch2 id=\"install-influxdb-with-helm\"\u003eInstall InfluxDB with helm\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/influxdata/helm-charts\"\u003eGitHub - influxdata/helm-charts: Official Helm Chart Repository for InfluxData Applications\u003c/a\u003e 가 helm chart를 이용한 설치법을 제공하는 공식 페이지.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ehelm repo add influxdata https://helm.influxdata.com/\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ helm repo list\nWARNING: Kubernetes configuration file is group-readable. This is insecure. Location: /home/cychong/.kube/config\nWARNING: Kubernetes configuration file is world-readable. This is insecure. Location: /home/cychong/.kube/config\nNAME        \tURL\nmyhelmrepo  \thttps://cychong47.github.io/helm-chart/\ninfracloudio\thttps://infracloudio.github.io/charts\ninfluxdata  \thttps://helm.influxdata.com/\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ helm search repo influxdata\nNAME                          \tCHART VERSION\tAPP VERSION\tDESCRIPTION\ninfluxdata/chronograf         \t1.1.17       \t1.8.0      \tOpen-source web application written in Go and R...\ninfluxdata/influxdb           \t4.8.5        \t1.8.0      \tScalable datastore for metrics, events, and rea...\ninfluxdata/influxdb-enterprise\t0.1.10       \t1.8.0      \tRun InfluxDB Enterprise on Kubernetes\ninfluxdata/influxdb2          \t1.0.7        \t2.0.0-beta \tA Helm chart for InfluxDB v2\ninfluxdata/kapacitor          \t1.3.1        \t1.5.4      \tInfluxDB\u0026#39;s native data processing engine. It ca...\ninfluxdata/telegraf           \t1.7.25       \t1.14       \tTelegraf is an agent written in Go for collecti...\ninfluxdata/telegraf-ds        \t1.0.16       \t1.14       \tTelegraf is an agent written in Go for collecti...\ninfluxdata/telegraf-operator  \t1.1.3        \tv1.1.0     \tA Helm chart for Kubernetes to deploy telegraf-...\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ helm upgrade --install -f influxdb-value.yaml influxdb influxdata/influxdb\nRelease \u0026#34;influxdb\u0026#34; does not exist. Installing it now.\nNAME: influxdb\nLAST DEPLOYED: Sat Oct  3 10:22:32 2020\nNAMESPACE: default\nSTATUS: deployed\nREVISION: 1\nTEST SUITE: None\nNOTES:\nInfluxDB can be accessed via port 8086 on the following DNS name from within your cluster:\n\n  http://influxdb.default:8086\n\nYou can connect to the remote instance with the influx CLI. To forward the API port to localhost:8086, run the following:\n\n  kubectl port-forward --namespace default $(kubectl get pods --namespace default -l app=influxdb -o jsonpath=\u0026#39;{ .items[0].metadata.name }\u0026#39;) 8086:8086\n\nYou can also connect to the influx CLI from inside the container. To open a shell session in the InfluxDB pod, run the following:\n\n  kubectl exec -i -t --namespace default $(kubectl get pods --namespace default -l app=influxdb -o jsonpath=\u0026#39;{.items[0].metadata.name}\u0026#39;) /bin/sh\n\nTo view the logs for the InfluxDB pod, run the following:\n\n  kubectl logs -f --namespace default $(kubectl get pods --namespace default -l app=influxdb -o jsonpath=\u0026#39;{ .items[0].metadata.name }\u0026#39;)\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ kubectl get pods\nNAME                             READY   STATUS    RESTARTS   AGE\ninfluxdb-0                       1/1     Running   0          87s\npodcast-nginx-659bcb6485-ps7qq   1/1     Running   0          86m\nsosa0sa-nginx-87fc9949c-wb4jp    1/1     Running   0          95m\n\n$ kubectl get svc\nNAME            TYPE        CLUSTER-IP      EXTERNAL-IP     PORT(S)             AGE\ninfluxdb        ClusterIP   10.110.66.138   \u0026lt;none\u0026gt;          8086/TCP,8088/TCP   92s\nkubernetes      ClusterIP   10.96.0.1       \u0026lt;none\u0026gt;          443/TCP             390d\npodcast-nginx   NodePort    10.108.15.141   192.168.1.100   8099:30912/TCP      86m\nsosa0sa-nginx   NodePort    10.100.21.119   192.168.1.100   80:31806/TCP        95m\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"influxdb-container에-접속해서-cli확인\"\u003eInfluxDB container에 접속해서 CLI확인\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekubectl exec [POD] [COMMAND] is DEPRECATED and will be removed in a future version. Use kubectl kubectl exec [POD] -- [COMMAND] instead.\nbash-4.4# influx\nConnected to http://localhost:8086 version 1.8.0\nInfluxDB shell version: 1.8.0\n\u0026gt;  show databases\nname: databases\nname\n----\n_internal\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ helm install -f pocket-stat-value.yaml pocket-stat helm-chart/charts/pocket-stat/\nNAME: pocket-stat\nLAST DEPLOYED: Sun Oct  4 20:40:11 2020\nNAMESPACE: default\nSTATUS: deployed\nREVISION: 1\nNOTES:\n1. Get the application URL by running these commands:\n  export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services pocket-stat)\n  export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;)\n  echo http://$NODE_IP:$NODE_PORT\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"pocket-stat-container를-이용해서-임시-데이터-입력\"\u003e\u003ccode\u003epocket-stat\u003c/code\u003e container를 이용해서 임시 데이터 입력\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ helm install -f pocket-stat-value.yaml pocket-stat ./helm-chart/charts/pocket-stat\nNAME: pocket-stat\nLAST DEPLOYED: Sun Oct  4 22:46:26 2020\nNAMESPACE: default\nSTATUS: deployed\nREVISION: 1\nNOTES:\n1. Get the application URL by running these commands:\n  export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services pocket-stat)\n  export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;)\n  echo http://$NODE_IP:$NODE_PORT\n\n$ kubectl get pods\nNAME                             READY   STATUS    RESTARTS   AGE\ninfluxdb-0                       1/1     Running   0          36h\npocket-stat-5b86fbc8f7-xpf9j     1/1     Running   0          20s\npodcast-nginx-659bcb6485-ps7qq   1/1     Running   0          37h\nsosa0sa-nginx-87fc9949c-wb4jp    1/1     Running   0          37h\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003epocket-stat\u003c/code\u003e example app은 5초 주기로 임의의 데이터를 influxdb에 저장하는 동작 수행\u003c/p\u003e","title":"Install Influxdb and Grafana With Helm"},{"content":"\n아침에는 ‘Morning has broken’ 이지. ","date":"2020-09-23T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-09-23-homepod-with-stereo/","summary":"\u003cp\u003e\u003cimg src=\"/images/2020/09/2020-09-23-IMG_0583.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/09/2020-09-23-IMG_0584.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/09/2020-09-23-IMG_0585.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e아침에는 ‘Morning has broken’ 이지.\n\u003cimg src=\"/images/2020/09/2020-09-23-IMG_0588.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"HomePod with stereo"},{"content":"GitHub Archive Program\nIt is a hidden cornerstone of modern civilization, and the shared heritage of all humanity. The mission of the GitHub Archive Program is to preserve open source software for future generations.\nGitHub Archive Program은 현재 전세계의 거의 모든 분야의 발전에 많은 기여한 OSS의 snapshot을 떠서 보존하는 프로그램이다. 마치 지구의 재난 후에도 인류가 멸종되는 것을 막기 위해 현재 인류가 섭취하는 곡물류의 씨앗을 냉동 보관하는 것과 유사한 것이다. 인류 최후의 보물창고, 종자 보관소! 참고\nOSS에 많은 기여를 한 어떤 분의 트윗을 보고 부러웠는데 나중에 보니 나도 먼지 하나를 더했네.\nProject에 대해 소개하는 GitHub의 공식 동영상 GitHub 오픈소스 북극 저장소 방문기 ","date":"2020-09-19T08:38:22+09:00","permalink":"https://cychong47.github.io/post/2020/2020-09-19-github-arctic-valut/","summary":"\u003cp\u003e\u003ca href=\"https://archiveprogram.github.com\"\u003eGitHub Archive Program\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIt is a hidden cornerstone of modern civilization, and the shared heritage of all humanity. The mission of the GitHub Archive Program is to preserve open source software for future generations.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eGitHub Archive Program은 현재 전세계의 거의 모든 분야의 발전에 많은 기여한 OSS의 snapshot을 떠서 보존하는 프로그램이다.\n마치 지구의 재난 후에도 인류가 멸종되는 것을 막기 위해 현재 인류가 섭취하는 곡물류의 씨앗을 냉동 보관하는 것과 유사한 것이다. \u003ca href=\"https://www.samsungsds.com/global/ko/news/story/1203160_2919.html\"\u003e인류 최후의 보물창고, 종자 보관소!  \u003c/a\u003e 참고\u003c/p\u003e","title":"Dust for Github Arctic Program"},{"content":"갑자기 iPad가 carrier를 잡지 못하는\u0026hellip; 이때 해결책은 예상대로 U-SIM을 뺐다 다시 끼운다.\n흔하지는 않아도 종종 있는 현상이라고. 한번도 핸드폰에서 경험한 적이 없었는데 왜 iPad에서 끼운 지 2달 밖에 안된 U-SIM이 그런 걸까?\n","date":"2020-09-15T14:27:17+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-25-ipad-lost-celluar-suddenly/","summary":"\u003cp\u003e갑자기 iPad가 carrier를 잡지 못하는\u0026hellip;\n이때 해결책은 예상대로 U-SIM을 뺐다 다시 끼운다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/08/2020-08-25-ipad-lost-celluar-suddenly.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e흔하지는 않아도 종종 있는 현상이라고. 한번도 핸드폰에서 경험한 적이 없었는데 왜 iPad에서 끼운 지 2달 밖에 안된 U-SIM이 그런 걸까?\u003c/p\u003e","title":"Ipad-lost-celluar-suddenly"},{"content":"신한카드와 아마존 이벤트로 100불 이상 구매 시 10% 할인. 어차피 iCloud 월간 구독 비용도 내야 하고, 앱도 살 일이 생길 테니.\n","date":"2020-09-15T12:17:54+09:00","permalink":"https://cychong47.github.io/post/2020/2020-09-13-purchase-an-apple-gift-card-with-10-percent-discount/","summary":"\u003cp\u003e신한카드와 아마존 이벤트로 100불 이상 구매 시 10% 할인.\n어차피 iCloud 월간 구독 비용도 내야 하고, 앱도 살 일이 생길 테니.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg src=\"/images/2020/09/2020-09-13-purchase-an-apple-gift-card-with-10-percent-discount-.jpg\"\n    alt=\"Purchase an Apple gift card with 10 percent discount \" width=\"1280\"\u003e\n\u003c/figure\u003e","title":"Apple gift card 10% 할인 구입"},{"content":"혹시나 했더니 사진 파일 형식이 JPEG이 아니라 HEIC(High Efficiency Image File) 였다는.\n아이패드에서는 사진을 찍지 않고, 아이폰으로만 사진을 찍고 있는데, 사진을 Mac으로 옮길 때 사용하는 PhotoSync에서는 파일 변환 기능을 켜서 자동으로 JPG로 변환하고 있으니 거기서 올린 사진은 아닌 듯 하고, iPad에서 iOS shortcut을 이용해서 git repo에 직접 사진을 업로드하는데, 이때 올린 사진이 iPhone에서 HEIC로 저장하고, iCloud를 통해 iPad로 동히과된 사진이었다.\niOS Shortcut에서는 사진의 크기를 resize만 해서 올리고 있어서 그랬다는.\n사진을 그냥 Mac에서 열었을 때는 전혀 문제 없이 열리고, 같은 MD 파일에 정상적으로 표시되는 다른 JPG 파일을 포함시켜도 잘 출력이 되서 찾기가 힘들었는데 화면에 표시가 잘 되는 사진과 잘 되지 않는 것 사이에 무슨 차이가 있나 하고 확인한 exiftool에서 단서를 찾은 것이다.\n그럼 해결책은 뭘까? iOS에서 사용하는 shortcut에서 사진이 HEIC만 JPG로 변환해서 올리면 될 것 같은데 파일 구분은 어떻게 할 수 있는 건지 알아봐야겠다.\n","date":"2020-09-12T22:26:02+09:00","permalink":"https://cychong47.github.io/post/2020/2020-09-12-image-is-not-jpg-but-heic/","summary":"\u003cp\u003e혹시나 했더니 사진 파일 형식이 JPEG이 아니라 HEIC(High Efficiency Image File) 였다는.\u003cbr\u003e\n아이패드에서는 사진을 찍지 않고, 아이폰으로만 사진을 찍고 있는데, 사진을 Mac으로 옮길 때 사용하는 PhotoSync에서는 파일 변환 기능을 켜서 자동으로 JPG로 변환하고 있으니 거기서 올린 사진은 아닌 듯 하고, iPad에서 iOS shortcut을 이용해서 git repo에 직접 사진을 업로드하는데, 이때 올린 사진이 iPhone에서 HEIC로 저장하고, iCloud를 통해 iPad로 동히과된 사진이었다.\u003c/p\u003e\n\u003cp\u003eiOS Shortcut에서는 사진의 크기를 resize만 해서 올리고 있어서 그랬다는.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/09/2020-09-12-image-is-not-jpg-but-heic.png\" alt=\"\"\u003e\u003c/p\u003e","title":"블로그에 몇 몇 사진이 안 보이는 문제 해결"},{"content":"docker로 실행할 대는 환경 변수 파일에 필요한 token정보 등을 적어서 넘겼는데\ndocker run -d -p 3010:3010 --env-file=slackbot.env my-slackbot helm으로 할 때는 configmap을 사용하거나, value의 env를 사용하거나 등등.\n$ helm repo update Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \u0026#34;infracloudio\u0026#34; chart repository ...Successfully got an update from the \u0026#34;myhelmrepo\u0026#34; chart repository Update Complete. ⎈Happy Helming!⎈ $ helm search repo slackbot NAME CHART VERSION\tAPP VERSION\tDESCRIPTION myhelmrepo/slackbot\t0.1.0 1.16.0 A Helm chart for Kubernetes $ helm install -f ../../slackbot-value.yaml --version 0.1.0 slackbot myhelmrepo/slackbot NAME: slackbot LAST DEPLOYED: Thu Sep 10 09:47:26 2020 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services slackbot) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT slackbot-value.yaml파일의 환경 변수에 필요한 token 정보들을 기술\n$ cat ../../slackbot-value.yaml env: slack_api_token: XXX slack_events_token: YYY slack_signing_secret: ZZZ verification_token: AAA tz: Asia/Seoul 잠시 후 띠릭띠릭 하고 slack에서 notification이 올라오는데 흠.. 결과를 에러…\n$ kubectl get pods NAME READY STATUS RESTARTS AGE podcast-nginx-659bcb6485-vc6lb 1/1 Running 2 69d slackbot-86bd64f8bf-84b7c 0/1 Running 3 3m26s sosa0sa-nginx-87fc9949c-462s6 1/1 Running 1 5d10h $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 367d podcast-nginx NodePort 10.102.38.142 192.168.1.100 8099:32529/TCP 69d slackbot NodePort 10.96.167.110 \u0026lt;none\u0026gt; 3010:31144/TCP 3m32s sosa0sa-nginx NodePort 10.99.91.25 192.168.1.100 80:32492/TCP 22d 흠. Pod는 정상적으로 deploy가 되었는데 뭔가 좀 이상하네…. 일단 external IP가 없고. 이러면 외부에서 통신이 안될텐데….. 혹시나 하고 slack에서 talk을 걸어보지만 무심한 당신은 답변이 없네.\n저건 service 설정이 잘못된 건데.\nHelm chart의 template/service.yaml 파일에 NodePort를 사용하도록 변경하고 Helm chart 를 다시 업로드한 후 다시 시도 [[Helm chart 버전 변경]]\n$ helm install -f slackbot-value.yaml --version 0.2.0 slackbot myhelmrepo/slackbot NAME: slackbot LAST DEPLOYED: Thu Sep 10 10:28:48 2020 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services slackbot) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT $ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 367d podcast-nginx NodePort 10.102.38.142 192.168.1.100 8099:32529/TCP 69d slackbot NodePort 10.103.61.67 192.168.1.100 3010:31407/TCP 25s sosa0sa-nginx NodePort 10.99.91.25 192.168.1.100 80:32492/TCP 22d 이전과 달리 NodePort 관련 에러는 없어졌다. 여전히 Readiness와 Liveness 에러는 있지만.\n$ kubectl get pods NAME READY STATUS RESTARTS AGE podcast-nginx-659bcb6485-vc6lb 1/1 Running 2 69d slackbot-86bd64f8bf-jhckf 0/1 Running 3 3m6s sosa0sa-nginx-87fc9949c-462s6 1/1 Running 1 5d10h 이전에 K8s에 올린 것들은 모두 nginx나 ghost 같이 기본적인 처리(?)를 해줘서 저런 문제가 없었나 보다. Flask에도 readiness, liveness를 추가해야겠다. [[Readiness and Liveness in flask]]\nLiveness 추가 [[Readiness and Liveness in flask]] 후에 드디어 정상적으로 flask 기반의 slackbot이 정상적으로 동작한다.\n$ helm repo update Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \u0026#34;infracloudio\u0026#34; chart repository ...Successfully got an update from the \u0026#34;myhelmrepo\u0026#34; chart repository Update Complete. ⎈Happy Helming!⎈ @mini1:~/work/helm/helm-chart$ helm search repo slackbot NAME CHART VERSION\tAPP VERSION\tDESCRIPTION myhelmrepo/slackbot\t0.3.0 1.16.0 A Helm chart for Kubernetes ","date":"2020-09-10T23:38:18+09:00","permalink":"https://cychong47.github.io/post/2020/2020-09-10-helmize-slackbot/","summary":"\u003cp\u003edocker로 실행할 대는 환경 변수 파일에 필요한 token정보 등을 적어서 넘겼는데\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edocker run -d -p 3010:3010 --env-file=slackbot.env my-slackbot\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ehelm으로 할 때는 configmap을 사용하거나, value의 \u003ccode\u003eenv\u003c/code\u003e를 사용하거나 등등.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ helm repo update\nHang tight while we grab the latest from your chart repositories...\n...Successfully got an update from the \u0026#34;infracloudio\u0026#34; chart repository\n...Successfully got an update from the \u0026#34;myhelmrepo\u0026#34; chart repository\nUpdate Complete. ⎈Happy Helming!⎈\n\n$ helm search repo slackbot\nNAME               \tCHART VERSION\tAPP VERSION\tDESCRIPTION                \nmyhelmrepo/slackbot\t0.1.0        \t1.16.0     \tA Helm chart for Kubernetes\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ helm install -f ../../slackbot-value.yaml --version 0.1.0 slackbot myhelmrepo/slackbot\nNAME: slackbot\nLAST DEPLOYED: Thu Sep 10 09:47:26 2020\nNAMESPACE: default\nSTATUS: deployed\nREVISION: 1\nNOTES:\n1. Get the application URL by running these commands:\n  export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services slackbot)\n  export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;)\n  echo http://$NODE_IP:$NODE_PORT\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003eslackbot-value.yaml\u003c/code\u003e파일의 환경 변수에 필요한 token 정보들을 기술\u003c/p\u003e","title":"Helmize Slackbot"},{"content":"docker image를 GHCR(GitHub Container Registry)에 업로드한 다음 같은 image ID를 갖는 여러 항목이 나타났다. 그동안 local machine에 있던 docker image를 GHCR에 업로드 했으니 더 이상 local host에 이미지가 없어도 되지 않을까 하는 생각에 원래 있던 image를 삭제하려고 하는데 이 경우 에러가 발생한다.\ncychong@mini1:~/work/slackbot$ docker images |grep slackbot my-slackbot latest 16cdaacd672e 5 days ago 133MB ghcr.io/cychong47/my-slackbot 0.1 16cdaacd672e 5 days ago 133MB ghcr.io/cychong47/slackbot 0.1 16cdaacd672e 5 days ago 133MB cychong@mini1:~/work/slackbot$ docker images |grep pocket pocket-retagger latest 942ef4cc7a60 2 days ago 285MB ghcr.io/cychong47/pocket-retagger latest 942ef4cc7a60 2 days ago 285MB cychong@mini1:~/work/slackbot$ docker images |grep ghost ghost 3.8.0 a6ab8e0a010a 6 months ago 394MB ghcr.io/cychong47/ghost 3.8.0 a6ab8e0a010a 6 months ago 394MB 그래서인지 docker image로 삭제하려고 하면 에러가 난다.\ncychong@mini1:~/work/slackbot$ docker rmi a6ab8e0a010a Error response from daemon: conflict: unable to delete a6ab8e0a010a (must be forced) - image is referenced in multiple repositories 음… 일단 한번 더 이상 사용하지 않는 docker image를 강제로 삭제해 봤다.\ncychong@mini1:~/work/slackbot$ docker images |grep ghost ghost 3.8.0 a6ab8e0a010a 6 months ago 394MB ghcr.io/cychong47/ghost 3.8.0 a6ab8e0a010a 6 months ago 394MB cychong@mini1:~/work/slackbot$ docker rmi -f a6ab8e0a010a Untagged: ghost:3.8.0 Untagged: ghost@sha256:821b1f33bc9868b39eea7ecd42a4b1320c7d5a8a5d3ed597c6d1c88fd55b0e52 Untagged: ghcr.io/cychong47/ghost:3.8.0 Untagged: ghcr.io/cychong47/ghost@sha256:d7305e5e7f9b24b69b2b883cc1b84988746c6ae8e88e862f2bfdc54d023ecfdc Deleted: sha256:a6ab8e0a010ae92f22619928aa62ffeb0370768bebe9e5a83b2676774a6af37e Deleted: sha256:7206e644229eafbb451a72727b84e36f65f8d5b98a8527837efb6c1057ecaedb Deleted: sha256:6c0b480a0f3ae04bc1ffd05175883781a6eff80b2ed6cd47234165cd8247722e Deleted: sha256:45b39ee767f6e9c2622980f3936fdb7d36f53d384a36a705f76e108cc8b049d2 Deleted: sha256:83b6ac7cf54af9c0ab9c4fc6e778ff58ad48867939f983aba7047d470bdacc68 Deleted: sha256:3dec8d1f9cbdc89ad4ea29e2f38d57b72e42baa4fe52595676582ee792989b99 Deleted: sha256:374cf1e1966728e5306fbeb61c7080535f3c0a078f7dcf65b0aabde1355d2c96 Deleted: sha256:b603cee30096ded2772fbb34552aa78a2e48e750a13a56eedc50c33b45b8353b Deleted: sha256:bf996bc2e6349602474e920ef3343776d26a9575d944967832f8e34c63a236e2 Deleted: sha256:f2cb0ecef392f2a630fa1205b874ab2e2aedf96de04d0b8838e4e728e28142da cychong@mini1:~/work/slackbot$ docker images |grep ghost 뭔가 찜찜(?)하게 Untagged 어쩌구 하는 메시지가 나온다.\n다행히 GitHub Container Registry(ghcr.io)에 등록된 docker image는 영향이 없네. 흠… 문제(?)는 지금 사용하고 있는 image는 어떻게 하지? 일단 현재 실행되고 있는 container를 우선 내린 후에 이미지를 삭\u001d제해야 하나?\n해결책은 의외로 간단하네.\ndocker rmi | Docker Documentation\n\u0026gt; $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE test1 latest fd484f19954f 23 seconds ago 7 B (virtual 4.964 MB) test latest fd484f19954f 23 seconds ago 7 B (virtual 4.964 MB) test2 latest fd484f19954f 23 seconds ago 7 B (virtual 4.964 MB) $ docker rmi fd484f19954f Error: Conflict, cannot delete image fd484f19954f because it is tagged in multiple repositories, use -f to force 2013/12/11 05:47:16 Error: failed to remove one or more images $ docker rmi test1:latest Untagged: test1:latest $ docker rmi test2:latest Untagged: test2:latest $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE test latest fd484f19954f 23 seconds ago 7 B (virtual 4.964 MB) $ docker rmi test:latest Untagged: test:latest Deleted: fd484f19954f4920da7ff372b5067f5b7ddb2fd3830cecd17b96ea9e286ba5b8 같은 방법으로 REPOSITORY:TAG의 형태로 image를 삭제하면\ncychong@mini1:~/work/slackbot$ docker rmi pocket-retagger:latest Untagged: pocket-retagger:latest cychong@mini1:~/work/slackbot$ docker images |grep pocket ghcr.io/cychong47/pocket-retagger latest 942ef4cc7a60 2 days ago 285MB RTFM\n#troubleshooting #TIL/docker\n","date":"2020-09-08T23:38:16+09:00","permalink":"https://cychong47.github.io/post/2020/2020-09-08-remove-docker-images-referenced-multiple-repos/","summary":"\u003cp\u003edocker image를 GHCR(GitHub Container Registry)에 업로드한 다음 같은 image ID를 갖는 여러 항목이 나타났다.\n그동안 local machine에 있던 docker image를 GHCR에 업로드 했으니 더 이상 local host에 이미지가 없어도 되지 않을까 하는 생각에 원래 있던 image를 삭제하려고 하는데 이 경우 에러가 발생한다.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/work/slackbot$ docker images |grep slackbot\nmy-slackbot                          latest              16cdaacd672e        5 days ago          133MB\nghcr.io/cychong47/my-slackbot        0.1                 16cdaacd672e        5 days ago          133MB\nghcr.io/cychong47/slackbot           0.1                 16cdaacd672e        5 days ago          133MB\ncychong@mini1:~/work/slackbot$ docker images |grep pocket\npocket-retagger                      latest              942ef4cc7a60        2 days ago          285MB\nghcr.io/cychong47/pocket-retagger    latest              942ef4cc7a60        2 days ago          285MB\ncychong@mini1:~/work/slackbot$ docker images |grep ghost\nghost                                3.8.0               a6ab8e0a010a        6 months ago        394MB\nghcr.io/cychong47/ghost              3.8.0               a6ab8e0a010a        6 months ago        394MB\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e그래서인지 docker image로 삭제하려고 하면 에러가 난다.\u003c/p\u003e","title":"Remove docker images referenced in multiple repos"},{"content":"helm chart 추가하기 charts 디렉토리 아래에 추가할 helm chart 만들기 이번에는 기존에 만들어 사용하던 ghost chart를 등록해 본다. 일단 ghost chart를 아래와 같이 charts/ghost 디렉토리에 복사하고 lint 검사.\ncychong@mini1:~/work/helm/my-helm-chart$ helm lint charts/ghost/ ==\u0026gt; Linting charts/ghost/ [INFO] Chart.yaml: icon is recommended 1 chart(s) linted, 0 chart(s) failed Helm chart 패키징 cychong@mini1:~/work/helm/my-helm-chart$ helm package charts/* Successfully packaged chart and saved it to: /home/cychong/work/helm/my-helm-chart/my-ghost-0.1.0.tgz Successfully packaged chart and saved it to: /home/cychong/work/helm/my-helm-chart/nginx-0.2.0.tgz cychong@mini1:~/work/helm/my-helm-chart$ ls *.tgz my-ghost-0.1.0.tgz nginx-0.2.0.tgz Chart indexing Helm chart 들을 indexing. Indexing 후 index.yaml 파일을 보면 이전에는 nginx만 있었는데 my-ghost라는 새로운 chart가 추가된 걸 확인할 수 있다.\ncychong@mini1:~/work/helm/my-helm-chart$ helm repo index --url https://cychong47.github.io/helm-chart/ . cychong@mini1:~/work/helm/my-helm-chart$ cat index.yaml apiVersion: v1 entries: my-ghost: - apiVersion: v1 appVersion: \u0026#34;1.0\u0026#34; created: \u0026#34;2020-09-07T21:29:59.12354973+09:00\u0026#34; description: A Helm chart for ghost digest: 9e8905399114cd3f8c45392fb7e716916379ad80eb366f466396722afdd6329b name: my-ghost urls: - https://cychong47.github.io/helm-chart/my-ghost-0.1.0.tgz version: 0.1.0 nginx: - apiVersion: v1 appVersion: \u0026#34;1.0\u0026#34; created: \u0026#34;2020-09-07T21:29:59.124928723+09:00\u0026#34; description: A Helm chart for nginx digest: 35b0caf13ee8f29a942de4994b4c43cc32adeef8ea7cd2273d779fde965e25ee maintainers: - email: cychong@gmail.com name: Chaeyong Chong name: nginx urls: - https://cychong47.github.io/helm-chart/nginx-0.2.0.tgz version: 0.2.0 generated: \u0026#34;2020-09-07T21:29:59.122168178+09:00\u0026#34; Chart upload 이제 chart 파일을 업로드\ncychong@mini1:~/work/helm/my-helm-chart$ git ci -m \u0026#34;add ghost chart\u0026#34; \u0026amp;\u0026amp; git push origin master [master 5152ee2] add ghost chart 4 files changed, 77 insertions(+), 3 deletions(-) create mode 100644 ghost-value.yaml create mode 100644 my-ghost-0.1.0.tgz rewrite nginx-0.2.0.tgz (98%) Username for \u0026#39;https://github.com\u0026#39;: cychong47 Password for \u0026#39;https://cychong47@github.com\u0026#39;: Enumerating objects: 9, done. Counting objects: 100% (9/9), done. Delta compression using up to 2 threads Compressing objects: 100% (6/6), done. Writing objects: 100% (6/6), 8.59 KiB | 8.59 MiB/s, done. Total 6 (delta 1), reused 0 (delta 0) remote: Resolving deltas: 100% (1/1), completed with 1 local object. To https://github.com/cychong47/helm-chart.git 1b9e101..5152ee2 master -\u0026gt; master helm 명령으로 chart 검색 helm 명령으로 추가한 ghost chart가 검색되는 지 확인\ncychong@mini1:~/work/helm/my-helm-chart$ helm search repo ghost NAME CHART VERSION\tAPP VERSION\tDESCRIPTION myhelmrepo/my-ghost\t0.1.0 1.0 A Helm chart for ghost Reference [[Setup GitHub based Helm repo]]\n","date":"2020-09-07T21:40:44+09:00","permalink":"https://cychong47.github.io/post/2020/2020-09-07-add-new-helm-chart/","summary":"\u003ch1 id=\"helm-chart-추가하기\"\u003ehelm chart 추가하기\u003c/h1\u003e\n\u003ch2 id=\"charts-디렉토리-아래에-추가할-helm-chart-만들기\"\u003e\u003ccode\u003echarts\u003c/code\u003e 디렉토리 아래에 추가할 helm chart 만들기\u003c/h2\u003e\n\u003cp\u003e이번에는 기존에 만들어 사용하던 \u003ccode\u003eghost\u003c/code\u003e chart를 등록해 본다.\n일단 \u003ccode\u003eghost\u003c/code\u003e chart를 아래와 같이 \u003ccode\u003echarts/ghost\u003c/code\u003e 디렉토리에 복사하고 lint 검사.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/work/helm/my-helm-chart$ helm lint charts/ghost/\n==\u0026gt; Linting charts/ghost/\n[INFO] Chart.yaml: icon is recommended\n\n1 chart(s) linted, 0 chart(s) failed\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"helm-chart-패키징\"\u003eHelm chart 패키징\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/work/helm/my-helm-chart$ helm package charts/*\nSuccessfully packaged chart and saved it to: /home/cychong/work/helm/my-helm-chart/my-ghost-0.1.0.tgz\nSuccessfully packaged chart and saved it to: /home/cychong/work/helm/my-helm-chart/nginx-0.2.0.tgz\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/work/helm/my-helm-chart$ ls *.tgz\nmy-ghost-0.1.0.tgz  nginx-0.2.0.tgz\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"chart-indexing\"\u003eChart indexing\u003c/h2\u003e\n\u003cp\u003eHelm chart 들을 indexing. Indexing 후 \u003ccode\u003eindex.yaml\u003c/code\u003e 파일을 보면 이전에는 \u003ccode\u003enginx\u003c/code\u003e만 있었는데 \u003ccode\u003emy-ghost\u003c/code\u003e라는 새로운 chart가 추가된 걸 확인할 수 있다.\u003c/p\u003e","title":"Add new Helm Chart"},{"content":"Install BotKube for k8s and slack Slack :: Messaging bot for monitoring and debugging Kubernetes clusters\ncychong@mini1:~$ helm repo add infracloudio https://infracloudio.github.io/charts \u0026#34;infracloudio\u0026#34; has been added to your repositories cychong@mini1:~$ helm repo update Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \u0026#34;infracloudio\u0026#34; chart repository ...Successfully got an update from the \u0026#34;myhelmrepo\u0026#34; chart repository Update Complete. ⎈ Happy Helming!⎈ botkube를 위한 namespace 만들어주기\ncychong@mini1:~$ kubectl create ns botkube namespace/botkube created Cluster 이름 알아내기\ncychong@mini1:~$ kubectl config view apiVersion: v1 clusters: - cluster: certificate-authority-data: DATA+OMITTED server: https://192.168.1.100:6443 name: kubernetes contexts: - context: cluster: kubernetes user: kubernetes-admin name: kubernetes-admin@kubernetes current-context: kubernetes-admin@kubernetes kind: Config preferences: {} users: - name: kubernetes-admin user: client-certificate-data: REDACTED client-key-data: REDACTED Helm을 이용해서 botkube 설치\ncychong@mini1:~$ helm install --version v0.10.0 botkube --namespace botkube \\ \u0026gt; --set communications.slack.enabled=true \\ \u0026gt; --set communications.slack.channel=notification \\ \u0026gt; --set communications.slack.token=\u0026lt;BOTKUBE_TOKEN_ASSIGNED_DURING_BOTKUBE_APP_INSTALL\u0026gt; \\ \u0026gt; --set config.settings.clustername=kubernetes \\ \u0026gt; --set config.settings.allowkubectl=true \\ \u0026gt; --set image.repository=infracloudio/botkube \\ \u0026gt; --set image.tag=v0.10.0 \\ \u0026gt; infracloudio/botkube NAME: botkube LAST DEPLOYED: Fri Sep 4 23:26:16 2020 NAMESPACE: botkube STATUS: deployed REVISION: 1 TEST SUITE: None cychong@mini1:~$ kubectl get pods -n botkube NAME READY STATUS RESTARTS AGE botkube-8cc75f5f-q6f52 1/1 Running 0 37s BotKube in slack 일단 @BotKube를 초대한 후 kubectl get commands Notification for pod deletion Pod를 임의로 삭제해 봤는데 이렇게 slack으로 이와 관련된 notification이. 받은 메시지 순서를 보면 우선 장애가 발생한 pod를 대체할 새로운 pod를 만들었다는 메시지가 먼저 오고, 그 다음 pod 장애, pod 삭제 등의 메시지가 수신된다. 요거 좀 확인해 봐야 겠다. 궁금하네.. 적어도 Pod Error가 먼저 올 줄 알았는데\u0026hellip;\nPod가 복구되었는 지 확인해 보니 새로운 pod 가 잘 동작하고 있다. AGE 3m24s 기본 value에 적힌 권한은 모두 read-only라고 하니 Slack을 이용해서 설정을 변경하려면 value.yaml 파일을 원하는 값으로 만들어 helm 을 다시 적용하면 된다. 일단 오늘은 여기 까지 하고 자야겠다. - Configuration :: Messaging bot for monitoring and debugging Kubernetes clusters 참고.\nReference Botkube + Kubernetes Slack :: Messaging bot for monitoring and debugging Kubernetes clusters #fun-for-life #public\n","date":"2020-09-04T23:51:45+09:00","permalink":"https://cychong47.github.io/post/2020/2020-09-04-install-botkube/","summary":"\u003ch1 id=\"install-botkube-for-k8s-and-slack\"\u003eInstall BotKube for k8s and slack\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://www.botkube.io/installation/slack/\"\u003eSlack :: Messaging bot for monitoring and debugging Kubernetes clusters\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ helm repo add infracloudio https://infracloudio.github.io/charts\n\u0026#34;infracloudio\u0026#34; has been added to your repositories\ncychong@mini1:~$ helm repo update\nHang tight while we grab the latest from your chart repositories...\n...Successfully got an update from the \u0026#34;infracloudio\u0026#34; chart repository\n...Successfully got an update from the \u0026#34;myhelmrepo\u0026#34; chart repository\nUpdate Complete. ⎈ Happy Helming!⎈\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003ebotkube를 위한 namespace 만들어주기\u003c/p\u003e","title":"Botkube to monitor K8s cluster in Slack"},{"content":"\n","date":"2020-09-03T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-09-03-slackbot-get-the-song-list/","summary":"\u003cp\u003e\u003cimg src=\"/images/2020/09/2020-09-03-IMG_0258.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"Slackbot get the song list"},{"content":"http://sosa0sa.com:8099/podcast/index.xml\n매번 까먹네. 중간에 podcast가 있다는 거. 블로그 자체는 http://sosa0sa.com:8099만으로 접속이 되니 저렇게 다른 경로가 기억이 나지 않네.\n수정할 수 있는 지 확인해 봐야겠다.\n","date":"2020-08-31T10:09:56+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-31-rss-feed-url-for-podcast/","summary":"\u003cp\u003e\u003ccode\u003ehttp://sosa0sa.com:8099/podcast/index.xml\u003c/code\u003e\u003c/p\u003e\n\u003cp\u003e매번 까먹네. 중간에 \u003ccode\u003epodcast\u003c/code\u003e가 있다는 거. 블로그 자체는 \u003ccode\u003ehttp://sosa0sa.com:8099\u003c/code\u003e만으로 접속이 되니 저렇게 다른 경로가 기억이 나지 않네.\u003c/p\u003e\n\u003cp\u003e수정할 수 있는 지 확인해 봐야겠다.\u003c/p\u003e","title":"RSS feed URL for podcast"},{"content":"\n","date":"2020-08-31T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-31-cannot-wait-for-ios14-gm/","summary":"\u003cp\u003e\u003cimg src=\"/images/2020/08/2020-08-31-IMG_0219.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/08/2020-08-31-IMG_0220.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"Cannot wait for iOS14 GM"},{"content":"\n","date":"2020-08-27T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-27-windy-day-in-watch-face/","summary":"\u003cp\u003e\u003cimg src=\"/images/2020/08/2020-08-27-IMG_0163.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/08/2020-08-27-IMG_0164.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"Windy day in watch face"},{"content":"https://ruddra.com/hugo-deploy-static-page-using-github-actions/ 에 있는 내용대로 git repository의 .github/workflows 아래 main.yml 몇 가지만 수정했더니 잘 동작하는 듯.\n이미 Hugo용 github repo를 가지고 있으므로 내가 추가로 해야 할일은\nGitHub 계정에서 Access Token 만들어서 Git repository에 Secret로 추가 GitHub Action 파일 작성 - .github/workflows/main.yml 일단 이거면 끝.\n.github/workflows/main.yml name: CI on: push jobs: deploy: runs-on: ubuntu-latest steps: - name: Git checkout uses: actions/checkout@v2 - name: Update theme # (Optional)If you have the theme added as submodule, you can pull it and use the most updated version run: git submodule update --init --recursive - name: Setup hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: \u0026#34;0.74.2\u0026#34; - name: Clean public directory run: rm -rf public - name: Build # remove --minify tag if you do not need it # docs: https://gohugo.io/hugo-pipes/minification/ run: hugo --minify - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: personal_token: ${{ secrets.TOKEN }} external_repository: cychong47/cychong47.github.io publish_dir: ./public # keep_files: true user_name: Chaeyong Chong user_email: cychonggmail.com publish_branch: master cname: cychong47.github.io 수정한 부분은 Hugo 버전, Deploy 의 external_repository, user_name, user_email, cname 정도 뿐.\nAction 이제 파일을 하나 추가해 보고 잘 동작하는 지 봐야 할 텐데 위 그림 파일을 먼저 commit해 보고 잘 동작하는 지 봐야겠다.\n잘 동작하네. 신기하네….. ㅎㅎ\n이제는 Bear에서 글을 쓰고, iOS shortcut을 이용해 commit하면 자동으로 블로그 업데이트는 GitHub Action이 알아서. 이젠 iPad에서 블로그에 글 올리는 게 진짜 편해졌네. 사람들이(주로 외국 사람들)이 왜 Working Copy를 그렇게 칭찬하는 지 조금 이해가 되네. GitHub나 GitLab등이 제공하는 자동화 기능을 iPad에서도 활용할 수 있는 중요한 glue 역할을 하네.\n첫번째 사진에 있는 workflow를 보니 첫 단계인 Set up job과 마지막 2개 단계인 Post Git Checkout, Complete job을 제외한 나머지는 모두 workflow 파일에 기술된 내용이네.\ncychong15:workflows cychong$ grep \u0026#34; name\u0026#34; main.yml | awk -F \u0026#34;:\u0026#34; \u0026#39;{print $2}\u0026#39; Git checkout Update theme Setup hugo Clean public directory Build Deploy ","date":"2020-08-19T23:01:58+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-19-automate-blog-posting-with-github-action/","summary":"\u003cp\u003e\u003ca href=\"https://ruddra.com/hugo-deploy-static-page-using-github-actions/\"\u003ehttps://ruddra.com/hugo-deploy-static-page-using-github-actions/\u003c/a\u003e 에 있는 내용대로 git repository의 \u003ccode\u003e.github/workflows\u003c/code\u003e 아래 \u003ccode\u003emain.yml\u003c/code\u003e 몇 가지만 수정했더니 잘 동작하는 듯.\u003c/p\u003e\n\u003cp\u003e이미 Hugo용 github repo를 가지고 있으므로 내가 추가로 해야 할일은\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGitHub 계정에서 Access Token 만들어서 Git repository에 \u003ccode\u003eSecret\u003c/code\u003e로 추가\u003c/li\u003e\n\u003cli\u003eGitHub Action 파일 작성 - \u003ccode\u003e.github/workflows/main.yml\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e일단 이거면 끝.\u003c/p\u003e\n\u003ch2 id=\"githubworkflowsmainyml\"\u003e\u003ccode\u003e.github/workflows/main.yml\u003c/code\u003e\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ename: CI\non: push\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Git checkout\n        uses: actions/checkout@v2\n\n      - name: Update theme\n        # (Optional)If you have the theme added as submodule, you can pull it and use the most updated version\n        run: git submodule update --init --recursive\n\n      - name: Setup hugo\n        uses: peaceiris/actions-hugo@v2\n        with:\n          hugo-version: \u0026#34;0.74.2\u0026#34;\n\n      - name: Clean public directory\n        run: rm -rf public\n      - name: Build\n        # remove --minify tag if you do not need it\n        # docs: https://gohugo.io/hugo-pipes/minification/\n        run: hugo --minify\n\n      - name: Deploy\n        uses: peaceiris/actions-gh-pages@v3\n        with:\n          personal_token: ${{ secrets.TOKEN }}\n          external_repository: cychong47/cychong47.github.io\n          publish_dir: ./public\n          #   keep_files: true\n          user_name: Chaeyong Chong\n          user_email: cychonggmail.com\n          publish_branch: master\n          cname: cychong47.github.io\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e수정한 부분은 Hugo 버전, \u003ccode\u003eDeploy\u003c/code\u003e 의 \u003ccode\u003eexternal_repository\u003c/code\u003e, \u003ccode\u003euser_name\u003c/code\u003e, \u003ccode\u003euser_email\u003c/code\u003e, \u003ccode\u003ecname\u003c/code\u003e 정도 뿐.\u003c/p\u003e","title":"Automate Blog Posting with GitHub Action"},{"content":"폰 수리 때문에 받은 대여폰. 며칠 이라도 돈 나갈 일은 있을테니 은행앱을 설치하는데 신한은행은 인증서 요구하지 않고 본인 인증하고 로그인해서 이체 하는데 전혀 문제 없는데 SC은행은 인증서 없다고 거부. 다행히 미리 오픈뱅킹으로 연동해놔서 신한에서 SC계좌 접근이 가능해서 문제는 없는데.\n매일 밤에는 계좌조회도 안되는 SC은행. 몇 년 전에는 적은 영업점 수를 경쟁 은행보다 앞선 인터넷 뱅킹 등으로 해결한다는 평이 많았는데 지금은 ‘갸우뚱’.\n‘제일 먼저’가 큰 의미를 갖는 건 맞지만 시간이 조금 지난 시점에는 그것보다는 ‘제일 우수’한 게 만 배는 더 중요하다. ‘제일 먼저’의 능력과 실천력 등을 발전시켜 그 격차를 유지한 게 아니라면 의미가 전혀 없게 된다는.\n예전에 가전 제품 보면 ‘세계 최초’ 표현이 달린 예전 제품을 자랑하는 걸 본적이 많았는데 그 옆에 함께 나열된 제품들은 이미 경쟁사 제품보다 훨씬 후진 걸 볼 때마다 안타까울 때가 많았다.\n아주 오래전에 우리가 만든 제품이 세계 최초로 실용화했다. 그리고 1년 인가 후에 (전해들은 내용으로는) 전시회에서 경쟁사 사람이 와서 한 이야기가 “니네가 world-first’인지는 몰라도 우리는 ‘world-best’다 라고 했다고” ‘선빵’이 중요한 것 맞는데 그 선빵의 기회를 잘 활용하고 선빵의 효과를 지속시키고 강화시키는 노력에 없으면 금새 사라지고 만다. 그저 ‘시장의 선구자’있다는 타이틀만 남기고 사라진다는.\n이게 비단 회사에만 해당 하는 일일까. 뜨끔. 아니 쓰리다\n","date":"2020-08-19T14:04:18+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-19-being-the-first-is-not-enough/","summary":"\u003cp\u003e폰 수리 때문에 받은 대여폰. 며칠 이라도 돈 나갈 일은 있을테니 은행앱을 설치하는데 신한은행은 인증서 요구하지 않고 본인 인증하고 로그인해서 이체 하는데 전혀 문제 없는데 SC은행은 인증서 없다고 거부. 다행히 미리 오픈뱅킹으로 연동해놔서 신한에서 SC계좌 접근이 가능해서 문제는 없는데.\u003c/p\u003e\n\u003cp\u003e매일 밤에는 계좌조회도 안되는 SC은행. 몇 년 전에는 적은 영업점 수를 경쟁 은행보다 앞선 인터넷 뱅킹 등으로 해결한다는 평이 많았는데 지금은 ‘갸우뚱’.\u003c/p\u003e\n\u003cp\u003e‘제일 먼저’가 큰 의미를 갖는 건 맞지만 시간이 조금 지난 시점에는 그것보다는 ‘제일 우수’한 게 만 배는 더 중요하다. ‘제일 먼저’의 능력과 실천력 등을 발전시켜 그 격차를 유지한 게 아니라면 의미가 전혀 없게 된다는.\u003c/p\u003e","title":"Being the First is not enough"},{"content":"Setup GitHub based Helm repo GitHub에 구성한 helm repository에 있는 Helm chart를 이용해서 nginx deploy하기\nGitHub에 Helm Repository 구축하기 Create a public Helm chart repository with GitHub Pages | by Mattia Peri | Medium 글을 참고해서 따라하면 특별한 문제 없이 Helm Repostiroy로 동작할 GitHub Page를 만들 수 있다.\ncychong@mini1:~/tmp$ wget https://cychong47.github.io/helm-chart/index.html --2020-08-18 23:49:28-- https://cychong47.github.io/helm-chart/index.html Resolving cychong47.github.io (cychong47.github.io)... 185.199.111.153, 185.199.109.153, 185.199.110.153, ... Connecting to cychong47.github.io (cychong47.github.io)|185.199.111.153|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 1501 (1.5K) [text/html] Saving to: ‘index.html’ index.html 100%[=======================================================\u0026gt;] 1.47K --.-KB/s in 0s 2020-08-18 23:49:29 (13.2 MB/s) - ‘index.html’ saved [1501/1501] index.html 의 내용을 보면\ncychong@mini1:~/tmp$ cat index.html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en-US\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;meta http-equiv=\u0026#34;X-UA-Compatible\u0026#34; content=\u0026#34;IE=edge\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;viewport\u0026#34; content=\u0026#34;width=device-width, initial-scale=1\u0026#34;\u0026gt; \u0026lt;!-- Begin Jekyll SEO tag v2.6.1 --\u0026gt; \u0026lt;title\u0026gt;helm-chart | Helm charts\u0026lt;/title\u0026gt; \u0026lt;meta name=\u0026#34;generator\u0026#34; content=\u0026#34;Jekyll v3.9.0\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:title\u0026#34; content=\u0026#34;helm-chart\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:locale\u0026#34; content=\u0026#34;en_US\u0026#34; /\u0026gt; \u0026lt;meta name=\u0026#34;description\u0026#34; content=\u0026#34;Helm charts\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:description\u0026#34; content=\u0026#34;Helm charts\u0026#34; /\u0026gt; \u0026lt;link rel=\u0026#34;canonical\u0026#34; href=\u0026#34;https://cychong47.github.io/helm-chart/\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:url\u0026#34; content=\u0026#34;https://cychong47.github.io/helm-chart/\u0026#34; /\u0026gt; \u0026lt;meta property=\u0026#34;og:site_name\u0026#34; content=\u0026#34;helm-chart\u0026#34; /\u0026gt; \u0026lt;script type=\u0026#34;application/ld+json\u0026#34;\u0026gt; {\u0026#34;@type\u0026#34;:\u0026#34;WebSite\u0026#34;,\u0026#34;headline\u0026#34;:\u0026#34;helm-chart\u0026#34;,\u0026#34;url\u0026#34;:\u0026#34;https://cychong47.github.io/helm-chart/\u0026#34;,\u0026#34;description\u0026#34;:\u0026#34;Helm charts\u0026#34;,\u0026#34;name\u0026#34;:\u0026#34;helm-chart\u0026#34;,\u0026#34;@context\u0026#34;:\u0026#34;https://schema.org\u0026#34;}\u0026lt;/script\u0026gt; \u0026lt;!-- End Jekyll SEO tag --\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;/helm-chart/assets/css/style.css?v=43e8ca4fe22a1b4d70df5464b14d221474a8b6a3\u0026#34;\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div class=\u0026#34;container-lg px-3 my-5 markdown-body\u0026#34;\u0026gt; \u0026lt;h1 id=\u0026#34;helm-chart\u0026#34;\u0026gt;helm-chart\u0026lt;/h1\u0026gt; \u0026lt;p\u0026gt;Helm charts\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.min.js\u0026#34; integrity=\u0026#34;sha256-lZaRhKri35AyJSypXXs4o6OPFTbTmUoltBbDCbdzegg=\u0026#34; crossorigin=\u0026#34;anonymous\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script\u0026gt;anchors.add();\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; 별 내용이 안 보이네…\nGitHub에 있는 Helm repository 추가하기 이제 Helm 으로 nginx를 설치할 노드에서 remote helm repository를 추가한다.\ncychong@mini1:~$ helm repo add myhelmrepo https://cychong47.github.io/helm-chart/ \u0026#34;myhelmrepo\u0026#34; has been added to your repositories 아래 명령으로 추가된 Helm repo 목록을 확인한다.\ncychong@mini1:~$ helm repo list NAME URL myhelmrepo\thttps://cychong47.github.io/helm-chart/ Ubuntu의 apt나 Fedora(Red Hat, CentOS) 계열의 yum처럼 chart list를 업데이트 한다.\ncychong@mini1:~$ helm repo update Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \u0026#34;myhelmrepo\u0026#34; chart repository Update Complete. ⎈ Happy Helming!⎈ Chart 업데이트 전에는 검색해도 나오는 결과가 없다.\ncychong@mini1:~/work/helm/my-helm-chart$ helm search repo nginx NAME CHART VERSION\tAPP VERSION\tDESCRIPTION myhelmrepo/nginx\t0.2.0 1.0 A Helm chart for nginx 앞에서 myhelmrepo로 추가한 Helm Repository에 nginx chart가 있는 걸 알 수 있다.\n(우선)( local file system에 있던 helm chart로 생성했던 helm release를 삭제하고 PV를 삭제한다.\ncychong@mini1:~$ helm list NAME NAMESPACE\tREVISION\tUPDATED STATUS CHART APP VERSION podcast\tdefault 1 2020-07-03 00:47:37.309008711 +0900 KST\tdeployed\tnginx-0.1.0\t1.0 sosa0sa\tdefault 1 2020-08-17 18:16:57.264926469 +0900 KST\tdeployed\tnginx-0.2.0\t1.0 Helm release 삭제.\ncychong@mini1:~$ helm delete sosa0sa release \u0026#34;sosa0sa\u0026#34; uninstalled PV 삭제 후 재 생성\ncychong@mini1:~/work/helm/my-helm-chart$ kubectl delete -f sosa0sa-pv.yaml persistentvolume \u0026#34;sosa0sa-pv\u0026#34; deleted cychong@mini1:~/work/helm/my-helm-chart$ kubectl create -f sosa0sa-pv.yaml persistentvolume/sosa0sa-pv created 이제 value 파일은 local file system에 있는 걸 이용하면서, Helm chart는 GitHub에 있는 걸 사용해서 Helm Install\ncychong@mini1:~/work/helm/my-helm-chart$ helm install -f sosa0sa-value.yaml sosa0sa myhelmrepo/nginx NAME: sosa0sa LAST DEPLOYED: Tue Aug 18 23:43:56 2020 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services sosa0sa-nginx) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT Helm Release가 잘 설치 되었다.\ncychong@mini1:~/tmp$ helm list NAME NAMESPACE\tREVISION\tUPDATED STATUS CHART APP VERSION podcast\tdefault 1 2020-07-03 00:47:37.309008711 +0900 KST\tdeployed\tnginx-0.1.0\t1.0 sosa0sa\tdefault 1 2020-08-18 23:43:56.44632142 +0900 KST deployed\tnginx-0.2.0\t1.0 cychong@mini1:~/work/helm/my-helm-chart$ kubectl get pods NAME READY STATUS RESTARTS AGE podcast-nginx-659bcb6485-vc6lb 1/1 Running 1 46d sosa0sa-nginx-87fc9949c-mj67c 1/1 Running 0 82s ","date":"2020-08-19T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-19-setup-github-based-helm-repo/","summary":"\u003ch1 id=\"setup-github-based-helm-repo\"\u003eSetup GitHub based Helm repo\u003c/h1\u003e\n\u003cp\u003eGitHub에 구성한 helm repository에 있는 Helm chart를 이용해서 nginx deploy하기\u003c/p\u003e\n\u003ch2 id=\"github에-helm-repository-구축하기\"\u003eGitHub에 Helm Repository 구축하기\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://medium.com/@mattiaperi/create-a-public-helm-chart-repository-with-github-pages-49b180dbb417\"\u003eCreate a public Helm chart repository with GitHub Pages | by Mattia Peri | Medium\u003c/a\u003e 글을 참고해서 따라하면 특별한 문제 없이 Helm Repostiroy로 동작할 GitHub Page를 만들 수 있다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/08/2020-08-18-IMG_0070.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/08/2020-08-18-IMG_0072.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/tmp$ wget https://cychong47.github.io/helm-chart/index.html\n--2020-08-18 23:49:28--  https://cychong47.github.io/helm-chart/index.html\nResolving cychong47.github.io (cychong47.github.io)... 185.199.111.153, 185.199.109.153, 185.199.110.153, ...\nConnecting to cychong47.github.io (cychong47.github.io)|185.199.111.153|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1501 (1.5K) [text/html]\nSaving to: ‘index.html’\n\nindex.html                      100%[=======================================================\u0026gt;]   1.47K  --.-KB/s    in 0s\n\n2020-08-18 23:49:29 (13.2 MB/s) - ‘index.html’ saved [1501/1501]\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003eindex.html\u003c/code\u003e 의 내용을 보면\u003c/p\u003e","title":"Setup GitHub based Helm repo"},{"content":"9개 아이콘에 숨어있는 패턴은?\n","date":"2020-08-17T00:09:30+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-17-any-pattern/","summary":"\u003cp\u003e9개 아이콘에 숨어있는 패턴은?\u003c/p\u003e\n\u003cfigure\u003e\u003cimg src=\"/images/2020/08/2020-08-17-any-pattern.jpg\"\n    alt=\"Any pattern\" width=\"1280\"\u003e\n\u003c/figure\u003e","title":"Any pattern?"},{"content":"오전에는 누군가 올려놓은 JTBC 슈가맨 보고 눈물 찔끔 흘리고, 오후에는 놀면 뭐하니에서 추억을 이야기하는 장면, 특히 배경에 깔리던 전람회의 노래를 듣고 또 눈물 찔끔.\n오랜만에 전람회의 노래가 듣고 싶었다.\n이젠 스트리밍 서비스 덕에 언제든지 원하는 노래를 들을 수 있어 좋네.\n오디오 좋기로 나름 소리를 듣고 있는 볼보 타고 볼륨 크게 해서 들으니 너무 좋네.\n갑자기 홈팟이 끌린다.\n예민해진 내 귀를 위해 이 정도 투자하는 건 괜찮지 않을까?\n","date":"2020-08-16T21:47:22+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-16-exihibition/","summary":"\u003cp\u003e오전에는 누군가 올려놓은 JTBC 슈가맨 보고 눈물 찔끔 흘리고,\n오후에는 \u003ccode\u003e놀면 뭐하니\u003c/code\u003e에서 추억을 이야기하는 장면, 특히 배경에 깔리던 \u003ccode\u003e전람회\u003c/code\u003e의 노래를 듣고 또 눈물 찔끔.\u003c/p\u003e\n\u003cp\u003e오랜만에 \u003ccode\u003e전람회\u003c/code\u003e의 노래가 듣고 싶었다.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg src=\"/images/2020/08/2020-08-16-exihibition.jpg\"\n    alt=\"Exihibition\" width=\"1280\"\u003e\n\u003c/figure\u003e\n\n\u003cp\u003e이젠 스트리밍 서비스 덕에 언제든지 원하는 노래를 들을 수 있어 좋네.\u003c/p\u003e\n\u003cp\u003e오디오 좋기로 나름 소리를 듣고 있는 볼보 타고 볼륨 크게 해서 들으니 너무 좋네.\u003c/p\u003e\n\u003cp\u003e갑자기 홈팟이 끌린다.\u003c/p\u003e\n\u003cp\u003e예민해진 내 귀를 위해 이 정도 투자하는 건 괜찮지 않을까?\u003c/p\u003e","title":"전람회"},{"content":"iPhone 이나 iPad에서 사진을 골라 사진과 markdown 파일을 만들어 Working Copy를 통해 git repo에 업로드하는 Shortcut을 마련했다.\nShortcut의 원본은 이 블로그(Posting to Hugo from iOS에서 얻었다.\nFront formatter만 일부 수정하면 그대로 사용할 수 있을 정도로 내가 기대하는 workflow가 구현이 되어 있었다. 실은 문법도 잘 모르면서 괜히 손을 댔다 제대로 동작 안하게 했다 다시 고치느라 시간만 보냈다는.\n이 Shortcut이 하는 일은 위 블로그에도 자세하게 설명되어 있지만(친절한 분\u0026hellip;)\n넘겨 받은 사진을 가로 1280 픽셀 크기로 조정 블로그 타이틀 입력 사진명을 오늘 날짜-블로그 타이틀로 만든 slug.jpg 로 변경해서 working copy를 이용해서 hugo의 static 디렉터리에 commit 사진을 링크하는 markdown을 같은 형식 오늘 날짜-블로그 타이틀로 만든 slug.md을 content 디렉터리에 commit git push 이 과정을 거치면 아래와 같이 git repo에 jpg 파일 하나와 md 파일 하나가 만들어진다.\n손을 봤으면 하는 내용이 몇 가지 있는데\n예외 처리. 사진이 넘어오지 않는 경우에 대한 고려. 이때는 그냥 markdown 파일만 생성.(그럼 굳이 markdown 파일을 만들 필요가 있나 싶긴 하지만, 일단 만들어진 markdown 파일은 iA Writer를 이용해서 내용을 추가하는 형태로 활용할 수 있고, 일단 사진이 넘어오지 않은 경우에 대해서는 예외 처리가 필요해 보인다. 동작을 멈출 건지, markdown 파일만 만들 건지) 날짜는 사진의 생성일 기준으로. 사진과 markdown 이름에 들어가는 날짜를 지금은 shortcut을 실행한 날짜를 사용하는데 예전에 찍은 사진을 활용하는 경우도 있을 테니 일단 사진에 사용하는 날짜는 사진의 EXIF정보를 이용해서 사진이 생성된 날짜로 하는 게 맞을 것 같다. 위에서 고려한 것처럼 만일 사진 파일이 없는 경우에는 오늘 날짜를 기준으로 하면 되고. 사진 이름 형식. 날짜 뒤에 붙일 사진이름도 원래 이름을 유지할 지, 지금처럼 title을 사용할 지 고민(?)이다. Title을 사용하면 markdown 파일과 함께 관리하기 편할 듯 한데, 내 경험상 블로그 파일들을 관리할 때 사진이 날짜로 되어 있으면 혹시나 블로그 폴더에서 잃어버린 경우에도 사진 원본을 이용해서 복구할 수 있다는 장점이 있다. 물론 거의 0에 가까운 확률이긴 하지만\u0026hellip; Repository 선택 회수 줄이기. 지금은 Working Copy 관련 action에서는 매번 repository를 선택하게 되어 있다. 그래서 pull, image commit, markdown commit, push 등의 절차에서 매번 블로그를 선택해야 한다. 처음 pull할 때 선택한 repository를 그대로 이후의 동작에서 사용할 수 있으면 좋겠는데 아직 방법을 찾지 못했다. 여러 사진 지원. 지금은 단 한 장의 사진만 처리하는데 여러 사진을 하나의 글에 사용하는 경우가 많으니 이를 고려해야 하는데 iOS shortcut에서 이런 동작(loop)를 얼마나 잘 지원하는 지 모르겠다. ","date":"2020-08-11T14:16:01+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-11-publish-hugo-post-from-ipad/","summary":"\u003cp\u003eiPhone 이나 iPad에서 사진을 골라 사진과 markdown 파일을 만들어 Working Copy를 통해 git repo에 업로드하는 Shortcut을 마련했다.\u003cbr\u003e\nShortcut의 원본은 이 블로그(\u003ca href=\"https://marcus.nordaaker.com/post/posting-to-hugo-from-ios/\"\u003ePosting to Hugo from iOS\u003c/a\u003e에서 얻었다.\u003cbr\u003e\nFront formatter만 일부 수정하면 그대로 사용할 수 있을 정도로 내가 기대하는 workflow가 구현이 되어 있었다. 실은 문법도 잘 모르면서 괜히 손을 댔다 제대로 동작 안하게 했다 다시 고치느라 시간만 보냈다는.\u003c/p\u003e\n\u003cp\u003e이 Shortcut이 하는 일은 위 블로그에도 자세하게 설명되어 있지만(친절한 분\u0026hellip;)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e넘겨 받은 사진을 가로 1280 픽셀 크기로 조정\u003c/li\u003e\n\u003cli\u003e블로그 타이틀 입력\u003c/li\u003e\n\u003cli\u003e사진명을 \u003ccode\u003e오늘 날짜-블로그 타이틀로 만든 slug.jpg\u003c/code\u003e 로 변경해서 working copy를 이용해서 hugo의 \u003ccode\u003estatic\u003c/code\u003e 디렉터리에 commit\u003c/li\u003e\n\u003cli\u003e사진을 링크하는 markdown을 같은 형식 \u003ccode\u003e오늘 날짜-블로그 타이틀로 만든 slug.md\u003c/code\u003e을 \u003ccode\u003econtent\u003c/code\u003e 디렉터리에 commit\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003egit push\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e이 과정을 거치면 아래와 같이 git repo에 jpg 파일 하나와 md 파일 하나가 만들어진다.\u003cbr\u003e\n\u003cfigure\u003e\u003cimg src=\"/images/2020/08/2020-08-11-publish-hugo-post-from-ipad.jpg\"\n    alt=\"Publish hugo post from iPad\" width=\"1280\"\u003e\n\u003c/figure\u003e\n\u003c/p\u003e","title":"Publish hugo post from iPad"},{"content":"1 physical core도 안되는 CPU를 사용하는 free timer의 한계인가?\n덧) 저 일이 있은 후에는 또 안정적으로 돌고 있다는\u0026hellip; 날짜별로 통계를 뽑아봐야겠다.\n","date":"2020-08-11T14:12:28+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-11-limit-of-free-tier/","summary":"\u003cp\u003e1 physical core도 안되는 CPU를 사용하는 free timer의 한계인가?\u003c/p\u003e\n\u003cfigure\u003e\u003cimg src=\"/images/2020/08/2020-08-11-limit-of-free-tier.jpg\"\n    alt=\"Limit of free tier\" width=\"1280\"\u003e\n\u003c/figure\u003e\n\n\u003cp\u003e덧) 저 일이 있은 후에는 또 안정적으로 돌고 있다는\u0026hellip;\n날짜별로 통계를 뽑아봐야겠다.\u003c/p\u003e","title":"Limitation of free tier"},{"content":"완벽한 SW면 더할 나위 없겠지만, 그것 외에도 SW의 신뢰도를 높이는 방법 중 하나는 쉽게 rollback할 수 있는 능력이 아닐까 싶다. ","date":"2020-08-10T18:18:26+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-10-easy-rollback-sw-release/","summary":"\u003cp\u003e완벽한 SW면 더할 나위 없겠지만, 그것 외에도 SW의 신뢰도를 높이는 방법 중 하나는 쉽게 rollback할 수 있는 능력이 아닐까 싶다.\n\u003cfigure\u003e\u003cimg src=\"/images/2020/08/2020-08-10-easy-rollback-sw-release.jpg\"\n    alt=\"able to rollback is one of the key in sw release\" width=\"1280\"\u003e\n\u003c/figure\u003e\n\u003c/p\u003e","title":"쉽게 rollback할 수 있는 SW"},{"content":"정말 멋지다. 저런 문화를 가진 곳이 있다니.\n어떤 ㅇ이유로 저런 게 가능한 지 모르겠지만, 아무튼 그 결과는 좋은 문화가 유지되고 확산될 거라는 상상을 하게 한다. 악의를 가지고 실수를 하는 사람은 흔치 않을테니.\n","date":"2020-08-10T18:08:38+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-10-blame-based-development/","summary":"\u003cp\u003e정말 멋지다. 저런 문화를 가진 곳이 있다니.\u003cbr\u003e\n어떤 ㅇ이유로 저런 게 가능한 지 모르겠지만,\n아무튼 그 결과는 좋은 문화가 유지되고 확산될 거라는 상상을 하게 한다.\n악의를 가지고 실수를 하는 사람은 흔치 않을테니.\u003c/p\u003e\n\u003cfigure\u003e\u003cimg src=\"/images/2020/08/2020-08-10-blame-based-development.jpg\"\n    alt=\"Blame based development\" width=\"1280\"\u003e\n\u003c/figure\u003e","title":"비난하지 않는 문화"},{"content":"Instagram에서 StandingDesk라는 태그를 following하고 있는데 오늘 본 멋진 사진.\n창 밖 풍경이 너무 멋져 보인다.\n징베 있는 책상을 바꾼다고 저런 뷰가 나오지는 않겠지만, 요즘 점점 책상에 앉아 뭔가를 하는게 힘들어서 Standing Desk를 보고 있긴한데 그냥 보고만 있다.\n","date":"2020-08-08T23:51:23+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-08-hammok-under-the-standing-desk/","summary":"\u003cp\u003eInstagram에서 \u003ccode\u003eStandingDesk\u003c/code\u003e라는 태그를 following하고 있는데 오늘 본 멋진 사진.\u003cbr\u003e\n창 밖 풍경이 너무 멋져 보인다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/08/2020-08-08-hammok-under-the-standing-desk.jpg\" alt=\"\"\u003e\u003cbr\u003e\n\u003cimg src=\"/images/2020/08/2020-08-08-hammok-under-the-standing-desk-2.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e징베 있는 책상을 바꾼다고 저런 뷰가 나오지는 않겠지만, 요즘 점점 책상에 앉아 뭔가를 하는게 힘들어서 Standing Desk를 보고 있긴한데 그냥 보고만 있다.\u003c/p\u003e","title":"스탠딩 데스크 아래 해먹이라니"},{"content":"iPhoneX가 망가져 급히 집에 있는 iPhone6에 USIM을 옮겨서 사용하고 있다. 아쉽게도 iPhone6S 부터 최신 버전의 iOS를 지원하고 있어 사용할 수 있는 iOS는 12.x\n그 결과 몇 몇 앱은 최신 버전이 아닌 12.x에서 사용 가능한 버전이 설치된다. Shortcuts 앱은 설치는 되지만, iOS12용 Shortcuts과 iOS13용 Shortcuts 데이터 차이로 이전에 사용하던 shortcuts들을 사용할 수가 없다.\n그리고 결정적으로 느리고. 마침 폰 케이스도 없어서 미끄럽고.\n가뜩이나 iPhone 12는 예전과 같은 9월이 아니라 10월 출시될 가능성이 높다고 하는데 애고\u0026hellip;.\n","date":"2020-08-08T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-08-iphone6-home-scree/","summary":"\u003cp\u003eiPhoneX가 망가져 급히 집에 있는 iPhone6에 USIM을 옮겨서 사용하고 있다.\n아쉽게도 iPhone6S 부터 최신 버전의 iOS를 지원하고 있어 사용할 수 있는 iOS는 12.x\u003cbr\u003e\n그 결과 몇 몇 앱은 최신 버전이 아닌 12.x에서 사용 가능한 버전이 설치된다.\nShortcuts 앱은 설치는 되지만, iOS12용 Shortcuts과 iOS13용 Shortcuts 데이터 차이로\n이전에 사용하던 shortcuts들을 사용할 수가 없다.\u003c/p\u003e\n\u003cp\u003e그리고 결정적으로 느리고. 마침 폰 케이스도 없어서 미끄럽고.\u003c/p\u003e\n\u003cp\u003e가뜩이나 iPhone 12는 예전과 같은 9월이 아니라 10월 출시될 가능성이 높다고 하는데 애고\u0026hellip;.\u003c/p\u003e","title":"iPhone6 home screen"},{"content":"너무 많네. 수리센터 테크니션도 이거 보고 놀라는 듯.\n","date":"2020-08-04T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-04-iphonex-panic-log/","summary":"\u003cp\u003e너무 많네.\n수리센터 테크니션도 이거 보고 놀라는 듯.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/08/2020-08-04-iphonex-full-of-panic-logs.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"Too many panic logs from iPhoneX"},{"content":" Tweetbot과 함께 하루 중 가장 많이 사용하는 앱인 Things는 2008년에 구입했구나. 중간에 1-2년 정도는 Omnifocus를 사용하다 돌아왔는데 Omnifocus는 여러 가지 프로젝트를 동시에 관리하기에는 편한데 많은 기능 때문에 너무 복잡한 느낌이. 간단하게 할일 관리할 때는 Things만한게 없는 듯.\nNotability를 2014년에 구입(아마도 무료로 풀린 걸 받았던 걸로 기억)했네. 오래됐다. 그 동안 안 쓰다가 아이패드를 본격적으로 사용하기 시작하면서 이 앱도 열심히 쓰기 시작한 듯\nThings가 새로운 이름(이라고 하지만 실은 이름에 버전 정보를 붙여서 새로 앱스토어에 등록한 거지만)이로 바뀐 거 말고 같은 이름을 유지하면서 지금도 사용하는 앱은 카카오지도가 제일 오래됐네. 무료 2009년이면 11년 전. 와\u0026hellip;. 지금이야 내비게이션은 T맵, 네이버 지도 등을 많이 쓰는 듯 하고, 카카오 내부에서도 김기사를 인수해서 카카오내비라는 앱을 따로 만들어서 앱스토어에 등록했지만 난 그래도 CarPlay를 강요하지 않아서(호환이 안되서인지도) 카카오내비를 즐겨 사용한다.\n","date":"2020-08-03T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-03-long-time-apps/","summary":"\u003cp\u003e\u003cfigure\u003e\u003cimg src=\"/images/2020/08/2020-08-03-long-time-apps1.jpg\"\n    alt=\"Long time app \" width=\"1280\"\u003e\n\u003c/figure\u003e\n\nTweetbot과 함께 하루 중 가장 많이 사용하는 앱인 Things는 2008년에 구입했구나. 중간에 1-2년 정도는 \u003ccode\u003eOmnifocus\u003c/code\u003e를 사용하다 돌아왔는데 \u003ccode\u003eOmnifocus\u003c/code\u003e는 여러 가지 프로젝트를 동시에 관리하기에는 편한데 많은 기능 때문에 너무 복잡한 느낌이. 간단하게 할일 관리할 때는 Things만한게 없는 듯.\u003c/p\u003e\n\u003cp\u003e\u003cfigure\u003e\u003cimg src=\"/images/2020/08/2020-08-03-long-time-apps.jpg\"\n    alt=\"Long time app \" width=\"1280\"\u003e\n\u003c/figure\u003e\n\nNotability를 2014년에 구입(아마도 무료로 풀린 걸 받았던 걸로 기억)했네. 오래됐다. 그 동안 안 쓰다가 아이패드를 본격적으로 사용하기 시작하면서 이 앱도 열심히 쓰기 시작한 듯\u003c/p\u003e\n\u003cp\u003e\u003cfigure\u003e\u003cimg src=\"/images/2020/08/2020-08-03-long-time-apps2.jpg\"\n    alt=\"Long time app \" width=\"1280\"\u003e\n\u003c/figure\u003e\n\nThings가 새로운 이름(이라고 하지만 실은 이름에 버전 정보를 붙여서 새로 앱스토어에 등록한 거지만)이로 바뀐 거 말고 같은 이름을 유지하면서 지금도 사용하는 앱은 카카오지도가 제일 오래됐네. 무료 2009년이면 11년 전. 와\u0026hellip;. 지금이야 내비게이션은 T맵, 네이버 지도 등을 많이 쓰는 듯 하고, 카카오 내부에서도 김기사를 인수해서 카카오내비라는 앱을 따로 만들어서 앱스토어에 등록했지만 난 그래도 CarPlay를 강요하지 않아서(호환이 안되서인지도) 카카오내비를 즐겨 사용한다.\u003c/p\u003e","title":"Long time apps"},{"content":"Upgrade kubernetes to 1.18.2\nNote etcd might be need to be upgrade\ncychong@mini1:~$ sudo kubeadm upgrade apply v1.18.2 [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39; [preflight] Running pre-flight checks. [upgrade] Running cluster health checks [upgrade/version] You have chosen to change the cluster version to \u0026#34;v1.18.2\u0026#34; [upgrade/versions] Cluster version: v1.17.2 [upgrade/versions] kubeadm version: v1.18.2 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd] [upgrade/prepull] Prepulling image for component etcd. [upgrade/prepull] Prepulling image for component kube-apiserver. [upgrade/prepull] Prepulling image for component kube-controller-manager. [upgrade/prepull] Prepulling image for component kube-scheduler. [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [upgrade/prepull] Prepulled image for component etcd. [upgrade/prepull] Prepulled image for component kube-scheduler. [upgrade/prepull] Prepulled image for component kube-apiserver. [upgrade/prepull] Prepulled image for component kube-controller-manager. [upgrade/prepull] Successfully prepulled the images for all the control plane components [upgrade/apply] Upgrading your Static Pod-hosted control plane to version \u0026#34;v1.18.2\u0026#34;... Static pod: kube-apiserver-mini1 hash: 4d9a965c0a14a45ea3d7db1e023096d4 Static pod: kube-controller-manager-mini1 hash: 85a33dac6d806801ba5efe4a4544194c Static pod: kube-scheduler-mini1 hash: 9c994ea62a2d8d6f1bb7498f10aa6fcf [upgrade/etcd] Upgrading to TLS for etcd [upgrade/etcd] Non fatal issue encountered during upgrade: the desired etcd version for this Kubernetes version \u0026#34;v1.18.2\u0026#34; is \u0026#34;3.4.3-0\u0026#34;, but the current etcd version is \u0026#34;3.4.3\u0026#34;. Won\u0026#39;t downgrade etcd, instead just continue [upgrade/staticpods] Writing new Static Pod manifests to \u0026#34;/etc/kubernetes/tmp/kubeadm-upgraded-manifests306630380\u0026#34; W0502 23:43:36.998909 12626 manifests.go:225] the default kube-apiserver authorization-mode is \u0026#34;Node,RBAC\u0026#34;; using \u0026#34;Node,RBAC\u0026#34; [upgrade/staticpods] Preparing for \u0026#34;kube-apiserver\u0026#34; upgrade [upgrade/staticpods] Renewing apiserver certificate [upgrade/staticpods] Renewing apiserver-kubelet-client certificate [upgrade/staticpods] Renewing front-proxy-client certificate [upgrade/staticpods] Renewing apiserver-etcd-client certificate [upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-apiserver.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-05-02-23-43-31/kube-apiserver.yaml\u0026#34; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-apiserver-mini1 hash: 4d9a965c0a14a45ea3d7db1e023096d4 Static pod: kube-apiserver-mini1 hash: 275339182618620ef41c93754b550d1b [apiclient] Found 1 Pods for label selector component=kube-apiserver [upgrade/staticpods] Component \u0026#34;kube-apiserver\u0026#34; upgraded successfully! [upgrade/staticpods] Preparing for \u0026#34;kube-controller-manager\u0026#34; upgrade [upgrade/staticpods] Renewing controller-manager.conf certificate [upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-controller-manager.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-05-02-23-43-31/kube-controller-manager.yaml\u0026#34; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-controller-manager-mini1 hash: 85a33dac6d806801ba5efe4a4544194c Static pod: kube-controller-manager-mini1 hash: 02126aeb8d0589669175da92c56e4904 [apiclient] Found 1 Pods for label selector component=kube-controller-manager [upgrade/staticpods] Component \u0026#34;kube-controller-manager\u0026#34; upgraded successfully! [upgrade/staticpods] Preparing for \u0026#34;kube-scheduler\u0026#34; upgrade [upgrade/staticpods] Renewing scheduler.conf certificate [upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-scheduler.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-05-02-23-43-31/kube-scheduler.yaml\u0026#34; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-scheduler-mini1 hash: 9c994ea62a2d8d6f1bb7498f10aa6fcf Static pod: kube-scheduler-mini1 hash: 7abb78dfbb4eae6cb52175046063ac8f [apiclient] Found 1 Pods for label selector component=kube-scheduler [upgrade/staticpods] Component \u0026#34;kube-scheduler\u0026#34; upgraded successfully! [upload-config] Storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace [kubelet] Creating a ConfigMap \u0026#34;kubelet-config-1.18\u0026#34; in namespace kube-system with the configuration for the kubelets in the cluster [kubelet-start] Downloading configuration for the kubelet from the \u0026#34;kubelet-config-1.18\u0026#34; ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy [upgrade/successful] SUCCESS! Your cluster was upgraded to \u0026#34;v1.18.2\u0026#34;. Enjoy! [upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven\u0026#39;t already done so. ","date":"2020-08-01T22:52:47+09:00","permalink":"https://cychong47.github.io/post/2020/2020-05-07-upgrade-kubernetes-1-18-2/","summary":"\u003cp\u003eUpgrade kubernetes to 1.18.2\u003c/p\u003e\n\u003cp\u003eNote etcd might be need to be upgrade\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ sudo kubeadm upgrade apply v1.18.2\n[upgrade/config] Making sure the configuration is correct:\n[upgrade/config] Reading configuration from the cluster...\n[upgrade/config] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39;\n[preflight] Running pre-flight checks.\n[upgrade] Running cluster health checks\n[upgrade/version] You have chosen to change the cluster version to \u0026#34;v1.18.2\u0026#34;\n[upgrade/versions] Cluster version: v1.17.2\n[upgrade/versions] kubeadm version: v1.18.2\n[upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y\n[upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd]\n[upgrade/prepull] Prepulling image for component etcd.\n[upgrade/prepull] Prepulling image for component kube-apiserver.\n[upgrade/prepull] Prepulling image for component kube-controller-manager.\n[upgrade/prepull] Prepulling image for component kube-scheduler.\n[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager\n[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler\n[upgrade/prepull] Prepulled image for component etcd.\n[upgrade/prepull] Prepulled image for component kube-scheduler.\n[upgrade/prepull] Prepulled image for component kube-apiserver.\n[upgrade/prepull] Prepulled image for component kube-controller-manager.\n[upgrade/prepull] Successfully prepulled the images for all the control plane components\n[upgrade/apply] Upgrading your Static Pod-hosted control plane to version \u0026#34;v1.18.2\u0026#34;...\nStatic pod: kube-apiserver-mini1 hash: 4d9a965c0a14a45ea3d7db1e023096d4\nStatic pod: kube-controller-manager-mini1 hash: 85a33dac6d806801ba5efe4a4544194c\nStatic pod: kube-scheduler-mini1 hash: 9c994ea62a2d8d6f1bb7498f10aa6fcf\n[upgrade/etcd] Upgrading to TLS for etcd\n[upgrade/etcd] Non fatal issue encountered during upgrade: the desired etcd version for this Kubernetes version \u0026#34;v1.18.2\u0026#34; is \u0026#34;3.4.3-0\u0026#34;, but the current etcd version is \u0026#34;3.4.3\u0026#34;. Won\u0026#39;t downgrade etcd, instead just continue\n[upgrade/staticpods] Writing new Static Pod manifests to \u0026#34;/etc/kubernetes/tmp/kubeadm-upgraded-manifests306630380\u0026#34;\nW0502 23:43:36.998909   12626 manifests.go:225] the default kube-apiserver authorization-mode is \u0026#34;Node,RBAC\u0026#34;; using \u0026#34;Node,RBAC\u0026#34;\n[upgrade/staticpods] Preparing for \u0026#34;kube-apiserver\u0026#34; upgrade\n[upgrade/staticpods] Renewing apiserver certificate\n[upgrade/staticpods] Renewing apiserver-kubelet-client certificate\n[upgrade/staticpods] Renewing front-proxy-client certificate\n[upgrade/staticpods] Renewing apiserver-etcd-client certificate\n[upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-apiserver.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-05-02-23-43-31/kube-apiserver.yaml\u0026#34;\n[upgrade/staticpods] Waiting for the kubelet to restart the component\n[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)\nStatic pod: kube-apiserver-mini1 hash: 4d9a965c0a14a45ea3d7db1e023096d4\nStatic pod: kube-apiserver-mini1 hash: 275339182618620ef41c93754b550d1b\n[apiclient] Found 1 Pods for label selector component=kube-apiserver\n[upgrade/staticpods] Component \u0026#34;kube-apiserver\u0026#34; upgraded successfully!\n[upgrade/staticpods] Preparing for \u0026#34;kube-controller-manager\u0026#34; upgrade\n[upgrade/staticpods] Renewing controller-manager.conf certificate\n[upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-controller-manager.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-05-02-23-43-31/kube-controller-manager.yaml\u0026#34;\n[upgrade/staticpods] Waiting for the kubelet to restart the component\n[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)\nStatic pod: kube-controller-manager-mini1 hash: 85a33dac6d806801ba5efe4a4544194c\nStatic pod: kube-controller-manager-mini1 hash: 02126aeb8d0589669175da92c56e4904\n[apiclient] Found 1 Pods for label selector component=kube-controller-manager\n[upgrade/staticpods] Component \u0026#34;kube-controller-manager\u0026#34; upgraded successfully!\n[upgrade/staticpods] Preparing for \u0026#34;kube-scheduler\u0026#34; upgrade\n[upgrade/staticpods] Renewing scheduler.conf certificate\n[upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-scheduler.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-05-02-23-43-31/kube-scheduler.yaml\u0026#34;\n[upgrade/staticpods] Waiting for the kubelet to restart the component\n[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)\nStatic pod: kube-scheduler-mini1 hash: 9c994ea62a2d8d6f1bb7498f10aa6fcf\nStatic pod: kube-scheduler-mini1 hash: 7abb78dfbb4eae6cb52175046063ac8f\n[apiclient] Found 1 Pods for label selector component=kube-scheduler\n[upgrade/staticpods] Component \u0026#34;kube-scheduler\u0026#34; upgraded successfully!\n[upload-config] Storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace\n[kubelet] Creating a ConfigMap \u0026#34;kubelet-config-1.18\u0026#34; in namespace kube-system with the configuration for the kubelets in the cluster\n[kubelet-start] Downloading configuration for the kubelet from the \u0026#34;kubelet-config-1.18\u0026#34; ConfigMap in the kube-system namespace\n[kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34;\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\n[upgrade/successful] SUCCESS! Your cluster was upgraded to \u0026#34;v1.18.2\u0026#34;. Enjoy!\n\n[upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven\u0026#39;t already done so.\n\u003c/code\u003e\u003c/pre\u003e","title":"Upgrade Kubernetes 1 18 2"},{"content":"어느 날 부터인가 이상하게 책상 의자 아래에 부스러기들이 보이기 시작했다는.\n의자에서 플라스틱에 떨어지는 것 같은데 의자에서는 흔적이 안 보이고.\n며칠을 봐도 그 이유를 찾지 못했는데 알고 보니 의자 바퀴 플라스틱이 부스러지고 있었다는 거.\n","date":"2020-08-01T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-08-01-old-chair-wheel/","summary":"\u003cp\u003e어느 날 부터인가 이상하게 책상 의자 아래에 부스러기들이 보이기 시작했다는.\u003cbr\u003e\n의자에서 플라스틱에 떨어지는 것 같은데 의자에서는 흔적이 안 보이고.\u003c/p\u003e\n\u003cp\u003e며칠을 봐도 그 이유를 찾지 못했는데 알고 보니 의자 바퀴 플라스틱이 부스러지고 있었다는 거.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/08/2020-08-01-old-chair-wheel.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"의자 아래 정체 모를 플라스틱"},{"content":"VPA는 K8s에서 Scale-in/out에 대한 기능을 제공.\n현재 동작하고 있는 pod에 대해 pod restart 없이 할당된 resource를 변경하는 것은 아직 미지원인듯\ngithub의 VPA repo https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler\nUpdating running pods is an experimental feature of VPA. Whenever VPA updates the pod resources the pod is recreated, which causes all running containers to be restarted. The pod may be recreated on a different node.\nhttps://stupefied-goodall-e282f7.netlify.app/contributors/design-proposals/autoscaling/vertical-pod-autoscaler/\nIn-place updates\nIn-place Pod updates (#5774) is a planned feature to allow changing resources (request/limit) of existing containers without killing them, assuming sufficient free resources available on the node. Vertical Pod Autoscaler will greatly benefit from this ability, however it is not considered a blocker for the MVP.\nGoogle Cloud 지원 상태 https://cloud.google.com/kubernetes-engine/docs/concepts/verticalpodautoscaler\nDue to Kubernetes limitations, the only way to modify the resource requests of a running Pod is to recreate the Pod. If you create a VerticalPodAutoscaler with an updateMode of \u0026ldquo;Auto\u0026rdquo;, the VerticalPodAutoscaler evicts a Pod if it needs to change the Pod\u0026rsquo;s resource requests.\nTo limit the amount of Pod restarts, use a Pod disruption budget.\nhttps://livewyer.io/blog/2019/06/24/vertical-pod-autoscaling/ 24 June 2019\nAuto Will assign request values both at pod startup and while the pod is live using the specified update mechanism. At the moment, this is equivalent to “recreate”, as there isn’t currently an “in-place” mechanism for updating request values on live pods\nReference Vertical Pod Autoscaler deep dive, limitations and real-world examples ","date":"2020-07-31T00:01:03+09:00","permalink":"https://cychong47.github.io/post/2020/2020-07-31-vertical-pod-autoscaler/","summary":"\u003cp\u003eVPA는 K8s에서 \u003ccode\u003eScale-in/out\u003c/code\u003e에 대한 기능을 제공.\u003c/p\u003e\n\u003cp\u003e현재 동작하고 있는 pod에 대해 pod restart 없이 할당된 resource를 변경하는 것은 아직 미지원인듯\u003c/p\u003e\n\u003ch2 id=\"github의-vpa-repo\"\u003egithub의 VPA repo\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler\"\u003ehttps://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eUpdating running pods is an experimental feature of VPA. Whenever VPA updates the pod resources the pod is recreated, which causes all running containers to be restarted. The pod may be recreated on a different node.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"https://stupefied-goodall-e282f7.netlify.app/contributors/design-proposals/autoscaling/vertical-pod-autoscaler/\"\u003ehttps://stupefied-goodall-e282f7.netlify.app/contributors/design-proposals/autoscaling/vertical-pod-autoscaler/\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIn-place updates\u003c/p\u003e\n\u003cp\u003eIn-place Pod updates (#5774) is a planned feature to allow changing resources (request/limit) of existing containers without killing them, assuming sufficient free resources available on the node. Vertical Pod Autoscaler will greatly benefit from this ability, however it is not considered a blocker for the MVP.\u003c/p\u003e","title":"K8s Vertical Pod Autoscaler"},{"content":"오늘 기준으로 이용하고 있는 subscription 들\n","date":"2020-07-24T06:56:44+09:00","permalink":"https://cychong47.github.io/post/2020/2020-07-24-apple-subscriptions/","summary":"\u003cp\u003e오늘 기준으로 이용하고 있는 subscription 들\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/07/20200722_1004_IMG_5043.PNG\" alt=\"\"\u003e\u003c/p\u003e","title":"Apple subscriptions update"},{"content":"갑자기 어느 날 부터(정확히 말하면 7월 14일부터) podcast가 업데이트가 되지 않는다.\n다음 날도, 그 다음 날도. 흠. 뭐가 문제일까?\n아무튼 hugo를 이용해서 직접 사이트를 빌드해 봤다. 그랬더니 이상한 에러가 난다. os.Stat 파일이 없다는 이야기도 나오고.\n뭔가 문제가 있는데 밤이라 그런지 그냥 단순하게 Hugo zen-theme 이 rss를 제대로 생성하지 못한다는 내용으로 검색을 해 봤는데 결과가 안 나온다.\ncychong@mini1:~/work/cbs-ost$ hugo -t zen Building sites … WARN 2020/07/23 23:21:25 .File.UniqueID on zero object. Wrap it in if or with: {{ with .File }}{{ .UniqueID }}{{ end }} Total in 10016 ms Error: Error building site: failed to render pages: render of \u0026#34;section\u0026#34; failed: \u0026#34;/home/cychong/work/cbs-ost/themes/zen/layouts/podcast/rss.xml:53:55\u0026#34;: execute of template failed: template: podcast/rss.xml:53:55: executing \u0026#34;podcast/rss.xml\u0026#34; at \u0026lt;os.Stat\u0026gt;: error calling Stat: LStat content/static/podcast/cinema-2020-07-14.mp3: file does not exist 똑같은 방법을 시도하면서 다른 결과를 기다하는 건 바보라는 말을 잊고 그 다음 날도 똑같은 짓을 했다. 여전히 답이 나올리가.\n며칠 간 포기하고 있다 오늘 마음을 잡고 다시 에러 메시지를 봤다. 에러 메시지에 찍힌 mp3 파일 경로 content/static/podcast/cinema-2020-07-14.mp3가 이상하게 보였다. content는 md 파일만 가지고 있고, static/podcast 디렉토리는 다른 곳에 있는데 왜 static/podcast 디렉토리가 content 디렉토리 밑에 있을까 라는 의문이. 그래서 저 파일이 있나 하고 cinema-2020-07-14.mp3 파일이 어디에 있는 지 찾아봤다. 그런데\n오잉 파일이 없다.\n이제서야 다시 에러 메시지를 찬찬히 보니 그냥(?) 그 파일이 없어서 에러가 난 거였다. 이런\u0026hellip;.. 정말 단순한 에러였는데 그걸 이해하지 못하고\u0026hellip;\n해결책은 해당 파일을 요구하는(?) md 파일을 삭제하거나, comment out시키면 된다.\n# mp3: \u0026#34;/podcast/cinema-2020-07-14.mp3\u0026#34; 그리고 다시 hugo로 사이트를 빌드하니 잘 된다. ㅎ\n이제 다시 이전에 Telegram으로 날아왔던 메시지를 보니까 흠\u0026hellip; 14일에 mp3 파일이 만들어지지 않았다. 무슨 일인 지 모르겠지만 그날 mp3 파일을 만드는 공장(?)에서 에러가 발생해서 이런 문제가 발생했나 보다.\n전날받은 메시지를 보면 mp3 파일이 먼저 만들어지고 md 파일을 만드는 정상적인 순서로 동작했는데 문제가 된 14일은 mp3 파일이 만들어진 시간이 나중에 수신되었다. mp3 파일이 없다는\u0026hellip;. 11:48 PM에 받은 메시지는 그 날 RSS가 업데이트 되지 않아서 디버깅하려고 164 초 짜리 mp3 파일을 수동으로 녹음을 한 내용이 보내진 거였다는.\n문제는 지금은 이런 경우에 md 파일을 만들어서 site rebuild를 시도하고 있으니 하루라도 이런 문제가 생기면 그 다음 날에 제대로 mp3 파일을 만들었다 하더라도 전날 만들어진 md 파일을 처리할 때 또 에러가 날 거라 또 수동으로 처리해야 한다는 거다.\n자동화된 해결책이 필요한데 한 가지 방법은 md 파일을 만드는 건 문제가 없는데 만일 mp3 파일이 없으면 위와 같이 mp3 파일을 comment 한 형태로 만들면 되겠다.\n36 comment = \u0026#34;#\u0026#34; if not os.path.exists(mp3_file) else \u0026#34;\u0026#34; 43 buf += \u0026#34;%s mp3: \\\u0026#34;/podcast/%s\\\u0026#34;\\n\u0026#34; %(comment, os.path.basename(mp3_file)) 이렇게 mp3 파일 경로를 확인해서 만일 없는 경우라면 앞에 #을 붙이는 정보면 될 듯.\n","date":"2020-07-24T00:22:45+09:00","permalink":"https://cychong47.github.io/post/2020/2020-07-24-rss-is-not-updated/","summary":"\u003cp\u003e갑자기 어느 날 부터(정확히 말하면 7월 14일부터) podcast가 업데이트가 되지 않는다.\u003c/p\u003e\n\u003cp\u003e다음 날도, 그 다음 날도. 흠. 뭐가 문제일까?\u003c/p\u003e\n\u003cp\u003e아무튼 \u003ccode\u003ehugo\u003c/code\u003e를 이용해서 직접 사이트를 빌드해 봤다. 그랬더니 이상한 에러가 난다. \u003ccode\u003eos.Stat\u003c/code\u003e 파일이 없다는 이야기도 나오고.\u003c/p\u003e\n\u003cp\u003e뭔가 문제가 있는데 밤이라 그런지 그냥 단순하게 Hugo \u003ccode\u003ezen-theme\u003c/code\u003e 이 rss를 제대로 생성하지 못한다는 내용으로 검색을 해 봤는데 결과가 안 나온다.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/work/cbs-ost$ hugo -t zen\nBuilding sites … WARN 2020/07/23 23:21:25 .File.UniqueID on zero object. Wrap it in if or with: {{ with .File }}{{ .UniqueID }}{{ end }}\nTotal in 10016 ms\nError: Error building site: failed to render pages: render of \u0026#34;section\u0026#34; failed: \u0026#34;/home/cychong/work/cbs-ost/themes/zen/layouts/podcast/rss.xml:53:55\u0026#34;: execute of template failed: template: podcast/rss.xml:53:55: executing \u0026#34;podcast/rss.xml\u0026#34; at \u0026lt;os.Stat\u0026gt;: error calling Stat: LStat content/static/podcast/cinema-2020-07-14.mp3: file does not exist\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e똑같은 방법을 시도하면서 다른 결과를 기다하는 건 바보라는 말을 잊고 그 다음 날도 똑같은 짓을 했다. 여전히 답이 나올리가.\u003c/p\u003e","title":"Troubleshooting - rss.xml is not updated"},{"content":"iPad 12.9 인치와 매직키보드를 구입해서 가지고 다니는데, 예전에 13인치 맥북프로를 가지고 외출할 때 사용하던 슬리브에 담아서 가지고 다녔다. 어렵사리 슬리브에 넣을 수 있을 정도라 가지고 다녔는데 슬리브 입구가 세로로 들어가는 방식이라 펜을 아이패드에 붙힌 상태로 넣기가 어렵고, 무엇보다 입구가 좁은 쪽에 있다 보니 꺼내기가 번거로웠다. 특히 매일 같이 퇴근 길에 카메라 봉인과 개인물품인지를 증명하는 스티커를 보안직원에게 보여줘야 하는데 그걸 하고는 슬리브에 다시 넣을 수가 없다. 그렇게 하려면 바닥에 두고 차근차근 하나씩 해야 하는데 그럴 공간도 없고, 그럴 시간도 없으니.\n그래서 슬리브를 찾아봤는데 마침 좋은 평을 받고 있는 슬리브가 국내에서는 5만원 가량인데 아마존에서는 20불에 팔고 있어 직구를 했다. 그런데 정작 직구한 것은 좀 더 예뻐보였던 tomtoc 제폼이라는\u0026hellip;\n다른 제품과 함께 직구하느라 1주일 넘는 배송기간을 거쳐 오늘 손에 들어왔는데\u0026hellip;\n먼저 제품 소개 페이지에 있는 것과 같이 아이패드만 넣은 경우\n제품 사진에서 본 것처럼 깔끔하게 들어간다. 하지만\u0026hellip;\n매직키보드와 함께 아이패드를 넣으면 좀 이상하다. 머리(?)가 보인다. 슬리브가 제대로 닫히질 않는다.\n이유는 매직 키보드의 두께 때문. 두께가 두꺼워지니 슬리브가 제대로 닫히지 않고, 밸크로끼리 만나질 못한다.\n결국 이 제품은 매직 키보드를 사용하는 사람에게는 쓸모가 없는 제품이라는 거.. 그리고 그게 바로 나라는 거\u0026hellip;\n이번 직구는 실패. 같이 받은 작은 파우치를 20불에 산 걸로 생각해야 하나.\n","date":"2020-07-09T22:59:49+09:00","permalink":"https://cychong47.github.io/post/2020/2020-07-09-ipad-is-not-an-ipad/","summary":"\u003cp\u003eiPad 12.9 인치와 매직키보드를 구입해서 가지고 다니는데, 예전에 13인치 맥북프로를 가지고 외출할 때 사용하던 슬리브에 담아서 가지고 다녔다. 어렵사리 슬리브에 넣을 수 있을 정도라 가지고 다녔는데 슬리브 입구가 세로로 들어가는 방식이라 펜을 아이패드에 붙힌 상태로 넣기가 어렵고, 무엇보다 입구가 좁은 쪽에 있다 보니 꺼내기가 번거로웠다.\n특히 매일 같이 퇴근 길에 카메라 봉인과 개인물품인지를 증명하는 스티커를 보안직원에게 보여줘야 하는데 그걸 하고는 슬리브에 다시 넣을 수가 없다. 그렇게 하려면 바닥에 두고 차근차근 하나씩 해야 하는데 그럴 공간도 없고, 그럴 시간도 없으니.\u003c/p\u003e","title":"매직키보드 단 iPad는 iPad가 아니다"},{"content":"우선 docker로 실행한 nginx container를 종료시키고\ncychong@mini1:~/work/helm-chart-github$ docker ps -a |grep nginx a66786635c60 nginx \u0026#34;/docker-entrypoint.…\u0026#34; 7 minutes ago Up 7 minutes k8s_nginx_my-nginx-77596b9fc6-7txns_default_44840d63-b496-4a58-9e18-83e503c6d2cf_0 85c85322ea59 k8s.gcr.io/pause:3.1 \u0026#34;/pause\u0026#34; 7 minutes ago Up 7 minutes k8s_POD_my-nginx-77596b9fc6-7txns_default_44840d63-b496-4a58-9e18-83e503c6d2cf_0 5be06dc3b184 nginx \u0026#34;nginx -g \u0026#39;daemon of…\u0026#34; 2 weeks ago Up 2 weeks 0.0.0.0:8099-\u0026gt;80/tcp podcast 2812c510a5b6 nginx \u0026#34;nginx -g \u0026#39;daemon of…\u0026#34; 2 weeks ago Up 2 weeks 0.0.0.0:80-\u0026gt;80/tcp sosa0sa cychong@mini1:~/work/helm-chart-github$ docker stop 5be06dc3b184 5be06dc3b184 nginx를 구동시킬 helm chart 준비\ncychong@mini1:~/work/helm-chart/nginx$ tree -f . ├── ./Chart.yaml ├── ./README.md ├── ./charts ├── ./nginx-pv.yaml ├── ./templates │ ├── ./templates/NOTES.txt │ ├── ./templates/_helpers.tpl │ ├── ./templates/deployment.yaml │ ├── ./templates/ingress.yaml │ ├── ./templates/pvc.yaml │ ├── ./templates/service.yaml │ └── ./templates/tests │ └── ./templates/tests/test-connection.yaml └── ./values.yaml 우선 PV(Persistent Volume) 생성.\ncychong@mini1:~/work/helm-chart$ kubectl delete -f nginx/nginx-pv.yaml persistentvolume \u0026#34;nginx-pv\u0026#34; deleted cychong@mini1:~/work/helm-chart$ kubectl create -f nginx/nginx-pv.yaml persistentvolume/nginx-pv created cychong@mini1:~/work/helm-chart$ helm install podcast nginx NAME: podcast LAST DEPLOYED: Fri Jul 3 00:01:05 2020 NAMESPACE: default STATUS: deployed REVISION: 1 NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services podcast-nginx) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT cychong@mini1:~/work/helm-chart$ kubectl get pods NAME READY STATUS RESTARTS AGE podcast-nginx-8674747f9c-5tdlf 1/1 Running 0 11s cychong@mini1:~/work/helm-chart$ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 298d podcast-nginx NodePort 10.107.86.180 192.168.1.100 8099:30492/TCP 14s 1361 kubectl delete -f nginx/sosa0sa-pv.yaml 1362 kubectl create -f nginx/sosa0sa-pv.yaml 1363 helm install -f values-sosa0sa.yaml sosa0sa nginx ","date":"2020-07-02T23:58:41+09:00","permalink":"https://cychong47.github.io/post/2020/2020-07-02-deploy-nginx-with-helm/","summary":"\u003cp\u003e우선 \u003ccode\u003edocker\u003c/code\u003e로 실행한 nginx container를 종료시키고\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/work/helm-chart-github$ docker ps -a |grep nginx\na66786635c60        nginx                     \u0026#34;/docker-entrypoint.…\u0026#34;   7 minutes ago       Up 7 minutes                                       k8s_nginx_my-nginx-77596b9fc6-7txns_default_44840d63-b496-4a58-9e18-83e503c6d2cf_0\n85c85322ea59        k8s.gcr.io/pause:3.1      \u0026#34;/pause\u0026#34;                 7 minutes ago       Up 7 minutes                                       k8s_POD_my-nginx-77596b9fc6-7txns_default_44840d63-b496-4a58-9e18-83e503c6d2cf_0\n5be06dc3b184        nginx                     \u0026#34;nginx -g \u0026#39;daemon of…\u0026#34;   2 weeks ago         Up 2 weeks                  0.0.0.0:8099-\u0026gt;80/tcp   podcast\n2812c510a5b6        nginx                     \u0026#34;nginx -g \u0026#39;daemon of…\u0026#34;   2 weeks ago         Up 2 weeks                  0.0.0.0:80-\u0026gt;80/tcp     sosa0sa\ncychong@mini1:~/work/helm-chart-github$ docker stop 5be06dc3b184\n5be06dc3b184\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003enginx를 구동시킬 helm chart 준비\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/work/helm-chart/nginx$ tree -f\n.\n├── ./Chart.yaml\n├── ./README.md\n├── ./charts\n├── ./nginx-pv.yaml\n├── ./templates\n│   ├── ./templates/NOTES.txt\n│   ├── ./templates/_helpers.tpl\n│   ├── ./templates/deployment.yaml\n│   ├── ./templates/ingress.yaml\n│   ├── ./templates/pvc.yaml\n│   ├── ./templates/service.yaml\n│   └── ./templates/tests\n│       └── ./templates/tests/test-connection.yaml\n└── ./values.yaml\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e우선 PV(\u003ccode\u003ePersistent Volume\u003c/code\u003e) 생성.\u003c/p\u003e","title":"Deploy nginx with helm"},{"content":"bitnami repo 추가 cychong@mini1:~$ helm repo add bitnami https://charts.bitnami.com/bitnami \u0026#34;bitnami\u0026#34; has been added to your repositories bitnami repo에 있는 chart 확인 cychong@mini1:~$ helm search repo bitnami NAME CHART VERSION\tAPP VERSION DESCRIPTION bitnami/bitnami-common 0.0.8 0.0.8 Chart with custom templates used in Bitnami cha... bitnami/airflow 6.3.4 1.10.10 Apache Airflow is a platform to programmaticall... bitnami/apache 7.3.18 2.4.43 Chart for Apache HTTP Server bitnami/cassandra 5.5.3 3.11.6 Apache Cassandra is a free and open-source dist... bitnami/common 0.3.1 0.3.1 A Library Helm Chart for grouping common logic ... bitnami/consul 7.1.2 1.8.0 Highly available and distributed service discov... bitnami/contour 1.0.1 1.6.0 Contour Ingress controller for Kubernetes bitnami/discourse 0.1.3 2.4.4 A Helm chart for deploying Discourse to Kubernetes bitnami/dokuwiki 6.1.1 0.20180422.202005011246\tDokuWiki is a standards-compliant, simple to us... bitnami/drupal 7.0.2 9.0.1 One of the most versatile open source content m... bitnami/elasticsearch 12.4.2 7.8.0 A highly scalable open-source full-text search ... bitnami/etcd 4.8.7 3.4.9 etcd is a distributed key value store that prov... bitnami/external-dns 3.2.3 0.7.2 ExternalDNS is a Kubernetes addon that configur... bitnami/fluentd 1.2.5 1.11.1 Fluentd is an open source data collector for un... bitnami/ghost 10.0.15 3.21.1 A simple, powerful publishing platform that all... bitnami/grafana 2.1.3 7.0.5 Grafana is an open source, feature rich metrics... bitnami/harbor 6.0.6 2.0.1 Harbor is an an open source trusted cloud nativ... bitnami/influxdb 0.5.3 1.8.0 InfluxDB is an open source time-series database... bitnami/jasperreports 8.0.1 7.5.0 The JasperReports server can be used as a stand... bitnami/jenkins 5.0.15 2.235.1 The leading open source automation server bitnami/joomla 7.1.19 3.9.19 PHP content management system (CMS) for publish... bitnami/kafka 11.3.1 2.5.0 Apache Kafka is a distributed streaming platform. bitnami/kibana 5.2.5 7.8.0 Kibana is an open source, browser based analyti... bitnami/kong 1.2.2 2.0.4 Kong is a scalable, open source API layer (aka ... bitnami/kube-state-metrics 0.4.1 1.9.7 kube-state-metrics is a simple service that lis... bitnami/kubeapps 3.7.2 v1.10.2 Kubeapps is a dashboard for your Kubernetes clu... bitnami/kubewatch 1.0.14 0.0.4 Kubewatch notifies your slack rooms when change... bitnami/logstash 0.4.2 7.8.0 Logstash is an open source, server-side data pr... bitnami/magento 13.1.1 2.3.5 A feature-rich flexible e-commerce solution. It... bitnami/mariadb 7.6.1 10.3.23 Fast, reliable, scalable, and easy to use open-... bitnami/mariadb-cluster 1.0.1 10.2.14 Chart to create a Highly available MariaDB cluster bitnami/mariadb-galera 3.1.3 10.4.13 MariaDB Galera is a multi-master database clust... bitnami/mean 6.1.1 4.6.2 MEAN is a free and open-source JavaScript softw... bitnami/mediawiki 9.1.19 1.34.2 Extremely powerful, scalable software and a fea... bitnami/memcached 4.2.19 1.6.6 Chart for Memcached bitnami/metallb 0.1.15 0.9.3 The Metal LB for Kubernetes bitnami/metrics-server 4.2.1 0.3.7 Metrics Server is a cluster-wide aggregator of ... bitnami/minio 3.4.12 2020.6.22 MinIO is an object storage server, compatible w... bitnami/mongodb 8.0.1 4.2.8 NoSQL document-oriented database that stores JS... bitnami/mongodb-sharded 1.5.3 4.2.8 NoSQL document-oriented database that stores JS... bitnami/moodle 7.2.16 3.9.0 Moodle is a learning platform designed to provi... bitnami/mxnet 1.4.20 1.6.0 A flexible and efficient library for deep learning bitnami/mysql 6.14.4 8.0.20 Chart to create a Highly available MySQL cluster bitnami/nats 4.4.1 2.1.7 An open-source, cloud-native messaging system bitnami/nginx 6.0.1 1.19.0 Chart for the nginx server bitnami/nginx-ingress-controller\t5.3.24 0.33.0 Chart for the nginx Ingress controller bitnami/node 11.4.27 10.21.0 Event-driven I/O server-side JavaScript environ... bitnami/node-exporter 1.0.1 1.0.1 Prometheus exporter for hardware and OS metrics... bitnami/odoo 14.0.8 13.0.20200610 A suite of web based open source business apps. bitnami/opencart 7.0.17 3.0.3-3 A free and open source e-commerce platform for ... bitnami/orangehrm 7.0.19 4.4.0-0 OrangeHRM is a free HR management system that o... bitnami/osclass 7.0.18 3.9.0 Osclass is a php script that allows you to quic... bitnami/owncloud 8.2.1 10.4.1 A file sharing server that puts the control and... bitnami/parse 10.3.19 4.2.0 Parse is a platform that enables users to add a... bitnami/phabricator 9.1.7 2020.22.0 Collection of open source web applications that... bitnami/phpbb 7.0.17 3.3.0 Community forum that supports the notion of use... bitnami/phpmyadmin 6.2.2 5.0.2 phpMyAdmin is an mysql administration frontend bitnami/postgresql 8.10.11 11.8.0 Chart for PostgreSQL, an object-relational data... bitnami/postgresql-ha 3.3.1 11.8.0 Chart for PostgreSQL with HA architecture (usin... bitnami/prestashop 9.2.7 1.7.6-5 A popular open source ecommerce solution. Profe... bitnami/prometheus-operator 0.21.3 0.40.0 The Prometheus Operator for Kubernetes provides... bitnami/pytorch 1.3.17 1.5.1 Deep learning platform that accelerates the tra... bitnami/rabbitmq 7.4.1 3.8.5 Open source message broker software that implem... bitnami/redis 10.7.9 6.0.5 Open source, advanced key-value store. It is of... bitnami/redis-cluster 3.1.5 6.0.5 Open source, advanced key-value store. It is of... bitnami/redmine 14.2.6 4.1.1 A flexible project management web application. bitnami/spark 2.0.0 3.0.0 Spark is a fast and general-purpose cluster com... bitnami/spring-cloud-dataflow 0.1.2 2.5.2 Spring Cloud Data Flow is a microservices-based... bitnami/sugarcrm 1.0.5 6.5.26 SugarCRM enables businesses to create extraordi... bitnami/suitecrm 8.0.19 7.11.15 SuiteCRM is a completely open source enterprise... bitnami/tensorflow-inception 3.3.1 1.13.0 Open-source software library for serving machin... bitnami/tensorflow-resnet 2.0.15 2.2.0 Open-source software library serving the ResNet... bitnami/testlink 7.2.6 1.9.20 Web-based test management system that facilitat... bitnami/thanos 1.1.1 0.13.0 Thanos is a highly available metrics system tha... bitnami/tomcat 6.3.11 9.0.36 Chart for Apache Tomcat bitnami/wildfly 4.0.0 20.0.0 Chart for Wildfly bitnami/wordpress 9.3.16 5.4.2 Web publishing platform for building blogs and ... bitnami/zookeeper 5.17.2 3.6.1 A centralized service for maintaining configura... nginx chart 검색 cychong@mini1:~$ helm search repo nginx NAME CHART VERSION\tAPP VERSION\tDESCRIPTION bitnami/nginx 6.0.1 1.19.0 Chart for the nginx server bitnami/nginx-ingress-controller\t5.3.24 0.33.0 Chart for the nginx Ingress controller nginx-stable/nginx-ingress 0.5.0 1.7.0 NGINX Ingress Controller bitnami/kong 1.2.2 2.0.4 Kong is a scalable, open source API layer (aka ... GitHub에 있는 bitnami helm chart repo는 아래 위치에.\nhttps://github.com/bitnami/charts\n여기서 nginx의 Values.yaml 을 다운받아 원하는 형태로 값을 설정한다.\nvalues.yaml은 아래 위치에\nhttps://github.com/bitnami/charts/blob/master/bitnami/nginx/values.yaml\n","date":"2020-07-01T18:58:06+09:00","permalink":"https://cychong47.github.io/post/2020/19-hard-things-you-need-to-do-to-be-successful/","summary":"\u003ch2 id=\"bitnami-repo-추가\"\u003ebitnami repo 추가\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ helm repo add bitnami https://charts.bitnami.com/bitnami\n\u0026#34;bitnami\u0026#34; has been added to your repositories\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"bitnami-repo에-있는-chart-확인\"\u003ebitnami repo에 있는 chart 확인\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ helm search repo bitnami\nNAME                            \tCHART VERSION\tAPP VERSION            \tDESCRIPTION\nbitnami/bitnami-common          \t0.0.8        \t0.0.8                  \tChart with custom templates used in Bitnami cha...\nbitnami/airflow                 \t6.3.4        \t1.10.10                \tApache Airflow is a platform to programmaticall...\nbitnami/apache                  \t7.3.18       \t2.4.43                 \tChart for Apache HTTP Server\nbitnami/cassandra               \t5.5.3        \t3.11.6                 \tApache Cassandra is a free and open-source dist...\nbitnami/common                  \t0.3.1        \t0.3.1                  \tA Library Helm Chart for grouping common logic ...\nbitnami/consul                  \t7.1.2        \t1.8.0                  \tHighly available and distributed service discov...\nbitnami/contour                 \t1.0.1        \t1.6.0                  \tContour Ingress controller for Kubernetes\nbitnami/discourse               \t0.1.3        \t2.4.4                  \tA Helm chart for deploying Discourse to Kubernetes\nbitnami/dokuwiki                \t6.1.1        \t0.20180422.202005011246\tDokuWiki is a standards-compliant, simple to us...\nbitnami/drupal                  \t7.0.2        \t9.0.1                  \tOne of the most versatile open source content m...\nbitnami/elasticsearch           \t12.4.2       \t7.8.0                  \tA highly scalable open-source full-text search ...\nbitnami/etcd                    \t4.8.7        \t3.4.9                  \tetcd is a distributed key value store that prov...\nbitnami/external-dns            \t3.2.3        \t0.7.2                  \tExternalDNS is a Kubernetes addon that configur...\nbitnami/fluentd                 \t1.2.5        \t1.11.1                 \tFluentd is an open source data collector for un...\nbitnami/ghost                   \t10.0.15      \t3.21.1                 \tA simple, powerful publishing platform that all...\nbitnami/grafana                 \t2.1.3        \t7.0.5                  \tGrafana is an open source, feature rich metrics...\nbitnami/harbor                  \t6.0.6        \t2.0.1                  \tHarbor is an an open source trusted cloud nativ...\nbitnami/influxdb                \t0.5.3        \t1.8.0                  \tInfluxDB is an open source time-series database...\nbitnami/jasperreports           \t8.0.1        \t7.5.0                  \tThe JasperReports server can be used as a stand...\nbitnami/jenkins                 \t5.0.15       \t2.235.1                \tThe leading open source automation server\nbitnami/joomla                  \t7.1.19       \t3.9.19                 \tPHP content management system (CMS) for publish...\nbitnami/kafka                   \t11.3.1       \t2.5.0                  \tApache Kafka is a distributed streaming platform.\nbitnami/kibana                  \t5.2.5        \t7.8.0                  \tKibana is an open source, browser based analyti...\nbitnami/kong                    \t1.2.2        \t2.0.4                  \tKong is a scalable, open source API layer (aka ...\nbitnami/kube-state-metrics      \t0.4.1        \t1.9.7                  \tkube-state-metrics is a simple service that lis...\nbitnami/kubeapps                \t3.7.2        \tv1.10.2                \tKubeapps is a dashboard for your Kubernetes clu...\nbitnami/kubewatch               \t1.0.14       \t0.0.4                  \tKubewatch notifies your slack rooms when change...\nbitnami/logstash                \t0.4.2        \t7.8.0                  \tLogstash is an open source, server-side data pr...\nbitnami/magento                 \t13.1.1       \t2.3.5                  \tA feature-rich flexible e-commerce solution. It...\nbitnami/mariadb                 \t7.6.1        \t10.3.23                \tFast, reliable, scalable, and easy to use open-...\nbitnami/mariadb-cluster         \t1.0.1        \t10.2.14                \tChart to create a Highly available MariaDB cluster\nbitnami/mariadb-galera          \t3.1.3        \t10.4.13                \tMariaDB Galera is a multi-master database clust...\nbitnami/mean                    \t6.1.1        \t4.6.2                  \tMEAN is a free and open-source JavaScript softw...\nbitnami/mediawiki               \t9.1.19       \t1.34.2                 \tExtremely powerful, scalable software and a fea...\nbitnami/memcached               \t4.2.19       \t1.6.6                  \tChart for Memcached\nbitnami/metallb                 \t0.1.15       \t0.9.3                  \tThe Metal LB for Kubernetes\nbitnami/metrics-server          \t4.2.1        \t0.3.7                  \tMetrics Server is a cluster-wide aggregator of ...\nbitnami/minio                   \t3.4.12       \t2020.6.22              \tMinIO is an object storage server, compatible w...\nbitnami/mongodb                 \t8.0.1        \t4.2.8                  \tNoSQL document-oriented database that stores JS...\nbitnami/mongodb-sharded         \t1.5.3        \t4.2.8                  \tNoSQL document-oriented database that stores JS...\nbitnami/moodle                  \t7.2.16       \t3.9.0                  \tMoodle is a learning platform designed to provi...\nbitnami/mxnet                   \t1.4.20       \t1.6.0                  \tA flexible and efficient library for deep learning\nbitnami/mysql                   \t6.14.4       \t8.0.20                 \tChart to create a Highly available MySQL cluster\nbitnami/nats                    \t4.4.1        \t2.1.7                  \tAn open-source, cloud-native messaging system\nbitnami/nginx                   \t6.0.1        \t1.19.0                 \tChart for the nginx server\nbitnami/nginx-ingress-controller\t5.3.24       \t0.33.0                 \tChart for the nginx Ingress controller\nbitnami/node                    \t11.4.27      \t10.21.0                \tEvent-driven I/O server-side JavaScript environ...\nbitnami/node-exporter           \t1.0.1        \t1.0.1                  \tPrometheus exporter for hardware and OS metrics...\nbitnami/odoo                    \t14.0.8       \t13.0.20200610          \tA suite of web based open source business apps.\nbitnami/opencart                \t7.0.17       \t3.0.3-3                \tA free and open source e-commerce platform for ...\nbitnami/orangehrm               \t7.0.19       \t4.4.0-0                \tOrangeHRM is a free HR management system that o...\nbitnami/osclass                 \t7.0.18       \t3.9.0                  \tOsclass is a php script that allows you to quic...\nbitnami/owncloud                \t8.2.1        \t10.4.1                 \tA file sharing server that puts the control and...\nbitnami/parse                   \t10.3.19      \t4.2.0                  \tParse is a platform that enables users to add a...\nbitnami/phabricator             \t9.1.7        \t2020.22.0              \tCollection of open source web applications that...\nbitnami/phpbb                   \t7.0.17       \t3.3.0                  \tCommunity forum that supports the notion of use...\nbitnami/phpmyadmin              \t6.2.2        \t5.0.2                  \tphpMyAdmin is an mysql administration frontend\nbitnami/postgresql              \t8.10.11      \t11.8.0                 \tChart for PostgreSQL, an object-relational data...\nbitnami/postgresql-ha           \t3.3.1        \t11.8.0                 \tChart for PostgreSQL with HA architecture (usin...\nbitnami/prestashop              \t9.2.7        \t1.7.6-5                \tA popular open source ecommerce solution. Profe...\nbitnami/prometheus-operator     \t0.21.3       \t0.40.0                 \tThe Prometheus Operator for Kubernetes provides...\nbitnami/pytorch                 \t1.3.17       \t1.5.1                  \tDeep learning platform that accelerates the tra...\nbitnami/rabbitmq                \t7.4.1        \t3.8.5                  \tOpen source message broker software that implem...\nbitnami/redis                   \t10.7.9       \t6.0.5                  \tOpen source, advanced key-value store. It is of...\nbitnami/redis-cluster           \t3.1.5        \t6.0.5                  \tOpen source, advanced key-value store. It is of...\nbitnami/redmine                 \t14.2.6       \t4.1.1                  \tA flexible project management web application.\nbitnami/spark                   \t2.0.0        \t3.0.0                  \tSpark is a fast and general-purpose cluster com...\nbitnami/spring-cloud-dataflow   \t0.1.2        \t2.5.2                  \tSpring Cloud Data Flow is a microservices-based...\nbitnami/sugarcrm                \t1.0.5        \t6.5.26                 \tSugarCRM enables businesses to create extraordi...\nbitnami/suitecrm                \t8.0.19       \t7.11.15                \tSuiteCRM is a completely open source enterprise...\nbitnami/tensorflow-inception    \t3.3.1        \t1.13.0                 \tOpen-source software library for serving machin...\nbitnami/tensorflow-resnet       \t2.0.15       \t2.2.0                  \tOpen-source software library serving the ResNet...\nbitnami/testlink                \t7.2.6        \t1.9.20                 \tWeb-based test management system that facilitat...\nbitnami/thanos                  \t1.1.1        \t0.13.0                 \tThanos is a highly available metrics system tha...\nbitnami/tomcat                  \t6.3.11       \t9.0.36                 \tChart for Apache Tomcat\nbitnami/wildfly                 \t4.0.0        \t20.0.0                 \tChart for Wildfly\nbitnami/wordpress               \t9.3.16       \t5.4.2                  \tWeb publishing platform for building blogs and ...\nbitnami/zookeeper               \t5.17.2       \t3.6.1                  \tA centralized service for maintaining configura...\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"nginx-chart-검색\"\u003e\u003ccode\u003enginx\u003c/code\u003e chart 검색\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ helm search repo nginx\nNAME                            \tCHART VERSION\tAPP VERSION\tDESCRIPTION\nbitnami/nginx                   \t6.0.1        \t1.19.0     \tChart for the nginx server\nbitnami/nginx-ingress-controller\t5.3.24       \t0.33.0     \tChart for the nginx Ingress controller\nnginx-stable/nginx-ingress      \t0.5.0        \t1.7.0      \tNGINX Ingress Controller\nbitnami/kong                    \t1.2.2        \t2.0.4      \tKong is a scalable, open source API layer (aka ...\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e\u003ccode\u003eGitHub\u003c/code\u003e에 있는 \u003ccode\u003ebitnami helm chart repo\u003c/code\u003e는 아래 위치에.\u003cbr\u003e\n\u003ca href=\"https://github.com/bitnami/charts\"\u003ehttps://github.com/bitnami/charts\u003c/a\u003e\u003c/p\u003e","title":"Setup hugo with bitnami chart"},{"content":"금요일 밤에 지난 오류를 수정한 후 토요일, 일요일에는 제대로 동작하는 듯\u0026hellip;\n그런데 오늘 우연히 발견한 문제는 토요일과 금요일에 올라온 에피소드에 곡 목록이 없다. 추정되는 이유가 있긴했는데 집에 와서 확인해 보니 예상대로. 주말이라 곡 목록이 늦게 업데이트가 되었다.\n토요일, 일요일 곡 목록이 모두 일요일 저녁 7시 반 경에 올라온 것이다.\n흠.. 그렇다고 mp3를 그때 포스팅하지 않을 수도 없고. 이럴 때는 어떻게 해야 할까\u0026hellip;\n고민 중..\n","date":"2020-06-28T23:27:48+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-28-podcast-another-issue/","summary":"\u003cp\u003e금요일 밤에 지난 오류를 수정한 후 토요일, 일요일에는 제대로 동작하는 듯\u0026hellip;\u003c/p\u003e\n\u003cp\u003e그런데 오늘 우연히 발견한 문제는 토요일과 금요일에 올라온 에피소드에 곡 목록이 없다.\n추정되는 이유가 있긴했는데 집에 와서 확인해 보니 예상대로. 주말이라 곡 목록이 늦게 업데이트가 되었다.\u003cbr\u003e\n토요일, 일요일 곡 목록이 모두 일요일 저녁 7시 반 경에 올라온 것이다.\u003c/p\u003e\n\u003cp\u003e흠..\n그렇다고 mp3를 그때 포스팅하지 않을 수도 없고. 이럴 때는 어떻게 해야 할까\u0026hellip;\u003c/p\u003e\n\u003cp\u003e고민 중..\u003c/p\u003e","title":"2020 06 28 Podcast Another Issue"},{"content":"한줄요약 : Hugo로 만든 blog 에서 video 파일을 지원하려면 shortcode를 활용한다.\n아래 shortcode는 mp3, mp4 파일을 지원하는 zen에서 사용하는 shortcode(zen/layouts/shortcodes/video.html)\n\u0026lt;figure {{ with .Get \u0026#34;class\u0026#34; }}class=\u0026#34;{{ . }}\u0026#34;{{ end }}\u0026gt; \u0026lt;video controls preload=\u0026#34;{{ .Get \u0026#34;preload\u0026#34; | default \u0026#34;metadata\u0026#34; }}\u0026#34; {{ with .Get \u0026#34;width\u0026#34; }}width=\u0026#34;{{ . }}\u0026#34;{{ end }}\u0026gt; {{ with .Get \u0026#34;src\u0026#34; }}\u0026lt;source src=\u0026#34;{{ . | relURL }}\u0026#34; type=\u0026#34;video/mp4\u0026#34;\u0026gt;{{ end }} \u0026lt;/video\u0026gt; {{ with .Get \u0026#34;caption\u0026#34; }}\u0026lt;figcaption\u0026gt;{{ . }}\u0026lt;/figcaption\u0026gt;{{ end }} \u0026lt;/figure\u0026gt; 이 파일을 hugo site의 layouts/shortcodes 디렉토리에 복사하고 md 파일에서 다음과 같이 작성한다.\n특별한 처리를 하지 않는 이상 Web browser 가 지원하는 표준(?) video 재생 기능을 사용하기에, mp4 파일은 지원되지만 mov 파일은 지원되지 않는다고 한다. Embedding local video in static/img or page folder to website\n실제로 shortcode를 이용해서 작성한 md 파일에서 만들어진 HTML 페이지를 보면 다음과 같다.\n\u0026lt;figure \u0026gt; \u0026lt;video controls preload=\u0026#34;metadata\u0026#34; \u0026gt; \u0026lt;source src=\u0026#34;/images/2020/06/20200606_1634_IMG_4080.MP4\u0026#34; type=\u0026#34;video/mp4\u0026#34;\u0026gt; \u0026lt;/video\u0026gt; \u0026lt;/figure\u0026gt; 즉 그냥 content type(media type이라고 하는 건가?)를 video/mp4라고 지정하고 그 파일의 위치를 src 태그로 지정하는 형태. video/mp4는 브라우저 설정 등에서 봤던 기억이 있는데\u0026hellip; 잘 모르지만 그래서 이 type의 파일은 브라우저가 알아서 지원해주는 거라고 추정된다.\nShortcodes에 대한 내용은 Create Your Own Shortcodes 를 참고하고.\n덕분에 이제 MP4 파일도 마음대로 blog에 추가할 수 있게 되었다는.\n","date":"2020-06-27T00:24:41+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-27-how-to-support-video/","summary":"\u003cp\u003e한줄요약 : Hugo로 만든 blog 에서 video 파일을 지원하려면 shortcode를 활용한다.\u003c/p\u003e\n\u003cp\u003e아래 shortcode는 mp3, mp4 파일을 지원하는 \u003ca href=\"https://github.com/frjo/hugo-theme-zen\"\u003ezen\u003c/a\u003e에서 사용하는 shortcode(\u003ccode\u003ezen/layouts/shortcodes/video.html\u003c/code\u003e)\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e\u0026lt;figure {{ with .Get \u0026#34;class\u0026#34; }}class=\u0026#34;{{ . }}\u0026#34;{{ end }}\u0026gt;\n\u0026lt;video controls preload=\u0026#34;{{ .Get \u0026#34;preload\u0026#34; | default \u0026#34;metadata\u0026#34; }}\u0026#34; {{ with .Get \u0026#34;width\u0026#34; }}width=\u0026#34;{{ . }}\u0026#34;{{ end }}\u0026gt;\n{{ with .Get \u0026#34;src\u0026#34; }}\u0026lt;source src=\u0026#34;{{ .  | relURL }}\u0026#34; type=\u0026#34;video/mp4\u0026#34;\u0026gt;{{ end }}\n\u0026lt;/video\u0026gt;\n{{ with .Get \u0026#34;caption\u0026#34; }}\u0026lt;figcaption\u0026gt;{{ . }}\u0026lt;/figcaption\u0026gt;{{ end }}\n\u0026lt;/figure\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e이 파일을 hugo site의 \u003ccode\u003elayouts/shortcodes\u003c/code\u003e 디렉토리에 복사하고 md 파일에서 다음과 같이 작성한다.\u003c/p\u003e","title":"How to embed video in hugo"},{"content":"음\n이건 무슨 상황일까?\nmp3 파일은 레코딩이 제대로 되었고, md 파일도 만들었는데 site를 rebuild했다는 메시지가 오질 않는다. 안그래도 Telegram 을 이용해서 메시지를 보내는 기능을 추가해야 겠다고 생각했을때 아래처럼 정상적으로 동작하는 경우가 아니라 뭔가 문제가 있는 상황을 어떻게 알 수 있을까 하는 고민을 했었는데 생각보다 일찍 그 상황(아마도 많은 경우 중 하나 겠지만) 이 온 듯했다. 이렇게 메시지가 안 온 것으로 뭔가 문제가 있다는 걸 판단하는 건 비효율적인 방법이라 보다 적극적으로 어떤 비정상 상황이고, 가능하면 왜 그런 지도 파악해서 메시지를 보내게 할 필요가 있다는 생각을 했었는데\u0026hellip;\n집에 와서 우선 상태부터 확인해 보니 mp3 파일은 정상적으로 만들어져 있고, md 파일도 만들어져있는데 사이트 리빌드가 안되었다. Cron에 12시 4분 그리고 5분에 각각 mp3 파일을 mini2에서 가져오고, mp3 파일의 길이를 확인해서 md 파일을 만들고 site를 다시 빌드하는 작업을 하게 했는데 연속으로 있는 이 두 개의 cron 작업 중 하나만 동작하지 않는 것은 아닌 듯 하다. 이틀 연속으로 첫번째 cron job은 동작하고, 두 번째만 동작하지 않을 확률은 거의 없어 보이는데 생각해 보니 md 파일을 만드는 작업 자체가 두 번째 cron job에서 하는 일 중 하나라 두 번째 cron job도 최소한 실행은 정상적으로 된 걸로 판단할 수 있다.\n그럼 왜 site rebuild가 안되었을까? Cron에 적어놓은 두 번째 job을 보니 cron의 동작을 /tmp/cron.out 파일에 기록하게 해 놨다는 게 보였다. 그래서 로그 파일을 확인해 보니 아하\u0026hellip;\nfile /XXX/static/podcast/cinema-2020-06-25.mp3 is not found 파일이 없다고?\n혹시나 하고 확인해 보니 파일이 멀쩡하게 존재한다.\n그럼 저 Cron job이 동작했을 때 파일이 없었다는 건가? 어떻게 확인할 수 있지 라고 고민하려는 순간 파일 시스템에서 파일 시간을 확인할 수 있겠다라는 생각이 들었다. 그래서 확인해 보니\n... -rw-r--r-- 1 cychong cychong 57600879 Jun 26 12:05 cinema-2020-06-24.mp3 -rw-r--r-- 1 cychong cychong 57600879 Jun 26 12:06 cinema-2020-06-25.mp3 -rw-r--r-- 1 cychong cychong 57600879 Jun 26 12:06 cinema-2020-06-26.mp3 정상적으로 사이트 빌드가 된 24일은 12:5분에 파일이 생성되었는데 제대로 사이트 빌드가 되지 않은 25, 26일은 12:6분에 파일이 생성되었다는 게 보였다. 저 시간은 실제로 사이트 빌드 작업을 수행하는 mini1에서 mini2으로부터 파일이 가져온 시점이니까 어떤 이유인 지는 알기 어렵지만 위에서 본 에러를 찍은 두 번째 cron job에서 호출한 스크립트가 동작할 시점에 파일이 없었다는 게 확인된 셈이다. 아마도 내부 네트웍에 뭔가 이슈가 있었던지, mini2나 mini1이 로드가 높았거나 했을 것 같은데 확률적으로는 mini1이 힘들어서 그랬을 것 같고(이틀 연속으로 12:00pm까지는 멀쩡하게 녹음을 한 mini2를 의심하기는 좀 무리인 듯 하니)\n이제 원인을 파악했으니 문제를 해결해야 할 차례.\n우선 기존에 녹음된 25일과 26일 건은 md 파일의 frontmatter에 적는 mp3 파일의 duration만 고치고 사이트를 다시 빌드하면 될 듯 하다. 지금 script에서 파일파일을 찾지 못하면 duration을 0으로 설정하고 md 파일을 만드는데, 내가 만든 script에서 사이트를 다시 빌드하는 조건을 md 파일과 mp3 파일이 모두 존재하는 경우로 했는데 이번 경우에는 아직 mp3 파일을 다 받아오기 전인 12:5분 상황이라 사이트를 빌드하지 않은 것으로 보인다.\nif options.no_publish == False: if os.path.exists(mp3_file) and os.path.exists(md_file): logger.info(\u0026#34;Rebuild site\u0026#34;) os.system(\u0026#34;cd %s ; /usr/bin/hugo -t zen\u0026#34; %podcast_base) tg.send_msg(\u0026#34;(%s) Rebuild site\u0026#34; %(hostname)) else: logger.info(\u0026#34;file(s) is missing - mp3(%s), md(%s)\u0026#34; %(os.path.exists(mp3_file), os.path.exists(md_file))) else: logger.info(\u0026#34;Skip site build\u0026#34;) 앞에서 이야기했던 비정상 상황일 때 telegram으로 알릴 수 있게 하려면 우선 여기부터 log 파일에 기록하는 것 외에 telegram으로 보내면 되겠다.\n위 코드에서 적은 로그 내용을 담은 파일을 확인해 보니 앞에서 파악하고 추정했던 바로 그 상황이 로그로 남아있는 걸 알 수 있다. 이것만 그냥 telegram으로 보냈으면 좋았으련만\u0026hellip;. 앞에서 파악하고 추정했던 바로 그 상황이 로그로 남아있는 걸 알 수 있다. 이것만 그냥 telegram으로 보냈으면 좋았으련만\u0026hellip;. 앞에서 파악하고 추정했던 바로 그 상황이 로그로 남아있는 걸 알 수 있다. 이것만 그냥 telegram으로 보냈으면 좋았으련만\u0026hellip;. 앞에서 파악하고 추정했던 바로 그 상황이 로그로 남아있는 걸 알 수 있다. 이것만 그냥 telegram으로 보냈으면 좋았으련만\u0026hellip;.\n... 2020-06-25 12:05:41,506 file(s) is missing - mp3(False), md(True) ... 2020-06-26 12:05:41,024 file(s) is missing - mp3(False), md(True) 지금은 정상적인 로그 상황을 보내고 있는데 뭔가\u0026hellip;.. 좀 내용을 요약해서 한번에 보내거나 조금 더 안정화 되면 비정상인 경우만 메시지를 보내는 방식으로 바꾸는 것도 고려해 봐야겠다. 충분히 안정화가 되었다는 확신이 생기면\n그리고 근본적인 문제였던 12:4분에 시작된 mp3 파일 복사가 12:5분이 되기 전에 끝나지 않아 사이트 빌드가 수행되지 않은 것은 우선 사이트 빌드를 파일을 가져오는 cron job 보다 10분 후에 수행하는 것으로 수정해야겠다. 설마 10분내에는 가져오겠지. 두 개 머신이 그것도 허브에 1Gbps 로 직접 연결되어 있는데 설마\u0026hellip;.\n하는 김에 파일 가져오는 것도 5분에 수행하도록 바꾸고(4분은 이상해\u0026hellip;.)\n05 12 * * * cd /home/cychong/work/cbs-ost/script \u0026amp;\u0026amp; ./scp.sh \u0026gt;\u0026gt; /tmp/cron.out 2\u0026gt;\u0026amp;1 15 12 * * * cd /home/cychong/work/cbs-ost/script \u0026amp;\u0026amp; ./publish.sh \u0026gt;\u0026gt; /tmp/cron.out 2\u0026gt;\u0026amp;1 ","date":"2020-06-26T22:11:32+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-26-no-podcast-update/","summary":"\u003cp\u003e음\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/06/20200626_1315_IMG_4474.PNG\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e이건 무슨 상황일까?\u003cbr\u003e\nmp3 파일은 레코딩이 제대로 되었고, md 파일도 만들었는데 site를 rebuild했다는 메시지가 오질 않는다. 안그래도 Telegram 을 이용해서 메시지를 보내는 기능을 추가해야 겠다고 생각했을때 아래처럼 정상적으로 동작하는 경우가 아니라 뭔가 문제가 있는 상황을 어떻게 알 수 있을까 하는 고민을 했었는데 생각보다 일찍 그 상황(아마도 많은 경우 중 하나 겠지만) 이 온 듯했다.\n이렇게 메시지가 안 온 것으로 뭔가 문제가 있다는 걸 판단하는 건 비효율적인 방법이라 보다 적극적으로 어떤 비정상 상황이고, 가능하면 왜 그런 지도 파악해서 메시지를 보내게 할 필요가 있다는 생각을 했었는데\u0026hellip;\u003c/p\u003e","title":"No Podcast Update?"},{"content":"\n","date":"2020-06-24T01:11:13+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-07-new-input-device-trio/","summary":"\u003cp\u003e\u003cimg src=\"/images/2020/06/20200607_2146_IMG_4291.JPG\" alt=\"\"\u003e\u003c/p\u003e","title":"New Input Device Trio"},{"content":"Get docker container id from container name\ndocker ps -aqf \u0026#34;name=containername\u0026#34; docker ps -aqf \u0026#34;name=^containername$\u0026#34; -q for quiet. output only the ID -a for all. works even if your container is not running -f for filter. ^ container name must start with this string $ container name must end with this string ","date":"2020-06-22T23:54:09+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-22-docker-ps-with-name/","summary":"\u003cp\u003e\u003ca href=\"https://stackoverflow.com/questions/34496882/get-docker-container-id-from-container-name\"\u003eGet docker container id from container name\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edocker ps -aqf \u0026#34;name=containername\u0026#34;\ndocker ps -aqf \u0026#34;name=^containername$\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e\u003ccode\u003e-q\u003c/code\u003e for quiet. output only the ID\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e-a\u003c/code\u003e for all. works even if your container is not running\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e-f\u003c/code\u003e for filter.\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e^\u003c/code\u003e container name must start with this string\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003e$\u003c/code\u003e container name must end with this string\u003c/li\u003e\n\u003c/ul\u003e","title":"Find container with its name"},{"content":"Scripts Automation\nmini2 - record mp3 file $ crontab -l 00 11 * * * cd /Users/cychong/work/cbs-ost/script \u0026amp;\u0026amp; ./record.sh \u0026gt;\u0026gt; /tmp/cron.out 2\u0026gt;\u0026amp;1 mini1 - create MD file and publish podcast $ crontab -l 04 12 * * * cd /home/cychong/work/cbs-ost/script \u0026amp;\u0026amp; ./scp.sh \u0026gt;\u0026gt; /tmp/cron.out 2\u0026gt;\u0026amp;1 05 12 * * * cd /home/cychong/work/cbs-ost/script \u0026amp;\u0026amp; ./publish.sh \u0026gt;\u0026gt; /tmp/cron.out 2\u0026gt;\u0026amp;1 Get mp3 file from mini2 Create md file after getting song list Rebuild site to publish the updated podcast ","date":"2020-06-20T22:33:02+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-20-setup-podcast-blog-5/","summary":"\u003ch1 id=\"scripts\"\u003eScripts\u003c/h1\u003e\n\u003cp\u003eAutomation\u003c/p\u003e\n\u003ch3 id=\"mini2---record-mp3-file\"\u003emini2 - record mp3 file\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ crontab -l\n00 11 *    *   *   cd /Users/cychong/work/cbs-ost/script \u0026amp;\u0026amp; ./record.sh \u0026gt;\u0026gt; /tmp/cron.out 2\u0026gt;\u0026amp;1\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"mini1---create-md-file-and-publish-podcast\"\u003emini1 - create MD file and publish podcast\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ crontab -l\n04 12 * * * cd /home/cychong/work/cbs-ost/script \u0026amp;\u0026amp; ./scp.sh \u0026gt;\u0026gt; /tmp/cron.out 2\u0026gt;\u0026amp;1\n05 12 * * * cd /home/cychong/work/cbs-ost/script \u0026amp;\u0026amp; ./publish.sh \u0026gt;\u0026gt; /tmp/cron.out 2\u0026gt;\u0026amp;1\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003eGet mp3 file from mini2\u003c/li\u003e\n\u003cli\u003eCreate md file after getting song list\u003c/li\u003e\n\u003cli\u003eRebuild site to publish the updated podcast\u003c/li\u003e\n\u003c/ul\u003e","title":"Setup podcast blog - 자동화"},{"content":"github가 제공하는 private repository를 사용하니 ID와 암호를 매번 물어보길래 찾아 보니 이렇게 해결할 수 있다고.\nsource : How do I avoid the specification of the username and password at every git push?\n$ git config credential.helper store $ git push https://github.com/repo.git Username for \u0026#39;https://github.com\u0026#39;: \u0026lt;USERNAME\u0026gt; Password for \u0026#39;https://USERNAME@github.com\u0026#39;: \u0026lt;PASSWORD\u0026gt; To set the timeout for \u0026ldquo;not-asking password\u0026rdquo;\ngit config --global credential.helper \u0026#39;cache --timeout 7200\u0026#39; ","date":"2020-06-19T06:41:02+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-19-disable-password-for-private-github-repo/","summary":"\u003cp\u003egithub가 제공하는 private repository를 사용하니 ID와 암호를 매번 물어보길래 찾아 보니 이렇게 해결할 수 있다고.\u003c/p\u003e\n\u003cp\u003esource : \u003ca href=\"https://stackoverflow.com/questions/8588768/how-do-i-avoid-the-specification-of-the-username-and-password-at-every-git-push\"\u003eHow do I avoid the specification of the username and password at every git push?\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ git config credential.helper store\n$ git push https://github.com/repo.git\n\nUsername for \u0026#39;https://github.com\u0026#39;: \u0026lt;USERNAME\u0026gt;\nPassword for \u0026#39;https://USERNAME@github.com\u0026#39;: \u0026lt;PASSWORD\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eTo set the timeout for \u0026ldquo;not-asking password\u0026rdquo;\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003egit config --global credential.helper \u0026#39;cache --timeout 7200\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e","title":"Disable Password for Private Github Repo"},{"content":"듣고 싶은 mp3 파일을 mini2를 이용해서 1시간 짜리 녹음 동작확인 결과 정상 동작 확인\n$ mp3info -p \u0026#34;%S\u0026#34; cinema-2020-06-18.mp3 3600 역시 mini1의 processing power 부족 때문에 제대로 1시간 녹음이 안된 듯.\n","date":"2020-06-18T23:10:45+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-18-setup-podcast-blog-2/","summary":"\u003cp\u003e듣고 싶은 mp3 파일을\nmini2를 이용해서 1시간 짜리 녹음 동작확인 결과 정상 동작 확인\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ mp3info -p \u0026#34;%S\u0026#34; cinema-2020-06-18.mp3\n3600\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e역시 mini1의 processing power 부족 때문에 제대로 1시간 녹음이 안된 듯.\u003c/p\u003e","title":"Setup podcast blog - recording 동작 확인"},{"content":"Podcast post 작성하기 Zen theme 덕분에 mp3 파일을 포함한 blog post를 markdown 파일로 작성하고 site build만 시키면 자동적으로 podcast feed를 만들어 준다.\nhttps://github.com/frjo/hugo-theme-zen에 있는 내용을 보면 md 파일의 frontformatter에 아래 내용을 채워야 하는 듯 하다. 이 중에서 필수인 항목은 mp3 파일의 위치를 가리키는 mp3와 mp3 파일의 길이를 알려주는 duration 두 개 필요. hugo에서 image 파일 위치를 가리킬 때 static\\images\\a.jpg에 위치한 파일을 markdown 파일에서는 \\images.a.jpg로 표현하는 것과 같은 형식을 사용하면 된다.\npodcast: mp3: # * The path to the mp3 file, duration: # * Episode duration, e.g 1:04:02 (iTunes). image: src: # Episode image src, place inside the assets directory (iTunes). alt: # Alt text for the image, explain what is on the image. width: # Image width in the article, defaults to 250px. class: # Image wrapper class. explicit: true/false # Episode explicit setting, default to false (iTunes). episode: # Episode number (iTunes). episodeType: full/trailer/bonus # Episode type, defaults to full (iTunes). season: # Episode season (iTunes). block: # Block the episode from iTunes, default to no (iTunes). 예를 들어 10초 짜리 mp3 파일을 static\\podcast\\a.mp3라고 저장했다면 다음과 같이 frontformatter를 적어주면 된다.\npodcast: mp3 : \u0026#34;/podcast/a.mp3\u0026#34; duration: 10 ","date":"2020-06-16T06:53:24+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-16-setup-podcast-blog-3/","summary":"\u003ch2 id=\"podcast-post-작성하기\"\u003ePodcast post 작성하기\u003c/h2\u003e\n\u003cp\u003eZen theme 덕분에 mp3 파일을 포함한 blog post를 markdown 파일로 작성하고 site build만 시키면 자동적으로 podcast feed를 만들어 준다.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/frjo/hugo-theme-zen\"\u003ehttps://github.com/frjo/hugo-theme-zen\u003c/a\u003e에 있는 내용을 보면 md 파일의 frontformatter에 아래 내용을 채워야 하는 듯 하다. 이 중에서 필수인 항목은 mp3 파일의 위치를 가리키는 \u003ccode\u003emp3\u003c/code\u003e와 mp3 파일의 길이를 알려주는 \u003ccode\u003eduration\u003c/code\u003e 두 개 필요.\nhugo에서 image 파일 위치를 가리킬 때 \u003ccode\u003estatic\\images\\a.jpg\u003c/code\u003e에 위치한 파일을 markdown 파일에서는 \u003ccode\u003e\\images.a.jpg\u003c/code\u003e로 표현하는 것과 같은 형식을 사용하면 된다.\u003c/p\u003e","title":"Setup podcast blog - post 작성"},{"content":"Install Create Hugo for podcast cychong15:writing_factory cychong$ hugo new site cbs-ost Congratulations! Your new Hugo site is created in /Users/cychong/workspace/writing_factory/cbs-ost. Just a few more steps and you\u0026#39;re ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \u0026#34;hugo new theme \u0026lt;THEMENAME\u0026gt;\u0026#34; command. 2. Perhaps you want to add some content. You can add single files with \u0026#34;hugo new \u0026lt;SECTIONNAME\u0026gt;/\u0026lt;FILENAME\u0026gt;.\u0026lt;FORMAT\u0026gt;\u0026#34;. 3. Start the built-in live server via \u0026#34;hugo server\u0026#34;. Visit https://gohugo.io/ for quickstart guide and full documentation. cychong15:writing_factory cychong$ cd cbs-ost cychong15:cbs-ost cychong$ 갓 만들어진 빈 Hugo site 구조\ncychong15:cbs-ost cychong$ tree -f . ├── ./archetypes │ └── ./archetypes/default.md ├── ./config.toml ├── ./content ├── ./data ├── ./layouts ├── ./static └── ./themes 6 directories, 2 files Setup git repo and add github and origin cychong15:cbs-ost cychong$ git init Initialized empty Git repository in /Users/cychong/workspace/writing_factory/cbs-ost/.git/ cychong15:cbs-ost cychong$ git remote add origin https://github.com/cychong47/cbs-ost.git Create .gitkeep files and commit the base files cychong15:cbs-ost cychong$ touch content/.gitkeep data/.gitkeep layouts/.gitkeep static/.gitkeep themes/.gitkeep cychong15:cbs-ost cychong$ git add . cychong15:cbs-ost cychong$ git status On branch master No commits yet Changes to be committed: (use \u0026#34;git rm --cached \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: archetypes/default.md new file: config.toml new file: content/.gitkeep new file: data/.gitkeep new file: layouts/.gitkeep cychong15:cbs-ost cychong$ git ci -m \u0026#34;initial\u0026#34; [master (root-commit) 041bae3] initial 5 files changed, 9 insertions(+) create mode 100644 archetypes/default.md create mode 100644 config.toml create mode 100644 content/.gitkeep create mode 100644 data/.gitkeep create mode 100644 layouts/.gitkeep Install zen theme Hugo에서 제일(?) 유명한 podcast용 theme이 castanet 인데 내 경우에는 잘 동작을 안 한다. Castanet go module이 없다는 에러가 나는데 무슨 말인지 이해를 못하겠다는. 그냥 시키는 대로 했는데\u0026hellip; 구글링을 좀 해봤지만 뾰족한 답을 찾지 못해 다른 theme을 찾았는데 이전에는 그냥 지나쳤던 theme이었는데(아마 theme demo가 castanet에 비해 podscastic(?) 하지 않아서 그랬던 것 같다.\n그냥 일반 blog theme처럼 보이는 대다 그닥 깔끔하거나 예쁘지 않아서 그냥 지나친 듯.\n설치는 여느 Hugo theme과 같은 방식으로 설치한다.\ncychong15:cbs-ost cychong$ git submodule add https://github.com/frjo/hugo-theme-zen.git themes/zen Cloning into \u0026#39;/Users/cychong/workspace/writing_factory/cbs-ost/themes/zen\u0026#39;... remote: Enumerating objects: 30, done. remote: Counting objects: 100% (30/30), done. remote: Compressing objects: 100% (27/27), done. remote: Total 2586 (delta 12), reused 9 (delta 3), pack-reused 2556 Receiving objects: 100% (2586/2586), 1.78 MiB | 1.72 MiB/s, done. Resolving deltas: 100% (1540/1540), done. cychong15:cbs-ost cychong$ git status On branch master Changes to be committed: (use \u0026#34;git restore --staged \u0026lt;file\u0026gt;...\u0026#34; to unstage) new file: .gitmodules new file: themes/zen cychong15:cbs-ost cychong$ git push origin master To https://github.com/cychong47/cbs-ost.git ! [rejected] master -\u0026gt; master (fetch first) error: failed to push some refs to \u0026#39;https://github.com/cychong47/cbs-ost.git\u0026#39; hint: Updates were rejected because the remote contains work that you do hint: not have locally. This is usually caused by another repository pushing hint: to the same ref. You may want to first integrate the remote changes hint: (e.g., \u0026#39;git pull ...\u0026#39;) before pushing again. hint: See the \u0026#39;Note about fast-forwards\u0026#39; in \u0026#39;git push --help\u0026#39; for details. cychong15:cbs-ost cychong$ git pull origin master remote: Enumerating objects: 3, done. remote: Counting objects: 100% (3/3), done. remote: Total 3 (delta 0), reused 0 (delta 0), pack-reused 0 Unpacking objects: 100% (3/3), 609 bytes | 304.00 KiB/s, done. From https://github.com/cychong47/cbs-ost * branch master -\u0026gt; FETCH_HEAD * [new branch] master -\u0026gt; origin/master fatal: refusing to merge unrelated histories cychong15:cbs-ost cychong$ git pull origin master --allow-unrelated-histories From https://github.com/cychong47/cbs-ost * branch master -\u0026gt; FETCH_HEAD Merge made by the \u0026#39;recursive\u0026#39; strategy. README.md | 2 ++ 1 file changed, 2 insertions(+) create mode 100644 README.md cychong15:cbs-ost cychong$ git status On branch master nothing to commit, working tree clean cychong15:cbs-ost cychong$ git push origin master Enumerating objects: 14, done. Counting objects: 100% (14/14), done. Delta compression using up to 8 threads Compressing objects: 100% (10/10), done. Writing objects: 100% (13/13), 1.23 KiB | 1.23 MiB/s, done. Total 13 (delta 2), reused 0 (delta 0), pack-reused 0 remote: Resolving deltas: 100% (2/2), done. To https://github.com/cychong47/cbs-ost.git 73d0c71..f94ec2b master -\u0026gt; master To update theme source : https://github.com/frjo/hugo-theme-zen\ngit submodule update --remote --merge Setup config Hugo site를 만들면 theme 설치 후에 해야 하는 일은 theme의 example config 파일을 가져다 수정하는 것\ncychong15:cbs-ost cychong$ cp themes/zen/exampleSite/config.yaml . Put image for podcast The image should be in the assets directory not the static directory(주의)\ncychong15:cbs-ost cychong$ tree -f assets/ assets └── assets/cbs-ost-logo.png 다른 machine에서 git repo clone하기 theme이 submodule로 추가되어 있는 상태라 이 경우 clone할 때 recursive 옵션을 주거나 submodule만 별도로 받아와야 한다. 기본적으로 submodule은 git repo에 함께 저장되지 않고, 다른 repo에 있다는 정보만 가지고 있으므로\nsource : https://kyubot.tistory.com/129\ncychong@mini1:~/tmp$ git clone https://github.com/cychong47/cbs-ost.git Cloning into \u0026#39;cbs-ost\u0026#39;... Username for \u0026#39;https://github.com\u0026#39;: cychong47 Password for \u0026#39;https://cychong47@github.com\u0026#39;: remote: Enumerating objects: 23, done. remote: Counting objects: 100% (23/23), done. remote: Compressing objects: 100% (13/13), done. remote: Total 23 (delta 4), reused 20 (delta 4), pack-reused 0 Unpacking objects: 100% (23/23), 529.45 KiB | 577.00 KiB/s, done. cychong@mini1:~/tmp$ tree -d cbs-ost/themes/zen/ cbs-ost/themes/zen/ 0 directories submodule만 따로 받아오려면 다음과 같이.\ncychong@mini1:~/work/cbs-ost$ git submodule update --init --recursive Submodule \u0026#39;themes/zen\u0026#39; (https://github.com/frjo/hugo-theme-zen.git) registered for path \u0026#39;themes/zen\u0026#39; Cloning into \u0026#39;/home/cychong/work/cbs-ost/themes/zen\u0026#39;... Submodule path \u0026#39;themes/zen\u0026#39;: checked out \u0026#39;d60e1a1582dcb882bab4fc1fef66a1ed5e19c583\u0026#39; 처음부터 git clone 할 때 recursive 옵션을 사용하면 repository를 가져올 때 submodule도 함께 받아 온다.\ncychong@mini1:~/tmp$ git clone --recursive https://github.com/cychong47/cbs-ost.git cbs-ost2 Cloning into \u0026#39;cbs-ost2\u0026#39;... Username for \u0026#39;https://github.com\u0026#39;: cychong47 Password for \u0026#39;https://cychong47@github.com\u0026#39;: remote: Enumerating objects: 23, done. remote: Counting objects: 100% (23/23), done. remote: Compressing objects: 100% (13/13), done. remote: Total 23 (delta 4), reused 20 (delta 4), pack-reused 0 Unpacking objects: 100% (23/23), 529.45 KiB | 668.00 KiB/s, done. Submodule \u0026#39;themes/zen\u0026#39; (https://github.com/frjo/hugo-theme-zen.git) registered for path \u0026#39;themes/zen\u0026#39; Cloning into \u0026#39;/home/cychong/tmp/cbs-ost2/themes/zen\u0026#39;... remote: Enumerating objects: 30, done. remote: Counting objects: 100% (30/30), done. remote: Compressing objects: 100% (27/27), done. remote: Total 2586 (delta 12), reused 9 (delta 3), pack-reused 2556 Receiving objects: 100% (2586/2586), 1.78 MiB | 1.60 MiB/s, done. Resolving deltas: 100% (1540/1540), done. Submodule path \u0026#39;themes/zen\u0026#39;: checked out \u0026#39;d60e1a1582dcb882bab4fc1fef66a1ed5e19c583\u0026#39; cychong@mini1:~/tmp$ tree -d cbs-ost2/themes/zen/ cbs-ost2/themes/zen/ ├── archetypes ├── assets │ ├── js │ │ ├── jq_versions │ │ └── lib ... ├── php ├── scripts └── static └── images 75 directories 이제 기본적인 blog 사이트 구성은 끝났다.\nPodcast post 작성하기 Zen theme 덕분에 mp3 파일을 포함한 blog post를 markdown 파일로 작성하고 site build만 시키면 자동적으로 podcast feed를 만들어 준다.\nhttps://github.com/frjo/hugo-theme-zen에 있는 내용을 보면 md 파일의 frontformatter에 아래 내용을 채워야 하는 듯 하다. 이 중에서 필수인 항목은 mp3 파일의 위치를 가리키는 mp3와 mp3 파일의 길이를 알려주는 duration 두 개 필요. hugo에서 image 파일 위치를 가리킬 때 static\\images\\a.jpg에 위치한 파일을 markdown 파일에서는 \\images.a.jpg로 표현하는 것과 같은 형식을 사용하면 된다.\npodcast: mp3: # * The path to the mp3 file, duration: # * Episode duration, e.g 1:04:02 (iTunes). image: src: # Episode image src, place inside the assets directory (iTunes). alt: # Alt text for the image, explain what is on the image. width: # Image width in the article, defaults to 250px. class: # Image wrapper class. explicit: true/false # Episode explicit setting, default to false (iTunes). episode: # Episode number (iTunes). episodeType: full/trailer/bonus # Episode type, defaults to full (iTunes). season: # Episode season (iTunes). block: # Block the episode from iTunes, default to no (iTunes). 예를 들어 10초 짜리 mp3 파일을 static\\podcast\\a.mp3라고 저장했다면 다음과 같이 frontformatter를 적어주면 된다.\npodcast: mp3 : \u0026#34;/podcast/a.mp3\u0026#34; duration: 10 ","date":"2020-06-16T06:53:24+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-16-setup-podcast-blog-1/","summary":"\u003ch1 id=\"install\"\u003eInstall\u003c/h1\u003e\n\u003ch2 id=\"create-hugo-for-podcast\"\u003eCreate Hugo for podcast\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong15:writing_factory cychong$ hugo new site cbs-ost\nCongratulations! Your new Hugo site is created in /Users/cychong/workspace/writing_factory/cbs-ost.\n\nJust a few more steps and you\u0026#39;re ready to go:\n\n1. Download a theme into the same-named folder.\n   Choose a theme from https://themes.gohugo.io/ or\n   create your own with the \u0026#34;hugo new theme \u0026lt;THEMENAME\u0026gt;\u0026#34; command.\n2. Perhaps you want to add some content. You can add single files\n   with \u0026#34;hugo new \u0026lt;SECTIONNAME\u0026gt;/\u0026lt;FILENAME\u0026gt;.\u0026lt;FORMAT\u0026gt;\u0026#34;.\n3. Start the built-in live server via \u0026#34;hugo server\u0026#34;.\n\nVisit https://gohugo.io/ for quickstart guide and full documentation.\ncychong15:writing_factory cychong$ cd cbs-ost\ncychong15:cbs-ost cychong$\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e갓 만들어진 빈 Hugo site 구조\u003c/p\u003e","title":"Setup podcast blog - Setup Hugo"},{"content":"From OS X dictionary\nGrain of salt\nPliny the Elder\u0026rsquo;s Naturalis Historia may be the origin of the phrase.\nTo take something with a \u0026ldquo;grain of salt\u0026rdquo; or \u0026ldquo;pinch of salt\u0026rdquo; is an English language idiom that means to view something with skepticism or not to interpret something literally.[1] In the old-fashioned English units of weight, a grain weighs approximately 60 mg, which is about how much table salt a person might pick up between the fingers as a pinch. History\nHypotheses of the phrase\u0026rsquo;s origin include Pliny the Elder\u0026rsquo;s Naturalis Historia, regarding the discovery of a recipe for an antidote to a poison.[2] In the antidote, one of the ingredients was a grain of salt. Threats involving the poison were thus to be taken \u0026ldquo;with a grain of salt\u0026rdquo;, and therefore less seriously. The phrase cum grano salis (\u0026ldquo;with a grain of salt\u0026rdquo;) is not what Pliny wrote. It is constructed according to the grammar of modern European languages rather than Classical Latin. Pliny\u0026rsquo;s actual words were addito salis grano (\u0026ldquo;after having added a grain of salt\u0026rdquo;). An alternative account says that the Roman general Pompey believed he could make himself immune to poison by ingesting small amounts of various poisons, and he took this treatment with a grain of salt to help him swallow the poison. In this version, the salt is not the antidote. It was taken merely to assist in swallowing the poison. The Latin word sal (\u0026ldquo;salis\u0026rdquo; is the genitive) means both \u0026ldquo;salt\u0026rdquo; and \u0026ldquo;wit\u0026rdquo;, thus the Latin phrase \u0026ldquo;cum grano salis\u0026rdquo; could be translated to either \u0026ldquo;with a grain of salt\u0026rdquo; or \u0026ldquo;with a grain (small amount) of wit\u0026rdquo;, actually to \u0026ldquo;with caution\u0026rdquo;/cautiously. [3] The phrase is said \u0026ldquo;with a pinch of salt\u0026rdquo; in British English and said \u0026ldquo;with a grain of salt\u0026rdquo; in American English.[4] References\n^ Webster\u0026rsquo;s New World College Dictionary ^ \u0026ldquo;Take with a grain of salt\u0026rdquo;. www.phrases.org.uk. ^ Book 23: LXXVI: 149 ^ \u0026ldquo;British Vs. American Idioms - Part 1\u0026rdquo;. www.lostinthepond.com. Retrieved 2017-10-25.\n","date":"2020-06-14T08:08:31+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-14-grain-of-salt/","summary":"\u003cp\u003eFrom OS X dictionary\u003c/p\u003e\n\u003cp\u003e\u003cstrong\u003eGrain of salt\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003ePliny the Elder\u0026rsquo;s Naturalis Historia may be the origin of the phrase.\u003c/p\u003e\n\u003cp\u003eTo take something with a \u0026ldquo;grain of salt\u0026rdquo; or \u0026ldquo;pinch of salt\u0026rdquo; is an English language idiom that means to view something with skepticism or not to interpret something literally.[1]\nIn the old-fashioned English units of weight, a grain weighs approximately 60 mg, which is about how much table salt a person might pick up between the fingers as a pinch.\nHistory\u003c/p\u003e","title":"Grain of Salt"},{"content":"record Find out duration of mp3 file mp3info, exiftool or ffmpeg can be used to get the duration of mp3 file\nThough mp3info and exiftool can be used to the exiting mp3 file while the ffmpeg give the duration on recording process.\n$ mp3info -p \u0026#34;%S\\n\u0026#34; Cinema_20200614.mp3 15 Exiftool does not give the correct duration.\n$ exiftool Cinema_20200614.mp3 ExifTool Version Number : 11.88 File Name : Cinema_20200614.mp3 Directory : . File Size : 235 kB File Modification Date/Time : 2020:06:14 07:16:03+09:00 File Access Date/Time : 2020:06:14 07:47:47+09:00 File Inode Change Date/Time : 2020:06:14 07:16:03+09:00 File Permissions : rw-rw-r-- File Type : MP3 File Type Extension : mp3 MIME Type : audio/mpeg MPEG Audio Version : 1 Audio Layer : 3 Audio Bitrate : 64 kbps Sample Rate : 44100 Channel Mode : Stereo MS Stereo : Off Intensity Stereo : Off Copyright Flag : False Original Media : False Emphasis : None ID3 Size : 45 Encoder Settings : Lavf58.29.100 Duration : 0:00:30 (approx) Setup cron job Use crontab which enables user to have a separated cron job\n$ crontab -e ... 59 10 * * * /home/cychong/work/record_cbs/record.py crontab: installing new crontab crontab-ui can be used to easily manage crontab file\nStart crontab-ui. Specify host IP address. 127.0.0.1 port 8000 are by default. To change the port, set with PORT\n$ sudo HOST=192.168.1.100 PORT=8000 crontab-ui \u0026amp; To learn the syntax of crontab, visit crontab guru\nHow to know if cron is working Check the syslog file\nThe following log is for the example cron - running at 7:16am\n$ grep CRON /var/log/syslog ... Jun 14 07:01:01 mini1 CRON[1497965]: (CRON) info (No MTA installed, discarding output) Jun 14 07:16:01 mini1 CRON[1513968]: (cychong) CMD (/home/cychong/work/record_cbs/record.py 15) Reference ","date":"2020-06-14T06:49:23+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-14-record-cbs-with-cron/","summary":"\u003ch2 id=\"record\"\u003erecord\u003c/h2\u003e\n\u003ch2 id=\"find-out-duration-of-mp3-file\"\u003eFind out duration of mp3 file\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://superuser.com/questions/63399/get-mp3-length-in-linux-freebsd\"\u003e\u003ccode\u003emp3info\u003c/code\u003e, \u003ccode\u003eexiftool\u003c/code\u003e or \u003ccode\u003effmpeg\u003c/code\u003e can be used to get the duration of mp3 file\u003c/a\u003e\u003cbr\u003e\nThough \u003ccode\u003emp3info\u003c/code\u003e and \u003ccode\u003eexiftool\u003c/code\u003e can be used to the exiting mp3 file while the ffmpeg give the duration on recording process.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ mp3info -p \u0026#34;%S\\n\u0026#34; Cinema_20200614.mp3\n15\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eExiftool does not give the correct duration.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ exiftool Cinema_20200614.mp3\nExifTool Version Number         : 11.88\nFile Name                       : Cinema_20200614.mp3\nDirectory                       : .\nFile Size                       : 235 kB\nFile Modification Date/Time     : 2020:06:14 07:16:03+09:00\nFile Access Date/Time           : 2020:06:14 07:47:47+09:00\nFile Inode Change Date/Time     : 2020:06:14 07:16:03+09:00\nFile Permissions                : rw-rw-r--\nFile Type                       : MP3\nFile Type Extension             : mp3\nMIME Type                       : audio/mpeg\nMPEG Audio Version              : 1\nAudio Layer                     : 3\nAudio Bitrate                   : 64 kbps\nSample Rate                     : 44100\nChannel Mode                    : Stereo\nMS Stereo                       : Off\nIntensity Stereo                : Off\nCopyright Flag                  : False\nOriginal Media                  : False\nEmphasis                        : None\nID3 Size                        : 45\nEncoder Settings                : Lavf58.29.100\nDuration                        : 0:00:30 (approx)\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"setup-cron-job\"\u003eSetup cron job\u003c/h2\u003e\n\u003cp\u003eUse \u003ccode\u003ecrontab\u003c/code\u003e which enables user to have a separated \u003ca href=\"https://phoenixnap.com/kb/set-up-cron-job-linux%5D\"\u003ecron job\u003c/a\u003e\u003c/p\u003e","title":"Record CBS radio in every day"},{"content":"Hugo로 옮긴 후 아직 찾지 못한 기능 중 하나가 글 들을 종류 별로 구분해서 보는 것이었다. 각 글마다 지정한 category나 tag별로 볼 수 있는 것은 지금 사용하는 mainroad theme에서도 지원하는데 예전에 wordpress에서 많이 사용하던, post, page 등 성격 별로 다른 글들을 볼 수 있는 방법이 아쉬웠다.\n하지만 hugo의 다른 theme 을 사용하는 다른 사이트에서도 유사한 기능을 사용하는 것이 보였고, 심지어 mainroad theme을 사용하는 다른 사이트에서도 같은 기능을 사용한는 것이 보였다.\n다만 이걸 어떻게 불러야 하는 지를 몰라 관련 정보를 찾는 것이 쉽지 않았는데 처음 hugo를 설치하려고 여기저기 정보를 찾던 때 봤던 내용이 우연히 기억이 나서 그걸 적용해 보니 짜잔 하고 이렇게 내가 원하던 기능을 사용할 수 있게 되었다.\n우선 이건 설정을 하기 전에 blog 화면. 블로그 제목 아래 바로 글들이 표시된다. 이제 설정을 변경한 후. 블로그 제목 아래 POST와 PAGE라는 메뉴가 보인다. 이제 PAGE 메뉴를 누르면 아래와 같이 몇 개 글만 나온다. 이 글들은 content 디렉토리 아래 page 디렉토리에 있는 글들이다. 예전에 wordpress에서 사용하던 패턴(?)인데 post는 특정 날에 있었던 어떤 일을 기록하는 데 사용하고, page는 날짜 보다는 특정 주제에 대해 적는 용도로 사용했다. 내 경우 주로 읽은 책 목록을 기록하거나, 다른 page 글과 같이 주로 오랜 시간을 두고 있었던 내용을 적는 용도로 사용했다.\n이렇게 메뉴를 구분하기 위해 config.toml 파일에 추가한 내용은 다음과 같다.\n[[menu.main]] name = \u0026#34;Post\u0026#34; url = \u0026#34;/post\u0026#34; weigth = 1 [[menu.main]] name = \u0026#34;Page\u0026#34; url = \u0026#34;/page\u0026#34; weigth = 2 위 내용만 있어도 기본적으로 화면에 메뉴는 표시가 되는데, 이미 기존 post 아래 글을 모아둔 것이 있으니 Post 메뉴는 제대로 동작하겠지만, page 디렉토리 아래에는 글이 없어 아무것도 표시가 되지 않았다. 그래서 우선 content/page 디렉토리를 만들고, 예전 wordpress에서 page에 해당하는 글들을 이 위치에 복사했다.\ncychong15:sosa0sa cychong$ tree -d -L 1 content/ content/ ├── page └── post 2 directories cychong15:sosa0sa cychong$ tree -f -L 2 content/ content ├── content/_index.md ├── content/archives.md ├── content/page │ ├── content/page/_index.md │ ├── content/page/apple.md │ ├── content/page/books.md │ └── content/page/designholic.md └── content/post ├── content/post/2003 ├── content/post/2004 ├── content/post/2005 ├── content/post/2006 ├── content/post/2007 ├── content/post/2008 ├── content/post/2009 ├── content/post/2010 ├── content/post/2011 ├── content/post/2012 ├── content/post/2013 ├── content/post/2014 ├── content/post/2015 ├── content/post/2016 ├── content/post/2017 ├── content/post/2018 ├── content/post/2019 └── content/post/2020 20 directories, 6 files ","date":"2020-06-13T23:46:10+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-13-add-menu-to-hugo/","summary":"\u003cp\u003eHugo로 옮긴 후 아직 찾지 못한 기능 중 하나가 글 들을 \u003cstrong\u003e종류\u003c/strong\u003e 별로 구분해서 보는 것이었다. 각 글마다 지정한 \u003ccode\u003ecategory\u003c/code\u003e나 \u003ccode\u003etag\u003c/code\u003e별로 볼 수 있는 것은 지금 사용하는 \u003ca href=\"https://github.com/Vimux/Mainroad/\"\u003emainroad\u003c/a\u003e theme에서도 지원하는데 예전에 wordpress에서 많이 사용하던, \u003ccode\u003epost\u003c/code\u003e, \u003ccode\u003epage\u003c/code\u003e 등 성격 별로 다른 글들을 볼 수 있는 방법이 아쉬웠다.\u003c/p\u003e\n\u003cp\u003e하지만 hugo의 다른 theme 을 사용하는 다른 사이트에서도 유사한 기능을 사용하는 것이 보였고, 심지어 mainroad theme을 사용하는 다른 사이트에서도 같은 기능을 사용한는 것이 보였다.\u003c/p\u003e\n\u003cp\u003e다만 이걸 어떻게 불러야 하는 지를 몰라 관련 정보를 찾는 것이 쉽지 않았는데 처음 hugo를 설치하려고 여기저기 정보를 찾던 때 봤던 내용이 우연히 기억이 나서 그걸 적용해 보니 짜잔 하고 이렇게 내가 원하던 기능을 사용할 수 있게 되었다.\u003c/p\u003e","title":"Hugo에 Main menu 추가하기"},{"content":"오늘 운전하는 시간이 마침 오전 11시라 CBS 신지혜의 영화음악을 들을 수 있었다. 어릴 적 부터 좋아하던 영화 음악을 괘 오래동안 듣게 해주고 있는 프로그램.\n편안한 목소리와 다양한 좋은 영화 음악을 들을 수 있어 정은영의 영화음악 이후 가장 좋아하는 라디오 프로그램이 되었다. 그런데 문제는 라디오 방송 시간이 오전 11시라 회사생활을 하면서 쉽게 듣기 어려운 상황이라는 거.\n2년 전에는 OS X에 cron을 이용해서 자동으로 녹음을 한 후 NAS로 파일을 옮겨서 DS Audio 앱으로 듣기도 했는데 파일 기반으로 되어 있다 보니 내가 어떤 파일을 들었는 지 알기가 어려웠다. 라디오를 녹음한 거다 보니 파일 이름에 쓸만한 것이 날짜 정도인데 그러다 보니 파일을 구분하기가 어렵다는 거. 거기에 DS Audio 앱이 그닥인 점도 한 몫을 했고.\n그래서 그 당시에도 blog을 이용해서 podcast를 만들면 해결이 되지 않을까 했는데 이리 저리 찾아보다 포기했던 기억이 있다. 그 당시에 사용하던 블로그 플랫폼이 wordpress, ghost 였는데 녹음된 파일을 ghost를 이용해서 podcast 피드를 만드는 건 더욱 희귀했지만, wordpress를 이용한 사이트도 그닥 녹녹치 않았다. 워낙 사용자 층이 넓다보니 wordpress 기반으로 podcast를 운영하는 사이트도 꽤 있었던 걸로 기억하고, 특히나 wordpress의 plugin 중에도 podcast를 위한 것이 있었던 걸로 기억한다. 다만 이런 저런 이유로 제대로 살펴보지를 않았고, 특히 podcast로 만드는 과정을 자동화해야 하는데(녹음 및 podcast로 만드는 건 시스템이 알아서 하고, 난 듣기만 해야) 이 부분에 대해서는 뾰족한 수를 찾지 못했다는\u0026hellip;\n그런데 이번에 텍스트 파일 기반의 hugo로 블로그 플랫폼을 변경한 김에 뭔가 자동화를 쉽게 할 수 있지 않을까 하는 생각이 들었다. 그래서 생각한 것이 아래와 같은 workflow다. 아이패드에서 대충 그린 그림인데 정말 알아보기 힘들군… (아이패드를 산 이유 중 하나가 바로 이렇게 스케치를 하다 필요하면 손쉽게 화면 캡처해서 파일로 활용할 수 있다는 거 였는데 적절한 활용 예)\nHugo+podcast 조합으로 구글링을 해 봤는데 예상한 것처럼 많은 글이 나오지는 않았지만 그래도 podcast에 특화된 castanet theme이 있는 걸 보면 분명히 방법이 있을 거라는 생각이 든다. 이게 잘 되면 매일 같이 좋은 DJ가 선곡해 주는 영화음악을 다시 들을 수 있겠지.\n","date":"2020-06-13T16:44:23+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-13-setup-podcast-blog-0/","summary":"\u003cp\u003e오늘 운전하는 시간이 마침 오전 11시라 CBS \u003ccode\u003e신지혜의 영화음악\u003c/code\u003e을 들을 수 있었다.\n어릴 적 부터 좋아하던 영화 음악을 괘 오래동안 듣게 해주고 있는 프로그램.\u003cbr\u003e\n편안한 목소리와 다양한 좋은 영화 음악을 들을 수 있어 \u003ccode\u003e정은영의 영화음악\u003c/code\u003e 이후 가장 좋아하는 라디오 프로그램이 되었다.\n그런데 문제는 라디오 방송 시간이 오전 11시라 회사생활을 하면서 쉽게 듣기 어려운 상황이라는 거.\u003c/p\u003e\n\u003cp\u003e2년 전에는 OS X에 cron을 이용해서 자동으로 녹음을 한 후 NAS로 파일을 옮겨서 \u003ccode\u003eDS Audio\u003c/code\u003e 앱으로 듣기도 했는데 파일 기반으로 되어 있다 보니 내가 어떤 파일을 들었는 지 알기가 어려웠다. 라디오를 녹음한 거다 보니 파일 이름에 쓸만한 것이 날짜 정도인데 그러다 보니 파일을 구분하기가 어렵다는 거. 거기에 \u003ccode\u003eDS Audio\u003c/code\u003e 앱이 그닥인 점도 한 몫을 했고.\u003c/p\u003e","title":"Setup podcast blog - beginning"},{"content":"Wordpress 블로그를 hugo로 바꾼 김에 ghost 블로그도 hugo로 이사하기로 결심했다.\nGhost 정말 애증이 담긴\u0026hellip;\nGhost가 1.0이 되기 전에 markdown 기반의 블로그 툴을 찾는 과정 에서 발견해서 0.9 버전인가 부터 사용해 왔다. Ghost가 node 기반이라 생전 처음 듣는 node를 OS X에 설치해보고, docker for OS X이 나와서 docker로 실행해 오다, docker-compose 도 써 보고, Ansible 로 deploy도 해보고. 그러다 2019년에는 kubernetes hands-on을 해 볼 겸해서 리눅스에서 microk8s를 설치해서 ghost도 k8s로 실행해 봈다. 그리고 k8s에서 기본처럼 사용되는 SW 배포/관리 툴인 helm도 hands-on을 해 보고 싶어서 helm chart로 ghost도 배포해 보고. 횟수로 치면 대략 2016년 정보 부터 같은데 그간 Ghost는 1.0을 거쳐 2.0 그리고 지금은 3.0까지 업데이트가 된 상태이다.\n처음에 Ghost에 끌렸던 이유는 markdown 기반이라는 점이 컸는데, 본격적으로 markdown을 기반으로 글을 쓰는 blog 툴이라는 점. 그리고 그때도 그랬지만, wordpress가 blog 외에 다양한 형태의 CMS(Contents Management System)으로 개발되다 보니 blog만 돌리기에는 too much하다는 느낌을 지울 수 없었다. Ghost가 sqlite를 backend DB로 사용할 수 있는 것과 달리 wordpress는 MySql등의 DB를 반드시 사용해야 한다는 점도 8GB의 리눅스 박스에서 돌리기엔 부담이 벅차서 메모리 부족으로 에러가 나기도 했다는\u0026hellip;\nGhost에서 hugo로 이전해야겠다는 마음을 먹게 한 가장 큰 이유는 Ghost의 editor때문이 아닌가 싶다. 초기에는 정말 간단한 형태의 text editor 였는데, 시간이 지나면서 점점 복잡한 형태의 editor로 바뀌었는데 내겐 오히려 적응하는 것이 쉽지 않았다. 그냥 markdown 문법 몇 가지만 익혀서 사용하면 될 듯 한데 그걸 WIGWYG 형태로 지원하다 보니 오히려 내겐 번거로운 절차가 되어 버렸다.\n어차피 Ghost blog에 올린 글들은 markdown으로 정리했던 내용이 대부분인 터라 그냥 향후에 platform 에 대한 의존성을 줄이는 셈 치고 Ghost에서 한 발 물러서기로 했다.\nHugo 를 이용한 사이트를 만드는 것도 아직 익숙하지 않아서 살짝 헤매긴 했지만, 더 큰 문제는 Ghost에 있는 글들을 어떻게 옮길 것인가 하는. 개발자 사이에서는 Hugo를 이용한 블로그를 쓰는 경우가 적지 않지만 Ghost를 사용하다 Hugo로 이전하는 경우는 그렇게 많아 보이지 않았다. 구글링을 해 보면 대부분 GhostToHugo라는 golang으로 작성된 앱을 이용해서 데이터를 전환했다는 경우가 많았다. 그래도 나도 같은 툴을 시도해 봤는데 왠걸 잘 안된다. golang 문법을 모르지만, 에러가 난 부분을 보면 file IO로 보이는데 잘 이해가 안된다. 간단하게 디버그 코드를 추가해서 확인해 보려고 해도 이상하게 내가 수정한 코드가 실행이 안되는. 아마도 이건 golang의 빌드 체계를 몰라서 그런 듯.\n또 다시 구글링을 해서 찾는 방법은 누군가 PHP로 작성한 스크립트인데 역시나 안된다. 워낙 코드가 간단하긴 한데 문제는 문제가 왜 발생하는 지 전혀 감을 못 잡겠다는\u0026hellip; 근데 그 간단한 코드를 보니 대략 어떻게 하고 있구나 하는 감이 잡혔다. 그래서 이번 기회에 그냥 스크립트를 직접 작성해 보자 하고 졸린 눈을 부비고 코드를 작성했다. mobiledoc 문법으로 되어 있는 블로그 본문을 제외한 부분은 대충 원하는 형태로 동작하도록 했는데 mobiledoc의 문법이 또 달라서 이걸 markdown으로 변경하는 것도 은근 시간이 필요한 작업으로 보였다. 그러다 다시 구글링을 mobiledoc to markdown을 주제로 하다 찾은 글이 바로 이 글 Migrating From Ghost to Hugo (Again) 이다. 2017년에 작성된 글인데 무려 내가 하고 싶었던, 내가 헤매고 있었던 부분이 모두 구현된 변환 스크립트였다. 거기에 내가 몇 줄을 사용해서 구현한 기능을 단 한 줄로 pythonic 한 코드로 깔끔하게 작성한 걸 보고 좌절감을 또\u0026hellip; ;\n지난 번 wordpress를 이전한 hugo는 Mainroad theme을 사용했는데 ghost 를 이전한 hugo는 pure를 선택했다. 둘 다 깔끔한데, hugo의 단점으로 보이는 것 중 하나가 theme 간에 대략적인 통일성은 있는데 그렇다고 기본적인 걸 모두 엄격하게 지키는 게 아니라 theme 마다 hugo configuration 파일(config.toml 혹은 config.yaml)의 내용을 모두 바꿔야 한다. 그리고 md 파일을 두는 위치도 content 아래에서는 각 theme마다 다르게 처리하고 있어 지금도 mainroad theme은 post를 사용하고, pure theme은 posts를 사용한다. (이 점도 내가 아직 hugo의 구조를 제대로 이해하지 못해서 그럴 수도 있다 물론\u0026hellip;)\n두 개 theme에서 공히 없는 기능은 monthly archive 목록을 sidebar에서 보여주는 거. 특히 journal 형태로 가족 블로그에서 아쉬운 기능이다. 특정 연도에 있던 일을 보고 싶을 때가 많은데 mainroad theme 뿐만 아니라 다른 hugo theme에서도 이런 기능이 흔하지는 않다. 아마도(?) hugo를 사용하는 사람들이 대부분 기술적인 내용을 남기는 tech blogger여서 그런게 아닌가 싶은데 나로서는 아쉬운 부분이다. 이 기능은 꼭 필요하다는 생각이 들어 시간 날 때마다 찾아봐야겠다.\n이번에 Ghost에서 hugo로 옮긴 블로그는 github.io에 호스팅을 해보기로 했다. wordpress에서 이전한 hugo 블로그처럼 직접 nginx container를 이용해서 호스팅해도 되는데, 그냥 이번에는 그렇게 해보려고 한다. 거기에 netify도 연동해서 글을 쓰면 자동으로 글이 github.io에 호스팅에 반영되는 것 까지 해보려고. 실은 이건 wordpress에서 이전한 hugo 블로그에도 필요한 기능인데 netify가 제공하는 한 개의 블로그에 sosa0sa.com 도메인을 넘겨버리면 집 mac mini 서버로 redirect하는 것이 어려워져서 제약이 생길 것 같아 고민 중이다. 그건 좀 써 보면서 생각을 해 보기로\u0026hellip;\nFarewell Ghost~\nMigrating from Ghost to Hugo - Why Bother? Moving from Ghost to Hugo https://blog.viktoradam.net/2019/03/28/netlify-hugo/ ","date":"2020-06-07T22:14:02+09:00","permalink":"https://cychong47.github.io/post/2020/2020-06-07-migrate-ghost-to-hugo/","summary":"\u003cp\u003eWordpress 블로그를 hugo로 바꾼 김에 ghost 블로그도 hugo로 이사하기로 결심했다.\u003cbr\u003e\n\u003ca href=\"http://ghost.org\"\u003eGhost\u003c/a\u003e 정말 애증이 담긴\u0026hellip;\u003c/p\u003e\n\u003cp\u003eGhost가 1.0이 되기 전에 markdown 기반의 블로그 툴을 찾는 과정\n에서 발견해서 0.9 버전인가 부터 사용해 왔다. \u003ccode\u003eGhost\u003c/code\u003e가 node 기반이라 생전 처음 듣는 node를 OS X에 설치해보고, docker for OS X이 나와서 \u003ca href=\"https://cychong47.github.io/2017/04/move-to-docker/\"\u003edocker\u003c/a\u003e로 실행해 오다, \u003ca href=\"https://cychong47.github.io/2017/09/ghost-container-with-docker-compose/\"\u003edocker-compose\u003c/a\u003e 도 써 보고, \u003ca href=\"https://cychong47.github.io/2017/12/recreate-ghost-container/\"\u003eAnsible\u003c/a\u003e 로 deploy도 해보고.\n그러다 2019년에는 kubernetes hands-on을 해 볼 겸해서 리눅스에서 microk8s를 설치해서 ghost도 \u003ca href=\"https://cychong47.github.io/2019/05/setup-ghost-in-microk8s-2/\"\u003ek8s\u003c/a\u003e로 실행해 봈다. 그리고 k8s에서 기본처럼 사용되는 SW 배포/관리 툴인 helm도 hands-on을 해 보고 싶어서 \u003ca href=\"https://cychong47.github.io/2019/09/ghost-season-5-helm/\"\u003ehelm chart로 ghost도 배포\u003c/a\u003e해 보고. 횟수로 치면 대략 2016년 정보 부터 같은데 그간 \u003ccode\u003eGhost\u003c/code\u003e는 1.0을 거쳐 2.0 그리고 지금은 3.0까지 업데이트가 된 상태이다.\u003c/p\u003e","title":"Migrate Ghost to Hugo"},{"content":"Wordpress 에서 hugo로 이사한 후 첫번째 시도. Hugo theme은 harbor를 사용하고, site 호스팅 방법은 nginx docker를 사용. (이상하게 nginx를 helm으로 띄우는 게 간단하지 않네)\nClone repogistry for raw blog data cychong15:migration_to_hugo cychong$ git clone https://github.com/cychong47/sosa0sa.git Cloning into \u0026#39;sosa0sa\u0026#39;... warning: You appear to have cloned an empty repository. Setup hugo inside of the git repository cychong15:migration_to_hugo cychong$ hugo new site sosa0sa Error: /Users/cychong/workspace/migration_to_hugo/sosa0sa already exists and is not empty. See --force. cychong15:migration_to_hugo cychong$ hugo new site sosa0sa --force Congratulations! Your new Hugo site is created in /Users/cychong/workspace/migration_to_hugo/sosa0sa. Just a few more steps and you\u0026#39;re ready to go: 1. Download a theme into the same-named folder. Choose a theme from https://themes.gohugo.io/ or create your own with the \u0026#34;hugo new theme \u0026lt;THEMENAME\u0026gt;\u0026#34; command. 2. Perhaps you want to add some content. You can add single files with \u0026#34;hugo new \u0026lt;SECTIONNAME\u0026gt;/\u0026lt;FILENAME\u0026gt;.\u0026lt;FORMAT\u0026gt;\u0026#34;. 3. Start the built-in live server via \u0026#34;hugo server\u0026#34;. Visit https://gohugo.io/ for quickstart guide and full documentation. Maybe not good to enforce to do something.\ncychong15:sosa0sa cychong$ tree -f . ├── ./archetypes │ └── ./archetypes/default.md ├── ./config.toml ├── ./content ├── ./data ├── ./layouts ├── ./static └── ./themes 6 directories, 2 files Add Theme cychong15:sosa0sa cychong$ cd themes/ cychong15:themes cychong$ ls cychong15:themes cychong$ git submodule add https://github.com/matsuyoshi30/harbor.git harbor Cloning into \u0026#39;/Users/cychong/workspace/migration_to_hugo/sosa0sa/themes/harbor\u0026#39;... remote: Enumerating objects: 213, done. remote: Counting objects: 100% (213/213), done. remote: Compressing objects: 100% (142/142), done. remote: Total 739 (delta 111), reused 134 (delta 55), pack-reused 526 Receiving objects: 100% (739/739), 7.90 MiB | 4.50 MiB/s, done. Resolving deltas: 100% (349/349), done. Copy example config.toml Default config.toml from harbor theme git repo which is a little bit different from that of the exampleSite directory of theme (themes/harbor/exampleSite/config.toml)\ntheme = \u0026#34;harbor\u0026#34; baseurl = \u0026#34;https://example.com/\u0026#34; title = \u0026#34;Hugo Themes\u0026#34; paginate = 3 languageCode = \u0026#34;en\u0026#34; DefaultContentLanguage = \u0026#34;en\u0026#34; enableInlineShortcodes = true footnoteReturnLinkContents = \u0026#34;^\u0026#34; # Optional # If you use googleAnalytics, you set top-level options in config.toml to the beginning of the config file like other top-level options. googleAnalytics = \u0026#34;UA-XXXXXXXX-XX\u0026#34; # and disqus too. disqusShortName = \u0026#34;yourdisqusshortname\u0026#34; [Author] name = \u0026#34;Hugo Author\u0026#34; [outputs] section = [\u0026#34;JSON\u0026#34;, \u0026#34;HTML\u0026#34;] [[params.nav]] identifier = \u0026#34;about\u0026#34; name = \u0026#34;About\u0026#34; icon = \u0026#34;fas fa-user fa-lg\u0026#34; url = \u0026#34;/about/\u0026#34; weight = 3 [[params.nav]] identifier = \u0026#34;tags\u0026#34; name = \u0026#34;Tags\u0026#34; icon = \u0026#34;fas fa-tag fa-lg\u0026#34; url = \u0026#34;tags\u0026#34; weight = 3 [[params.nav]] identifier = \u0026#34;categories\u0026#34; name = \u0026#34;Category\u0026#34; icon = \u0026#34;fas fa-folder-open fa-lg\u0026#34; url = \u0026#34;categories\u0026#34; weight = 3 [[params.nav]] identifier = \u0026#34;search\u0026#34; name = \u0026#34;Search\u0026#34; icon = \u0026#34;fas fa-search fa-lg\u0026#34; url = \u0026#34;search\u0026#34; weight = 3 [[params.nav]] identifier = \u0026#34;archives\u0026#34; name = \u0026#34;Archives\u0026#34; icon = \u0026#34;fas fa-archive fa-lg\u0026#34; url = \u0026#34;archives\u0026#34; weight = 3 [params.logo] url = \u0026#34;icon.png\u0026#34; # static/images/icon.png width = 50 height = 50 alt = \u0026#34;Logo\u0026#34; Update a few things baseurl = \u0026#34;https://sosa0sa.com/\u0026#34; title = \u0026#34; sosa0sa.com\u0026#34; paginate = 5 Put markdown files under the content directory (venv) cychong15:sosa0sa cychong$ tree -d content/ -L 2 content/ └── post ├── 2003 ├── 2004 ├── 2005 ├── 2006 ├── 2007 ├── 2008 ├── 2009 ├── 2010 ├── 2011 ├── 2012 ├── 2013 ├── 2014 ├── 2015 ├── 2016 ├── 2017 ├── 2018 ├── 2019 └── 2020 19 directories Put image files under the static files cychong15:static cychong$ tree -d -L 2 . └── images ├── 2002 ├── 2003 ├── 2004 ├── 2005 ├── 2006 ├── 2007 ├── 2008 ├── 2009 ├── 2010 ├── 2011 ├── 2012 ├── 2013 ├── 2014 ├── 2015 ├── 2016 ├── 2017 ├── 2018 ├── 2019 └── 2020 20 directories Customize theme head.html Copy themes/harbor/layouts/partials/head.htmlto layouts/partials/head.html\nAnd change the css filename to use from dark.css to main.css\n(venv) cychong15:sosa0sa cychong$ diff themes/harbor/layouts/partials/head.html layouts/partials/head.html 14c14 \u0026lt; \u0026lt;link id=\u0026#34;dark-mode-theme\u0026#34; rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{{ .Site.BaseURL }}css/dark.css\u0026#34; /\u0026gt; --- \u0026gt; \u0026lt;link id=\u0026#34;dark-mode-theme\u0026#34; rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;{{ .Site.BaseURL }}css/main.css\u0026#34; /\u0026gt; Create HTML files (venv) cychong15:sosa0sa cychong$ hugo | EN -------------------+------- Pages | 3706 Paginator pages | 1096 Non-page files | 0 Static files | 6354 Processed images | 0 Aliases | 550 Sitemaps | 1 Cleaned | 0 Total in 5964 ms (venv) cychong15:sosa0sa cychong$ tree -d -L 1 public/ public/ ├── archives ├── categories ├── css ├── fontawesome ├── fonts ├── images ├── js ├── page ├── post ├── src └── tags 11 directories (venv) cychong15:sosa0sa cychong$ du -hs public/ 1.8G\tpublic/ Setup nginx docker - To Go cychong@mini1:~$ helm repo add nginx-stable https://helm.nginx.com/stable \u0026#34;nginx-stable\u0026#34; has been added to your repositories cychong@mini1:~$ helm repo update Hang tight while we grab the latest from your chart repositories... ...Successfully got an update from the \u0026#34;nginx-stable\u0026#34; chart repository Update Complete. ⎈ Happy Helming!⎈ cychong@mini1:~/work$ helm install nginx nginx-stable/nginx-ingress NAME: nginx LAST DEPLOYED: Sun May 31 08:58:59 2020 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None NOTES: The NGINX Ingress Controller has been installed. Deploy nginx with customized values.yaml https://raw.githubusercontent.com/kubernetes/ingress-nginx/master/charts/ingress-nginx/values.yaml\n파일을 받아 필요한 내용을 수정한 후 사용\nTry with docker Copy the default nginx configuration file and change to listen 0.0.0.0 rather than 127.0.0.1\nroot@e364ef9bb706:/etc/nginx# cat conf.d/default.conf server { listen 80; server_name localhost; #charset koi8-r; #access_log /var/log/nginx/host.access.log main; location / { root /usr/share/nginx/html; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache\u0026#39;s document root # concurs with nginx\u0026#39;s one # #location ~ /\\.ht { # deny all; #} } cychong@mini1:~$ docker run --name nginx -p80:80 -v /home/cychong/work/nginx/default.conf:/etc/nginx/conf.d/default.conf:ro -v /home/cychong/Documents/hugo/:/usr/share/nginx/html -d nginx ce4d05fb3895a825ac8fee1723c3b7417c281e035b9bebeff91aa73e3749d317 cychong@mini1:~$ docker ps -a |grep nginx ce4d05fb3895 nginx \u0026#34;nginx -g \u0026#39;daemon of…\u0026#34; 35 seconds ago Up 33 seconds 0.0.0.0:80-\u0026gt;80/tcp nginx Stop the wordpress and mysql dockers cychong@mini1:~$ docker ps -a |grep wordpress 18203ecb1459 wordpress \u0026#34;docker-entrypoint.s…\u0026#34; 3 months ago Up 5 days 0.0.0.0:80-\u0026gt;80/tcp wordpress cychong@mini1:~$ docker stop wordpress wordpress cychong@mini1:~$ docker stop mysql mysql Setup Hugo docker for hosting generated Static files cychong@mini1:~$ docker pull tarampampam/hugo:latest latest: Pulling from tarampampam/hugo df20fa9351a1: Pull complete 6da297b993f4: Pull complete ec2cc2aeaf82: Pull complete Digest: sha256:878b09a81c0594482a2c8291ea587b3b4b262069b64b0af0838d50438711926c Status: Downloaded newer image for tarampampam/hugo:latest docker.io/tarampampam/hugo:latest https://github.com/matsuyoshi30/harbor https://hahafamilia.github.io/howto/hugo-staticgen/ Installation with Helm Helm chart 목록 nginx의 chart를 보려면 github.com/kubernetes 에 있는 해당 패키지의 charts 디렉토리를 확인한다 nginx configuration The most downloaded hugo docker image hugo 사용의 기본적인 절차를 간략하게 잘 요약한 글 Using git submodule for Hugo themes ","date":"2020-05-31T14:56:52+09:00","permalink":"https://cychong47.github.io/post/2020/hugo-seutp-with-git/","summary":"\u003cp\u003eWordpress 에서 hugo로 이사한 후 첫번째 시도.\nHugo theme은 harbor를 사용하고, site 호스팅 방법은 nginx docker를 사용.\n(이상하게 nginx를 helm으로 띄우는 게 간단하지 않네)\u003c/p\u003e\n\u003ch3 id=\"clone-repogistry-for-raw-blog-data\"\u003eClone repogistry for raw blog data\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong15:migration_to_hugo cychong$ git clone https://github.com/cychong47/sosa0sa.git\nCloning into \u0026#39;sosa0sa\u0026#39;...\nwarning: You appear to have cloned an empty repository.\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"setup-hugo-inside-of-the-git-repository\"\u003eSetup hugo inside of the git repository\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong15:migration_to_hugo cychong$ hugo new site sosa0sa\nError: /Users/cychong/workspace/migration_to_hugo/sosa0sa already exists and is not empty. See --force.\n\ncychong15:migration_to_hugo cychong$ hugo new site sosa0sa --force\nCongratulations! Your new Hugo site is created in /Users/cychong/workspace/migration_to_hugo/sosa0sa.\n\nJust a few more steps and you\u0026#39;re ready to go:\n\n1. Download a theme into the same-named folder.\n   Choose a theme from https://themes.gohugo.io/ or\n   create your own with the \u0026#34;hugo new theme \u0026lt;THEMENAME\u0026gt;\u0026#34; command.\n2. Perhaps you want to add some content. You can add single files\n   with \u0026#34;hugo new \u0026lt;SECTIONNAME\u0026gt;/\u0026lt;FILENAME\u0026gt;.\u0026lt;FORMAT\u0026gt;\u0026#34;.\n3. Start the built-in live server via \u0026#34;hugo server\u0026#34;.\n\nVisit https://gohugo.io/ for quickstart guide and full documentation.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eMaybe not good to \u003cstrong\u003eenforce\u003c/strong\u003e to do something.\u003c/p\u003e","title":"Migrate wordpress to hugo"},{"content":"https://devblogs.nvidia.com/building-accelerated-5g-cloudran-at-the-edge/\nMellanox ConnectX-6 Dx SmartNIC exceeds stringent industry-standard timing specifications for eCPRI-based RANs by ensuring clock accuracy of 16ns or less\n5T for 5G enables packet-based, ethernet RANs to provide precise time-stamping of packets for delivering highly accurate time references to 5G fronthaul and backhaul networks.\n5T-for-5G, or time-triggered transmission technology for telco\nhttps://news.developer.nvidia.com/new-real-time-smartnic-technology-5t-for-5g/\nReal-time transmission hardware acceleration: 5T-for-5G simplifies time synchronization and data transmission across servers, GPUs, radios, and baseband units in wireless network rollouts, making 5G rollouts easier and more efficient.\nPrecise time stamping: It supports IEEE 1588v2 PTP for precise timing synchronization.\nHighest clock accuracy: It ensures extremely precise timing accuracy within 16 ns, adhering to the stringent ITU-T G8273.2 standard.\neCPRI windowing: It supports precise transmission of eCPRI packets within the O-RAN specified timing window.\nASAP2 time-based flow engine: It allows packet time stamping and time-bound packet steering using Mellanox ASAP2.\nHighly efficient: 5T-for-5G enables more accurate time synchronization than software solutions and lower costs and power consumption than traditional FPGA-based solutions, enabling efficient CloudRAN and edge rollouts.\nNVIDIA EGX–ready: Developers can create GPU-based CloudRAN solutions with the NVIDIA Aerial SDK that use precise timing without investing in expensive and proprietary FPGA solutions.\nhttps://www.youtube.com/watch?v=rxLejojuMjM\u0026amp;feature=youtu.be\nGPUDirect Remote Direct Memory Access (RDMA) store data by eliminating unnecessary duplicates and decreasing latency. By reducing the back and forth with the CPU memory, GPUDirect saves computation cycles for memory access.\nHeader/data split functionality With cuVNF, you have the header/data split functionality that allows agile packet filtering.\nO-RAN format identification feature does faster packet flow steering based on the MAC address\ncuVNF EGX A100 edge server platform ConnectX-6 with 5T-for-5G\nLinks CUDA CUDA download and additional resources such as training, open source packages and etc https://news.developer.nvidia.com https://developer.nvidia.com/nvidia-aerial-sdk-early-access-program ","date":"2020-05-20T15:01:44+09:00","permalink":"https://cychong47.github.io/post/2020/nvidia-vran-solution/","summary":"\u003cp\u003e\u003ca href=\"https://devblogs.nvidia.com/building-accelerated-5g-cloudran-at-the-edge/\"\u003ehttps://devblogs.nvidia.com/building-accelerated-5g-cloudran-at-the-edge/\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"mellanox-connectx-6-dx-smartnic\"\u003eMellanox ConnectX-6 Dx SmartNIC\u003c/h2\u003e\n\u003cp\u003eexceeds stringent industry-standard timing specifications for eCPRI-based RANs by ensuring clock accuracy of 16ns or less\u003c/p\u003e\n\u003cp\u003e5T for 5G enables packet-based, ethernet RANs to provide precise time-stamping of packets for delivering highly accurate time references to 5G fronthaul and backhaul networks.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e5T-for-5G, or time-triggered transmission technology for telco\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"https://news.developer.nvidia.com/new-real-time-smartnic-technology-5t-for-5g/\"\u003ehttps://news.developer.nvidia.com/new-real-time-smartnic-technology-5t-for-5g/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"https://news.developer.nvidia.com/wp-content/uploads/2020/05/pasted-image-0-17-624x271.png\" alt=\"img\"\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e\u003cstrong\u003eReal-time transmission hardware acceleration\u003c/strong\u003e: 5T-for-5G simplifies time synchronization and data transmission across servers, GPUs, radios, and baseband units in wireless network rollouts, making 5G rollouts easier and more efficient.\u003c/p\u003e","title":"NVIDIA vRAN Solution"},{"content":"말썽쟁이(?) wordpress 블로그가 또 문제를 일으켰다.\n이번에도 로그인이 안되는 현상인데 지난 번과는 다른 에러 메시지가 나온다. 즉 지난 번 해결책은 소용이 없을 거라는 불길한 예감이.\n로그인 계정 자체가 없다는 이 어이없는 상황.\n그래서 지난 번에 유용하게 사용했던 phpmyadmin을 이용해서 DB 정보를 확인해봤다. (다행히 MySql, wordpress 와 함께 실행시켜놓은 phpmyadmin container가 동작하고 있어서 지난 번과 같이 8181 포트로 접속하면 된단. 다만 로그인 암호를 기억하지 못하고 있는 나 대신 Safari가 기억하고 있어서 그냥 접속했다는)\n뭔가 이상하다.\n#1812 - Tablespace is missing for table wordpress_db.wp_users.\n이게 무슨 말인가 하고 구글링을 해 보니 DB 파일에 문제가 생겨서 그렇다고. 이걸 해결하려면 이전에 백업한 DB 파일이 있어야 한다는 청천벽력 같은 말. 거기에 전에 DB를 모두 restore하는 방식으로 해결했다는 글이 보인다. ERROR 1812 (HY000): Tablespace is missing for table in MYSQL\nSolution We must have backup for restore, We have taken on Sunday, deletion of TEST2 happen on Monday.\n음.. 이러면 백업된 시점 이후에 변경된 내용은 모두 잃어버린다는 것 같은데\n다른 글에서는 일단 db 파일에 문제가 생긴 경우(파일이 없거나, 파일 퍼미션이 정상이 아닌에도 동일한 문제가 발생할 수 있다고. How to fix error “1812 Tablespace is missing for table XXXX”\nTable files have the wrong ownership/permissions The table file is misplaced The data file is corrupted or deleted 만일 idb 파일에 문제가 생긴 경우라면 문제가 생긴 파일만 백업 본으로 교체하거나 파일 권한을 수정하면 간단하게 해결이 될 거고, SQL DB 전체에 대한 거라면 역시나 기존 DB를 지우고 백업된 걸로 복원을 해야 한다고\nIf the backups are stored as .ibd files, we copy the table files into the database folder and set the right permissions. Everything usually works fine from that point. On the other hand, if it’s in the SQL format, we drop the current database, and restore the full database from backup. This method will create fresh entries in the System tables, and build proper linkages.\n그나마 이건 백업 본이 있을 때나 하는 이야기고\u0026hellip;\n그래서 mysql container에 접속해서 확인해 보니 과연 위에서 에러난 table 파일만 찾을 수 없다. 아무리 봐도 wordpress 버전 업그레이드를 하면서 일부 파일에 문제가 생긴 듯\u0026hellip;\ncychong@mini1:~$ sudo docker ps -a |grep mysql [sudo] password for cychong: faafa54b9184 mysql:8 \u0026#34;docker-entrypoint.s…\u0026#34; 2 months ago Up 2 days 3306/tcp, 33060/tcp mysql cychong@mini1:~$ sudo docker exec -it faafa54b9184 /bin/bash root@faafa54b9184:/# find . -name *.ibd find: \u0026#39;./proc/1/map_files\u0026#39;: Permission denied ./var/lib/mysql/wordpress_db/wp_options.ibd ./var/lib/mysql/wordpress_db/wp_postmeta.ibd ./var/lib/mysql/wordpress_db/wp_posts.ibd ./var/lib/mysql/wordpress_db/wp_usermeta.ibd ./var/lib/mysql/wordpress_db/wp_comments.ibd ./var/lib/mysql/wordpress_db/wp_commentmeta.ibd ./var/lib/mysql/wordpress_db/wp_terms.ibd ./var/lib/mysql/wordpress_db/wp_term_taxonomy.ibd ./var/lib/mysql/wordpress_db/wp_term_relationships.ibd ./var/lib/mysql/mysql.ibd ./var/lib/mysql/sys/sys_config.ibd 하지만 내 문제는 백업된 SQL이 파일이 없다는 거. 가진 건 XML 형태 뿐. 이걸로 어떻게 고칠 수 없을까?\n일단 wp_users 외 다른 table에는 문제가 없는 각 table 별로 확인을 해보니(phpmyadmin에서 각 table별로 클릭해 보면 확인 가능) termmeta와 links도 같은 에러가 있다. 첩첩산중이네.\n아무래도 인터넷에 많이 있는 해결책으로는 내 문제를 해결할 수 없는 듯하다. 직접 문제를 해결해야 할 듯.\nTable을 새로 만들어 보자 기존에 백업된 걸로 복원하는 방식을 사용할 수 없다면 새로 만드는 수 밖에. 다행히 posts table이 아니고 일단 로그인 문제는 users table만 관계된 듯 하니 문제가 된 table을 직접 만들어 보기로 했다. 구글링을 해서 users table의 구조(schema)를 찾아 보니 2019년 3월 29일에 작성된 이 글 이 있는데 문제는 1년 전에 작성된 이 글에 있는 내용이 최신 구조와 같은 지 판단하기 어렵다는. 그래서 추가로 확인해 보니 앞 글 보다 더 최근에 작성된 다른 글 에서는 조금 다른 형태라고 설명이 되어 있다. 예를 들면 user_pass가 64가 아니라 255비트로 늘어난 걸로. 아무래도 직접 wordpress 코드를 보고 파악하는게 낫겠다.(나중에 깨달았지만, 내가 사용하는 wordpress가 최신 버전이 아닌데 최신 코드를 보고 작업하는 게 맞는 거 였을까 싶은\u0026hellip;)\nwordpress.org에서 wordpress 소스 코드를 받아 보기로.\ncychong15:workspace cychong$ wget https://wordpress.org/latest.tar.gz wp-admin/includes/schema.php파일에 DB table을 만드는 코드가 있는 듯 한데 다음과 같이 정의되어 있다.\n// Single site users table. The multisite flavor of the users table is handled below. $users_single_table = \u0026#34;CREATE TABLE $wpdb-\u0026gt;users ( ID bigint(20) unsigned NOT NULL auto_increment, user_login varchar(60) NOT NULL default \u0026#39;\u0026#39;, user_pass varchar(255) NOT NULL default \u0026#39;\u0026#39;, user_nicename varchar(50) NOT NULL default \u0026#39;\u0026#39;, user_email varchar(100) NOT NULL default \u0026#39;\u0026#39;, user_url varchar(100) NOT NULL default \u0026#39;\u0026#39;, user_registered datetime NOT NULL default \u0026#39;0000-00-00 00:00:00\u0026#39;, user_activation_key varchar(255) NOT NULL default \u0026#39;\u0026#39;, user_status int(11) NOT NULL default \u0026#39;0\u0026#39;, display_name varchar(250) NOT NULL default \u0026#39;\u0026#39;, PRIMARY KEY (ID), KEY user_login_key (user_login), KEY user_nicename (user_nicename), KEY user_email (user_email) ) $charset_collate;\\n\u0026#34;; (이것도 Single site인 경우와 Multi site 인 경우가 다른 듯 한데, 일단 난 single site인 걸로)\n이제 구조를 알았으니 phpmyadmin을 이용해서 직접 DB에 users table을 추가하기로\n고장난 집부터 부수기 일단 문제가 된 users table을 삭제하고, 새로 만들기로\n그 다음 insert 메뉴를 통해 새로 users table을 추가해 본다.\n위 Schema에 있는 대로 각 항목별 필드 이름, 타입(int, varchar or datetime) 등을 고르고, varchar 타입인 경우 길이 지정하고. user_registered 항목의 default 값이 0000-00-00 00:00:00으로 되어 있는데 이렇게 하면 에러가 난다.\n구글링해보니 mysql 버전(설정?)에 따라 허용하지 않는 경우가 있다고. 내 경우는 허용하지 않는 상황인 듯. 그래서 그냥 1970-01-01로 변경\n참고로 오른쪽 아래 있는 \u0026ldquo;Preview SQL\u0026rdquo; 을 클릭하면 실제로 수행될 SQL 명령을 볼 수 있다. 이걸 통해 위 php 코드에 있는 SQL 유사한 명령처럼 나오는 지 비교하면 편하다(예를 들면 not null 이나 auto_increment 등은 옵션이 눈에 띄지 않는데 각각 NULL, A.I 선택 버튼을 클릭한 후 SQL 명령을 확인해서 옵션을 제대로 골랐는 지 파악할 수 있다)\n이제 명시적으로 정의해야 하는 필드 들은 모두 추가하고, ID를 primary key로 지정하는 건 알겠는데 나머지 3개 항목 user_login_key, user_nicename, user_email을 KEY형태로 하는 건 어떻게 해야 하는 지 모르겠다. 각 항목별 옵션에 primary key 외에 그냥 key로 지정하는 건 없는 듯한데\u0026hellip; 그래서 추가 검색해 보니 역시나 다른 옵션으로 보였던 INDEX를 사용하는 거 였다.\n나머지 항목들도 모두 추가\nusers table을 생성했으니 이제 실제 사용자 정보를 추가해 본다.\n자 이제 제대로 복구했는지 wordpress admin 페이지에 접속해 보면\n드.디.어.\nDB 망가진 지 몇 달만에 복구하는데 성공했다. 아직 다른 2개 table도 남아있긴 하지만 일단 로그인이 되니 좀 낫겠지.\n백업!\n백업! 백업!\n중요하다. 중요해.\n","date":"2020-05-08T23:36:45+09:00","permalink":"https://cychong47.github.io/post/2020/recover-broken-users-table/","summary":"\u003cp\u003e말썽쟁이(?) wordpress 블로그가 또 문제를 일으켰다.\u003cbr\u003e\n이번에도 로그인이 안되는 현상인데 \u003ca href=\"/post/wordpress-admin-login-fail/\"\u003e지난 번\u003c/a\u003e과는 다른 에러 메시지가 나온다. 즉 지난 번 해결책은 소용이 없을 거라는 불길한 예감이.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2020/05/wordpress_login_error_account_is_missing.png\" alt=\"wordpress_login_error_account_is_missing\"\u003e\u003c/p\u003e\n\u003cp\u003e로그인 계정 자체가 없다는 이 어이없는 상황.\u003c/p\u003e\n\u003cp\u003e그래서 지난 번에 유용하게 사용했던 phpmyadmin을 이용해서 DB 정보를 확인해봤다.\n(다행히 MySql, wordpress 와 함께 실행시켜놓은 phpmyadmin container가 동작하고 있어서 지난 번과 같이 \u003ccode\u003e8181\u003c/code\u003e 포트로 접속하면 된단. 다만 로그인 암호를 기억하지 못하고 있는 나 대신 Safari가 기억하고 있어서 그냥 접속했다는)\u003c/p\u003e","title":"WordPress 로그인 불가 문제 해결"},{"content":"내게 권한이 있다면\n이런 글을 쓴 적이 있었네. 우연히 ghost 블로그에 이전 글들이 2개씩 존재하는 걸 발견해서 중복된 글을 지우는 과정에서 이런 글을 썼다는 걸 알아냈다. 중복 글은 아마도 ghost 버전을 2에서 3으로 올리는 과정이나 복구하는 과정에서 발생한 듯 한데. 그 덕에 각 글들이 실제로 작성된 날짜정보는 사라지고 가장 오래된 글도 2년 전(2018) 정도로 나오는데 실제 내용은 2014년 글도 있다는.\n덕분에 이 글을 언제 썼는 지, 그 당시 어떤 일을 하고 있었는 지는 정확하지 않지만 글을 읽다 보니 어렴풋이 왜 이런 생각을 그때 했는 지 알겠다 싶다. 그간 많은 일이 있었고, 글의 제목에 있는 대로 \u0026lsquo;권한\u0026rsquo;을 갖거나 위임받아 운영한 적이 있었으니 그 결과를 하나씩 따져본 후 각 항목별로 O, X를 구분해 봤다. 관련 업무를 하지 않아 실행(혹은 시도)해 보지 못한 항목은 -로 구분했다. 적어도 정보를 excel로 관리하던 행태는 피한 듯 하다. 나름 자부심을 가지고 있는 건(아무도 알아주지 않지만) 십 수년 전에 시도했던 것과 같이 회사에 wiki를 제대로 활용해서 업무를 진행한 덕에 엑셀 사용을 최소화하고, 관련된 사람들이 쉽게 정보를 공유하고, 찾을 수 있도록 wiki를 기반으로 일을 진행했다. 덕분에 검색이 가능한 CMS 환경을 갖췄지만, 한 가지 아쉬운 점은 페이지 수가 많다보니 실제로 가치가 큰 정보를 찾는 게 쉽지 않았다는 점이다. tag(confluence wiki에서는 label이라고 부르는) 사용을 잘 활용하면 되었을 텐데 이 부분에 대해서는 아쉬움이 남는다.\n그래도 생각보다 O로 생각되는 항목이 많으니 나름 재밌는, 나름 의미있는 일을 했다는 생각이 드네.\n[O] 우선 할 것은 모든 과제의 진행상황을 투명하게 볼 수 있는 시스템만들기\n[O] 엑셀로 관리하고 있는 정보에 대해 최적의 대안을 찾아 엑셀 사용을 최소화 하기\n[O] 파일 서버에 단순히 모으고 있는 자료를 DB화. 적어도 하나의 과제에 관련된 문서를 한눈에 볼 수 있게 하고, 검색이 가능하도록 변경\n[O] File based DB 시스템 대체 방안. 필요하다면 기존 요구사항만 기존 담당자들로부터 받고, 새로운 생각을 가진 사람들에게 대안을 제안하도록\n[-] Code Coverage 100% 같은 비효율적인 업무 없애기\n[O] Inventory 정보 투명화. 어떤 실험 자산을 어떻게 사용하고 있는지, 부서간 공유.\n[O] 분야별 정보 공유할 수 있는 공간 만들고, 정보 공유 독려. 무슨무슨 TF니 WG를 만들기 보다 스스로 정보를 공유하도록 만들기(보다 구체적인 방안 필요)\n메일을 통한 정보 공유 최소화. 메일과 같은 휘발성 매체가 아닌(적어도 사내에서는 휘발성이 높음) CMS에 기록해서 이력 관리가 쉽도록\n[O] 모든 공유 정보는 CMS에 기록(위키 등)\n[-] Unit Test 강화. 불필요한 코드 삭제 유도\n[-] 비현실적이고, 불합리한 무리한 패키지 개발 계획 조정. 1년에 최대 2개만 개발\n[-] SIT단계 이후 진행되는 pre-SIT 같은 바보같은 업무 없앰\n[-] TC 개수 관리 같은 의미없는 숫자기반 관리 지양\n[O] 아침 8시 회의 같은 어이없는 회의 금지\n[-] SE Lab 강화.\n[-] 모 부서와의 전쟁. 미개하고, 무례하고, 개념없는 놈들.\n[O] 비효율적인 문서 작성 기반의 업무 보고 대안 강구.\n[?] 부서 혹은 부문 별 wish list 관리. 각 부서는 제기된 요청사항에 대해 검토 후 선정된 결과에 대해 기능 구현/개선. 단 선정 내용에 대해 필히 공유(그렇지 않으면 의미 있는 것보다는 쉬운 것을 선정할 수 있으므로)\n","date":"2020-05-08T14:03:04+09:00","permalink":"https://cychong47.github.io/post/2020/if-i-have-authority-5-years-later/","summary":"\u003cp\u003e\u003ca href=\"/post/naege-gweonhani-issdamyeon/\"\u003e내게 권한이 있다면\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e이런 글을 쓴 적이 있었네. 우연히 ghost 블로그에 이전 글들이 2개씩 존재하는 걸 발견해서 중복된 글을 지우는 과정에서 이런 글을 썼다는 걸 알아냈다. 중복 글은 아마도 ghost 버전을 2에서 3으로 올리는 과정이나 복구하는 과정에서 발생한 듯 한데. 그 덕에 각 글들이 실제로 작성된 날짜정보는 사라지고 가장 오래된 글도 2년 전(2018) 정도로 나오는데 실제 내용은 2014년 글도 있다는.\u003c/p\u003e\n\u003cp\u003e덕분에 이 글을 언제 썼는 지, 그 당시 어떤 일을 하고 있었는 지는 정확하지 않지만 글을 읽다 보니 어렴풋이 왜 이런 생각을 그때 했는 지 알겠다 싶다. 그간 많은 일이 있었고, 글의 제목에 있는 대로 \u0026lsquo;권한\u0026rsquo;을 갖거나 위임받아 운영한 적이 있었으니 그 결과를 하나씩 따져본 후 각 항목별로 \u003ccode\u003eO\u003c/code\u003e, \u003ccode\u003eX\u003c/code\u003e를 구분해 봤다. 관련 업무를 하지 않아 실행(혹은 시도)해 보지 못한 항목은 \u003ccode\u003e-\u003c/code\u003e로 구분했다.\n적어도 정보를 excel로 관리하던 행태는 피한 듯 하다. 나름 자부심을 가지고 있는 건(아무도 알아주지 않지만) 십 수년 전에 시도했던 것과 같이 회사에 wiki를 제대로 활용해서 업무를 진행한 덕에 엑셀 사용을 최소화하고, 관련된 사람들이 쉽게 정보를 공유하고, 찾을 수 있도록 wiki를 기반으로 일을 진행했다.  덕분에 검색이 가능한 CMS 환경을 갖췄지만, 한 가지 아쉬운 점은 페이지 수가 많다보니 실제로 가치가 큰 정보를 찾는 게 쉽지 않았다는 점이다. tag(confluence wiki에서는 label이라고 부르는) 사용을 잘 활용하면 되었을 텐데 이 부분에 대해서는 아쉬움이 남는다.\u003c/p\u003e","title":"내게 권한이 있다면 - 그 이후"},{"content":"지난 2016년 난생 처음으로 자발적으로 부서를 옮긴 후에 경험한 것들.\n그 전의 십수년간에는 해보지 않은 많은 새로운 경험들을 가질 수 있었다. 주변의 도움 덕에. 특히 날 믿어주는 지인 덕에 이런 새로운 경험을 해 봐서 재밌었다.\n팀으로 일하기 Agile practice 해보기. Scrum meeting, Daily meeting, 회고 등 재밌게 일하기 의미를 가지며 일하기 의미있는 TF하기 Leading(TF, 파트) 외국 연구소, 사업자 직접 만나서 대화하기 정보를 입수해 가공해서 잘 전달하기 정보를 집중해서 관리하는 사이트 구축하기 사람들 독려하기 주간 리포트를 통해 업무 진행 공유하기 정치 맛 보기(이건 좀 힘들었네) 새로운 분야의 일 - Bearer Processing, OAM, MAC, PHY, 가상화 인프라 구축 - OpenStack, container 상용 솔류션 도입 - DB, Container platform 신기술을 컴파일해서 우리 것에 적용방안 찾기 (가상화 TF) 전화 영어로 일하기 밤 늦은 시간에 사업자마 해외 연구소와 콜하기 전략적으로 판단하기 (무조건 아는 걸 다 이야기하면 안되는) 팀 빌드의 중요성 옆에서 보기 다른 사람 평가하기 회사 평가 시스템 이해(TO는 생각보다 많이 적다, 연봉 캡, 동기부여의 수단은 별로 없다) 아는 것과 남들 특히 다른 생각을 가진 사람들을 설득하는 것이 어떤 지 배우기 영어로 업무하기. 외국 업체나 해외연구소 혹은 외국 인력과 함께 일하기 해외 연구소와 함께 일하기. Wiki등을 이용하여 협업하고, 주간 콜을 통해 업무 상황 공유. 사내 정치 맛 보기 그 전의 십수년간 경험한 것보다 훨씬 많은, 다양한 일들을 짧은 시간 동안 경험한 듯. 덕분에 새로운 사람들도 많이 만날 수 있었고, 이전과 다른 입장에서 일할 수 있는 기회도 가졌다. 그 전에는 SW architecture 측면에서 가장 아래쪽에 가까운 분야를 했다면, 그것보다는 보다 높은 layer의 업무도 해보고, 극단적으로 사업자와 대화를 하는 상당히 높은 게층의 일(계급이 아니라\u0026hellip;)도 해보고, 무형의 결과물을 만들어내는 일도 잠시나마 해 봤다.\n그리고 앞으로는\u0026hellip;?\n","date":"2020-05-07T14:34:55+09:00","permalink":"https://cychong47.github.io/post/2020/new-things-in-last-4-years/","summary":"\u003cp\u003e지난 2016년 난생 처음으로 자발적으로 부서를 옮긴 후에 경험한 것들.\u003cbr\u003e\n그 전의 십수년간에는 해보지 않은 많은 새로운 경험들을 가질 수 있었다. 주변의 도움 덕에. 특히 날 믿어주는 지인 덕에 이런 새로운 경험을 해 봐서 재밌었다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e팀으로 일하기\u003c/li\u003e\n\u003cli\u003eAgile practice 해보기. Scrum meeting, Daily meeting, 회고 등\u003c/li\u003e\n\u003cli\u003e재밌게 일하기\u003c/li\u003e\n\u003cli\u003e의미를 가지며 일하기\u003c/li\u003e\n\u003cli\u003e의미있는 TF하기\u003c/li\u003e\n\u003cli\u003eLeading(TF, 파트)\u003c/li\u003e\n\u003cli\u003e외국 연구소, 사업자 직접 만나서 대화하기\u003c/li\u003e\n\u003cli\u003e정보를 입수해 가공해서 잘 전달하기\u003c/li\u003e\n\u003cli\u003e정보를 집중해서 관리하는 사이트 구축하기\u003c/li\u003e\n\u003cli\u003e사람들 독려하기\u003c/li\u003e\n\u003cli\u003e주간 리포트를 통해 업무 진행 공유하기\u003c/li\u003e\n\u003cli\u003e정치 맛 보기(이건 좀 힘들었네)\u003c/li\u003e\n\u003cli\u003e새로운 분야의 일 - Bearer Processing, OAM, MAC, PHY,\u003c/li\u003e\n\u003cli\u003e가상화 인프라 구축 - OpenStack, container\u003c/li\u003e\n\u003cli\u003e상용 솔류션 도입 - DB, Container platform\u003c/li\u003e\n\u003cli\u003e신기술을 컴파일해서 우리 것에 적용방안 찾기 (가상화 TF)\u003c/li\u003e\n\u003cli\u003e전화 영어로 일하기\u003c/li\u003e\n\u003cli\u003e밤 늦은 시간에 사업자마 해외 연구소와 콜하기\u003c/li\u003e\n\u003cli\u003e전략적으로 판단하기 (무조건 아는 걸 다 이야기하면 안되는)\u003c/li\u003e\n\u003cli\u003e팀 빌드의 중요성 옆에서 보기\u003c/li\u003e\n\u003cli\u003e다른 사람 평가하기\u003c/li\u003e\n\u003cli\u003e회사 평가 시스템 이해(TO는 생각보다 많이 적다, 연봉 캡, 동기부여의 수단은 별로 없다)\u003c/li\u003e\n\u003cli\u003e아는 것과 남들 특히 다른 생각을 가진 사람들을 설득하는 것이 어떤 지 배우기\u003c/li\u003e\n\u003cli\u003e영어로 업무하기. 외국 업체나 해외연구소 혹은 외국 인력과 함께 일하기\u003c/li\u003e\n\u003cli\u003e해외 연구소와 함께 일하기. Wiki등을 이용하여 협업하고, 주간 콜을 통해 업무 상황 공유.\u003c/li\u003e\n\u003cli\u003e사내 정치 맛 보기\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e그 전의 십수년간 경험한 것보다 훨씬 많은, 다양한 일들을 짧은 시간 동안 경험한 듯. 덕분에 새로운 사람들도 많이 만날 수 있었고, 이전과 다른 입장에서 일할 수 있는 기회도 가졌다. 그 전에는 SW architecture 측면에서 가장 아래쪽에 가까운 분야를 했다면, 그것보다는 보다 높은 layer의 업무도 해보고, 극단적으로 사업자와 대화를 하는 상당히 높은 게층의 일(계급이 아니라\u0026hellip;)도 해보고, 무형의 결과물을 만들어내는 일도 잠시나마 해 봤다.\u003c/p\u003e","title":"새로운 경험 들"},{"content":"This ghost-backup container will backup in every 3am\nStart ghost-backup container cychong@mini1:~/Documents/docker-daily-backup$ docker run --name ghost-backup -d -v /home/cychong/Documents/docker-daily-backup:/backups --volumes-from 388c84247267 bennetimo/ghost-backup ea33f148122bbe0d90a502bfd884e4c988e9f8837921f725ca7317afff7fa149 Instant backup cychong@mini1:~/Documents/docker-daily-backup$ ls -al total 8 drwxrwxr-x 2 cychong cychong 4096 Mar 3 23:25 . drwxr-xr-x 5 cychong cychong 4096 Mar 3 23:25 .. cychong@mini1:~/Documents/docker-daily-backup$ docker exec ghost-backup backup Tue Mar 3 14:27:27 UTC 2020: Checking if a mysql container exists on the network at mysql:3306 Tue Mar 3 14:27:33 UTC 2020: ...no mysql container exists on the network. Using sqlite mode Tue Mar 3 14:27:33 UTC 2020: creating backup: 20200303-1427... Tue Mar 3 14:27:33 UTC 2020: backing up ghost database Tue Mar 3 14:27:33 UTC 2020: creating ghost db archive (sqlite)... Tue Mar 3 14:27:33 UTC 2020: ...completed: /backups/backup-db_20200303-1427.gz Tue Mar 3 14:27:33 UTC 2020: backing up ghost content files Tue Mar 3 14:27:33 UTC 2020: creating ghost content files archive... Tue Mar 3 14:27:40 UTC 2020: ...completed: /backups/backup-ghost_20200303-1427.tar.gz Tue Mar 3 14:27:40 UTC 2020: backing up ghost json file Tue Mar 3 14:27:40 UTC 2020: ...checking if a ghost container exists on the network at ghost:2368 Tue Mar 3 14:27:41 UTC 2020: ...no ghost service found on the network Tue Mar 3 14:27:41 UTC 2020: ...skipping: Your ghost service was not found on the network. Configure GHOST_SERVICE_NAME and GHOST_SERVICE_PORT Tue Mar 3 14:27:41 UTC 2020: purging old backups (set to retain the most recent 30) Tue Mar 3 14:27:41 UTC 2020: ...found 1 database files (purging 0) Tue Mar 3 14:27:41 UTC 2020: ...found 1 ghost content archive files (purging 0) Tue Mar 3 14:27:41 UTC 2020: ...found 0 ghost json files (purging 0) Tue Mar 3 14:27:41 UTC 2020: completed backup to /backups Check backup output cychong@mini1:~/Documents/docker-daily-backup$ ls -al total 67236 drwxrwxr-x 2 cychong cychong 4096 Mar 3 23:27 . drwxr-xr-x 5 cychong cychong 4096 Mar 3 23:25 .. -rw-r--r-- 1 root root 1829326 Mar 3 23:27 backup-db_20200303-1427.gz -rw-r--r-- 1 root root 67004766 Mar 3 23:27 backup-ghost_20200303-1427.tar.gz reference https://hub.docker.com/r/bennetimo/ghost-backup/?ref=login ","date":"2020-03-03T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/2020-03-03-backup-ghost-database-periodically/","summary":"\u003cp\u003eThis ghost-backup container will backup in every 3am\u003c/p\u003e\n\u003ch1 id=\"start-ghost-backup-container\"\u003eStart ghost-backup container\u003c/h1\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/Documents/docker-daily-backup$ docker run --name ghost-backup -d -v /home/cychong/Documents/docker-daily-backup:/backups --volumes-from 388c84247267 bennetimo/ghost-backup\nea33f148122bbe0d90a502bfd884e4c988e9f8837921f725ca7317afff7fa149\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"instant-backup\"\u003eInstant backup\u003c/h1\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/Documents/docker-daily-backup$ ls -al\ntotal 8\ndrwxrwxr-x 2 cychong cychong 4096 Mar  3 23:25 .\ndrwxr-xr-x 5 cychong cychong 4096 Mar  3 23:25 ..\ncychong@mini1:~/Documents/docker-daily-backup$ docker exec ghost-backup backup\nTue Mar  3 14:27:27 UTC 2020: Checking if a mysql container exists on the network at mysql:3306\nTue Mar  3 14:27:33 UTC 2020:  ...no mysql container exists on the network. Using sqlite mode\nTue Mar  3 14:27:33 UTC 2020: creating backup: 20200303-1427...\nTue Mar  3 14:27:33 UTC 2020: backing up ghost database\nTue Mar  3 14:27:33 UTC 2020:  creating ghost db archive (sqlite)...\nTue Mar  3 14:27:33 UTC 2020:  ...completed: /backups/backup-db_20200303-1427.gz\nTue Mar  3 14:27:33 UTC 2020: backing up ghost content files\nTue Mar  3 14:27:33 UTC 2020:  creating ghost content files archive...\nTue Mar  3 14:27:40 UTC 2020:  ...completed: /backups/backup-ghost_20200303-1427.tar.gz\nTue Mar  3 14:27:40 UTC 2020: backing up ghost json file\nTue Mar  3 14:27:40 UTC 2020:  ...checking if a ghost container exists on the network at ghost:2368\nTue Mar  3 14:27:41 UTC 2020:  ...no ghost service found on the network\nTue Mar  3 14:27:41 UTC 2020:  ...skipping: Your ghost service was not found on the network. Configure GHOST_SERVICE_NAME and GHOST_SERVICE_PORT\nTue Mar  3 14:27:41 UTC 2020: purging old backups (set to retain the most recent 30)\nTue Mar  3 14:27:41 UTC 2020:  ...found 1 database files (purging 0)\nTue Mar  3 14:27:41 UTC 2020:  ...found 1 ghost content archive files (purging 0)\nTue Mar  3 14:27:41 UTC 2020:  ...found 0 ghost json files (purging 0)\nTue Mar  3 14:27:41 UTC 2020: completed backup to /backups\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"check-backup-output\"\u003eCheck backup output\u003c/h1\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/Documents/docker-daily-backup$ ls -al\ntotal 67236\ndrwxrwxr-x 2 cychong cychong     4096 Mar  3 23:27 .\ndrwxr-xr-x 5 cychong cychong     4096 Mar  3 23:25 ..\n-rw-r--r-- 1 root    root     1829326 Mar  3 23:27 backup-db_20200303-1427.gz\n-rw-r--r-- 1 root    root    67004766 Mar  3 23:27 backup-ghost_20200303-1427.tar.gz\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"reference\"\u003ereference\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://hub.docker.com/r/bennetimo/ghost-backup/?ref=login\"\u003ehttps://hub.docker.com/r/bennetimo/ghost-backup/?ref=login\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Backup Ghost Database Periodically"},{"content":"preparation cychong@mini1:~$ sudo apt update [sudo] password for cychong: Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease Get:2 http://dl.google.com/linux/chrome/deb stable Release [943 B] Get:3 http://dl.google.com/linux/chrome/deb stable Release.gpg [819 B] ... Get the lastest version cychong@mini1:~$ sudo apt-cache policy kubeadm kubeadm: Installed: 1.16.1-00 Candidate: 1.17.2-00 Version table: 1.17.2-00 500 500 http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages 1.17.1-00 500 500 http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages 1.17.0-00 500 500 http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages ... cychong@mini1:~$ apt-cache madison kubeadm kubeadm | 1.17.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.17.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.17.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.16.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.16.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.16.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.16.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.16.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.16.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.16.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.15.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.15.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.15.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.15.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.15.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.15.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.15.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.15.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.15.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.15.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.14.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.14.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.14.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.14.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.14.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.14.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.14.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.14.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.14.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.14.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.14.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.13.12-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.13.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.13.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.13.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.13.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.13.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.13.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.13.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.13.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.13.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.13.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.13.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.13.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.12.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.12.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.12.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.12.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.12.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.12.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.12.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.12.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.12.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.12.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.12.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.11.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.11.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.11.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.11.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.11.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.11.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.11.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.11.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.11.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.11.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.11.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.10.13-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.10.12-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.10.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.10.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.10.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.10.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.10.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.10.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.10.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.10.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.10.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.10.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.10.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.10.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.9.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.9.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.9.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.9.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.9.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.9.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.9.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.9.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.9.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.9.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.9.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.9.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.15-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.14-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.13-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.12-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.1-01 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.0-01 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.8.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.16-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.15-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.14-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.3-01 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.7.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.6.13-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.6.12-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.6.11-01 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.6.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.6.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.6.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.6.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.6.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.6.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.6.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.6.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.6.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.6.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages kubeadm | 1.5.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages cychong@mini1:~$ sudo apt-mark unhold kubeadm \u0026amp;\u0026amp; sudo apt-get install -y kubeadm=1.17.2-00 \u0026amp;\u0026amp; sudo apt-mark hold kubeadm Canceled hold on kubeadm. Reading package lists... Done Building dependency tree Reading state information... Done The following packages will be upgraded: kubeadm 1 upgraded, 0 newly installed, 0 to remove and 46 not upgraded. Need to get 8061 kB of archives. After this operation, 4907 kB disk space will be freed. Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.17.2-00 [8061 kB] Fetched 8061 kB in 3s (3164 kB/s) (Reading database ... 248932 files and directories currently installed.) Preparing to unpack .../kubeadm_1.17.2-00_amd64.deb ... Unpacking kubeadm (1.17.2-00) over (1.16.1-00) ... Setting up kubeadm (1.17.2-00) ... kubeadm set on hold. cychong@mini1:~$ sudo apt-get update \u0026amp;\u0026amp; apt-get install -y --allow-change-held-packages kubeadm=1.17.2-00 Ign:2 http://dl.google.com/linux/chrome/deb stable InRelease Hit:3 https://download.docker.com/linux/ubuntu bionic InRelease Hit:4 http://dl.google.com/linux/chrome/deb stable Release Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Hit:8 http://ppa.launchpad.net/x2go/stable/ubuntu bionic InRelease Hit:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease Hit:10 http://archive.ubuntu.com/ubuntu bionic-security InRelease Reading package lists... Done E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied) E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root? cychong@mini1:~$ sudo apt-get install -y --allow-change-held-packages kubeadm=1.17.2-00 Reading package lists... Done Building dependency tree Reading state information... Done kubeadm is already the newest version (1.17.2-00). 0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded. cychong@mini1:~$ kubeadm version kubeadm version: \u0026amp;version.Info{Major:\u0026#34;1\u0026#34;, Minor:\u0026#34;17\u0026#34;, GitVersion:\u0026#34;v1.17.2\u0026#34;, GitCommit:\u0026#34;59603c6e503c87169aea6106f57b9f242f64df89\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;, BuildDate:\u0026#34;2020-01-18T23:27:49Z\u0026#34;, GoVersion:\u0026#34;go1.13.5\u0026#34;, Compiler:\u0026#34;gc\u0026#34;, Platform:\u0026#34;linux/amd64\u0026#34;} cychong@mini1:~$ sudo kubeadm upgrade plan [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39; [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade] Fetching available versions to upgrade to [upgrade/versions] Cluster version: v1.16.1 [upgrade/versions] kubeadm version: v1.17.2 [upgrade/versions] Latest stable version: v1.17.2 [upgrade/versions] Latest version in the v1.16 series: v1.16.6 Components that must be upgraded manually after you have upgraded the control plane with \u0026#39;kubeadm upgrade apply\u0026#39;: COMPONENT CURRENT AVAILABLE Kubelet 1 x v1.16.1 v1.16.6 Upgrade to the latest version in the v1.16 series: COMPONENT CURRENT AVAILABLE API Server v1.16.1 v1.16.6 Controller Manager v1.16.1 v1.16.6 Scheduler v1.16.1 v1.16.6 Kube Proxy v1.16.1 v1.16.6 CoreDNS 1.6.2 1.6.5 Etcd 3.3.15 3.3.17-0 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.16.6 _____________________________________________________________________ Components that must be upgraded manually after you have upgraded the control plane with \u0026#39;kubeadm upgrade apply\u0026#39;: COMPONENT CURRENT AVAILABLE Kubelet 1 x v1.16.1 v1.17.2 Upgrade to the latest stable version: COMPONENT CURRENT AVAILABLE API Server v1.16.1 v1.17.2 Controller Manager v1.16.1 v1.17.2 Scheduler v1.16.1 v1.17.2 Kube Proxy v1.16.1 v1.17.2 CoreDNS 1.6.2 1.6.5 Etcd 3.3.15 3.4.3-0 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.17.2 _____________________________________________________________________ cychong@mini1:~$ sudo kubeadm upgrade apply v1.17.2 [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39; [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade/version] You have chosen to change the cluster version to \u0026#34;v1.17.2\u0026#34; [upgrade/versions] Cluster version: v1.16.1 [upgrade/versions] kubeadm version: v1.17.2 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd] [upgrade/prepull] Prepulling image for component etcd. [upgrade/prepull] Prepulling image for component kube-apiserver. [upgrade/prepull] Prepulling image for component kube-controller-manager. [upgrade/prepull] Prepulling image for component kube-scheduler. [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd [upgrade/prepull] Prepulled image for component kube-controller-manager. [upgrade/prepull] Prepulled image for component kube-apiserver. [upgrade/prepull] Prepulled image for component kube-scheduler. [upgrade/prepull] Prepulled image for component etcd. [upgrade/prepull] Successfully prepulled the images for all the control plane components [upgrade/apply] Upgrading your Static Pod-hosted control plane to version \u0026#34;v1.17.2\u0026#34;... Static pod: kube-apiserver-mini1 hash: 66d5b6802b69fcb461e22c159ef72783 Static pod: kube-controller-manager-mini1 hash: 98ded181cb6da00c408078fe0832bddf Static pod: kube-scheduler-mini1 hash: e05eb744bc3406614b4a55dd00e7af9f [upgrade/etcd] Upgrading to TLS for etcd Static pod: etcd-mini1 hash: 9e59bd8449d154ddd6acfbbb3a74181f [upgrade/staticpods] Preparing for \u0026#34;etcd\u0026#34; upgrade [upgrade/staticpods] Renewing etcd-server certificate [upgrade/staticpods] Renewing etcd-peer certificate [upgrade/staticpods] Renewing etcd-healthcheck-client certificate [upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/etcd.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-01-30-22-21-26/etcd.yaml\u0026#34; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: etcd-mini1 hash: 9e59bd8449d154ddd6acfbbb3a74181f Static pod: etcd-mini1 hash: 9b305733637de70ef82ca5b0b18c65e1 [apiclient] Found 1 Pods for label selector component=etcd [upgrade/staticpods] Component \u0026#34;etcd\u0026#34; upgraded successfully! [upgrade/etcd] Waiting for etcd to become available [upgrade/staticpods] Writing new Static Pod manifests to \u0026#34;/etc/kubernetes/tmp/kubeadm-upgraded-manifests216455436\u0026#34; W0130 22:22:01.351368 10213 manifests.go:214] the default kube-apiserver authorization-mode is \u0026#34;Node,RBAC\u0026#34;; using \u0026#34;Node,RBAC\u0026#34; [upgrade/staticpods] Preparing for \u0026#34;kube-apiserver\u0026#34; upgrade [upgrade/staticpods] Renewing apiserver certificate [upgrade/staticpods] Renewing apiserver-kubelet-client certificate [upgrade/staticpods] Renewing front-proxy-client certificate [upgrade/staticpods] Renewing apiserver-etcd-client certificate [upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-apiserver.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-01-30-22-21-26/kube-apiserver.yaml\u0026#34; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-apiserver-mini1 hash: 66d5b6802b69fcb461e22c159ef72783 Static pod: kube-apiserver-mini1 hash: 4d9a965c0a14a45ea3d7db1e023096d4 [apiclient] Found 1 Pods for label selector component=kube-apiserver [upgrade/staticpods] Component \u0026#34;kube-apiserver\u0026#34; upgraded successfully! [upgrade/staticpods] Preparing for \u0026#34;kube-controller-manager\u0026#34; upgrade [upgrade/staticpods] Renewing controller-manager.conf certificate [upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-controller-manager.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-01-30-22-21-26/kube-controller-manager.yaml\u0026#34; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-controller-manager-mini1 hash: 98ded181cb6da00c408078fe0832bddf Static pod: kube-controller-manager-mini1 hash: 98ded181cb6da00c408078fe0832bddf Static pod: kube-controller-manager-mini1 hash: 85a33dac6d806801ba5efe4a4544194c [apiclient] Found 1 Pods for label selector component=kube-controller-manager [upgrade/staticpods] Component \u0026#34;kube-controller-manager\u0026#34; upgraded successfully! [upgrade/staticpods] Preparing for \u0026#34;kube-scheduler\u0026#34; upgrade [upgrade/staticpods] Renewing scheduler.conf certificate [upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-scheduler.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-01-30-22-21-26/kube-scheduler.yaml\u0026#34; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-scheduler-mini1 hash: e05eb744bc3406614b4a55dd00e7af9f Static pod: kube-scheduler-mini1 hash: 9c994ea62a2d8d6f1bb7498f10aa6fcf [apiclient] Found 1 Pods for label selector component=kube-scheduler [upgrade/staticpods] Component \u0026#34;kube-scheduler\u0026#34; upgraded successfully! [upload-config] Storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace [kubelet] Creating a ConfigMap \u0026#34;kubelet-config-1.17\u0026#34; in namespace kube-system with the configuration for the kubelets in the cluster [kubelet-start] Downloading configuration for the kubelet from the \u0026#34;kubelet-config-1.17\u0026#34; ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [addons]: Migrating CoreDNS Corefile [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy [upgrade/successful] SUCCESS! Your cluster was upgraded to \u0026#34;v1.17.2\u0026#34;. Enjoy! [upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven\u0026#39;t already done so. calico cychong@mini1:~$ wget https://docs.projectcalico.org/manifests/calico.yaml --2020-01-30 22:34:28-- https://docs.projectcalico.org/manifests/calico.yaml Resolving docs.projectcalico.org (docs.projectcalico.org)... 206.189.89.118, 2400:6180:0:d1::57a:6001 Connecting to docs.projectcalico.org (docs.projectcalico.org)|206.189.89.118|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 20935 (20K) [application/x-yaml] Saving to: ‘calico.yaml.2’ calico.yaml.2 100%[===========================================================================================================================================\u0026gt;] 20.44K --.-KB/s in 0.07s 2020-01-30 22:34:29 (275 KB/s) - ‘calico.yaml.2’ saved [20935/20935] 618 - name: CALICO_IPV4POOL_CIDR 619 value: \u0026#34;10.201.0.0/24\u0026#34; cychong@mini1:~$ kubectl apply -f calico.yaml configmap/calico-config unchanged customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org unchanged clusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrole.rbac.authorization.k8s.io/calico-node configured clusterrolebinding.rbac.authorization.k8s.io/calico-node unchanged daemonset.apps/calico-node configured serviceaccount/calico-node unchanged deployment.apps/calico-kube-controllers configured serviceaccount/calico-kube-controllers unchanged kubelet and kubectl cychong@mini1:~$ sudo apt-mark unhold kubelet kubectl \u0026amp;\u0026amp; sudo apt-get install -y kubelet=1.17.2-00 kubectl=1.17.2-00 \u0026amp;\u0026amp; sudo apt-mark hold kubelet kubectl kubelet was already not hold. kubectl was already not hold. Reading package lists... Done Building dependency tree Reading state information... Done The following packages will be upgraded: kubectl kubelet 2 upgraded, 0 newly installed, 0 to remove and 44 not upgraded. Need to get 27.9 MB of archives. After this operation, 14.8 MB disk space will be freed. Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubectl amd64 1.17.2-00 [8738 kB] Get:2 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubelet amd64 1.17.2-00 [19.2 MB] Fetched 27.9 MB in 6s (4994 kB/s) (Reading database ... 248932 files and directories currently installed.) Preparing to unpack .../kubectl_1.17.2-00_amd64.deb ... Unpacking kubectl (1.17.2-00) over (1.16.1-00) ... Preparing to unpack .../kubelet_1.17.2-00_amd64.deb ... Unpacking kubelet (1.17.2-00) over (1.16.1-00) ... Setting up kubelet (1.17.2-00) ... Setting up kubectl (1.17.2-00) ... kubelet set on hold. kubectl set on hold. wrap-up cychong@mini1:~$ sudo systemctl restart kubelet cychong@mini1:~$ kubectl get nodes NAME STATUS ROLES AGE VERSION mini1 Ready master 144d v1.17.2 reference https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/ ","date":"2020-01-30T00:00:00+09:00","permalink":"https://cychong47.github.io/post/2020/new-things-in-last-4-years/","summary":"\u003ch1 id=\"preparation\"\u003epreparation\u003c/h1\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ sudo apt update\n[sudo] password for cychong:\nIgn:1 http://dl.google.com/linux/chrome/deb stable InRelease\nGet:2 http://dl.google.com/linux/chrome/deb stable Release [943 B]\nGet:3 http://dl.google.com/linux/chrome/deb stable Release.gpg [819 B]\n...\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"get-the-lastest-version\"\u003eGet the lastest version\u003c/h1\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ sudo apt-cache policy kubeadm\nkubeadm:\n  Installed: 1.16.1-00\n  Candidate: 1.17.2-00\n  Version table:\n     1.17.2-00 500\n        500 http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n     1.17.1-00 500\n        500 http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n     1.17.0-00 500\n        500 http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n...\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ apt-cache madison kubeadm\n   kubeadm |  1.17.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.17.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.17.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.16.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.16.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.16.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.16.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.16.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.16.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.16.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.15.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.15.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.15.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.15.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.15.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.15.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.15.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.15.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.15.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.15.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm | 1.14.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.14.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.14.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.14.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.14.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.14.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.14.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.14.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.14.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.14.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.14.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm | 1.13.12-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm | 1.13.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm | 1.13.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.13.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.13.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.13.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.13.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.13.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.13.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.13.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.13.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.13.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.13.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm | 1.12.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.12.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.12.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.12.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.12.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.12.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.12.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.12.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.12.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.12.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.12.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm | 1.11.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.11.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.11.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.11.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.11.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.11.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.11.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.11.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.11.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.11.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.11.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm | 1.10.13-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm | 1.10.12-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm | 1.10.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm | 1.10.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.10.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.10.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.10.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.10.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.10.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.10.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.10.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.10.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.10.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.10.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.9.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.9.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.9.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.9.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.9.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.9.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.9.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.9.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.9.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.9.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.9.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.9.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.8.15-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.8.14-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.8.13-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.8.12-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.8.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.8.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.8.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.8.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.8.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.8.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.8.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.8.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.8.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.8.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.8.1-01 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.8.0-01 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.8.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.7.16-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.7.15-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.7.14-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.7.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.7.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.7.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.7.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.7.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.7.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.7.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.7.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.7.3-01 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.7.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.7.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.7.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.6.13-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.6.12-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.6.11-01 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |  1.6.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.6.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.6.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.6.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.6.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.6.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.6.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.6.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.6.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.6.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\n   kubeadm |   1.5.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages\ncychong@mini1:~$ sudo apt-mark unhold kubeadm \u0026amp;\u0026amp; sudo apt-get install -y kubeadm=1.17.2-00 \u0026amp;\u0026amp; sudo apt-mark hold kubeadm\nCanceled hold on kubeadm.\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following packages will be upgraded:\n  kubeadm\n1 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\nNeed to get 8061 kB of archives.\nAfter this operation, 4907 kB disk space will be freed.\nGet:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.17.2-00 [8061 kB]\nFetched 8061 kB in 3s (3164 kB/s)           \n(Reading database ... 248932 files and directories currently installed.)\nPreparing to unpack .../kubeadm_1.17.2-00_amd64.deb ...\nUnpacking kubeadm (1.17.2-00) over (1.16.1-00) ...\nSetting up kubeadm (1.17.2-00) ...\nkubeadm set on hold.\ncychong@mini1:~$ sudo apt-get update \u0026amp;\u0026amp; apt-get install -y --allow-change-held-packages kubeadm=1.17.2-00\nIgn:2 http://dl.google.com/linux/chrome/deb stable InRelease                                                                                            \nHit:3 https://download.docker.com/linux/ubuntu bionic InRelease                                                                                         \nHit:4 http://dl.google.com/linux/chrome/deb stable Release                                                                \nHit:5 http://archive.ubuntu.com/ubuntu bionic InRelease                                                                   \nHit:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease                                               \nHit:8 http://ppa.launchpad.net/x2go/stable/ubuntu bionic InRelease                                                                 \nHit:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease                                                                  \nHit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease                                      \nHit:10 http://archive.ubuntu.com/ubuntu bionic-security InRelease        \nReading package lists... Done                      \nE: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)\nE: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?\ncychong@mini1:~$ sudo apt-get install -y --allow-change-held-packages kubeadm=1.17.2-00\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nkubeadm is already the newest version (1.17.2-00).\n0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\ncychong@mini1:~$ kubeadm version\nkubeadm version: \u0026amp;version.Info{Major:\u0026#34;1\u0026#34;, Minor:\u0026#34;17\u0026#34;, GitVersion:\u0026#34;v1.17.2\u0026#34;, GitCommit:\u0026#34;59603c6e503c87169aea6106f57b9f242f64df89\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;, BuildDate:\u0026#34;2020-01-18T23:27:49Z\u0026#34;, GoVersion:\u0026#34;go1.13.5\u0026#34;, Compiler:\u0026#34;gc\u0026#34;, Platform:\u0026#34;linux/amd64\u0026#34;}\ncychong@mini1:~$ sudo kubeadm upgrade plan\n[upgrade/config] Making sure the configuration is correct:\n[upgrade/config] Reading configuration from the cluster...\n[upgrade/config] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39;\n[preflight] Running pre-flight checks.\n[upgrade] Making sure the cluster is healthy:\n[upgrade] Fetching available versions to upgrade to\n[upgrade/versions] Cluster version: v1.16.1\n[upgrade/versions] kubeadm version: v1.17.2\n[upgrade/versions] Latest stable version: v1.17.2\n[upgrade/versions] Latest version in the v1.16 series: v1.16.6\n\nComponents that must be upgraded manually after you have upgraded the control plane with \u0026#39;kubeadm upgrade apply\u0026#39;:\nCOMPONENT   CURRENT       AVAILABLE\nKubelet     1 x v1.16.1   v1.16.6\n\nUpgrade to the latest version in the v1.16 series:\n\nCOMPONENT            CURRENT   AVAILABLE\nAPI Server           v1.16.1   v1.16.6\nController Manager   v1.16.1   v1.16.6\nScheduler            v1.16.1   v1.16.6\nKube Proxy           v1.16.1   v1.16.6\nCoreDNS              1.6.2     1.6.5\nEtcd                 3.3.15    3.3.17-0\n\nYou can now apply the upgrade by executing the following command:\n\n\tkubeadm upgrade apply v1.16.6\n\n_____________________________________________________________________\n\nComponents that must be upgraded manually after you have upgraded the control plane with \u0026#39;kubeadm upgrade apply\u0026#39;:\nCOMPONENT   CURRENT       AVAILABLE\nKubelet     1 x v1.16.1   v1.17.2\n\nUpgrade to the latest stable version:\n\nCOMPONENT            CURRENT   AVAILABLE\nAPI Server           v1.16.1   v1.17.2\nController Manager   v1.16.1   v1.17.2\nScheduler            v1.16.1   v1.17.2\nKube Proxy           v1.16.1   v1.17.2\nCoreDNS              1.6.2     1.6.5\nEtcd                 3.3.15    3.4.3-0\n\nYou can now apply the upgrade by executing the following command:\n\n\tkubeadm upgrade apply v1.17.2\n\n_____________________________________________________________________\n\ncychong@mini1:~$ sudo kubeadm upgrade apply v1.17.2\n[upgrade/config] Making sure the configuration is correct:\n[upgrade/config] Reading configuration from the cluster...\n[upgrade/config] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39;\n[preflight] Running pre-flight checks.\n[upgrade] Making sure the cluster is healthy:\n[upgrade/version] You have chosen to change the cluster version to \u0026#34;v1.17.2\u0026#34;\n[upgrade/versions] Cluster version: v1.16.1\n[upgrade/versions] kubeadm version: v1.17.2\n[upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y\n[upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd]\n[upgrade/prepull] Prepulling image for component etcd.\n[upgrade/prepull] Prepulling image for component kube-apiserver.\n[upgrade/prepull] Prepulling image for component kube-controller-manager.\n[upgrade/prepull] Prepulling image for component kube-scheduler.\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager\n[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver\n[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd\n[upgrade/prepull] Prepulled image for component kube-controller-manager.\n[upgrade/prepull] Prepulled image for component kube-apiserver.\n[upgrade/prepull] Prepulled image for component kube-scheduler.\n[upgrade/prepull] Prepulled image for component etcd.\n[upgrade/prepull] Successfully prepulled the images for all the control plane components\n[upgrade/apply] Upgrading your Static Pod-hosted control plane to version \u0026#34;v1.17.2\u0026#34;...\nStatic pod: kube-apiserver-mini1 hash: 66d5b6802b69fcb461e22c159ef72783\nStatic pod: kube-controller-manager-mini1 hash: 98ded181cb6da00c408078fe0832bddf\nStatic pod: kube-scheduler-mini1 hash: e05eb744bc3406614b4a55dd00e7af9f\n[upgrade/etcd] Upgrading to TLS for etcd\nStatic pod: etcd-mini1 hash: 9e59bd8449d154ddd6acfbbb3a74181f\n[upgrade/staticpods] Preparing for \u0026#34;etcd\u0026#34; upgrade\n[upgrade/staticpods] Renewing etcd-server certificate\n[upgrade/staticpods] Renewing etcd-peer certificate\n[upgrade/staticpods] Renewing etcd-healthcheck-client certificate\n[upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/etcd.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-01-30-22-21-26/etcd.yaml\u0026#34;\n[upgrade/staticpods] Waiting for the kubelet to restart the component\n[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)\nStatic pod: etcd-mini1 hash: 9e59bd8449d154ddd6acfbbb3a74181f\nStatic pod: etcd-mini1 hash: 9b305733637de70ef82ca5b0b18c65e1\n[apiclient] Found 1 Pods for label selector component=etcd\n[upgrade/staticpods] Component \u0026#34;etcd\u0026#34; upgraded successfully!\n[upgrade/etcd] Waiting for etcd to become available\n[upgrade/staticpods] Writing new Static Pod manifests to \u0026#34;/etc/kubernetes/tmp/kubeadm-upgraded-manifests216455436\u0026#34;\nW0130 22:22:01.351368   10213 manifests.go:214] the default kube-apiserver authorization-mode is \u0026#34;Node,RBAC\u0026#34;; using \u0026#34;Node,RBAC\u0026#34;\n[upgrade/staticpods] Preparing for \u0026#34;kube-apiserver\u0026#34; upgrade\n[upgrade/staticpods] Renewing apiserver certificate\n[upgrade/staticpods] Renewing apiserver-kubelet-client certificate\n[upgrade/staticpods] Renewing front-proxy-client certificate\n[upgrade/staticpods] Renewing apiserver-etcd-client certificate\n[upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-apiserver.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-01-30-22-21-26/kube-apiserver.yaml\u0026#34;\n[upgrade/staticpods] Waiting for the kubelet to restart the component\n[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)\nStatic pod: kube-apiserver-mini1 hash: 66d5b6802b69fcb461e22c159ef72783\nStatic pod: kube-apiserver-mini1 hash: 4d9a965c0a14a45ea3d7db1e023096d4\n[apiclient] Found 1 Pods for label selector component=kube-apiserver\n[upgrade/staticpods] Component \u0026#34;kube-apiserver\u0026#34; upgraded successfully!\n[upgrade/staticpods] Preparing for \u0026#34;kube-controller-manager\u0026#34; upgrade\n[upgrade/staticpods] Renewing controller-manager.conf certificate\n[upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-controller-manager.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-01-30-22-21-26/kube-controller-manager.yaml\u0026#34;\n[upgrade/staticpods] Waiting for the kubelet to restart the component\n[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)\nStatic pod: kube-controller-manager-mini1 hash: 98ded181cb6da00c408078fe0832bddf\nStatic pod: kube-controller-manager-mini1 hash: 98ded181cb6da00c408078fe0832bddf\nStatic pod: kube-controller-manager-mini1 hash: 85a33dac6d806801ba5efe4a4544194c\n[apiclient] Found 1 Pods for label selector component=kube-controller-manager\n[upgrade/staticpods] Component \u0026#34;kube-controller-manager\u0026#34; upgraded successfully!\n[upgrade/staticpods] Preparing for \u0026#34;kube-scheduler\u0026#34; upgrade\n[upgrade/staticpods] Renewing scheduler.conf certificate\n[upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-scheduler.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-01-30-22-21-26/kube-scheduler.yaml\u0026#34;\n[upgrade/staticpods] Waiting for the kubelet to restart the component\n[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)\nStatic pod: kube-scheduler-mini1 hash: e05eb744bc3406614b4a55dd00e7af9f\nStatic pod: kube-scheduler-mini1 hash: 9c994ea62a2d8d6f1bb7498f10aa6fcf\n[apiclient] Found 1 Pods for label selector component=kube-scheduler\n[upgrade/staticpods] Component \u0026#34;kube-scheduler\u0026#34; upgraded successfully!\n[upload-config] Storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace\n[kubelet] Creating a ConfigMap \u0026#34;kubelet-config-1.17\u0026#34; in namespace kube-system with the configuration for the kubelets in the cluster\n[kubelet-start] Downloading configuration for the kubelet from the \u0026#34;kubelet-config-1.17\u0026#34; ConfigMap in the kube-system namespace\n[kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34;\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[addons]: Migrating CoreDNS Corefile\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\n[upgrade/successful] SUCCESS! Your cluster was upgraded to \u0026#34;v1.17.2\u0026#34;. Enjoy!\n\n[upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven\u0026#39;t already done so.\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"calico\"\u003ecalico\u003c/h1\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ wget https://docs.projectcalico.org/manifests/calico.yaml\n--2020-01-30 22:34:28--  https://docs.projectcalico.org/manifests/calico.yaml\nResolving docs.projectcalico.org (docs.projectcalico.org)... 206.189.89.118, 2400:6180:0:d1::57a:6001\nConnecting to docs.projectcalico.org (docs.projectcalico.org)|206.189.89.118|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20935 (20K) [application/x-yaml]\nSaving to: ‘calico.yaml.2’\n\ncalico.yaml.2                                               100%[===========================================================================================================================================\u0026gt;]  20.44K  --.-KB/s    in 0.07s   \n\n2020-01-30 22:34:29 (275 KB/s) - ‘calico.yaml.2’ saved [20935/20935]\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e618             - name: CALICO_IPV4POOL_CIDR\n619               value: \u0026#34;10.201.0.0/24\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ kubectl apply -f calico.yaml\nconfigmap/calico-config unchanged\ncustomresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org unchanged\nclusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchanged\nclusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchanged\nclusterrole.rbac.authorization.k8s.io/calico-node configured\nclusterrolebinding.rbac.authorization.k8s.io/calico-node unchanged\ndaemonset.apps/calico-node configured\nserviceaccount/calico-node unchanged\ndeployment.apps/calico-kube-controllers configured\nserviceaccount/calico-kube-controllers unchanged\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"kubelet-and-kubectl\"\u003ekubelet and kubectl\u003c/h1\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ sudo apt-mark unhold kubelet kubectl \u0026amp;\u0026amp; sudo apt-get install -y kubelet=1.17.2-00 kubectl=1.17.2-00 \u0026amp;\u0026amp; sudo apt-mark hold kubelet kubectl\nkubelet was already not hold.\nkubectl was already not hold.\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\nThe following packages will be upgraded:\n  kubectl kubelet\n2 upgraded, 0 newly installed, 0 to remove and 44 not upgraded.\nNeed to get 27.9 MB of archives.\nAfter this operation, 14.8 MB disk space will be freed.\nGet:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubectl amd64 1.17.2-00 [8738 kB]\nGet:2 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubelet amd64 1.17.2-00 [19.2 MB]\nFetched 27.9 MB in 6s (4994 kB/s)   \n(Reading database ... 248932 files and directories currently installed.)\nPreparing to unpack .../kubectl_1.17.2-00_amd64.deb ...\nUnpacking kubectl (1.17.2-00) over (1.16.1-00) ...\nPreparing to unpack .../kubelet_1.17.2-00_amd64.deb ...\nUnpacking kubelet (1.17.2-00) over (1.16.1-00) ...\nSetting up kubelet (1.17.2-00) ...\nSetting up kubectl (1.17.2-00) ...\nkubelet set on hold.\nkubectl set on hold.\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"wrap-up\"\u003ewrap-up\u003c/h1\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ sudo systemctl restart kubelet\ncychong@mini1:~$ kubectl get nodes\nNAME    STATUS   ROLES    AGE    VERSION\nmini1   Ready    master   144d   v1.17.2\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"reference\"\u003ereference\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/\"\u003ehttps://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Upgrade kubenetes to 1.17.2-0"},{"content":"리얼하다 조승연\nLunch or Happy Hour 뭔가 약속을 잡아야 할 때 점심 시간 혹은 저녁 업무 종료 후 저녁 식사 시간 전(Happy Hour, 5-7pm) 때 약속을 주로 잡는다고. 그래야 별도 개인 시간 낭비를 안하고, 저녁의 경우 필요하면 저녁 약속 을 핑계로 이야기를 끊을 수 있어서 주로 이렇게 한다고 한다.\n이메일로 할 수 있는 걸 전화로 하지 않고, 전화로 할 수 있는 걸 만나서 하지 않는다. 뉴욕의 사업자는 대부분 이민자 출신이라 길거리에서 생존을 배워와서 \u0026lsquo;실행해서 결과를 도출해 보기 전까지는 무엇도 알 수 없다\u0026rsquo;고 생각.\n일을 할 거면 당장 시작해서, 실패를 해도 빠르게 해보고 보완을 하든지 그만두든지 해야지, 일을 시작하기 전에 논의를 길게 하는 것은 쓸데없는 추측을 불러일으켜 추진력만 떨어뜨린다고 생각\n이게 Lean Startup 이라고 군더더기를 빼고 고강도로 업무에 임해 필요한 일을 마친 후 가질 수 있는 그들이 즐기는 Downtime이라는 개념.\n할 때는 하고, 안 할 때는 안 한다 늘 긴장하고 있는 게 아니라 집중해서 해야 할 때는 집중하고, 그렇지 않을 때는 relax.\n우리는 쉴 때 제대로 쉬고 있는가? 그리고 일할 때는 제대로 일하고 있는가?\n어중간한 상태에서 의미없는 피로에 피폭되고 있는 것은 아닌가?\n뉴욕을 통해 우리가 한 가지 배울 수 있는 것은, 40세가 되건 60세가 되건 새로운 도전을 할 수 있는 무대가 되어주는 사회, 그리고 새로운 도전에 나선 사람에게 단체로 \u0026lsquo;철이나 들라\u0026rsquo;며 끌끌 혀를 차는 대신, 새하얀 스케치북을 들려주며 용기를 북돋아주는 분위기에는 가격을 매길 수 없다는 것이다.\nHe is a New Yorker. He has to earn it\n\u0026lsquo;One little, Two little Three little Indian\u0026rsquo; 송은 아메리카 원주민의 땅을 잔혹하게 빼앗은 커스타드 장군 시대의 것. 죽인 인디안 수를 자랑하는 인종차별적인 내용\n필드에서 치열한 경쟁을 거쳐 살아남은 뉴요커는 실질적인 사회생활 능력을 정말로 중요시한다는 것 말이다. 이를 가리켜 미국인은 흔히 \u0026lsquo;Life Skills\u0026rsquo;라고 부른다. 인생의 맛과 멋을 스스로 터득하고, 누구 앞에서나 당당하게 자기 주장을 펴며, 자기 시간과 스트레스를 스스로 관리할 수 있고, 자기가 내린 결정의 이유를 알고 그 결과를 예측할 수 있는 사람은 어떤 환경에서도 살아남을 수 있다는 것을 뉴요커는 치열한 20세기를 겪으면서 뼈저리게 터득했다.\n\u0026lsquo;공부를 시킨다\u0026rsquo;가 아니라 \u0026lsquo;알아서 공부할 줄 알고 험한 세상을 헤쳐나갈 수 있는 영리한 아이를 만든다\u0026rsquo;를 목표로 영유아기에 집중적인 교육 투자를 하기 때문에 이와 관련된 시장의 규모가 엄청나게 크다. 미국인이 \u0026lsquo;discipline\u0026rsquo;이라고 부르는 자기 통제력은 다른 문화에 대한 존중과 더불어 뉴요커 교육 철학의 두 번째 축이다.\n책에서 머리를 떼지 않고 공부만 하느라 어른이 되었는데도 낯선 곳에서 스스로 길 하나를 찾지 못하고, 새로운 사람과 말을 트지도 못하며, 자기가 먹을 음식조차 스스로 만드지 못하는 어른이 되지 않도록 철저히 훈련을 시키는 것이ㅏㄷ. 앞에서 행복의 지름길은 경제적 자립이라고 말한 것과도 상통한다. 그래서 뉴요커는 부자라고 하더라도 이민자의 마인드를 자녀에게 계승시키려고 하는 것 같다.\n영화 \u0026lsquo;\u0026rsquo; 중\nI am not going to tell the story the way it happened\nI am going to tell it the way I remember it\n","date":"2019-12-15T06:46:24+09:00","permalink":"https://cychong47.github.io/post/2019/book-so-real/","summary":"\u003ch1 id=\"리얼하다\"\u003e리얼하다\u003c/h1\u003e\n\u003cp\u003e조승연\u003c/p\u003e\n\u003ch3 id=\"lunch-or-happy-hour\"\u003eLunch or Happy Hour\u003c/h3\u003e\n\u003cp\u003e뭔가 약속을 잡아야 할 때 점심 시간 혹은 저녁 업무 종료 후 저녁 식사 시간 전(Happy Hour, 5-7pm) 때 약속을 주로 잡는다고. 그래야 별도 개인 시간 낭비를 안하고, 저녁의 경우 필요하면 저녁 약속\n을 핑계로 이야기를 끊을 수 있어서 주로 이렇게 한다고 한다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e이메일로 할 수 있는 걸 전화로 하지 않고,\u003c/li\u003e\n\u003cli\u003e전화로 할 수 있는 걸 만나서 하지 않는다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e뉴욕의 사업자는 대부분 이민자 출신이라 길거리에서 생존을 배워와서 \u0026lsquo;실행해서 결과를 도출해 보기 전까지는 무엇도 알 수 없다\u0026rsquo;고 생각.\u003c/p\u003e","title":"(책) 리얼하다"},{"content":"https://github.com/huangyuzhang/Fizzy-Theme\n오늘 우연히 발견한 ghost theme. 중국 친구가 만든 것 같은데 꽤 괜찮다. 검색 기능에 필요한 Content API key 등만 Site Header에 추가하면 검색 기능을 이용할 수 있고, TOC도 지원이 된다는. 특히 중국 친구가 만든 거라 그런지 한글 검색도 잘 지원된다.\n한 동안 이 테마로 지내면 될 듯.\n","date":"2019-12-10T14:09:19+09:00","permalink":"https://cychong47.github.io/post/2019/change-ghost-theme-fizzy/","summary":"\u003cp\u003e\u003ca href=\"https://github.com/huangyuzhang/Fizzy-Theme\"\u003ehttps://github.com/huangyuzhang/Fizzy-Theme\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e오늘 우연히 발견한 ghost theme. 중국 친구가 만든 것 같은데 꽤 괜찮다.\n검색 기능에 필요한 Content API key 등만 Site Header에 추가하면 검색 기능을 이용할 수 있고, TOC도 지원이 된다는. 특히 중국 친구가 만든 거라 그런지 한글 검색도 잘 지원된다.\u003c/p\u003e\n\u003cp\u003e한 동안 이 테마로 지내면 될 듯.\u003c/p\u003e","title":"Ghost theme 변경 - Fizzy"},{"content":"swap을 사용하지 못하는 kubenertes를 사용해서 ghost pod/container를 구동하니 메모리가 부족하다고 종료되어 버린다.\n확인해 보니 서버로 사용하고 있는 mac mini 2009에 장착된 RAM이 4G였다. 흠\u0026hellip;\n인터넷에서 mac mini 2009의 HW 사양을 찾아 보니 DDR3 1066 MHz라고. 그리고 다른 블로그를 찾아 보니 그 보다 나중에 나온 더 높은 클럭의 RAM을 실장해도 동작하는 데는 문제가 없단다. 다만 지금은 사용하지 않는 DDR3 제품이라 구하는 게 문제일 듯. 하지만 혹시나 하고 예전에 모아둔 메모리 더미를 뒤져보니 딱 맞는 메모리가 있었다. 1066 MHz에 4G짜리 2개. 정말 안성맞춤.\n이제 kubernetes를 이용해서 ghost를 실행하고, docker를 이용해서 mysql과 wordpress를 실행해도 비정상 종료되지 않는다. 하지만 메모리 상황을 보면 간당간당하긴 하네.\n$ free -h total used free shared buff/cache available Mem: 7.5G 2.8G 170M 33M 4.6G 4.5G Swap: 0B 0B 0B 오늘 PC를 교체받은 회사 친구가 받은 노트북에 실장된 메모리가 32G던데 참 격세지감이다.\n저기서 buff/cache가 왜 이렇게 큰 지 좀 확인해 봐야겠다.\n간만에 뜯는 거라(예전에는 항상 ifixit 사이트를 보고 했는데 이젠 예전의 기억을 더듬어가면서 작업하긴 했지만) 그래도 딱 필요한 (블로그 글)[https://centerone.tistory.com/entry/맥미니-메모리램-업그레이드-Mac-mini-Late-2009MC238KHA])을 찾을 수 있어 큰 도움이 되었다.\n","date":"2019-11-18T15:11:08+09:00","permalink":"https://cychong47.github.io/post/2019/mac-mini-2009-upgrade/","summary":"\u003cp\u003eswap을 사용하지 못하는 kubenertes를 사용해서 ghost pod/container를 구동하니 메모리가 부족하다고 종료되어 버린다.\u003c/p\u003e\n\u003cp\u003e확인해 보니 서버로 사용하고 있는 mac mini 2009에 장착된 RAM이 4G였다.\n흠\u0026hellip;\u003c/p\u003e\n\u003cp\u003e인터넷에서 \u003ca href=\"https://support.apple.com/kb/sp505?locale=en_US\"\u003emac mini 2009의 HW 사양\u003c/a\u003e을 찾아 보니 DDR3 1066 MHz라고. 그리고 다른 블로그를 찾아 보니 그 보다 나중에 나온 더 높은 클럭의 RAM을 실장해도 동작하는 데는 문제가 없단다. 다만 지금은 사용하지 않는 DDR3 제품이라 구하는 게 문제일 듯.\n하지만 혹시나 하고 예전에 모아둔 메모리 더미를 뒤져보니 딱 맞는 메모리가 있었다. 1066 MHz에 4G짜리 2개. 정말 안성맞춤.\u003c/p\u003e","title":"Mac mini 2009 upgrade"},{"content":"중요한 일은\n생각을 기반으로 함. 기계적으로 대응 불가 소통이 따름. 조직의 일은 혼자 할 수 없으므로 결정이 수반되야 함. 길이 하나가 아닌 까닭 실행이 따름. 결정만으로 결과가 오는 것이 아님 52시간법은 일하는 시간에 제약이 가해지는 것이다. 충분한 시간을 투자해서 결과를 얻어내던 방식에서 달라져야 한다.\n직장 생활에서 반드시 익혀야 할 기술은 \u0026lsquo;생각을 정리하여 말이나 글로 표현하는 기술\u0026rsquo;\n일 때문에 일을 하는 것이 아니라 성과를 위해 일을 하는 것이다.\nWBS(Work Breakdown Structure)\n","date":"2019-11-17T11:12:41+09:00","permalink":"https://cychong47.github.io/post/2019/samuryeog/","summary":"\u003cp\u003e\u003cstrong\u003e중요한 일\u003c/strong\u003e은\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e생각을 기반으로 함. 기계적으로 대응 불가\u003c/li\u003e\n\u003cli\u003e소통이 따름. 조직의 일은 혼자 할 수 없으므로\u003c/li\u003e\n\u003cli\u003e결정이 수반되야 함. 길이 하나가 아닌 까닭\u003c/li\u003e\n\u003cli\u003e실행이 따름. 결정만으로 결과가 오는 것이 아님\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e52시간법은 \u003cstrong\u003e일하는 시간에 제약\u003c/strong\u003e이 가해지는 것이다. 충분한 시간을 투자해서 결과를 얻어내던 방식에서 달라져야 한다.\u003c/p\u003e\n\u003cp\u003e직장 생활에서 반드시 익혀야 할 기술은 \u0026lsquo;생각을 정리하여 말이나 글로 표현하는 기술\u0026rsquo;\u003c/p\u003e\n\u003cp\u003e일 때문에 일을 하는 것이 아니라 성과를 위해 일을 하는 것이다.\u003c/p\u003e\n\u003cp\u003eWBS(Work Breakdown Structure)\u003c/p\u003e","title":"사무력"},{"content":" 부제 1. pod가 동작하지 않을때 원인 찾기 부제 2. helm upgrade 명령을 이용하여 업데이트 하기 부제 3. sqlite를 이용해서 ghost.db 직접 수정하기 values.yaml에 명시되어 있는 ghost docker image의 버전 정보를 2.31.0에서 3.0.2 최신 버전으로 업데이트 후 아래 명령어로 업데이트\n$ helm upgrade --debug my-ghost ghost-with-helm [debug] Created tunnel using local port: \u0026#39;45263\u0026#39; [debug] SERVER: \u0026#34;127.0.0.1:45263\u0026#34; REVISION: 6 RELEASED: Tue Nov 5 22:25:19 2019 CHART: ghost-0.1.0 USER-SUPPLIED VALUES: {} COMPUTED VALUES: affinity: {} env: node_env: production url: http://sosa0sa.com:2368 fullnameOverride: \u0026#34;\u0026#34; image: pullPolicy: Always registry: docekr.io repository: ghost tag: 3.0.2 Helm upgrade는 완료되었지만 ghost 블로그가 접속이 되지 않는다. 상태를 확인해 보니\n$ kubectl get pod NAME READY STATUS RESTARTS AGE my-ghost-795c6d674f-jb6t2 0/1 CrashLoopBackOff 4 3m6s sctp-7c94d9b5c9-wsjnd 1/1 Running 2 28d $ kubectl describe pod my-ghost-795c6d674f-jb6t2 ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled \u0026lt;unknown\u0026gt; default-scheduler Successfully assigned default/my-ghost-795c6d674f-jb6t2 to mini1 Normal Started 5m32s (x2 over 6m1s) kubelet, mini1 Started container ghost Warning Unhealthy 5m29s (x2 over 5m59s) kubelet, mini1 Readiness probe failed: Get http://10.244.51.112:2368/: dial tcp 10.244.51.112:2368: connect: connection refused Warning Unhealthy 5m26s (x2 over 5m56s) kubelet, mini1 Liveness probe failed: Get http://10.244.51.112:2368/: dial tcp 10.244.51.112:2368: connect: connection refused Warning Unhealthy 5m9s (x4 over 5m48s) kubelet, mini1 Readiness probe failed: HTTP probe failed with statuscode: 500 Warning Unhealthy 5m6s (x4 over 5m46s) kubelet, mini1 Liveness probe failed: HTTP probe failed with statuscode: 500 Normal Killing 5m6s (x2 over 5m36s) kubelet, mini1 Container ghost failed liveness probe, will be restarted Normal Pulling 5m6s (x3 over 6m6s) kubelet, mini1 Pulling image \u0026#34;ghost:3.0.2\u0026#34; Normal Pulled 5m2s (x3 over 6m2s) kubelet, mini1 Successfully pulled image \u0026#34;ghost:3.0.2\u0026#34; Normal Created 5m2s (x3 over 6m2s) kubelet, mini1 Created container ghost Warning BackOff 63s (x10 over 3m35s) kubelet, mini1 Back-off restarting failed container my-ghost로 시작하는 pod가 제대로 실행되지 않아 반복해서 재시동 되었지만 제대로 동작하지 않아 결국 실패했다.\nGhost update! 쉽게 될 리가 없지 pod 에서 발생하는 로그를 분석해서 ghost가 제대로 실행되지 않는 이유를 알아보기로 했다. Container의 로그를 인하기 위해 kubectl logs 명령어를 사용한다.\n만일 pod에 여러 개의 container가 있는 경우 pod 명 뒤에 contaienr 명을 지정한다. 자세한 내용은 kubectl logs -h 로 확인해 본다.\n$ kubectl logs my-ghost-795c6d674f-jb6t2 [2019-11-05 13:41:48] ERROR The currently active theme \u0026#34;simply\u0026#34; is invalid. The currently active theme \u0026#34;simply\u0026#34; is invalid. Error ID: 03c2e4b0-ffd2-11e9-9543-b7dca11c112e Details: checkedVersion: 3.x name: simply-godofredoninja path: /var/lib/ghost/content/themes/simply version: 0.1.1 errors: - fatal: true level: error rule: The v0.1 API and \u0026lt;code\u0026gt;ghost.url.api()\u0026lt;/code\u0026gt; JavaScript helper have been removed. details: The v0.1 API \u0026amp; Public API Beta have been removed, along with the \u0026lt;code\u0026gt;public/ghost-sdk.min.js\u0026lt;/code\u0026gt; file \u0026amp; the \u0026lt;code\u0026gt;ghost.url.api()\u0026lt;/code\u0026gt; helper.\u0026lt;br\u0026gt;All code relying on the v0.1 API must be upgraded to use the \u0026lt;a href=\u0026#34;https://ghost.org/faq/upgrades/\u0026#34; target=_blank\u0026gt;new API\u0026lt;/a\u0026gt;. regex: failures: - ref: assets/scripts/main.js code: GS060-JS-GUA ---------------------------------------- ThemeValidationError: The currently active theme \u0026#34;simply\u0026#34; is invalid. at ThemeValidationError.GhostError (/var/lib/ghost/versions/3.0.2/core/server/lib/common/errors.js:10:26) at new ThemeValidationError (/var/lib/ghost/versions/3.0.2/core/server/lib/common/errors.js:40:20) at validationSuccess (/var/lib/ghost/versions/3.0.2/core/frontend/services/themes/index.js:34:48) at tryCatcher (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/util.js:16:23) at Promise._settlePromiseFromHandler (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/promise.js:547:31) at Promise._settlePromise (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/promise.js:604:18) at Promise._settlePromise0 (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/promise.js:649:10) at Promise._settlePromises (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/promise.js:729:18) at _drainQueueStep (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/async.js:93:12) at _drainQueue (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/async.js:86:9) at Async._drainQueues (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/async.js:102:5) at Immediate.Async.drainQueues [as _onImmediate] (/var/lib/ghost/versions/3.0.2/node_modules/bluebird/js/release/async.js:15:14) at runCallback (timers.js:705:18) at tryOnImmediate (timers.js:676:5) at processImmediate (timers.js:658:5) [2019-11-05 13:41:52] INFO Ghost is running in production... [2019-11-05 13:41:52] INFO Your site is now available on http://sosa0sa.com:2368/ [2019-11-05 13:41:52] INFO Ctrl+C to shut down [2019-11-05 13:41:52] INFO Ghost boot 9.265s [2019-11-05 13:41:53] ERROR \u0026#34;GET /\u0026#34; 500 70ms [error.hbs] Missing helper: \u0026#34;foreach\u0026#34; ---------------------------------------- Error: [error.hbs] Missing helper: \u0026#34;foreach\u0026#34; at Object.\u0026lt;anonymous\u0026gt; (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/helpers/helper-missing.js:19:13) at eval (eval at createFunctionContext (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/javascript-compiler.js:262:23), \u0026lt;anonymous\u0026gt;:6:95) at Object.prog [as fn] (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:229:12) at Object.\u0026lt;anonymous\u0026gt; (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/helpers/if.js:19:22) at Object.eval [as main] (eval at createFunctionContext (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/javascript-compiler.js:262:23), \u0026lt;anonymous\u0026gt;:20:32) at main (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:176:32) at ret (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:179:12) at ret (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/compiler.js:526:21) at renderTemplate (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:490:13) at render (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:526:5) at renderIt (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:588:18) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:611:11 at parseLayout (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:471:7) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:577:7 at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:565:14 at FSReqWrap.readFileAfterClose [as oncomplete] (internal/fs/read_file_context.js:53:3) [2019-11-05 13:42:00] ERROR \u0026#34;GET /\u0026#34; 500 14ms [error.hbs] Missing helper: \u0026#34;foreach\u0026#34; ---------------------------------------- Error: [error.hbs] Missing helper: \u0026#34;foreach\u0026#34; at Object.\u0026lt;anonymous\u0026gt; (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/helpers/helper-missing.js:19:13) at eval (eval at createFunctionContext (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/javascript-compiler.js:262:23), \u0026lt;anonymous\u0026gt;:6:95) at Object.prog [as fn] (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:229:12) at Object.\u0026lt;anonymous\u0026gt; (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/helpers/if.js:19:22) at Object.eval [as main] (eval at createFunctionContext (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/javascript-compiler.js:262:23), \u0026lt;anonymous\u0026gt;:20:32) at main (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:176:32) at ret (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:179:12) at ret (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/compiler.js:526:21) at renderTemplate (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:490:13) at render (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:526:5) at renderIt (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:588:18) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:611:11 at parseLayout (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:471:7) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:577:7 at getSourceTemplate (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:551:16) at compileFile (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:573:5) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:660:12 at ExpressHbs.loadDefaultLayout (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:296:44) at ExpressHbs.___express (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:648:8) at View.render (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/view.js:135:8) at tryRender (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/application.js:640:10) at Function.render (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/application.js:592:3) at ServerResponse.render (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/response.js:1012:7) at _private.ThemeErrorRenderer (/var/lib/ghost/versions/3.0.2/core/server/web/shared/middlewares/error-handler.js:188:9) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:71:5) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at _private.prepareError (/var/lib/ghost/versions/3.0.2/core/server/web/shared/middlewares/error-handler.js:70:5) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:71:5) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) [2019-11-05 13:42:03] ERROR \u0026#34;GET /\u0026#34; 500 26ms [error.hbs] Missing helper: \u0026#34;foreach\u0026#34; ---------------------------------------- Error: [error.hbs] Missing helper: \u0026#34;foreach\u0026#34; at Object.\u0026lt;anonymous\u0026gt; (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/helpers/helper-missing.js:19:13) at eval (eval at createFunctionContext (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/javascript-compiler.js:262:23), \u0026lt;anonymous\u0026gt;:6:95) at Object.prog [as fn] (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:229:12) at Object.\u0026lt;anonymous\u0026gt; (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/helpers/if.js:19:22) at Object.eval [as main] (eval at createFunctionContext (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/javascript-compiler.js:262:23), \u0026lt;anonymous\u0026gt;:20:32) at main (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:176:32) at ret (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/runtime.js:179:12) at ret (/var/lib/ghost/versions/3.0.2/node_modules/handlebars/dist/cjs/handlebars/compiler/compiler.js:526:21) at renderTemplate (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:490:13) at render (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:526:5) at renderIt (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:588:18) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:611:11 at parseLayout (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:471:7) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:577:7 at getSourceTemplate (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:551:16) at compileFile (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:573:5) at /var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:660:12 at ExpressHbs.loadDefaultLayout (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:296:44) at ExpressHbs.___express (/var/lib/ghost/versions/3.0.2/node_modules/express-hbs/lib/hbs.js:648:8) at View.render (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/view.js:135:8) at tryRender (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/application.js:640:10) at Function.render (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/application.js:592:3) at ServerResponse.render (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/response.js:1012:7) at _private.ThemeErrorRenderer (/var/lib/ghost/versions/3.0.2/core/server/web/shared/middlewares/error-handler.js:188:9) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:71:5) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at _private.prepareError (/var/lib/ghost/versions/3.0.2/core/server/web/shared/middlewares/error-handler.js:70:5) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:71:5) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) at /var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:284:7 at Function.process_params (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:335:12) at next (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:275:10) at Layer.handle_error (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/layer.js:67:12) at trim_prefix (/var/lib/ghost/versions/3.0.2/node_modules/express/lib/router/index.js:315:13) [2019-11-05 13:42:03] WARN Ghost has shut down [2019-11-05 13:42:03] WARN Your site is now offline 에러 로그를 보니 기존에 ghost 2.x에서 사용하던 theme simply 가 ghost 3.0과 호환이 되지 않아서 그런 듯 한다.\nghost theme 파일들은 PV(Persistent Volume)로 마운트 되는 디렉토리에 있는데 문제를 해결할 해결책을 생각해 보면\ntheme simply를 수정해서 ghost 3.0과 호환되게 만든다. theme simpy 대신 ghost 3.0과 호횐되는 기본 casper 3.0 theme을 사용한다. 첫번째 옵션은 ghost theme에 대한 연구(?)가 필요해서 보다 쉬운 두 번째 방법으로 시도해 보기로 한다. ghost 3.0과 함께 발표된 기본 theme 인 casper 3.0을 사용하도록 변경하면 되는데 문제는 theme을 변경할 수 있는 화면도 ghost가 정상적으로 실행된 경우에 접근할 수 있는 설정 화면에 있다는 거.\n그렇지만 아마도 ghost가 사용하는 theme 정보가 어딘가 파일에 저장되어 있을 듯 하니 그걸 변경하면 해결할 수 있을 듯 하다.\nghost.db 파일을 직접 수정해서 theme 변경 https://blog.tylerbuchea.com/customizing-ghost/ 그리고 https://www.ghostforbeginners.com/change-ghost-theme-from-command-line/ 를 본 ghost가 동작하는데 사용하는 설정 정보들이 ghost.db에 저장되어 있는 듯 하다. 그리고 sqlite로 저장된 이 파일을 직접 수정할 수 도 있는 듯.\nPV로 마운트하는 ghost의 content/data 디렉토리에 있는 ghost.db 파일을 sqlite 툴로 열어본다. 설정에 관련된 내용은 settings 테이블에 저장된 듯 하다.\n$ sqlite3 ghost.db SQLite version 3.22.0 2018-01-22 18:45:57 Enter \u0026#34;.help\u0026#34; for usage hints. sqlite\u0026gt; .tables actions permissions_apps api_keys permissions_roles app_fields permissions_users app_settings posts apps posts_authors brute posts_meta integrations posts_tags invites roles members roles_users members_stripe_customers sessions members_stripe_customers_subscriptions settings migrations tags migrations_lock users mobiledoc_revisions webhooks permissions sqlite\u0026gt; select * FROM settings; ... 59929168a13f9a00014e67da|title|Another|blog|2016-09-20 14:03:55|1|2017-11-21 14:58:13|1 59929168a13f9a00014e67db|description|Thoughts, stories and ideas.|blog|2016-09-20 14:03:55|1|2017-11-21 14:58:13|1 ... https://www.ghostforbeginners.com/change-ghost-theme-from-command-line/ 글을 참조하여 현재 사용하고 있는 theme을 가리키는 key인 activeTheme을 찾아보지만 2016 년 글이라 그런지 activeTheme이라는 key는 존재하지 않는다. DB scheme가 변경된 듯 하다. 하지만activeTheme이 아닌 유사한 이름인 active_theme 을 찾을 수 있다.\nsqlite\u0026gt; SELECT * FROM settings where key = \u0026#39;active_theme\u0026#39;; 59929168a13f9a00014e67eb|active_theme|simply|theme|2017-08-15 06:15:04|1|2019-03-20 14:49:09|1 active_theme 키 값을 확인해 보니 문제가 되는 바로 그 simply임을 확인할 수 있다.\n값 변경은 update 명령을 이용해서 변경할 수 있다. 역시 위 글 참조\nsqlite\u0026gt; update settings set value=\u0026#39;casper\u0026#39; where key = \u0026#39;active_theme\u0026#39;; sqlite\u0026gt; SELECT * FROM settings where key = \u0026#39;active_theme\u0026#39;; 59929168a13f9a00014e67eb|active_theme|casper|theme|2017-08-15 06:15:04|1|2019-03-20 14:49:09|1 sqlite3 종료는 ctrl + d로.\n이제 다시 pod의 상태를 확인해 보면 정상적으로 pod가 실행되고 있음을 확인할 수 있다.\n$ kubectl get pods NAME READY STATUS RESTARTS AGE my-ghost-795c6d674f-jb6t2 1/1 Running 22 60m sctp-7c94d9b5c9-wsjnd 1/1 Running 2 28d 웹 브라우저로 URL 접속하니 정상적으로 동작한다. 문제 해결\u0026hellip;\n","date":"2019-11-05T14:58:16+09:00","permalink":"https://cychong47.github.io/post/2019/upgrade-ghost-to-v3-0/","summary":"\u003cul\u003e\n\u003cli\u003e부제 1. pod가 동작하지 않을때 원인 찾기\u003c/li\u003e\n\u003cli\u003e부제 2. helm upgrade 명령을 이용하여 업데이트 하기\u003c/li\u003e\n\u003cli\u003e부제 3. sqlite를 이용해서 ghost.db 직접 수정하기\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003evalues.yaml에 명시되어 있는 ghost docker image의 버전 정보를 2.31.0에서 3.0.2 최신 버전으로 업데이트 후 아래 명령어로 업데이트\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ helm upgrade --debug my-ghost ghost-with-helm\n[debug] Created tunnel using local port: \u0026#39;45263\u0026#39;\n\n[debug] SERVER: \u0026#34;127.0.0.1:45263\u0026#34;\n\nREVISION: 6\nRELEASED: Tue Nov  5 22:25:19 2019\nCHART: ghost-0.1.0\nUSER-SUPPLIED VALUES:\n{}\n\nCOMPUTED VALUES:\naffinity: {}\nenv:\n  node_env: production\n  url: http://sosa0sa.com:2368\nfullnameOverride: \u0026#34;\u0026#34;\nimage:\n  pullPolicy: Always\n  registry: docekr.io\n  repository: ghost\n  tag: 3.0.2\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eHelm upgrade는 완료되었지만 ghost 블로그가 접속이 되지 않는다. 상태를 확인해 보니\u003c/p\u003e","title":"Upgrade ghost to v3.0"},{"content":"helm 명령을 입력했는데 다음과 같은 에러 메시지를 내면서 실행을 거부한다.\n$ helm ls snap-confine has elevated permissions and is not confined but should be. Refusing to continue to avoid permission escalation attacks 에러 메시지를 찾아보니 보안 관련된 내용이 이슈라고 다음과 같이 하면 해결된다.\n$ sudo systemctl enable --now apparmor.service Synchronizing state of apparmor.service with SysV service script with /lib/systemd/systemd-sysv-install. Executing: /lib/systemd/systemd-sysv-install enable apparmor 하지만 이제는 helm의 client와 server 버전이 맞지 않다는 에러\n$ helm ls Error: incompatible versions client[v2.15.1] server[v2.14.3] 해결책은 helm server 버전을 client와 같은 버전으로 변경하면 된다고.\n$ helm init --upgrade $HELM_HOME has been configured at /home/cychong/.helm. Tiller (the Helm server-side component) has been updated to gcr.io/kubernetes-helm/tiller:v2.15.1 . Reference\nhttps://github.com/ubuntu/microk8s/issues/249 https://kubernetes.io/docs/tutorials/clusters/apparmor/ Helm: Incompatible versions between client and server ","date":"2019-11-05T14:47:41+09:00","permalink":"https://cychong47.github.io/post/2019/what-if-helm-command-refuses/","summary":"\u003cp\u003ehelm 명령을 입력했는데 다음과 같은 에러 메시지를 내면서 실행을 거부한다.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ helm ls\nsnap-confine has elevated permissions and is not confined but should be. Refusing to continue to avoid permission escalation attacks\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e에러 메시지를 찾아보니 보안 관련된 내용이 이슈라고\n다음과 같이 하면 해결된다.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ sudo systemctl enable --now apparmor.service\nSynchronizing state of apparmor.service with SysV service script with /lib/systemd/systemd-sysv-install.\nExecuting: /lib/systemd/systemd-sysv-install enable apparmor\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e하지만 이제는 helm의 client와 server 버전이 맞지 않다는 에러\u003c/p\u003e","title":"What if helm command refuse to execute"},{"content":"mini1 리붓 후 ghost 접속이 안됨.\ndocker를 직접 실행시키는 wordpress는 정상적으로 실행\n그래서 kubectl get svc 명령을 치니 접속이 안된다고.\n$ ps -ef |grep kube cychong 7461 2486 0 23:26 pts/0 00:00:00 grep --color=auto kube $ service kubelet status ● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled) Drop-In: /etc/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: activating (auto-restart) (Result: exit-code) since Mon 2019-11-04 23:26:47 KST; 5s ago Docs: https://kubernetes.io/docs/home/ Process: 7664 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=255 Main PID: 7664 (code=exited, status=255) $ journalctl -xeu kubelet Nov 04 23:28:32 mini1 kubelet[8695]: I1104 23:28:32.418274 8695 server.go:773] Client rotation is on, will bootstrap in background Nov 04 23:28:32 mini1 kubelet[8695]: I1104 23:28:32.427223 8695 certificate_store.go:129] Loading cert/key pair from \u0026#34;/var/lib/kubelet/pki/kubelet-clien Nov 04 23:28:32 mini1 kubelet[8695]: I1104 23:28:32.580296 8695 server.go:644] --cgroups-per-qos enabled, but --cgroup-root was not specified. defaulti Nov 04 23:28:32 mini1 kubelet[8695]: F1104 23:28:32.580915 8695 server.go:271] failed to run Kubelet: running with swap on is not supported, please disa Nov 04 23:28:32 mini1 systemd[1]: kubelet.service: Main process exited, code=exited, status=255/n/a Nov 04 23:28:32 mini1 systemd[1]: kubelet.service: Failed with result \u0026#39;exit-code\u0026#39;. Nov 04 23:28:42 mini1 systemd[1]: kubelet.service: Service hold-off time over, scheduling restart. Nov 04 23:28:42 mini1 systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 30. -- Subject: Automatic restarting of a unit has been scheduled -- Defined-By: systemd -- Support: http://www.ubuntu.com/support -- -- Automatic restarting of the unit kubelet.service has been scheduled, as the result for -- the configured Restart= setting for the unit. Nov 04 23:28:42 mini1 systemd[1]: Stopped kubelet: The Kubernetes Node Agent. -- Subject: Unit kubelet.service has finished shutting down -- Defined-By: systemd -- Support: http://www.ubuntu.com/support -- -- Unit kubelet.service has finished shutting down. Nov 04 23:28:42 mini1 systemd[1]: Started kubelet: The Kubernetes Node Agent. -- Subject: Unit kubelet.service has finished start-up -- Defined-By: systemd -- Support: http://www.ubuntu.com/support -- -- Unit kubelet.service has finished starting up. -- -- The start-up result is RESULT. Nov 04 23:28:42 mini1 kubelet[8795]: Flag --cgroup-driver has been deprecated, This parameter should be set via the config file specified by the Kubelet\u0026#39;s Nov 04 23:28:42 mini1 kubelet[8795]: Flag --resolv-conf has been deprecated, This parameter should be set via the config file specified by the Kubelet\u0026#39;s -- Nov 04 23:28:42 mini1 kubelet[8795]: Flag --cgroup-driver has been deprecated, This parameter should be set via the config file specified by the Kubelet\u0026#39;s Nov 04 23:28:42 mini1 kubelet[8795]: Flag --resolv-conf has been deprecated, This parameter should be set via the config file specified by the Kubelet\u0026#39;s -- Nov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.907863 8795 server.go:410] Version: v1.16.1 Nov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.908251 8795 plugins.go:100] No cloud provider specified. Nov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.908283 8795 server.go:773] Client rotation is on, will bootstrap in background Nov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.917653 8795 certificate_store.go:129] Loading cert/key pair from \u0026#34;/var/lib/kubelet/pki/kubelet-clien Nov 04 23:28:43 mini1 kubelet[8795]: I1104 23:28:43.073234 8795 server.go:644] --cgroups-per-qos enabled, but --cgroup-root was not specified. defaulti Nov 04 23:28:43 mini1 kubelet[8795]: F1104 23:28:43.073886 8795 server.go:271] failed to run Kubelet: running with swap on is not supported, please disa Nov 04 23:28:43 mini1 systemd[1]: kubelet.service: Main process exited, code=exited, status=255/n/a Nov 04 23:28:43 mini1 systemd[1]: kubelet.service: Failed with result \u0026#39;exit-code\u0026#39;. lines 1947-1986/1986 (END) 찾아보니 docker가 정상적으로 실행 중인지 확인해 보라고.\n하지만 정상적으로 동작 중\n$ systemctl status docker ● docker.service - Docker Application Container Engine Loaded: loaded (/lib/systemd/system/docker.service; enabled; vendor preset: enabled) Active: active (running) since Mon 2019-11-04 23:25:40 KST; 7min ago Docs: https://docs.docker.com Main PID: 5285 (dockerd) Tasks: 59 CGroup: /system.slice/docker.service ├─5285 /usr/bin/dockerd -H fd:// --containerd=/run/containerd/containerd.sock ├─5586 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 80 -container-ip 172.17.0.3 -container-port 80 └─5598 /usr/bin/docker-proxy -proto tcp -host-ip 0.0.0.0 -host-port 8181 -container-ip 172.17.0.4 -container-port 80 Nov 04 23:25:35 mini1 dockerd[5285]: time=\u0026#34;2019-11-04T23:25:35.378057010+09:00\u0026#34; level=warning msg=\u0026#34;Your kernel does not support swap memory limit\u0026#34; Nov 04 23:25:35 mini1 dockerd[5285]: time=\u0026#34;2019-11-04T23:25:35.378125944+09:00\u0026#34; level=warning msg=\u0026#34;Your kernel does not support cgroup rt period\u0026#34; Nov 04 23:25:35 mini1 dockerd[5285]: time=\u0026#34;2019-11-04T23:25:35.378148389+09:00\u0026#34; level=warning msg=\u0026#34;Your kernel does not support cgroup rt runtime\u0026#34; Nov 04 23:25:35 mini1 dockerd[5285]: time=\u0026#34;2019-11-04T23:25:35.378414322+09:00\u0026#34; level=info msg=\u0026#34;Loading containers: start.\u0026#34; Nov 04 23:25:36 mini1 dockerd[5285]: time=\u0026#34;2019-11-04T23:25:36.163613079+09:00\u0026#34; level=info msg=\u0026#34;Default bridge (docker0) is assigned with an IP address 172 Nov 04 23:25:39 mini1 dockerd[5285]: time=\u0026#34;2019-11-04T23:25:39.843337707+09:00\u0026#34; level=info msg=\u0026#34;Loading containers: done.\u0026#34; Nov 04 23:25:40 mini1 dockerd[5285]: time=\u0026#34;2019-11-04T23:25:40.046412649+09:00\u0026#34; level=info msg=\u0026#34;Docker daemon\u0026#34; commit=9013bf583a graphdriver(s)=overlay2 ve Nov 04 23:25:40 mini1 dockerd[5285]: time=\u0026#34;2019-11-04T23:25:40.047017959+09:00\u0026#34; level=info msg=\u0026#34;Daemon has completed initialization\u0026#34; Nov 04 23:25:40 mini1 dockerd[5285]: time=\u0026#34;2019-11-04T23:25:40.109258901+09:00\u0026#34; level=info msg=\u0026#34;API listen on /var/run/docker.sock\u0026#34; Nov 04 23:25:40 mini1 systemd[1]: Started Docker Application Container Engine. 범인은 아니 문제에 대한 설명은 에러 메시지에 있을 확률이 가장 높으니 위 systemctl status kubelet의 결과를 찬찬히 살펴보니 swap에 대한 내용이 눈에 띈다.\n그래서 바로 해결 시도.\n$ sudo swapoff -a [sudo] password for cychong: cychong@mini1:~$ systemctl status kubelet ● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled) Drop-In: /etc/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: active (running) since Mon 2019-11-04 23:48:43 KST; 2s ago Docs: https://kubernetes.io/docs/home/ Main PID: 18121 (kubelet) Tasks: 11 (limit: 4306) CGroup: /system.slice/kubelet.service └─18121 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/l Nov 04 23:48:43 mini1 kubelet[18121]: I1104 23:48:43.741976 18121 remote_image.go:50] parsed scheme: \u0026#34;\u0026#34; Nov 04 23:48:43 mini1 kubelet[18121]: I1104 23:48:43.742008 18121 remote_image.go:50] scheme \u0026#34;\u0026#34; not registered, fallback to default scheme Nov 04 23:48:43 mini1 kubelet[18121]: I1104 23:48:43.742038 18121 passthrough.go:48] ccResolverWrapper: sending update to cc: {[{/var/run/dockershim.sock Nov 04 23:48:43 mini1 kubelet[18121]: I1104 23:48:43.742058 18121 clientconn.go:577] ClientConn switching balancer to \u0026#34;pick_first\u0026#34; Nov 04 23:48:44 mini1 kubelet[18121]: E1104 23:48:44.424387 18121 reflector.go:123] k8s.io/kubernetes/pkg/kubelet/kubelet.go:459: Failed to list *v1.Node Nov 04 23:48:44 mini1 kubelet[18121]: E1104 23:48:44.428655 18121 reflector.go:123] k8s.io/kubernetes/pkg/kubelet/kubelet.go:450: Failed to list *v1.Serv Nov 04 23:48:44 mini1 kubelet[18121]: E1104 23:48:44.429959 18121 reflector.go:123] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:46: Failed to list Nov 04 23:48:45 mini1 kubelet[18121]: E1104 23:48:45.425295 18121 reflector.go:123] k8s.io/kubernetes/pkg/kubelet/kubelet.go:459: Failed to list *v1.Node Nov 04 23:48:45 mini1 kubelet[18121]: E1104 23:48:45.429648 18121 reflector.go:123] k8s.io/kubernetes/pkg/kubelet/kubelet.go:450: Failed to list *v1.Serv Nov 04 23:48:45 mini1 kubelet[18121]: E1104 23:48:45.430623 18121 reflector.go:123] k8s.io/kubernetes/pkg/kubelet/config/apiserver.go:46: Failed to list 우연치 않게 회사에서도 비슷한 문제가 있었는데 그것도 swap이 원인이었다는\u0026hellip;\n","date":"2019-11-05T14:43:35+09:00","permalink":"https://cychong47.github.io/post/2019/what-if-kubelet-is-not-started/","summary":"\u003cp\u003emini1 리붓 후 ghost 접속이 안됨.\u003c/p\u003e\n\u003cp\u003edocker를 직접 실행시키는 wordpress는 정상적으로 실행\u003c/p\u003e\n\u003cp\u003e그래서 kubectl get svc 명령을 치니 접속이 안된다고.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ ps -ef |grep kube\ncychong   7461  2486  0 23:26 pts/0    00:00:00 grep --color=auto kube\n$ service kubelet status\n● kubelet.service - kubelet: The Kubernetes Node Agent\n   Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)\n  Drop-In: /etc/systemd/system/kubelet.service.d\n           └─10-kubeadm.conf\n   Active: activating (auto-restart) (Result: exit-code) since Mon 2019-11-04 23:26:47 KST; 5s ago\n     Docs: https://kubernetes.io/docs/home/\n  Process: 7664 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=255\n Main PID: 7664 (code=exited, status=255)\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ journalctl -xeu kubelet\nNov 04 23:28:32 mini1 kubelet[8695]: I1104 23:28:32.418274    8695 server.go:773] Client rotation is on, will bootstrap in background\nNov 04 23:28:32 mini1 kubelet[8695]: I1104 23:28:32.427223    8695 certificate_store.go:129] Loading cert/key pair from \u0026#34;/var/lib/kubelet/pki/kubelet-clien\nNov 04 23:28:32 mini1 kubelet[8695]: I1104 23:28:32.580296    8695 server.go:644] --cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulti\nNov 04 23:28:32 mini1 kubelet[8695]: F1104 23:28:32.580915    8695 server.go:271] failed to run Kubelet: running with swap on is not supported, please disa\nNov 04 23:28:32 mini1 systemd[1]: kubelet.service: Main process exited, code=exited, status=255/n/a\nNov 04 23:28:32 mini1 systemd[1]: kubelet.service: Failed with result \u0026#39;exit-code\u0026#39;.\nNov 04 23:28:42 mini1 systemd[1]: kubelet.service: Service hold-off time over, scheduling restart.\nNov 04 23:28:42 mini1 systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 30.\n-- Subject: Automatic restarting of a unit has been scheduled\n-- Defined-By: systemd\n-- Support: http://www.ubuntu.com/support\n--\n-- Automatic restarting of the unit kubelet.service has been scheduled, as the result for\n-- the configured Restart= setting for the unit.\nNov 04 23:28:42 mini1 systemd[1]: Stopped kubelet: The Kubernetes Node Agent.\n-- Subject: Unit kubelet.service has finished shutting down\n-- Defined-By: systemd\n-- Support: http://www.ubuntu.com/support\n--\n-- Unit kubelet.service has finished shutting down.\nNov 04 23:28:42 mini1 systemd[1]: Started kubelet: The Kubernetes Node Agent.\n-- Subject: Unit kubelet.service has finished start-up\n-- Defined-By: systemd\n-- Support: http://www.ubuntu.com/support\n--\n-- Unit kubelet.service has finished starting up.\n--\n-- The start-up result is RESULT.\nNov 04 23:28:42 mini1 kubelet[8795]: Flag --cgroup-driver has been deprecated, This parameter should be set via the config file specified by the Kubelet\u0026#39;s\nNov 04 23:28:42 mini1 kubelet[8795]: Flag --resolv-conf has been deprecated, This parameter should be set via the config file specified by the Kubelet\u0026#39;s --\nNov 04 23:28:42 mini1 kubelet[8795]: Flag --cgroup-driver has been deprecated, This parameter should be set via the config file specified by the Kubelet\u0026#39;s\nNov 04 23:28:42 mini1 kubelet[8795]: Flag --resolv-conf has been deprecated, This parameter should be set via the config file specified by the Kubelet\u0026#39;s --\nNov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.907863    8795 server.go:410] Version: v1.16.1\nNov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.908251    8795 plugins.go:100] No cloud provider specified.\nNov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.908283    8795 server.go:773] Client rotation is on, will bootstrap in background\nNov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.917653    8795 certificate_store.go:129] Loading cert/key pair from \u0026#34;/var/lib/kubelet/pki/kubelet-clien\nNov 04 23:28:43 mini1 kubelet[8795]: I1104 23:28:43.073234    8795 server.go:644] --cgroups-per-qos enabled, but --cgroup-root was not specified.  defaulti\nNov 04 23:28:43 mini1 kubelet[8795]: F1104 23:28:43.073886    8795 server.go:271] failed to run Kubelet: running with swap on is not supported, please disa\nNov 04 23:28:43 mini1 systemd[1]: kubelet.service: Main process exited, code=exited, status=255/n/a\nNov 04 23:28:43 mini1 systemd[1]: kubelet.service: Failed with result \u0026#39;exit-code\u0026#39;.\nlines 1947-1986/1986 (END)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e찾아보니 \u003ccode\u003edocker\u003c/code\u003e가 정상적으로 실행 중인지 확인해 보라고.\u003c/p\u003e","title":"kubelet이 실행되지 않을때"},{"content":"Check if SCTP is supported by creating SCTP service https://blog.aweimeow.tw/enable-sctp-in-kubernetes-cluster/\ncychong@mini1:~/work/sctp$ cat service.yaml apiVersion: v1 kind: Service metadata: name: sctp spec: selector: app: sctp ports: - protocol: SCTP port: 9999 targetPort: 30001 cychong@mini1:~/work/sctp$ kubectl create -f service.yaml The Service \u0026#34;sctp\u0026#34; is invalid: spec.ports[0].protocol: Unsupported value: \u0026#34;SCTP\u0026#34;: supported values: \u0026#34;TCP\u0026#34;, \u0026#34;UDP\u0026#34; Enable SCTP in running kubernetes cluster https://stackoverflow.com/questions/55909512/how-to-configure-already-running-cluster-in-kubernetes\nBasically you must pass this flag to kube-apiserver. How you can do that depends on how you set up the cluster. If you used kubeadm or kubespray then you should edit file /etc/kubernetes/manifests/kube-apiserver.yaml and add this flag somewhere under \u0026ldquo;command\u0026rdquo; field (somewhere between other flags). After that kube-apiserver pod should be restarted automatically. If not - you can kill it by hand.\nAdd --feature-gates=SCTPSupport=True to /etc/kubernetes/manifest/kube-apiserver.yaml\n- --tls-private-key-file=/etc/kubernetes/pki/apiserver.key - --feature-gates=SCTPSupport=True image: k8s.gcr.io/kube-apiserver:v1.16.1 Restart kube-apiserver. Just kill it and wait restarted\ncychong@mini1:/etc/kubernetes$ ps -ef |grep kube-api root 21846 21824 9 00:02 ? 00:00:24 kube-apiserver --advertise-address=192.168.1.100 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --insecure-port=0 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-cluster-ip-range=10.96.0.0/12 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key --feature-gates=SCTPSupport=True cychong 29605 13731 0 00:06 pts/1 00:00:00 grep --color=auto kube-api cychong@mini1:/etc/kubernetes$ sudo kill -SIGHUP 21846 cychong@mini1:/etc/kubernetes$ ps -ef |grep kube-api root 30272 30246 79 00:07 ? 00:00:06 kube-apiserver --advertise-address=192.168.1.100 --allow-privileged=true --authorization-mode=Node,RBAC --client-ca-file=/etc/kubernetes/pki/ca.crt --enable-admission-plugins=NodeRestriction --enable-bootstrap-token-auth=true --etcd-cafile=/etc/kubernetes/pki/etcd/ca.crt --etcd-certfile=/etc/kubernetes/pki/apiserver-etcd-client.crt --etcd-keyfile=/etc/kubernetes/pki/apiserver-etcd-client.key --etcd-servers=https://127.0.0.1:2379 --insecure-port=0 --kubelet-client-certificate=/etc/kubernetes/pki/apiserver-kubelet-client.crt --kubelet-client-key=/etc/kubernetes/pki/apiserver-kubelet-client.key --kubelet-preferred-address-types=InternalIP,ExternalIP,Hostname --proxy-client-cert-file=/etc/kubernetes/pki/front-proxy-client.crt --proxy-client-key-file=/etc/kubernetes/pki/front-proxy-client.key --requestheader-allowed-names=front-proxy-client --requestheader-client-ca-file=/etc/kubernetes/pki/front-proxy-ca.crt --requestheader-extra-headers-prefix=X-Remote-Extra- --requestheader-group-headers=X-Remote-Group --requestheader-username-headers=X-Remote-User --secure-port=6443 --service-account-key-file=/etc/kubernetes/pki/sa.pub --service-cluster-ip-range=10.96.0.0/12 --tls-cert-file=/etc/kubernetes/pki/apiserver.crt --tls-private-key-file=/etc/kubernetes/pki/apiserver.key --feature-gates=SCTPSupport=True cychong 30644 13731 0 00:07 pts/1 00:00:00 grep --color=auto kube-api Check if SCTP service is supported cychong@mini1:~/work/sctp$ kubectl create -f service.yaml service/sctp created Check iptables cychong@mini1:~/work/sctp$ sudo iptables -L -n |grep 9999 REJECT sctp -- 0.0.0.0/0 10.98.74.252 /* default/sctp: has no endpoints */ sctp dpt:9999 reject-with icmp-port-unreachable Check SCTP by creating sample SCTP-server First delete manullay created service\ncychong@mini1:~/work/sctp$ kubectl delete svc sctp service \u0026#34;sctp\u0026#34; deleted Install helm chart from https://github.com/aweimeow/sctp-server. This helm chart will deploy a pod which has python based SCTP server.\ncychong@mini1:~/work/sctp$ git clone https://github.com/aweimeow/sctp-server Cloning into \u0026#39;sctp-server\u0026#39;... remote: Enumerating objects: 17, done. remote: Total 17 (delta 0), reused 0 (delta 0), pack-reused 17 Unpacking objects: 100% (17/17), done. cychong@mini1:~/work/sctp$ helm install -n sctp sctp-server NAME: sctp LAST DEPLOYED: Tue Oct 8 00:12:01 2019 NAMESPACE: default STATUS: DEPLOYED RESOURCES: ==\u0026gt; v1/Deployment NAME READY UP-TO-DATE AVAILABLE AGE sctp 0/1 0 0 3s ==\u0026gt; v1/Namespace NAME STATUS AGE sctp Active 4s ==\u0026gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE sctp-7c94d9b5c9-wsjnd 0/1 Pending 0 1s ==\u0026gt; v1/Service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE sctp NodePort 10.108.218.164 \u0026lt;none\u0026gt; 9999:30001/SCTP 4s NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services sctp) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT Check the pod and service\ncychong@mini1:~/work/sctp$ kubectl get svc NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.96.0.1 \u0026lt;none\u0026gt; 443/TCP 29d my-ghost NodePort 10.105.125.54 192.168.1.100 2368:32326/TCP 11d sctp NodePort 10.108.218.164 \u0026lt;none\u0026gt; 9999:30001/SCTP 2m42s cychong@mini1:~/work/sctp$ kubectl get pods -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES my-ghost-5f6578fd76-lb7xc 1/1 Running 41 11d 10.244.51.82 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; sctp-7c94d9b5c9-wsjnd 1/1 Running 0 2m55s 10.244.51.90 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; From the host, check if SCTP server is reachable from the host\ncychong@mini1:~/work/sctp$ ncat --sctp mini1 30001 Howdy! What\u0026#39;s your name? Memphis Ncat: Connection reset by peer. cychong@mini1:~/work/sctp$ TODO - client in Pod and server in outside cluster Reference Enabled SCTP in Kubernetes Cluster - aweimeow SCTP-server docker image - aweimeow Python sctp module - server side SCTP-server Helm Chart - aweimeow SCTP support in Openshift maybe be from 4.3 https://discuss.kubernetes.io/t/sctp-support-for-version-1-12-1/3203/8 ","date":"2019-10-07T15:39:35+09:00","permalink":"https://cychong47.github.io/post/2019/enable-sctp-in-kubernetes/","summary":"\u003ch2 id=\"check-if-sctp-is-supported-by-creating-sctp-service\"\u003eCheck if SCTP is supported by creating SCTP service\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://blog.aweimeow.tw/enable-sctp-in-kubernetes-cluster/\"\u003ehttps://blog.aweimeow.tw/enable-sctp-in-kubernetes-cluster/\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/work/sctp$ cat service.yaml\napiVersion: v1\nkind: Service\nmetadata:\n  name: sctp\nspec:\n  selector:\n    app: sctp\n  ports:\n  - protocol: SCTP\n    port: 9999\n    targetPort: 30001\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/work/sctp$ kubectl create -f service.yaml\nThe Service \u0026#34;sctp\u0026#34; is invalid: spec.ports[0].protocol: Unsupported value: \u0026#34;SCTP\u0026#34;: supported values: \u0026#34;TCP\u0026#34;, \u0026#34;UDP\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"enable-sctp-in-running-kubernetes-cluster\"\u003eEnable SCTP in running kubernetes cluster\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://stackoverflow.com/questions/55909512/how-to-configure-already-running-cluster-in-kubernetes\"\u003ehttps://stackoverflow.com/questions/55909512/how-to-configure-already-running-cluster-in-kubernetes\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eBasically you must pass this flag to kube-apiserver. How you can do that depends on how you set up the cluster. If you used kubeadm or kubespray then you should edit file \u003ccode\u003e/etc/kubernetes/manifests/kube-apiserver.yaml\u003c/code\u003e and add this flag somewhere under \u0026ldquo;command\u0026rdquo; field (somewhere between other flags). After that kube-apiserver pod should be restarted automatically. If not - you can kill it by hand.\u003c/p\u003e","title":"Enable SCTP in kubernetes"},{"content":"cychong@mini1:~/work/ghost-with-helm-x$ sudo apt update [sudo] password for cychong: Ign:2 http://dl.google.com/linux/chrome/deb stable InRelease Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:4 https://download.docker.com/linux/ubuntu bionic InRelease Hit:5 http://dl.google.com/linux/chrome/deb stable Release Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] Get:9 http://archive.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB] Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 DEP-11 Metadata [295 kB] Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 48x48 Icons [73.8 kB] Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 64x64 Icons [147 kB] Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 DEP-11 Metadata [254 kB] Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 48x48 Icons [197 kB] Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 64x64 Icons [453 kB] Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 DEP-11 Metadata [2468 B] Get:17 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 DEP-11 Metadata [7916 B] Get:18 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 Packages [526 kB] Get:19 http://archive.ubuntu.com/ubuntu bionic-security/main Translation-en [176 kB] Get:20 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 DEP-11 Metadata [38.5 kB] Get:21 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 48x48 Icons [17.6 kB] Get:22 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 64x64 Icons [41.5 kB] Get:23 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [611 kB] Get:24 http://archive.ubuntu.com/ubuntu bionic-security/universe Translation-en [203 kB] Get:25 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 DEP-11 Metadata [42.2 kB] Get:26 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 48x48 Icons [16.4 kB] Get:27 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 64x64 Icons [111 kB] Get:28 http://archive.ubuntu.com/ubuntu bionic-security/multiverse amd64 DEP-11 Metadata [2464 B] Fetched 3467 kB in 27s (128 kB/s) Reading package lists... Done Building dependency tree Reading state information... Done 41 packages can be upgraded. Run \u0026#39;apt list --upgradable\u0026#39; to see them. cychong@mini1:~/work/ghost-with-helm-x$ sudo apt-cache policy kubeadm kubeadm: Installed: 1.15.3-00 Candidate: 1.16.1-00 cychong@mini1:~/work/ghost-with-helm-x$ sudo apt-get install -y kubeadm=1.16.1-00 \u0026amp;\u0026amp; sudo apt-mark hold kubeadm Reading package lists... Done Building dependency tree Reading state information... Done The following package was automatically installed and is no longer required: libllvm7 Use \u0026#39;sudo apt autoremove\u0026#39; to remove it. The following packages will be upgraded: kubeadm 1 upgraded, 0 newly installed, 0 to remove and 40 not upgraded. Need to get 8764 kB of archives. After this operation, 4062 kB of additional disk space will be used. Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.16.1-00 [8764 kB] Fetched 8764 kB in 6s (1489 kB/s) (Reading database ... 237550 files and directories currently installed.) Preparing to unpack .../kubeadm_1.16.1-00_amd64.deb ... Unpacking kubeadm (1.16.1-00) over (1.15.3-00) ... Setting up kubeadm (1.16.1-00) ... kubeadm set on hold. cychong@mini1:~/work/ghost-with-helm-x$ kubeadm version kubeadm version: \u0026amp;version.Info{Major:\u0026#34;1\u0026#34;, Minor:\u0026#34;16\u0026#34;, GitVersion:\u0026#34;v1.16.1\u0026#34;, GitCommit:\u0026#34;d647ddbd755faf07169599a625faf302ffc34458\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;, BuildDate:\u0026#34;2019-10-02T16:58:27Z\u0026#34;, GoVersion:\u0026#34;go1.12.10\u0026#34;, Compiler:\u0026#34;gc\u0026#34;, Platform:\u0026#34;linux/amd64\u0026#34;} cychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade plan [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39; [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade] Fetching available versions to upgrade to [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/versions] Latest stable version: v1.16.1 [upgrade/versions] Latest version in the v1.15 series: v1.15.4 Components that must be upgraded manually after you have upgraded the control plane with \u0026#39;kubeadm upgrade apply\u0026#39;: COMPONENT CURRENT AVAILABLE Kubelet 1 x v1.15.3 v1.15.4 Upgrade to the latest version in the v1.15 series: COMPONENT CURRENT AVAILABLE API Server v1.15.3 v1.15.4 Controller Manager v1.15.3 v1.15.4 Scheduler v1.15.3 v1.15.4 Kube Proxy v1.15.3 v1.15.4 CoreDNS 1.3.1 1.6.2 Etcd 3.3.10 3.3.10 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.15.4 _____________________________________________________________________ Components that must be upgraded manually after you have upgraded the control plane with \u0026#39;kubeadm upgrade apply\u0026#39;: COMPONENT CURRENT AVAILABLE Kubelet 1 x v1.15.3 v1.16.1 Upgrade to the latest stable version: COMPONENT CURRENT AVAILABLE API Server v1.15.3 v1.16.1 Controller Manager v1.15.3 v1.16.1 Scheduler v1.15.3 v1.16.1 Kube Proxy v1.15.3 v1.16.1 CoreDNS 1.3.1 1.6.2 Etcd 3.3.10 3.3.15-0 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.16.1 _____________________________________________________________________ failed cychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade apply v1.16.1 [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39; [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade/version] You have chosen to change the cluster version to \u0026#34;v1.16.1\u0026#34; [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd] [upgrade/prepull] Prepulling image for component etcd. [upgrade/prepull] Prepulling image for component kube-controller-manager. [upgrade/prepull] Prepulling image for component kube-apiserver. [upgrade/prepull] Prepulling image for component kube-scheduler. [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [upgrade/prepull] Failed prepulled the images for the control plane components error: the prepull operation timed out To see the stack trace of this error execute with --v=5 or higher retry cychong@mini1:~$ sudo kubeadm upgrade apply v1.16.1 [sudo] password for cychong: [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39; [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade/version] You have chosen to change the cluster version to \u0026#34;v1.16.1\u0026#34; [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd] [upgrade/prepull] Prepulling image for component etcd. [upgrade/prepull] Prepulling image for component kube-controller-manager. [upgrade/prepull] Prepulling image for component kube-scheduler. [upgrade/prepull] Prepulling image for component kube-apiserver. [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [upgrade/prepull] Prepulled image for component kube-apiserver. [upgrade/prepull] Prepulled image for component etcd. [upgrade/prepull] Prepulled image for component kube-controller-manager. [upgrade/prepull] Prepulled image for component kube-scheduler. [upgrade/prepull] Successfully prepulled the images for all the control plane components [upgrade/apply] Upgrading your Static Pod-hosted control plane to version \u0026#34;v1.16.1\u0026#34;... Static pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538 Static pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10 Static pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75 [upgrade/etcd] Upgrading to TLS for etcd Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa [upgrade/staticpods] Preparing for \u0026#34;etcd\u0026#34; upgrade [upgrade/staticpods] Renewing etcd-server certificate [upgrade/staticpods] Renewing etcd-peer certificate [upgrade/staticpods] Renewing etcd-healthcheck-client certificate [upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/etcd.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/etcd.yaml\u0026#34; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: d96090bab45a5dababb3c3015960926b [apiclient] Found 1 Pods for label selector component=etcd [upgrade/staticpods] Component \u0026#34;etcd\u0026#34; upgraded successfully! [upgrade/etcd] Waiting for etcd to become available [upgrade/staticpods] Writing new Static Pod manifests to \u0026#34;/etc/kubernetes/tmp/kubeadm-upgraded-manifests306281752\u0026#34; [upgrade/staticpods] Preparing for \u0026#34;kube-apiserver\u0026#34; upgrade [upgrade/staticpods] Renewing apiserver certificate [upgrade/staticpods] Renewing apiserver-kubelet-client certificate [upgrade/staticpods] Renewing front-proxy-client certificate [upgrade/staticpods] Renewing apiserver-etcd-client certificate [upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-apiserver.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-apiserver.yaml\u0026#34; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538 Static pod: kube-apiserver-mini1 hash: 01800dd11dfbda441372caf7cbf8aa39 [apiclient] Found 1 Pods for label selector component=kube-apiserver [upgrade/staticpods] Component \u0026#34;kube-apiserver\u0026#34; upgraded successfully! [upgrade/staticpods] Preparing for \u0026#34;kube-controller-manager\u0026#34; upgrade [upgrade/staticpods] Renewing controller-manager.conf certificate [upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-controller-manager.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-controller-manager.yaml\u0026#34; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10 Static pod: kube-controller-manager-mini1 hash: e12d193633dcf11f6095d89ee58c45a9 [apiclient] Found 1 Pods for label selector component=kube-controller-manager [upgrade/staticpods] Component \u0026#34;kube-controller-manager\u0026#34; upgraded successfully! [upgrade/staticpods] Preparing for \u0026#34;kube-scheduler\u0026#34; upgrade [upgrade/staticpods] Renewing scheduler.conf certificate [upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-scheduler.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-scheduler.yaml\u0026#34; [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75 Static pod: kube-scheduler-mini1 hash: bf9014e67294b0df0bc373fd7024ced7 [apiclient] Found 1 Pods for label selector component=kube-scheduler [upgrade/staticpods] Component \u0026#34;kube-scheduler\u0026#34; upgraded successfully! [upload-config] Storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace [kubelet] Creating a ConfigMap \u0026#34;kubelet-config-1.16\u0026#34; in namespace kube-system with the configuration for the kubelets in the cluster [kubelet-start] Downloading configuration for the kubelet from the \u0026#34;kubelet-config-1.16\u0026#34; ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34; [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy [upgrade/successful] SUCCESS! Your cluster was upgraded to \u0026#34;v1.16.1\u0026#34;. Enjoy! [upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven\u0026#39;t already done so. Upgrade calico from v3.8 to v3.9 kubectl apply -f https://docs.projectcalico.org/v3.9/manifests/calico.yaml configmap/calico-config unchanged customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org unchanged clusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrole.rbac.authorization.k8s.io/calico-node configured clusterrolebinding.rbac.authorization.k8s.io/calico-node unchanged daemonset.apps/calico-node configured serviceaccount/calico-node unchanged deployment.apps/calico-kube-controllers configured serviceaccount/calico-kube-controllers unchanged 앗. 서브넷 변경하는 걸 깜빡\ncychong@mini1:~$ wget https://docs.projectcalico.org/v3.9/manifests/calico.yaml --2019-10-07 23:49:13-- https://docs.projectcalico.org/v3.9/manifests/calico.yaml Resolving docs.projectcalico.org (docs.projectcalico.org)... 104.248.78.23, 2604:a880:2:d0::21e9:b001 Connecting to docs.projectcalico.org (docs.projectcalico.org)|104.248.78.23|:443... connected. HTTP request sent, awaiting response... v200 OK Length: 20648 (20K) [application/x-yaml] Saving to: ‘calico.yaml’ calico.yaml 0%[ ] 0 --.-KB/s icalico.yaml 100%[=============================================================\u0026gt;] 20.16K 123KB/s in 0.2s c2019-10-07 23:49:14 (123 KB/s) - ‘calico.yaml’ saved [20648/20648] Change CALICO_IPV4POOL_CIDR\n- name: CALICO_IPV4POOL_CIDR value: \u0026#34;10.201.0.0/24\u0026#34; Upgrade kubelet and kubectl cychong@mini1:~$ sudo apt-mark unhold kubelet kubectl \u0026amp;\u0026amp; sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y kubelet=1.16.1-00 kubectl=1.16.1-00 \u0026amp;\u0026amp; sudo apt-mark hold kubelet kubectl Canceled hold on kubelet. Canceled hold on kubectl. Ign:2 http://dl.google.com/linux/chrome/deb stable InRelease Hit:3 http://dl.google.com/linux/chrome/deb stable Release Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:5 https://download.docker.com/linux/ubuntu bionic InRelease Hit:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease Hit:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Hit:9 http://archive.ubuntu.com/ubuntu bionic-security InRelease Reading package lists... Done Reading package lists... Done Building dependency tree Reading state information... Done The following package was automatically installed and is no longer required: libllvm7 Use \u0026#39;sudo apt autoremove\u0026#39; to remove it. The following packages will be upgraded: kubectl kubelet 2 upgraded, 0 newly installed, 0 to remove and 39 not upgraded. Need to get 29.9 MB of archives. After this operation, 7179 kB of additional disk space will be used. Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubectl amd64 1.16.1-00 [9234 kB] Get:2 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubelet amd64 1.16.1-00 [20.7 MB] Fetched 29.9 MB in 6s (4899 kB/s) (Reading database ... 237550 files and directories currently installed.) Preparing to unpack .../kubectl_1.16.1-00_amd64.deb ... Unpacking kubectl (1.16.1-00) over (1.15.3-00) ... Preparing to unpack .../kubelet_1.16.1-00_amd64.deb ... Unpacking kubelet (1.16.1-00) over (1.15.3-00) ... Setting up kubelet (1.16.1-00) ... Setting up kubectl (1.16.1-00) ... kubelet set on hold. kubectl set on hold. cychong@mini1:~$ sudo systemctl restart kubelet cychong@mini1:~$ Check the status cychong@mini1:~$ kubectl get nodes NAME STATUS ROLES AGE VERSION mini1 Ready master 29d v1.16.1 Reference\nhttps://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/ ","date":"2019-10-07T15:37:14+09:00","permalink":"https://cychong47.github.io/post/2019/upgrade-kubernetes/","summary":"\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/work/ghost-with-helm-x$ sudo apt update\n[sudo] password for cychong:\nIgn:2 http://dl.google.com/linux/chrome/deb stable InRelease\nHit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\nHit:4 https://download.docker.com/linux/ubuntu bionic InRelease\nHit:5 http://dl.google.com/linux/chrome/deb stable Release\nGet:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\nHit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease\nGet:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\nGet:9 http://archive.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\nGet:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 DEP-11 Metadata [295 kB]\nGet:11 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 48x48 Icons [73.8 kB]\nGet:12 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 64x64 Icons [147 kB]\nGet:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 DEP-11 Metadata [254 kB]\nGet:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 48x48 Icons [197 kB]\nGet:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 64x64 Icons [453 kB]\nGet:16 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 DEP-11 Metadata [2468 B]\nGet:17 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 DEP-11 Metadata [7916 B]\nGet:18 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 Packages [526 kB]\nGet:19 http://archive.ubuntu.com/ubuntu bionic-security/main Translation-en [176 kB]\nGet:20 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 DEP-11 Metadata [38.5 kB]\nGet:21 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 48x48 Icons [17.6 kB]\nGet:22 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 64x64 Icons [41.5 kB]\nGet:23 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [611 kB]\nGet:24 http://archive.ubuntu.com/ubuntu bionic-security/universe Translation-en [203 kB]\nGet:25 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 DEP-11 Metadata [42.2 kB]\nGet:26 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 48x48 Icons [16.4 kB]\nGet:27 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 64x64 Icons [111 kB]\nGet:28 http://archive.ubuntu.com/ubuntu bionic-security/multiverse amd64 DEP-11 Metadata [2464 B]\nFetched 3467 kB in 27s (128 kB/s)\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\n41 packages can be upgraded. Run \u0026#39;apt list --upgradable\u0026#39; to see them.\n\ncychong@mini1:~/work/ghost-with-helm-x$ sudo apt-cache policy kubeadm\nkubeadm:\n  Installed: 1.15.3-00\n  Candidate: 1.16.1-00\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/work/ghost-with-helm-x$  sudo apt-get install -y kubeadm=1.16.1-00 \u0026amp;\u0026amp; sudo apt-mark hold kubeadm\nReading package lists... Done\nBuilding dependency tree\nReading state information... Done\nThe following package was automatically installed and is no longer required:\n  libllvm7\nUse \u0026#39;sudo apt autoremove\u0026#39; to remove it.\nThe following packages will be upgraded:\n  kubeadm\n1 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\nNeed to get 8764 kB of archives.\nAfter this operation, 4062 kB of additional disk space will be used.\nGet:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.16.1-00 [8764 kB]\nFetched 8764 kB in 6s (1489 kB/s)\n(Reading database ... 237550 files and directories currently installed.)\nPreparing to unpack .../kubeadm_1.16.1-00_amd64.deb ...\nUnpacking kubeadm (1.16.1-00) over (1.15.3-00) ...\nSetting up kubeadm (1.16.1-00) ...\nkubeadm set on hold.\n\ncychong@mini1:~/work/ghost-with-helm-x$ kubeadm version\nkubeadm version: \u0026amp;version.Info{Major:\u0026#34;1\u0026#34;, Minor:\u0026#34;16\u0026#34;, GitVersion:\u0026#34;v1.16.1\u0026#34;, GitCommit:\u0026#34;d647ddbd755faf07169599a625faf302ffc34458\u0026#34;, GitTreeState:\u0026#34;clean\u0026#34;, BuildDate:\u0026#34;2019-10-02T16:58:27Z\u0026#34;, GoVersion:\u0026#34;go1.12.10\u0026#34;, Compiler:\u0026#34;gc\u0026#34;, Platform:\u0026#34;linux/amd64\u0026#34;}\n\ncychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade plan\n[upgrade/config] Making sure the configuration is correct:\n[upgrade/config] Reading configuration from the cluster...\n[upgrade/config] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39;\n[preflight] Running pre-flight checks.\n[upgrade] Making sure the cluster is healthy:\n[upgrade] Fetching available versions to upgrade to\n[upgrade/versions] Cluster version: v1.15.3\n[upgrade/versions] kubeadm version: v1.16.1\n[upgrade/versions] Latest stable version: v1.16.1\n[upgrade/versions] Latest version in the v1.15 series: v1.15.4\n\nComponents that must be upgraded manually after you have upgraded the control plane with \u0026#39;kubeadm upgrade apply\u0026#39;:\nCOMPONENT   CURRENT       AVAILABLE\nKubelet     1 x v1.15.3   v1.15.4\n\nUpgrade to the latest version in the v1.15 series:\n\nCOMPONENT            CURRENT   AVAILABLE\nAPI Server           v1.15.3   v1.15.4\nController Manager   v1.15.3   v1.15.4\nScheduler            v1.15.3   v1.15.4\nKube Proxy           v1.15.3   v1.15.4\nCoreDNS              1.3.1     1.6.2\nEtcd                 3.3.10    3.3.10\n\nYou can now apply the upgrade by executing the following command:\n\n\tkubeadm upgrade apply v1.15.4\n\n_____________________________________________________________________\n\nComponents that must be upgraded manually after you have upgraded the control plane with \u0026#39;kubeadm upgrade apply\u0026#39;:\nCOMPONENT   CURRENT       AVAILABLE\nKubelet     1 x v1.15.3   v1.16.1\n\nUpgrade to the latest stable version:\n\nCOMPONENT            CURRENT   AVAILABLE\nAPI Server           v1.15.3   v1.16.1\nController Manager   v1.15.3   v1.16.1\nScheduler            v1.15.3   v1.16.1\nKube Proxy           v1.15.3   v1.16.1\nCoreDNS              1.3.1     1.6.2\nEtcd                 3.3.10    3.3.15-0\n\nYou can now apply the upgrade by executing the following command:\n\n\tkubeadm upgrade apply v1.16.1\n\n_____________________________________________________________________\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"failed\"\u003efailed\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade apply v1.16.1\n[upgrade/config] Making sure the configuration is correct:\n[upgrade/config] Reading configuration from the cluster...\n[upgrade/config] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39;\n[preflight] Running pre-flight checks.\n[upgrade] Making sure the cluster is healthy:\n[upgrade/version] You have chosen to change the cluster version to \u0026#34;v1.16.1\u0026#34;\n[upgrade/versions] Cluster version: v1.15.3\n[upgrade/versions] kubeadm version: v1.16.1\n[upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y\n[upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd]\n[upgrade/prepull] Prepulling image for component etcd.\n[upgrade/prepull] Prepulling image for component kube-controller-manager.\n[upgrade/prepull] Prepulling image for component kube-apiserver.\n[upgrade/prepull] Prepulling image for component kube-scheduler.\n[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler\n[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver\n[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager\n[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver\n\n\n[upgrade/prepull] Failed prepulled the images for the control plane components error: the prepull operation timed out\nTo see the stack trace of this error execute with --v=5 or higher\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"retry\"\u003eretry\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ sudo kubeadm upgrade apply v1.16.1\n[sudo] password for cychong:\n[upgrade/config] Making sure the configuration is correct:\n[upgrade/config] Reading configuration from the cluster...\n[upgrade/config] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39;\n[preflight] Running pre-flight checks.\n[upgrade] Making sure the cluster is healthy:\n[upgrade/version] You have chosen to change the cluster version to \u0026#34;v1.16.1\u0026#34;\n[upgrade/versions] Cluster version: v1.15.3\n[upgrade/versions] kubeadm version: v1.16.1\n[upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y\n[upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd]\n[upgrade/prepull] Prepulling image for component etcd.\n[upgrade/prepull] Prepulling image for component kube-controller-manager.\n[upgrade/prepull] Prepulling image for component kube-scheduler.\n[upgrade/prepull] Prepulling image for component kube-apiserver.\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager\n[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler\n[upgrade/prepull] Prepulled image for component kube-apiserver.\n[upgrade/prepull] Prepulled image for component etcd.\n[upgrade/prepull] Prepulled image for component kube-controller-manager.\n[upgrade/prepull] Prepulled image for component kube-scheduler.\n[upgrade/prepull] Successfully prepulled the images for all the control plane components\n[upgrade/apply] Upgrading your Static Pod-hosted control plane to version \u0026#34;v1.16.1\u0026#34;...\nStatic pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538\nStatic pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10\nStatic pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75\n[upgrade/etcd] Upgrading to TLS for etcd\nStatic pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa\n[upgrade/staticpods] Preparing for \u0026#34;etcd\u0026#34; upgrade\n[upgrade/staticpods] Renewing etcd-server certificate\n[upgrade/staticpods] Renewing etcd-peer certificate\n[upgrade/staticpods] Renewing etcd-healthcheck-client certificate\n[upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/etcd.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/etcd.yaml\u0026#34;\n[upgrade/staticpods] Waiting for the kubelet to restart the component\n[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)\nStatic pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa\nStatic pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa\nStatic pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa\nStatic pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa\nStatic pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa\nStatic pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa\nStatic pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa\nStatic pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa\nStatic pod: etcd-mini1 hash: d96090bab45a5dababb3c3015960926b\n[apiclient] Found 1 Pods for label selector component=etcd\n[upgrade/staticpods] Component \u0026#34;etcd\u0026#34; upgraded successfully!\n[upgrade/etcd] Waiting for etcd to become available\n[upgrade/staticpods] Writing new Static Pod manifests to \u0026#34;/etc/kubernetes/tmp/kubeadm-upgraded-manifests306281752\u0026#34;\n[upgrade/staticpods] Preparing for \u0026#34;kube-apiserver\u0026#34; upgrade\n[upgrade/staticpods] Renewing apiserver certificate\n[upgrade/staticpods] Renewing apiserver-kubelet-client certificate\n[upgrade/staticpods] Renewing front-proxy-client certificate\n[upgrade/staticpods] Renewing apiserver-etcd-client certificate\n[upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-apiserver.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-apiserver.yaml\u0026#34;\n[upgrade/staticpods] Waiting for the kubelet to restart the component\n[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)\nStatic pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538\nStatic pod: kube-apiserver-mini1 hash: 01800dd11dfbda441372caf7cbf8aa39\n[apiclient] Found 1 Pods for label selector component=kube-apiserver\n[upgrade/staticpods] Component \u0026#34;kube-apiserver\u0026#34; upgraded successfully!\n[upgrade/staticpods] Preparing for \u0026#34;kube-controller-manager\u0026#34; upgrade\n[upgrade/staticpods] Renewing controller-manager.conf certificate\n[upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-controller-manager.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-controller-manager.yaml\u0026#34;\n[upgrade/staticpods] Waiting for the kubelet to restart the component\n[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)\nStatic pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10\nStatic pod: kube-controller-manager-mini1 hash: e12d193633dcf11f6095d89ee58c45a9\n[apiclient] Found 1 Pods for label selector component=kube-controller-manager\n[upgrade/staticpods] Component \u0026#34;kube-controller-manager\u0026#34; upgraded successfully!\n[upgrade/staticpods] Preparing for \u0026#34;kube-scheduler\u0026#34; upgrade\n[upgrade/staticpods] Renewing scheduler.conf certificate\n[upgrade/staticpods] Moved new manifest to \u0026#34;/etc/kubernetes/manifests/kube-scheduler.yaml\u0026#34; and backed up old manifest to \u0026#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-scheduler.yaml\u0026#34;\n[upgrade/staticpods] Waiting for the kubelet to restart the component\n[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)\nStatic pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75\nStatic pod: kube-scheduler-mini1 hash: bf9014e67294b0df0bc373fd7024ced7\n[apiclient] Found 1 Pods for label selector component=kube-scheduler\n[upgrade/staticpods] Component \u0026#34;kube-scheduler\u0026#34; upgraded successfully!\n[upload-config] Storing the configuration used in ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace\n[kubelet] Creating a ConfigMap \u0026#34;kubelet-config-1.16\u0026#34; in namespace kube-system with the configuration for the kubelets in the cluster\n[kubelet-start] Downloading configuration for the kubelet from the \u0026#34;kubelet-config-1.16\u0026#34; ConfigMap in the kube-system namespace\n[kubelet-start] Writing kubelet configuration to file \u0026#34;/var/lib/kubelet/config.yaml\u0026#34;\n[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials\n[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token\n[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster\n[addons] Applied essential addon: CoreDNS\n[addons] Applied essential addon: kube-proxy\n\n[upgrade/successful] SUCCESS! Your cluster was upgraded to \u0026#34;v1.16.1\u0026#34;. Enjoy!\n\n[upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven\u0026#39;t already done so.\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"upgrade-calico-from-v38-to-v39\"\u003eUpgrade calico from v3.8 to v3.9\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ekubectl apply -f https://docs.projectcalico.org/v3.9/manifests/calico.yaml\nconfigmap/calico-config unchanged\ncustomresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org unchanged\ncustomresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org unchanged\nclusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchanged\nclusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchanged\nclusterrole.rbac.authorization.k8s.io/calico-node configured\nclusterrolebinding.rbac.authorization.k8s.io/calico-node unchanged\ndaemonset.apps/calico-node configured\nserviceaccount/calico-node unchanged\ndeployment.apps/calico-kube-controllers configured\nserviceaccount/calico-kube-controllers unchanged\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e앗. 서브넷 변경하는 걸 깜빡\u003c/p\u003e","title":"Upgrade kubernetes to 1.16.1"},{"content":"하나의 Helm chart를 이용하여 여러 개의 pod를 설치 하는 nested chart 인 경우 각각의 pod에 대한 CPU requirement는 각 subchart의 values.yaml에 resources 항목에 기술하면 된다.\n아래는 ONAP중 closed loop control에서 Data collection을 담당하는 DCAE의 SW들을 kubernets에 배포하기 위해 만들어진 차트들이다. 다음과 같이 8개의 chart들로 구성되어 있고,\n$ tree -d oom/kubernetes/dcaegen2/charts/ -L 1 oom/kubernetes/dcaegen2/charts/ ├── dcae-bootstrap ├── dcae-cloudify-manager ├── dcae-config-binding-service ├── dcae-deployment-handler ├── dcae-healthcheck ├── dcae-policy-handler ├── dcae-redis └── dcae-servicechange-handler 8 directories 각각의 subchart는 각자의 values.yaml 파일을 가지고 있다.\ncychong@mini1:~/work/oom/kubernetes/dcaegen2$ find . -name values.yaml ./charts/dcae-redis/values.yaml ./charts/dcae-deployment-handler/values.yaml ./charts/dcae-servicechange-handler/charts/dcae-inventory-api/values.yaml ./charts/dcae-servicechange-handler/values.yaml ./charts/dcae-policy-handler/values.yaml ./charts/dcae-healthcheck/values.yaml ./charts/dcae-config-binding-service/values.yaml ./charts/dcae-bootstrap/values.yaml ./charts/dcae-cloudify-manager/values.yaml ./values.yaml dcae-redis chart의 values.yaml 파일을 보면 다음과 같이 CPU, memory에 대한 요구사항을 기술하고 있다.\n# Resource Limit flavor -By Default using small flavor: small # Segregation for Different environment (Small and Large) resources: small: limits: cpu: 2 memory: 2Gi requests: cpu: 1 memory: 1Gi large: limits: cpu: 4 memory: 4Gi requests: cpu: 2 memory: 2Gi unlimited: {} ","date":"2019-09-29T14:35:21+09:00","permalink":"https://cychong47.github.io/post/2019/convention-on-impose-core-requirements/","summary":"\u003cp\u003e하나의 Helm chart를 이용하여 여러 개의 pod를 설치 하는 nested chart 인 경우 각각의 pod에 대한 CPU requirement는 각 subchart의 values.yaml에 resources 항목에 기술하면 된다.\u003c/p\u003e\n\u003cp\u003e아래는 ONAP중 closed loop control에서 Data collection을 담당하는 \u003ca href=\"https://wiki.onap.org/pages/viewpage.action?pageId=1015831\"\u003eDCAE\u003c/a\u003e의 SW들을 kubernets에 배포하기 위해 만들어진 차트들이다. 다음과 같이 8개의 chart들로 구성되어 있고,\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ tree -d oom/kubernetes/dcaegen2/charts/ -L 1\noom/kubernetes/dcaegen2/charts/\n├── dcae-bootstrap\n├── dcae-cloudify-manager\n├── dcae-config-binding-service\n├── dcae-deployment-handler\n├── dcae-healthcheck\n├── dcae-policy-handler\n├── dcae-redis\n└── dcae-servicechange-handler\n\n8 directories\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e각각의 subchart는 각자의 values.yaml 파일을 가지고 있다.\u003c/p\u003e","title":"Convention on impose core requirements"},{"content":"multipass? Multipass is a lightweight VM manager for Linux, Windows and macOS. It\u0026rsquo;s designed for developers who want a fresh Ubuntu environment with a single command. It uses KVM on Linux, Hyper-V on Windows and HyperKit on macOS to run the VM with minimal overhead. It can also use VirtualBox on Windows and macOS. Multipass will fetch images for you and keep them up to date.\nSince it supports metadata for cloud-init, you can simulate a small cloud deployment on your laptop or workstation.\nhttps://github.com/CanonicalLtd/multipass\nLinux 외에 Windows 그리고 Mac OS를 지원하는 multipass를 사용하면 virtualbox를 사용하지 않고도 OS X에서 VM을 쉽게 만들어 linux 기반의 환경을 구성할 수 있다.\n아래 예에서는 OS X에서 multipass를 이용해서 Linux(Ubuntu) VM을 생성하고, kubernetes를 설치해 본다.\ninstall multipass with brew mbpr15:~ cychong$ brew cask install multipass Updating Homebrew... ... ==\u0026gt; Satisfying dependencies ==\u0026gt; Downloading https://github.com/CanonicalLtd/multipass/releases/download/v0.8.0/multipass-0.8.0+mac-Darwin.pkg ==\u0026gt; Downloading from https://github-production-release-asset-2e65be.s3.amazonaws.com/114128199/8489a680-ac9c-11e9-99 ######################################################################## 100.0% ==\u0026gt; Verifying SHA-256 checksum for Cask \u0026#39;multipass\u0026#39;. ==\u0026gt; Installing Cask multipass ==\u0026gt; Running installer for multipass; your password may be necessary. ==\u0026gt; Package installers may write to any location; options such as --appdir are ignored. Password: installer: Package name is multipass installer: Installing at base path / installer: The install was successful. 🍺 multipass was successfully installed! Multipass multipass find mbpr15:~ cychong$ multipass find Image Aliases Version Description snapcraft:core core16 20190819 Snapcraft builder for Core 16 snapcraft:core18 20190820 Snapcraft builder for Core 18 16.04 xenial 20190814 Ubuntu 16.04 LTS 18.04 bionic,lts 20190813.1 Ubuntu 18.04 LTS Create VM multipass launch mbpr15:~ cychong$ multipass launch --name vm --mem 4G --disk 20G --cpus 2 Launched: vm list VMs mbpr15:~ cychong$ multipass list Name State IPv4 Image vm Running 192.168.64.2 Ubuntu 18.04 LTS execute command in VM from host mbpr15:~ cychong$ multipass exec vm -- uname -a Linux vm 4.15.0-58-generic #64-Ubuntu SMP Tue Aug 6 11:12:41 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux login to VM mbpr15:~ cychong$ multipass shell vm Welcome to Ubuntu 18.04.3 LTS (GNU/Linux 4.15.0-58-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage System information as of Sun Aug 25 20:26:01 KST 2019 System load: 0.0 Processes: 101 Usage of /: 5.1% of 19.21GB Users logged in: 0 Memory usage: 3% IP address for enp0s2: 192.168.64.2 Swap usage: 0% 0 packages can be updated. 0 updates are security updates. To run a command as administrator (user \u0026#34;root\u0026#34;), use \u0026#34;sudo \u0026lt;command\u0026gt;\u0026#34;. See \u0026#34;man sudo_root\u0026#34; for details. multipass@vm:~$ Setup a single node kubernetes cluster multipass@vm:~$ curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - OK multipass@vm:~$ sudo add-apt-repository \u0026#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable\u0026#34; Get:1 https://download.docker.com/linux/ubuntu bionic InRelease [64.4 kB] Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease Get:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB] Get:5 https://download.docker.com/linux/ubuntu bionic/stable amd64 Packages [7889 B] Get:6 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [485 kB] Get:7 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] Get:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [8570 kB] Get:9 http://security.ubuntu.com/ubuntu bionic-security/main Translation-en [165 kB] Get:10 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [4976 B] Get:11 http://security.ubuntu.com/ubuntu bionic-security/restricted Translation-en [2476 B] Get:12 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [598 kB] Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe Translation-en [199 kB] Get:14 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [4004 B] Get:15 http://security.ubuntu.com/ubuntu bionic-security/multiverse Translation-en [2060 B] Get:16 http://archive.ubuntu.com/ubuntu bionic/universe Translation-en [4941 kB] Get:17 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [151 kB] Get:18 http://archive.ubuntu.com/ubuntu bionic/multiverse Translation-en [108 kB] Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [712 kB] Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main Translation-en [259 kB] Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [11.9 kB] Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/restricted Translation-en [4156 B] Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [999 kB] Get:24 http://archive.ubuntu.com/ubuntu bionic-updates/universe Translation-en [306 kB] Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [6636 B] Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse Translation-en [3556 B] Get:27 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [2512 B] Get:28 http://archive.ubuntu.com/ubuntu bionic-backports/main Translation-en [1644 B] Get:29 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [4000 B] Get:30 http://archive.ubuntu.com/ubuntu bionic-backports/universe Translation-en [1856 B] Preparing to unpack .../1-aufs-tools_1%3a4.9+20170918-1ubuntu1_amd64.deb ... Unpacking aufs-tools (1:4.9+20170918-1ubuntu1) ... Selecting previously unselected package cgroupfs-mount. Preparing to unpack .../2-cgroupfs-mount_1.4_all.deb ... Unpacking cgroupfs-mount (1.4) ... Selecting previously unselected package containerd.io. Preparing to unpack .../3-containerd.io_1.2.6-3_amd64.deb ... Unpacking containerd.io (1.2.6-3) ... Selecting previously unselected package docker-ce-cli. Preparing to unpack .../4-docker-ce-cli_5%3a19.03.1~3-0~ubuntu-bionic_amd64.deb ... Unpacking docker-ce-cli (5:19.03.1~3-0~ubuntu-bionic) ... Selecting previously unselected package docker-ce. Preparing to unpack .../5-docker-ce_5%3a19.03.1~3-0~ubuntu-bionic_amd64.deb ... Unpacking docker-ce (5:19.03.1~3-0~ubuntu-bionic) ... Selecting previously unselected package libltdl7:amd64. Preparing to unpack .../6-libltdl7_2.4.6-2_amd64.deb ... Unpacking libltdl7:amd64 (2.4.6-2) ... Setting up aufs-tools (1:4.9+20170918-1ubuntu1) ... Setting up containerd.io (1.2.6-3) ... Created symlink /etc/systemd/system/multi-user.target.wants/containerd.service → /lib/systemd/system/containerd.service. Processing triggers for ureadahead (0.100.0-21) ... Setting up cgroupfs-mount (1.4) ... Processing triggers for libc-bin (2.27-3ubuntu1) ... Processing triggers for systemd (237-3ubuntu10.25) ... Setting up libltdl7:amd64 (2.4.6-2) ... Processing triggers for man-db (2.8.3-2ubuntu0.1) ... Setting up docker-ce-cli (5:19.03.1~3-0~ubuntu-bionic) ... Setting up pigz (2.4-1) ... Setting up docker-ce (5:19.03.1~3-0~ubuntu-bionic) ... Created symlink /etc/systemd/system/multi-user.target.wants/docker.service → /lib/systemd/system/docker.service. Created symlink /etc/systemd/system/sockets.target.wants/docker.socket → /lib/systemd/system/docker.socket. Processing triggers for ureadahead (0.100.0-21) ... Processing triggers for libc-bin (2.27-3ubuntu1) ... Processing triggers for systemd (237-3ubuntu10.25) ... multipass@vm:~$ sudo swapoff -a multipass@vm:~$ sudo sed -i \u0026#39;/ swap / s/^\\(.*\\)$/#\\1/g\u0026#39; /etc/fstab multipass@vm:~$ sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y apt-transport-https \u0026amp;\u0026amp; curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:3 https://download.docker.com/linux/ubuntu bionic InRelease Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Hit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Reading package lists... Done Reading package lists... Done Building dependency tree Reading state information... Done The following package was automatically installed and is no longer required: grub-pc-bin Use \u0026#39;sudo apt autoremove\u0026#39; to remove it. The following NEW packages will be installed: apt-transport-https 0 upgraded, 1 newly installed, 0 to remove and 6 not upgraded. Need to get 1692 B of archives. After this operation, 153 kB of additional disk space will be used. Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 apt-transport-https all 1.6.11 [1692 B] Fetched 1692 B in 1s (2906 B/s) Selecting previously unselected package apt-transport-https. (Reading database ... 60304 files and directories currently installed.) Preparing to unpack .../apt-transport-https_1.6.11_all.deb ... Unpacking apt-transport-https (1.6.11) ... Setting up apt-transport-https (1.6.11) ... OK multipass@vm:~$ echo \u0026#34;deb http://apt.kubernetes.io/ kubernetes-xenial main\u0026#34; | sudo tee -a /etc/apt/sources.list.d/kubernetes.list \u0026amp;\u0026amp; sudo apt-get update deb http://apt.kubernetes.io/ kubernetes-xenial main Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:3 https://download.docker.com/linux/ubuntu bionic InRelease Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Hit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Get:6 https://packages.cloud.google.com/apt kubernetes-xenial InRelease [8993 B] Get:7 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 Packages [28.9 kB] Fetched 37.9 kB in 2s (15.3 kB/s) Reading package lists... Done multipass@vm:~$ sudo apt-get update \u0026amp;\u0026amp; sudo apt-get install -y apt-transport-https \u0026amp;\u0026amp; curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - Hit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease Hit:2 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:3 https://download.docker.com/linux/ubuntu bionic InRelease Hit:4 http://archive.ubuntu.com/ubuntu bionic-updates InRelease Hit:5 http://archive.ubuntu.com/ubuntu bionic-backports InRelease Reading package lists... Done Reading package lists... Done Building dependency tree Reading state information... Done The following package was automatically installed and is no longer required: grub-pc-bin Use \u0026#39;sudo apt autoremove\u0026#39; to remove it. The following NEW packages will be installed: apt-transport-https 0 upgraded, 1 newly installed, 0 to remove and 6 not upgraded. Need to get 1692 B of archives. After this operation, 153 kB of additional disk space will be used. Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 apt-transport-https all 1.6.11 [1692 B] Fetched 1692 B in 1s (2906 B/s) Selecting previously unselected package apt-transport-https. (Reading database ... 60304 files and directories currently installed.) Preparing to unpack .../apt-transport-https_1.6.11_all.deb ... Unpacking apt-transport-https (1.6.11) ... Get:3 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubelet amd64 1.15.3-00 [20.2 MB] Get:4 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubectl amd64 1.15.3-00 [8763 kB] Get:5 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.15.3-00 [8248 kB] Fetched 52.9 MB in 27s (1972 kB/s) Selecting previously unselected package conntrack. (Reading database ... 60308 files and directories currently installed.) Preparing to unpack .../0-conntrack_1%3a1.4.4+snapshot20161117-6ubuntu2_amd64.deb ... Unpacking conntrack (1:1.4.4+snapshot20161117-6ubuntu2) ... Selecting previously unselected package cri-tools. Preparing to unpack .../1-cri-tools_1.13.0-00_amd64.deb ... Unpacking cri-tools (1.13.0-00) ... Selecting previously unselected package kubernetes-cni. Preparing to unpack .../2-kubernetes-cni_0.7.5-00_amd64.deb ... Unpacking kubernetes-cni (0.7.5-00) ... Selecting previously unselected package socat. Preparing to unpack .../3-socat_1.7.3.2-2ubuntu2_amd64.deb ... Unpacking socat (1.7.3.2-2ubuntu2) ... Selecting previously unselected package kubelet. Preparing to unpack .../4-kubelet_1.15.3-00_amd64.deb ... Unpacking kubelet (1.15.3-00) ... Selecting previously unselected package kubectl. Preparing to unpack .../5-kubectl_1.15.3-00_amd64.deb ... Unpacking kubectl (1.15.3-00) ... Selecting previously unselected package kubeadm. Preparing to unpack .../6-kubeadm_1.15.3-00_amd64.deb ... Unpacking kubeadm (1.15.3-00) ... Setting up conntrack (1:1.4.4+snapshot20161117-6ubuntu2) ... Setting up kubernetes-cni (0.7.5-00) ... Setting up cri-tools (1.13.0-00) ... Setting up socat (1.7.3.2-2ubuntu2) ... Setting up kubelet (1.15.3-00) ... Created symlink /etc/systemd/system/multi-user.target.wants/kubelet.service → /lib/systemd/system/kubelet.service. Setting up kubectl (1.15.3-00) ... Processing triggers for man-db (2.8.3-2ubuntu0.1) ... Setting up kubeadm (1.15.3-00) ... multipass@vm:~$ sudo kubeadm init --pod-network-cidr=10.201.0.0/24 --token-ttl 0 ... multipass@vm:~$ mkdir -p $HOME/.kube multipass@vm:~$ sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config multipass@vm:~$ sudo chown $(id -u):$(id -g) $HOME/.kube/config multipass@vm:~$ kubectl get pods --all-namespaces -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system coredns-5c98db65d4-ksh4p 0/1 Pending 0 21m \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system coredns-5c98db65d4-nvvzg 0/1 Pending 0 21m \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system etcd-vm 1/1 Running 0 20m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-apiserver-vm 1/1 Running 0 20m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-controller-manager-vm 1/1 Running 0 20m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-proxy-b8qf2 1/1 Running 0 21m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-scheduler-vm 1/1 Running 0 20m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; install calico multipass@vm:~$ wget https://docs.projectcalico.org/v3.8/manifests/calico.yaml --2019-08-25 21:26:00-- https://docs.projectcalico.org/v3.8/manifests/calico.yaml Resolving docs.projectcalico.org (docs.projectcalico.org)... 206.189.73.52, 2604:a880:2:d0::21e9:c001 Connecting to docs.projectcalico.org (docs.projectcalico.org)|206.189.73.52|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 20628 (20K) [application/x-yaml] Saving to: ‘calico.yaml’ calico.yaml 100%[==============================================\u0026gt;] 20.14K 93.2KB/s in 0.2s 2019-08-25 21:26:02 (93.2 KB/s) - ‘calico.yaml’ saved [20628/20628] Change CALICO_IPV4POOL_CIDR\n- name: CALICO_IPV4POOL_CIDR value: \u0026#34;10.201.0.0/24\u0026#34; multipass@vm:~$ kubectl apply -f calico.yaml configmap/calico-config unchanged customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org unchanged clusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrole.rbac.authorization.k8s.io/calico-node unchanged clusterrolebinding.rbac.authorization.k8s.io/calico-node unchanged daemonset.apps/calico-node configured serviceaccount/calico-node unchanged deployment.apps/calico-kube-controllers unchanged serviceaccount/calico-kube-controllers unchanged multipass@vm:~$ kubectl get pods --all-namespaces -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system calico-kube-controllers-65b8787765-5rftm 1/1 Running 0 3m57s 192.168.141.65 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system calico-node-dtbhl 1/1 Running 0 44s 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system coredns-5c98db65d4-ksh4p 1/1 Running 0 25m 192.168.141.66 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system coredns-5c98db65d4-nvvzg 1/1 Running 0 25m 192.168.141.67 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system etcd-vm 1/1 Running 0 24m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-apiserver-vm 1/1 Running 0 24m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-controller-manager-vm 1/1 Running 0 24m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-proxy-b8qf2 1/1 Running 0 25m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-scheduler-vm 1/1 Running 0 25m 192.168.64.2 vm \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; multipass@vm:~$ kubectl taint nodes --all node-role.kubernetes.io/master- node/vm untainted Install calicoctl https://docs.projectcalico.org/v3.5/usage/calicoctl/install\nmultipass@vm:~$ curl -O -L https://github.com/projectcalico/calicoctl/releases/download/v3.5.8/calicoctl multipass@vm:~$ chmod +x calicoctl multipass@vm:~$ ./calicoctl get profiles Failed to create Calico API client: no etcd endpoints specified multipass@vm:~$ kubectl apply -f \\ \u0026gt; https://docs.projectcalico.org/v3.5/getting-started/kubernetes/installation/hosted/calicoctl.yaml pod/calicoctl created multipass@vm:~$ kubectl exec -ti -n kube-system calicoctl -- /calicoctl get profiles -o wide error: unable to upgrade connection: container not found (\u0026#34;calicoctl\u0026#34;) multipass@vm:~$ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system calico-kube-controllers-65b8787765-5rftm 1/1 Running 0 10m kube-system calico-node-dtbhl 1/1 Running 0 7m46s kube-system calicoctl 0/1 CreateContainerConfigError 0 38s kube-system coredns-5c98db65d4-ksh4p 1/1 Running 0 33m kube-system coredns-5c98db65d4-nvvzg 1/1 Running 0 33m kube-system etcd-vm 1/1 Running 0 32m kube-system kube-apiserver-vm 1/1 Running 0 31m kube-system kube-controller-manager-vm 1/1 Running 0 31m kube-system kube-proxy-b8qf2 1/1 Running 0 33m kube-system kube-scheduler-vm 1/1 Running 0 32m multipass@vm:~$ kubectl describe pod calicoctl --namespace=kube-system Name: calicoctl Namespace: kube-system Priority: 0 Node: vm/192.168.64.2 Start Time: Sun, 25 Aug 2019 21:35:02 +0900 Labels: \u0026lt;none\u0026gt; Annotations: kubectl.kubernetes.io/last-applied-configuration: {\u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;Pod\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;annotations\u0026#34;:{},\u0026#34;name\u0026#34;:\u0026#34;calicoctl\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;},\u0026#34;spec\u0026#34;:{\u0026#34;containers\u0026#34;:[{\u0026#34;command... Status: Pending IP: 192.168.64.2 Containers: calicoctl: Container ID: Image: calico/ctl:v3.5.8 Image ID: Port: \u0026lt;none\u0026gt; Host Port: \u0026lt;none\u0026gt; Command: /bin/sh -c while true; do sleep 3600; done State: Waiting Reason: CreateContainerConfigError Ready: False Restart Count: 0 Environment: ETCD_ENDPOINTS: \u0026lt;set to the key \u0026#39;etcd_endpoints\u0026#39; of config map \u0026#39;calico-config\u0026#39;\u0026gt; Optional: false Mounts: /var/run/secrets/kubernetes.io/serviceaccount from default-token-w2l7q (ro) Conditions: Type Status Initialized True Ready False ContainersReady False PodScheduled True Volumes: default-token-w2l7q: Type: Secret (a volume populated by a Secret) SecretName: default-token-w2l7q Optional: false QoS Class: BestEffort Node-Selectors: beta.kubernetes.io/os=linux Tolerations: node.kubernetes.io/not-ready:NoExecute for 300s node.kubernetes.io/unreachable:NoExecute for 300s Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 72s default-scheduler Successfully assigned kube-system/calicoctl to vm Normal Pulling 71s kubelet, vm Pulling image \u0026#34;calico/ctl:v3.5.8\u0026#34; Normal Pulled 57s kubelet, vm Successfully pulled image \u0026#34;calico/ctl:v3.5.8\u0026#34; Warning Failed 3s (x6 over 57s) kubelet, vm Error: Couldn\u0026#39;t find key etcd_endpoints in ConfigMap kube-system/calico-config Normal Pulled 3s (x5 over 57s) kubelet, vm Container image \u0026#34;calico/ctl:v3.5.8\u0026#34; already present on machine delete kubenetes cluster multipass@vm:~$ kubectl drain vm --delete-local-data --force --ignore-daemonsets node/vm cordoned WARNING: ignoring DaemonSet-managed Pods: kube-system/calico-node-dtbhl, kube-system/kube-proxy-b8qf2; deleting Pods not managed by ReplicationController, ReplicaSet, Job, DaemonSet or StatefulSet: kube-system/calicoctl evicting pod \u0026#34;coredns-5c98db65d4-nvvzg\u0026#34; evicting pod \u0026#34;calico-kube-controllers-65b8787765-5rftm\u0026#34; evicting pod \u0026#34;calicoctl\u0026#34; evicting pod \u0026#34;coredns-5c98db65d4-ksh4p\u0026#34; pod/calicoctl evicted pod/coredns-5c98db65d4-nvvzg evicted pod/calico-kube-controllers-65b8787765-5rftm evicted pod/coredns-5c98db65d4-ksh4p evicted node/vm evicted multipass@vm:~$ sudo kubeadm reset [reset] Reading configuration from the cluster... [reset] FYI: You can look at this config file with \u0026#39;kubectl -n kube-system get cm kubeadm-config -oyaml\u0026#39; [reset] WARNING: Changes made to this host by \u0026#39;kubeadm init\u0026#39; or \u0026#39;kubeadm join\u0026#39; will be reverted. [reset] Are you sure you want to proceed? [y/N]: y [preflight] Running pre-flight checks [reset] Removing info for node \u0026#34;vm\u0026#34; from the ConfigMap \u0026#34;kubeadm-config\u0026#34; in the \u0026#34;kube-system\u0026#34; Namespace W0825 21:46:06.943208 4603 removeetcdmember.go:61] [reset] failed to remove etcd member: error syncing endpoints with etc: etcdclient: no available endpoints .Please manually remove this etcd member using etcdctl [reset] Stopping the kubelet service [reset] Unmounting mounted directories in \u0026#34;/var/lib/kubelet\u0026#34; [reset] Deleting contents of config directories: [/etc/kubernetes/manifests /etc/kubernetes/pki] [reset] Deleting files: [/etc/kubernetes/admin.conf /etc/kubernetes/kubelet.conf /etc/kubernetes/bootstrap-kubelet.conf /etc/kubernetes/controller-manager.conf /etc/kubernetes/scheduler.conf] [reset] Deleting contents of stateful directories: [/var/lib/etcd /var/lib/kubelet /etc/cni/net.d /var/lib/dockershim /var/run/kubernetes] The reset process does not reset or clean up iptables rules or IPVS tables. If you wish to reset iptables, you must do so manually. For example: iptables -F \u0026amp;\u0026amp; iptables -t nat -F \u0026amp;\u0026amp; iptables -t mangle -F \u0026amp;\u0026amp; iptables -X If your cluster was setup to utilize IPVS, run ipvsadm --clear (or similar) to reset your system\u0026#39;s IPVS tables. The reset process does not clean your kubeconfig files and you must remove them manually. Please, check the contents of the $HOME/.kube/config file. multipass@vm:~$ sudo rm -rf /var/etcd Reference multipass https://multipass.run https://github.com/CanonicalLtd/multipass OS X에서 multipass를 이용하여 microk8s 환경 구성 Create a single node Kubernetes cluster on Ubuntu 18.04.1 (Bionic Beaver) with kubeadm https://docs.projectcalico.org/v3.8/getting-started/kubernetes/ k8s 설치 상세 절차 private helm repository 구성하기-조대협 ","date":"2019-09-28T15:17:26+09:00","permalink":"https://cychong47.github.io/post/2019/install-vm-with-multipass/","summary":"\u003ch2 id=\"multipass\"\u003emultipass?\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eMultipass is a lightweight VM manager for Linux, Windows and macOS. It\u0026rsquo;s designed for developers who want a fresh Ubuntu environment with a single command. It uses KVM on Linux, Hyper-V on Windows and HyperKit on macOS to run the VM with minimal overhead. It can also use VirtualBox on Windows and macOS. Multipass will fetch images for you and keep them up to date.\u003c/p\u003e\n\u003cp\u003eSince it supports metadata for cloud-init, you can simulate a small cloud deployment on your laptop or workstation.\u003c/p\u003e","title":"Install VM with multipass on OS X"},{"content":"Replace microk8s with kubernetes in mini1\nremove micro.k8s with snap command cychong@mini1:~$ sudo snap remove microk8s Save data of snap \u0026#34;microk8s\u0026#34; in automatic snapshot set microk8s removed cychong@mini1:~$ setup kubernetes Reference : https://phoenixnap.com/kb/install-kubernetes-on-ubuntu\ncychong@mini1:~$ sudo kubeadm init --pod-network-cidr=10.244.0.0/16 [init] Using Kubernetes version: v1.15.3 cychong@mini1:~$ kubectl get pods --all-namespaces -o wide NAMESPACE NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kube-system coredns-5c98db65d4-r468f 0/1 Pending 0 2m3s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system coredns-5c98db65d4-wcm2n 0/1 Pending 0 2m3s \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system etcd-mini1 1/1 Running 0 79s 192.168.1.100 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-apiserver-mini1 1/1 Running 0 76s 192.168.1.100 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-controller-manager-mini1 1/1 Running 0 72s 192.168.1.100 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-proxy-rzpkc 1/1 Running 0 2m4s 192.168.1.100 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-system kube-scheduler-mini1 1/1 Running 0 82s 192.168.1.100 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; Install Calico cychong@mini1:~$ wget https://docs.projectcalico.org/v3.8/manifests/calico.yaml --2019-09-08 21:53:13-- https://docs.projectcalico.org/v3.8/manifests/calico.yaml Resolving docs.projectcalico.org (docs.projectcalico.org)... 178.128.115.5, 2400:6180:0:d1::575:a001 Connecting to docs.projectcalico.org (docs.projectcalico.org)|178.128.115.5|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 20628 (20K) [application/x-yaml] Saving to: ‘calico.yaml’ calico.yaml 100%[====================================================================================\u0026gt;] 20.14K --.-KB/s in 0.08s 2019-09-08 21:53:14 (240 KB/s) - ‘calico.yaml’ saved [20628/20628] Change CALICO_IPV4POOL_CIDR\n- name: CALICO_IPV4POOL_CIDR value: \u0026#34;10.201.0.0/24\u0026#34; cychong@mini1:~$ kubectl apply -f calico.yaml configmap/calico-config created customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org created customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org created clusterrole.rbac.authorization.k8s.io/calico-kube-controllers created clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers created clusterrole.rbac.authorization.k8s.io/calico-node created clusterrolebinding.rbac.authorization.k8s.io/calico-node created daemonset.apps/calico-node created serviceaccount/calico-node created deployment.apps/calico-kube-controllers created serviceaccount/calico-kube-controllers created cychong@mini1:~$ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system calico-kube-controllers-65b8787765-7nmjw 1/1 Running 0 3m26s kube-system calico-node-8spzh 1/1 Running 0 3m26s kube-system coredns-5c98db65d4-r468f 1/1 Running 0 7m33s kube-system coredns-5c98db65d4-wcm2n 1/1 Running 0 7m33s kube-system etcd-mini1 1/1 Running 0 6m49s kube-system kube-apiserver-mini1 1/1 Running 0 6m46s kube-system kube-controller-manager-mini1 1/1 Running 0 6m42s kube-system kube-proxy-rzpkc 1/1 Running 0 7m34s kube-system kube-scheduler-mini1 1/1 Running 0 6m52s cychong@mini1:~$ kubectl get nodes NAME STATUS ROLES AGE VERSION mini1 Ready master 11m v1.15.3 cychong@mini1:~$ kubectl describe node mini1 Name: mini1 Roles: master Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux kubernetes.io/arch=amd64 kubernetes.io/hostname=mini1 kubernetes.io/os=linux node-role.kubernetes.io/master= Annotations: kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock node.alpha.kubernetes.io/ttl: 0 projectcalico.org/IPv4Address: 192.168.1.100/24 projectcalico.org/IPv4IPIPTunnelAddr: 10.244.51.64 volumes.kubernetes.io/controller-managed-attach-detach: true CreationTimestamp: Sun, 08 Sep 2019 21:49:54 +0900 Taints: node-role.kubernetes.io/master:NoSchedule Unschedulable: false To use the master node as a worker node at the same time cychong@mini1:~$ kubectl taint nodes --all node-role.kubernetes.io/master- node/mini1 untainted cychong@mini1:~$ kubectl describe node mini1 Name: mini1 Roles: master Labels: beta.kubernetes.io/arch=amd64 beta.kubernetes.io/os=linux kubernetes.io/arch=amd64 kubernetes.io/hostname=mini1 kubernetes.io/os=linux node-role.kubernetes.io/master= Annotations: kubeadm.alpha.kubernetes.io/cri-socket: /var/run/dockershim.sock node.alpha.kubernetes.io/ttl: 0 projectcalico.org/IPv4Address: 192.168.1.100/24 projectcalico.org/IPv4IPIPTunnelAddr: 10.244.51.64 volumes.kubernetes.io/controller-managed-attach-detach: true CreationTimestamp: Sun, 08 Sep 2019 21:49:54 +0900 Taints: \u0026lt;none\u0026gt; Unschedulable: false install helm with snap cychong@mini1:~$ sudo snap install helm --classic [sudo] password for cychong: helm 2.14.3 from Snapcrafters installed if Kubelet is not started after reboot Disable swap\ncychong@mini1:~$ sudo swapoff -a cychong@mini1:~$ sudo systemctl status kubelet ● kubelet.service - kubelet: The Kubernetes Node Agent Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled) Drop-In: /etc/systemd/system/kubelet.service.d └─10-kubeadm.conf Active: active (running) since Sun 2019-09-08 22:34:24 KST; 1s ago Docs: https://kubernetes.io/docs/home/ Main PID: 16565 (kubelet) Tasks: 11 (limit: 4306) CGroup: /system.slice/kubelet.service └─16565 /usr/bin/kubelet --bootstrap-kubeconfig=/etc/kubernetes/bootstrap-kubelet.conf --kubeconfig=/etc/kubernetes/kubelet.conf --config=/var/lib/kubelet/config.yaml --cgroup-dr helm init cychong@mini1:~$ sudo helm init --history-max 200 $HELM_HOME has been configured at /home/cychong/.helm. Error: error installing: Post https://192.168.1.100:6443/apis/extensions/v1beta1/namespaces/kube-system/deployments: dial tcp 192.168.1.100:6443: connect: connection refused Fix the Kubelet issue(due to the swap),\ncychong@mini1:~$ sudo helm init --history-max 200 $HELM_HOME has been configured at /home/cychong/.helm. Tiller (the Helm server-side component) has been installed into your Kubernetes Cluster. Please note: by default, Tiller is deployed with an insecure \u0026#39;allow unauthenticated users\u0026#39; policy. To prevent this, run `helm init` with the --tiller-tls-verify flag. For more information on securing your installation see: https://docs.helm.sh/using_helm/#securing-your-helm-installation Instal ghost with Helm - failed cychong@mini1:~$ sudo helm search ghost NAME CHART VERSION\tAPP VERSION\tDESCRIPTION stable/ghost\t7.2.1 2.30.2 A simple, powerful publishing platform that allows you to... Helm은 기본적으로 maridb를 사용하고 있으므로 values.yaml 파일을 override 해서 helm을 사용해야 한다. 문제는\nHelm install failed - “no available release name” cychong@mini1:~/work/ghost-with-helm$ sudo helm install -f values.yaml stable/ghost Error: no available release name found 해결책 : https://scriptcrunch.com/helm-error-no-available-release/\ncychong@mini1:~/work/ghost-with-helm$ kubectl get deployment --all-namespaces NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE kube-system calico-kube-controllers 1/1 1 1 24h kube-system coredns 2/2 2 2 25h kube-system tiller-deploy 1/1 1 1 24h cychong@mini1:~/work/ghost-with-helm$ kubectl delete deployment tiller-deploy -n kube-system deployment.extensions \u0026#34;tiller-deploy\u0026#34; deleted cychong@mini1:~/work/ghost-with-helm$ kubectl get deployment tiller-deploy --all-namespaces error: a resource cannot be retrieved by name across all namespaces cychong@mini1:~/work/ghost-with-helm$ sudo helm init --service-account=tiller $HELM_HOME has been configured at /home/cychong/.helm. Warning: Tiller is already installed in the cluster. (Use --client-only to suppress this message, or --upgrade to upgrade Tiller to the current version.) cychong@mini1:~/work/ghost-with-helm$ kubectl create -f rbac-config.yaml serviceaccount/tiller created clusterrolebinding.rbac.authorization.k8s.io/tiller created reference https://www.linode.com/docs/applications/containers/kubernetes/how-to-install-apps-on-kubernetes-with-helm/ https://phoenixnap.com/kb/install-kubernetes-on-ubuntu ","date":"2019-09-23T15:03:13+09:00","permalink":"https://cychong47.github.io/post/2019/setup-kubernetes-with-a-single-host/","summary":"\u003cp\u003eReplace microk8s with kubernetes in mini1\u003c/p\u003e\n\u003ch1 id=\"remove-microk8s-with-snap-command\"\u003eremove micro.k8s with snap command\u003c/h1\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ sudo snap remove microk8s\nSave data of snap \u0026#34;microk8s\u0026#34; in automatic snapshot set \nmicrok8s removed\ncychong@mini1:~$\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"setup-kubernetes\"\u003esetup kubernetes\u003c/h1\u003e\n\u003cp\u003eReference : \u003ca href=\"https://phoenixnap.com/kb/install-kubernetes-on-ubuntu\"\u003ehttps://phoenixnap.com/kb/install-kubernetes-on-ubuntu\u003c/a\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ sudo kubeadm init --pod-network-cidr=10.244.0.0/16\n[init] Using Kubernetes version: v1.15.3\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ kubectl get pods --all-namespaces -o wide\nNAMESPACE     NAME                            READY   STATUS    RESTARTS   AGE    IP              NODE     NOMINATED NODE   READINESS GATES\nkube-system   coredns-5c98db65d4-r468f        0/1     Pending   0          2m3s   \u0026lt;none\u0026gt;          \u0026lt;none\u0026gt;   \u0026lt;none\u0026gt;           \u0026lt;none\u0026gt;\nkube-system   coredns-5c98db65d4-wcm2n        0/1     Pending   0          2m3s   \u0026lt;none\u0026gt;          \u0026lt;none\u0026gt;   \u0026lt;none\u0026gt;           \u0026lt;none\u0026gt;\nkube-system   etcd-mini1                      1/1     Running   0          79s    192.168.1.100   mini1    \u0026lt;none\u0026gt;           \u0026lt;none\u0026gt;\nkube-system   kube-apiserver-mini1            1/1     Running   0          76s    192.168.1.100   mini1    \u0026lt;none\u0026gt;           \u0026lt;none\u0026gt;\nkube-system   kube-controller-manager-mini1   1/1     Running   0          72s    192.168.1.100   mini1    \u0026lt;none\u0026gt;           \u0026lt;none\u0026gt;\nkube-system   kube-proxy-rzpkc                1/1     Running   0          2m4s   192.168.1.100   mini1    \u0026lt;none\u0026gt;           \u0026lt;none\u0026gt;\nkube-system   kube-scheduler-mini1            1/1     Running   0          82s    192.168.1.100   mini1    \u0026lt;none\u0026gt;           \u0026lt;none\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"install-calico\"\u003eInstall Calico\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@mini1:~$ wget https://docs.projectcalico.org/v3.8/manifests/calico.yaml\n--2019-09-08 21:53:13--  https://docs.projectcalico.org/v3.8/manifests/calico.yaml\nResolving docs.projectcalico.org (docs.projectcalico.org)... 178.128.115.5, 2400:6180:0:d1::575:a001\nConnecting to docs.projectcalico.org (docs.projectcalico.org)|178.128.115.5|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 20628 (20K) [application/x-yaml]\nSaving to: ‘calico.yaml’\n\ncalico.yaml                               100%[====================================================================================\u0026gt;]  20.14K  --.-KB/s    in 0.08s\n\n2019-09-08 21:53:14 (240 KB/s) - ‘calico.yaml’ saved [20628/20628]\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eChange \u003ccode\u003eCALICO_IPV4POOL_CIDR\u003c/code\u003e\u003c/p\u003e","title":"Setup kubernetes in a single host"},{"content":"ghost를 설치한 지 몇 년이 지났는데 그 동안 여러 가지 방법으로 Ghost 운용 환경을 구축해왔다.\nHost 환경, Docker, Ansible, kubernetes 에 이어 이번은 5번째 시즌인데 Helm Chart 를 시용해서 설치해 보는 것이다. 처음 시작은 helm repository에 있는 공식(?) 공개된 helm chart를 이용하여 values.yaml 파일만 내 환경에 맞게 변경해서 사용하려던 것이었는데 아쉽게 아직은 그렇게 하기 힘든 것으로 보여 직접 helm chart를 만들어서 사용하고 있다. 이 문서는 그 과정을 기술한 것으로 향후 공식 helm chart를 활용할 수 있는 때가 오면 시즌 6에 해당하는 글을 또 쓸 듯 하다.\nPV PV(Persistent Volume을 만드는 건 Helm의 역할이 아닌 듯. 대부분의 Helm Chart는 필요한 PVC(Persistent Volume Claim)은 정의하고 있어도 PV 생성에 대한 책임은 지고 있지 않은 듯 하다.\nghost-pv.yaml kind: PersistentVolume apiVersion: v1 metadata: name: ghost-pv labels: type: local spec: storageClassName: manual capacity: storage: 12Gi accessModes: - ReadWriteOnce hostPath: path: \u0026#34;/home/cychong/Dropbox/Apps/ghost/content\u0026#34; Kubectl 명령을 이용하여 직접 PV 생성한다.\ncychong@mini1:~/work$ kubectl create -f ghost-in-k8s/ghost-pv.yaml persistentvolume/ghost-pv created cychong@mini1:~/work$ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-pv 12Gi RWO Retain Available manual 8s 다음은 helm을 이용해서 ghost를 deploy한다.\n처음 helm을 이용해서 손쉽게 ghost를 설치할 수 있다는 걸 알고( How to Install Apps on Kubernetes with Helm ) 부푼 기대감을 가지고 설치해 봤는데 아쉽게 github에 있는 건 mariadb를 backend DB로 사용하는 형태였다. Sqlite를 backend로 해서 가볍게 개인 블로그를 운용하고 있는 입장에서는 이걸 위해 mariadb를 사용하기는 배보다 배꼽이 더 큰 상황이 아닌가 싶어 mariadb를 사용하지 않고 ghost를 설치할 수 있는 지 helm chart를 살펴봤다. 그런데 아무리 봐도 mariadb 혹은 별도의 외부 DB가 없으면 제대로 동작하지 않는(ghost를 deploy할 수 없는) 듯 해 보였다. https://github.com/helm/charts/issues/16989 에도 issue를 올렸는데 반응을 보인 한 명이 별 문제 없을 것 같은데 라고 하길래 현상을 자세히 적어줬지만 그 다음부터는 감감무소식이라. 오픈 소스가 원래 그런 거 지만\u0026hellip; 다들 문제가 없는 건지 내가 하는 것처럼 ghost + kubernetes + helm + sqlite 의 조합으로 사용을 안하는 건지\u0026hellip;\n결국 목마른 사람이 우물을 판다고 이전에 직접 만들어서 사용했던 YAML 파일 들을 이용해서 직접 Helm chart를 만들어 보기로 마음 먹었다. 겸사겸사 이러다 보면 Helm chart의 복잡한(?) 문법도 어쩔 수 없이 조금은 이해할 수 밖에 없는 상황이 되지 않을까 하고\n접근 방법은 Helm chart의 convention과는 조금 다르지만 근본적으로 결국 deployment, service 등의 조합으로 이루어지는 거라 일단 잘(적어도 내가 원하는 형태대로) 동작하는 YAML 파일들 과 helm create 명령을 통해 만들어진 기본 형태의 파일들과 비교해 가면서 기존 YAML 파일들의 내용을 helm chart에 반영해서 제대로 된 동작하는 helm chart를 만들기로 했다. 제대로의 기준 중 하나는 helm이 추구하는 것과 같이 배포 site와 무관한 내용은 YAML이나 template 파일들에 정의하고 배포 site별로 다를 수 있는 내용은 values.yaml 파일에 정의하는 것이다. 이를 테면 블로그 URL등을 이전에는 deployment.yaml파일에 직접 정의했지만 이번에는 values.yaml에 정의하고 이 값을 참조하도록 했다.\n처음 helm을 사용해 보는 거라 쉽게 되지는 않았다. 밤 늦게 퇴근해서 뭔가를 한다는 건 정말 힘든 일이었고, 주말에 어쩌다 시간이 나면 시도해 보는 건데 이마저도 제대로 집중해서 보질 못하니. 그렇게 trial \u0026amp; error를 통해 만든 ghost helm chart를 github repo 에 올렸다. 참고로 이 repo에 있는 내용은 새로 ghost를 만드는 경우에도 잘 동작하는 지는 확인하지 못했다. 기존 sqlite DB파일을 가지고 있는 내 동작 환경에서만 확인해 본 거라 아직은 얼마나 범용성을 가지고 있는 지는 잘 모르겠다. 그렇게 하려면 완전히 새로운 환경에서 해 봐야 하는데 내 코가 석자라 그건 나중에 시간이 나면\u0026hellip;\n이 helm chart를 이용해 ghost를 설치하는 과정은 다음과 같다.\nhelm chart를 ghost-with-helm 이라는 디렉토리에 만들었다.\n$ tree -l ghost-with-helm ghost-with-helm ├── Chart.yaml ├── README.md ├── charts ├── templates │ ├── NOTES.txt │ ├── _helpers.tpl │ ├── deployment.yaml │ ├── ingress.yaml │ ├── pvc.yaml │ ├── service.yaml │ └── tests │ └── test-connection.yaml └── values.yaml 참고로 ingress.yaml은 아직 사용하지 않고 직접 NodePort를 이용해서 처리하고 있다. 이 부분은 향후 개선할 점 중 하나.\nhelm chart의 values.yaml을 맞게 고친 후 설치한다.\ncychong@mini1:~/work$ helm install --name my-ghost ghost-with-helm NAME: my-ghost LAST DEPLOYED: Sun Sep 22 21:39:34 2019 NAMESPACE: default STATUS: DEPLOYED RESOURCES: ==\u0026gt; v1/Deployment NAME READY UP-TO-DATE AVAILABLE AGE my-ghost 0/1 1 0 0s ==\u0026gt; v1/PersistentVolumeClaim NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE ghost-pvc Bound ghost-pv 12Gi RWO manual 1s ==\u0026gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE my-ghost-5f6578fd76-djd2g 0/1 Pending 0 0s ==\u0026gt; v1/Service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE my-ghost NodePort 10.97.215.158 \u0026lt;none\u0026gt; 2368:30025/TCP 1s NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services my-ghost) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT helm install 명령을 내리면 chart로 생성된 application과 관련된 resource 들 pod, service, PVCs 등의 상태가 한번에 모두 확인된다. Pod는 명령을 내리자 마자 상태를 조회한 거라 STATUS가 아직 Pending 상태로 나온다. kubectl 명령으로 pod의 상태를 다시 확인해 본다.\ncychong@mini1:~/work$ kubectl get pod my-ghost-5f6578fd76-djd2g NAME READY STATUS RESTARTS AGE my-ghost-5f6578fd76-djd2g 1/1 Running 0 2m43s Pod의 STATUS가 정상적으로 RUNNING으로 출력된다. 이제 pod는 정상적으로 deploy가 된 상태인데 Service를 NodePort 타입으로 지정한 경우 Host에서 접속하려면 실제 pod가 listening하는 것과 다른 port를 사용하므로 위 NOTES에 있는 대로 실제로 서비스에 할당된 port 정보를 확인해야 한다.\ncychong@mini1:~/work$ export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services my-ghost) cychong@mini1:~/work$ export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) cychong@mini1:~/work$ echo http://$NODE_IP:$NODE_PORT http://192.168.1.100:30025 이번에 할당된 port는 30025다. 이제 NODE_IP와 NODE_PORT값을 이용해서 해당 주소에 접속하면 정상적으로 ghost 화면이 나온다.\n이 port 정보를 이용해서 공유기의 port forwarding 규칙에 추가한다. 외부에서 sosa0sa.com:2368로 접슨 시 실제 ghost 가 실행된 mini1의 내부 IP로 포워딩 하되 port 번호를 30025로 변환해서(NAPT) 전달하도록 변경한 후 접속해 본다.\nOn-premise 환경에서 kubernetes를 사용하는 경우 LoadBalancer를 별도로 설치하지 않고 외부와 통신하기 위해 사용하는 NodePort는 이렇게 service를 deploy할 때마다 port가 바뀌는 문제가 존재한다. 내 경우 공유기의 port forwarding을 이용해서 블로그에 접속할 수 있도록 하고 있어 매번 공유기의 port forwarding 규칙을 고쳐야 하므로 개선이 필요하다(포트 값을 고정값으로 할당하거나, Ingress Controller혹은 MetalLB등을 사용하여 NodePort가 아닌 LoadBalancer 타입으로 변경할 예정이다)\nhelm-test cychong@mini1:~/work/ghost-with-helm$ helm test my-ghost RUNNING: my-ghost-test-connection PASSED: my-ghost-test-connection Port Number NodePort를 사용하면 해당 서비스를 위한 30000에서 32767 사이의 포트 번호가 할당된다. 그런데 위와 같이 port와 TargetPort를 지정하면 위 30000번대 포트 외에 의도한 포트로도 접근이 가능하다.\ncychong@mini1:~/work/ghost-with-helm$ echo $(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services my-ghost) 32326 cychong@mini1:~/work/ghost-with-helm$ sudo netstat -atnp |grep kube-proxy [sudo] password for cychong: tcp 0 0 127.0.0.1:10249 0.0.0.0:* LISTEN 18392/kube-proxy tcp 0 0 192.168.1.100:2368 0.0.0.0:* LISTEN 18392/kube-proxy tcp 0 0 192.168.1.100:49778 192.168.1.100:6443 ESTABLISHED 18392/kube-proxy tcp6 0 0 :::32326 :::* LISTEN 18392/kube-proxy tcp6 0 0 :::10256 :::* LISTEN 18392/kube-proxy 위 내용을 보면 my-ghost 서비스에 할당된 NodePort 32326 외에 TargetPort인 2368이 그대로 보이는 것을 알 수 있다.\nUpgrade Helm Chart에 변경이 있는 경우에는 upgrade 명령을 이용한다. 만일 value 파일에 변화가 있는 경우에는 전체를 다시 deploy하는 듯 하다. 아래는 targetPort 값을 임시로 다른 값으로 변경해서 upgrade 했다 다시 원복한 경우다.\ncychong@mini1:~/work$ helm upgrade --debug my-ghost ghost-with-helm [debug] Created tunnel using local port: \u0026#39;44111\u0026#39; [debug] SERVER: \u0026#34;127.0.0.1:44111\u0026#34; REVISION: 5 RELEASED: Thu Sep 26 01:06:32 2019 CHART: ghost-0.1.0 USER-SUPPLIED VALUES: {} ... Release \u0026#34;my-ghost\u0026#34; has been upgraded. LAST DEPLOYED: Thu Sep 26 01:06:32 2019 NAMESPACE: default STATUS: DEPLOYED RESOURCES: ==\u0026gt; v1/Deployment NAME READY UP-TO-DATE AVAILABLE AGE my-ghost 1/1 1 1 18m ==\u0026gt; v1/PersistentVolumeClaim NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE ghost-pvc Bound ghost-pv 12Gi RWO manual 18m ==\u0026gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE my-ghost-5f6578fd76-lb7xc 1/1 Running 0 18m ==\u0026gt; v1/Service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE my-ghost NodePort 10.105.125.54 192.168.1.100 2368:32326/TCP 18m Troubleshooting 동일한 helm release 이름을 다시 사용하려면 삭제한 helm release를 재사용하려면 delete 외에 delete —purge 옵션으로 삭제할 것\ncychong@mini1:~/work$ helm install --name my-ghost ghost-with-helm Error: a release named my-ghost already exists. Run: helm ls --all my-ghost; to check the status of the release Or run: helm del --purge my-ghost; to delete it cychong@mini1:~/work$ helm ls cychong@mini1:~/work$ helm ls -A Error: unknown shorthand flag: \u0026#39;A\u0026#39; in -A cychong@mini1:~/work$ helm ls --all my-ghost NAME REVISION\tUPDATED STATUS CHART APP VERSION\tNAMESPACE my-ghost\t1 Sun Sep 22 21:36:42 2019\tDELETED\tghost-0.1.0\t1.0 default cychong@mini1:~/work$ helm del --purge my-ghost release \u0026#34;my-ghost\u0026#34; deleted helm delete 후 PV 연결이 안되는 경우 한번 Release를 생성한 후 삭제한 경우 PVC가 제대로 할당되지 않는 현상이 있다. 이 경우 PV를 삭제한 후 다시 Helm install을 수행한다.\ncychong@mini1:~/work$ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-pv 12Gi RWO Retain Bound default/ghost-pvc manual 13m cychong@mini1:~/work$ helm ls helm delete NAME REVISION\tUPDATED STATUS CHART APP VERSION\tNAMESPACE my-ghost\t1 Sun Sep 22 21:39:34 2019\tDEPLOYED\tghost-0.1.0\t1.0 default cychong@mini1:~/work$ helm delete --purge my-ghost release \u0026#34;my-ghost\u0026#34; deleted cychong@mini1:~/work$ helm ls cychong@mini1:~/work$ kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-pv 12Gi RWO Retain Released default/ghost-pvc manual 14m 이 상태에서 다시 helm install을 수행하면\ncychong@mini1:~/work$ helm install --name my-ghost ghost-with-helm NAME: my-ghost LAST DEPLOYED: Sun Sep 22 21:53:40 2019 NAMESPACE: default STATUS: DEPLOYED RESOURCES: ==\u0026gt; v1/Deployment NAME READY UP-TO-DATE AVAILABLE AGE my-ghost 0/1 1 0 1s ==\u0026gt; v1/PersistentVolumeClaim NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE ghost-pvc Pending manual 1s ==\u0026gt; v1/Pod(related) NAME READY STATUS RESTARTS AGE my-ghost-5f6578fd76-kddlg 0/1 Pending 0 1s ==\u0026gt; v1/Service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE my-ghost NodePort 10.96.105.207 \u0026lt;none\u0026gt; 2368:32615/TCP 1s NOTES: 1. Get the application URL by running these commands: export NODE_PORT=$(kubectl get --namespace default -o jsonpath=\u0026#34;{.spec.ports[0].nodePort}\u0026#34; services my-ghost) export NODE_IP=$(kubectl get nodes --namespace default -o jsonpath=\u0026#34;{.items[0].status.addresses[0].address}\u0026#34;) echo http://$NODE_IP:$NODE_PORT cychong@mini1:~/work$ kubectl describe pod my-ghost-5f6578fd76-kddlg Name: my-ghost-5f6578fd76-kddlg Namespace: default Priority: 0 Node: \u0026lt;none\u0026gt; Labels: app.kubernetes.io/instance=my-ghost app.kubernetes.io/name=ghost pod-template-hash=5f6578fd76 Annotations: \u0026lt;none\u0026gt; Status: Pending … Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 26s (x2 over 87s) default-scheduler pod has unbound immediate PersistentVolumeClaims 이 경우 다시 PV를 삭제하고 새로 PV를 정의한 후 helm install을 실행해야 한다.\ncychong@mini1:~/work$ helm ls helm del NAME REVISION\tUPDATED STATUS CHART APP VERSION\tNAMESPACE my-ghost\t1 Sun Sep 22 21:53:40 2019\tDEPLOYED\tghost-0.1.0\t1.0 default cychong@mini1:~/work$ helm del --purge my-ghost release \u0026#34;my-ghost\u0026#34; deleted cychong@mini1:~/work$ kubectl delete -f ghost-in-k8s/ghost-pv.yaml persistentvolume \u0026#34;ghost-pv\u0026#34; deleted cychong@mini1:~/work$ kubectl create -f ghost-in-k8s/ghost-pv.yaml persistentvolume/ghost-pv created cychong@mini1:~/work$ helm install --name my-ghost ghost-with-helm NAME: my-ghost LAST DEPLOYED: Sun Sep 22 21:56:42 2019 NAMESPACE: default STATUS: DEPLOYED … cychong@mini1:~/work$ kubectl get pod NAME READY STATUS RESTARTS AGE my-ghost-5f6578fd76-k5xcs 1/1 Running 0 50s ","date":"2019-09-22T13:14:16+09:00","permalink":"https://cychong47.github.io/post/2019/ghost-season-5-helm/","summary":"\u003cp\u003eghost를 설치한 지 몇 년이 지났는데 그 동안 여러 가지 방법으로 \u003ca href=\"http://sosa0sa.com:2368/ghost-deployment-season-4/\"\u003eGhost 운용 환경을 구축\u003c/a\u003e해왔다.\u003c/p\u003e\n\u003cp\u003eHost 환경, Docker, Ansible, kubernetes 에 이어 이번은 5번째 시즌인데 \u003ca href=\"https://helm.sh\"\u003eHelm Chart\u003c/a\u003e 를 시용해서 설치해 보는 것이다. 처음 시작은 helm repository에 있는 공식(?) 공개된 helm chart를 이용하여 values.yaml 파일만 내 환경에 맞게 변경해서 사용하려던 것이었는데 아쉽게 아직은 그렇게 하기 힘든 것으로 보여 직접 helm chart를 만들어서 사용하고 있다. 이 문서는 그 과정을 기술한 것으로 향후 공식 helm chart를 활용할 수 있는 때가 오면 시즌 6에 해당하는 글을 또 쓸 듯 하다.\u003c/p\u003e","title":"Ghost Season 5 - Helm"},{"content":"간혹 아니 자주 블루투스로 연결한 마우스가 너무 반응이 느리다. 맥이 이상한 가 싶어 트랙패드를 만져보면 전혀 반응 속도에 이상이 없다.\n인터넷을 뒤져보니 Wifi 2.5GHz와 블루투스가 간섭을 일으켜서 그런다고. 가장 간단한 해결책은 2.5GHz인데, 설명서에 있는 대로 2.5GHz에 대해 Radio Enable 를 꺼도 여전히 AP list에 나온다. 그러다 우연히 본 옵션이 \u0026ldquo;Bluetooth coexistence\u0026rdquo;. 5GHz에 대해서는 이 옵션이 없는 걸 보니 뭔가 영향을 줄 것 같다. 일단 옵션을 Enable로 변경.\nLet\u0026rsquo;s see what happens. 5분 정도 지난 아직까지는 마우스 움직임이 둔해지는 현상이 없네. 왠지 느낌이 좋네.\n","date":"2019-08-26T15:46:19+09:00","permalink":"https://cychong47.github.io/post/2019/wifi-5ghz-bluetooth-coexistence/","summary":"\u003cp\u003e간혹 아니 자주 블루투스로 연결한 마우스가 너무 반응이 느리다.\n맥이 이상한 가 싶어 트랙패드를 만져보면 전혀 반응 속도에 이상이 없다.\u003cbr\u003e\n인터넷을 뒤져보니 Wifi 2.5GHz와 블루투스가 간섭을 일으켜서 그런다고.\n가장 간단한 해결책은 2.5GHz인데, 설명서에 있는 대로 2.5GHz에 대해 \u003ccode\u003eRadio Enable\u003c/code\u003e 를 꺼도 여전히 AP list에 나온다.\n그러다 우연히 본 옵션이 \u0026ldquo;Bluetooth coexistence\u0026rdquo;. 5GHz에 대해서는 이 옵션이 없는 걸 보니 뭔가 영향을 줄 것 같다.\n일단 옵션을 Enable로 변경.\u003c/p\u003e\n\u003cp\u003eLet\u0026rsquo;s see what happens.\n\u003cimg src=\"/images/2019/08/enable_bluetooth_coexist.png\" alt=\"enable_bluetooth_coexist\"\u003e\u003c/p\u003e","title":"Wifi 2.5GHz bluetooth coexist"},{"content":"Getting started with Calico on Kubernetes Calico를 사용하는 경우 kubelet의 실행 옵션 중 --network-plugin=cni와 같이 변경된다.\nkube-controller-manager의 실행 옵션 중 --allocate-node-cidrs=false 로 역시 변경된다. 이는 CNI(여기서는 Calico의 IPAM)에서 IP 주소를 할당하기 때문\nPod 내 route table에서는 host의 link local address를 default route로 사용한다.\nPod가 갖는 eth0 interface는 root(혹은 default) namespace에 존재하는 \u0026lsquo;cali\u0026rsquo;로 시작하는 interface와 veh pair 관계를 갖는다.\nveth pairs는 아래 설명과 같이 서로 연결된 두 개의 interface를 의미하는데 한쪽으로 들어가면 연결된 다른 인터페이스로 나온다. 즉 pod의 eth0 interface를 통해 패킷을 전송하면 host의 cali interface로 나와 커널의 라우팅 혹은 iptable 처리를 받는다. https://www.fir3net.com/Networking/Terms-and-Concepts/virtual-networking-devices-tun-tap-and-veth-pairs-explained.html What goes in one end will come out the other.\nCalico and Kubernetes Series 1 to 4 kubernetes를 설치하는 방법부터 Calico 설치 그리고 sample application을 이용해서 calico를 이용한 전반적인 네트워킹을 친절하고 상세하게 설명.\nk8s 설치 방법 : kubeadm을 이용해서 설치할 수 있다. https://kubenetes.io/docs/setup/independent/install-kubeadm sudo systemctl start docker ; sudo systemctl enable docker Virtualbox 등을 사용해서 설치하는 경우 최소 core 2개 이상은 할당해야 함. 그렇지 않으면 kubeadm 실행할 때 core 부족을 이유로 에러 발생. 추가로 swap 도 꺼야 함 sudo swapoff -a Ubuntu 에 kubenetes 설치하는 것은 (https://www.linuxtechi.com/install-configure-kubernetes-ubuntu-18-04-ubuntu-18-10/ 참고. master node를 worker node로 사용하려면 \u0026lsquo;kubectl taint\u0026rsquo; 명령을 사용하면 된다 kubectl taint nodes --all node-role,kubernetes.io/master- 일반 사용자도 kubectl 을 사용하게 하려면 /etc/kubenetes/admin.conf' 사용자 계정 아래 $HOME/.kube/config` 파일로 복사하고 권한을 사용자로 주면 된다. sudo cp -i /etc/kubenetes/admin.conf $HOME/.kube/config ; sudo chown $(id -u):$(id -g) $HOME/.kube/config Calico 관련 설정 내용을 확인하려면 kube-system namespace에서 동작하고 있는 calicoctl pod의 calicoctl 을 사용한다. kubectl exec -ti -n kube-system calicoctl -- /calicoctl get profiles -o wide kubectl exec -ti -n kube-system calicoctl -- /calicoctl get -o yaml ippool nat-outging: true container에서 외부로 향하는 패킷 중 목적지가 calico CIDR에 속하지 않는 경우 NAT를 수행한다는 의미. 자세한 내용은 iptables -L -t nat -n 명령에서 확인할 수 있음 ippool을 추가하려면 kind: ipPool을 갖는 yaml 파일을 만들어 calico 명령으로 적용한다. calicoctl pod에서 실행해야 하는데 yaml 파일을 해당 pod 내에서 만들어서 적용해야 하므로 calicoctl pod에 ssh로 접속한 후 YAML 파일 만들어 calicoctl create -f XXX.yaml 명령으로 적용한다. 2개 이상의 ippool을 만든 경우 특정 pod가 특정 subnet에서 ip를 할당받도록 하려면 annotation 을 이용해서 pod 생성시 calico subnet을 지정한다. annotations: \u0026quot;cni.projectcalico.org/ipv4pools\u0026quot;: \u0026quot;[\\\u0026quot;10.91.1.0/24\\\u0026quot;]\u0026quot; 다목적 시험용 sshd pod는 이걸 사용 kubectl run sushi-1 --image=rastasheep/ubuntu-sshd:16.04 단 2017년 글이라 그런지 kubectl run 대신 kubectl create를 사용하라고 경고가 나온다 추가로 패키지를 몇 개 설치할 섯. apt-get update ; apt-get install iproute2 inetutils-ping traceroute container내 eth0 interface의 IP는 /32로 host의 cali로 시작하는 veth pair 관계를 갖는다. pod내에서 ip -d link 명령의 결과에 나오는 interface 이름 정보를 통해 Veth pair 인터페이스가 어떤 것인지 확인할 수 있다. 예를 들어 pod 내에서 확인한 정보가 eth0@if5면 이 pod의 eth0는 host에서 5번째 interface라는 것을 알 수 있다. 특정 pod가 위치할 node를 지정하기 위해 node에 label을 지정하려면 kubectl label nodes NODE-NAME node_id=NODE-LABEL Calico의 bop 기능을 사용하려면 \u0026ldquo;kind: bgpPeer\u0026quot;인 YAML 파일을 만들어 적용한다. (calicoctl pod 내에서 작업) calicoctl create -f bgp.yaml calicoctl get -o yaml bgppeer calicoctl node status 여러 노드들이 동일한 bgp 정보를 adversize하여 특정 pod의 subnet이 여러 node에서 수신하도록 외부에 adversize될 수도 있음. 확인 필요 ","date":"2019-08-18T15:20:01+09:00","permalink":"https://cychong47.github.io/post/2019/calico-cni-1/","summary":"\u003ch2 id=\"getting-started-with-calico-on-kubernetes\"\u003e\u003ca href=\"https://www.dasblinkenlichten.com/getting-started-with-calico-on-kubernetes/\"\u003eGetting started with Calico on Kubernetes\u003c/a\u003e\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eCalico를 사용하는 경우 kubelet의 실행 옵션 중 \u003ccode\u003e--network-plugin=cni\u003c/code\u003e와 같이 변경된다.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ekube-controller-manager의 실행 옵션 중 \u003ccode\u003e--allocate-node-cidrs=false\u003c/code\u003e 로 역시 변경된다. 이는 CNI(여기서는 Calico의 IPAM)에서 IP 주소를 할당하기 때문\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePod 내 route table에서는 host의 link local address를 default route로 사용한다.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003ePod가 갖는 eth0 interface는 root(혹은 default) namespace에 존재하는 \u0026lsquo;cali\u0026rsquo;로 시작하는 interface와 veh pair 관계를 갖는다.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eveth pairs는 아래 설명과 같이 서로 연결된 두 개의 interface를 의미하는데 한쪽으로 들어가면 연결된 다른 인터페이스로 나온다. 즉 pod의 eth0 interface를 통해 패킷을 전송하면 host의 cali interface로 나와 커널의 라우팅 혹은 iptable 처리를 받는다.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.fir3net.com/Networking/Terms-and-Concepts/virtual-networking-devices-tun-tap-and-veth-pairs-explained.html\"\u003ehttps://www.fir3net.com/Networking/Terms-and-Concepts/virtual-networking-devices-tun-tap-and-veth-pairs-explained.html\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003eWhat goes in one end will come out the other.\u003c/p\u003e","title":"Calico CNI (draft)"},{"content":"IEEE 1588: What’s the difference between a Boundary Clock and Transparent Clock?\nIEEE 1588 2002 Original standard Ordinary Clock : GrandMaster of Slave. Always a single port Boundary Clock clock node that has two or more ports (router or switch) One port as a slave clock, The remaining ports are master clock for other nodes. BC recovers the time of day within the slave clock and relays it as a reference to the mater clock function 1PPS Pulse-Per-Second https://www.iqdfrequencyproducts.com/media/pg/1589/1495630251/gps-do.pdf Holdover time Time to maintain the accuracy during the GPS is not locked OXCO vs. TCXO Oven Controlled Oscillator ensure 8 microseconds of holdover from 8 to 24 hours, https://www.eetimes.com/document.asp?doc_id=1278627# TCXO(Temperature-Compensated Crystal Oscillator) ","date":"2019-07-18T14:19:02+09:00","permalink":"https://cychong47.github.io/post/2019/boundary-clock/","summary":"\u003cp\u003e\u003ca href=\"http://community.cambiumnetworks.com/t5/PTP-FAQ/IEEE-1588-What-s-the-difference-between-a-Boundary-Clock-and/td-p/50392\"\u003eIEEE 1588: What’s the difference between a Boundary Clock and Transparent Clock?\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"ieee-1588-2002\"\u003eIEEE 1588 2002\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eOriginal standard\u003c/li\u003e\n\u003cli\u003eOrdinary Clock : GrandMaster of Slave. Always a single port\u003c/li\u003e\n\u003cli\u003eBoundary Clock\n\u003cul\u003e\n\u003cli\u003eclock node that has two or more ports (router or switch)\u003c/li\u003e\n\u003cli\u003eOne port as a slave clock,\u003c/li\u003e\n\u003cli\u003eThe remaining ports are master clock for other nodes.\u003c/li\u003e\n\u003cli\u003eBC recovers the time of day within the slave clock and relays it as a reference to the mater clock function\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"1pps\"\u003e1PPS\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ePulse-Per-Second\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.iqdfrequencyproducts.com/media/pg/1589/1495630251/gps-do.pdf\"\u003ehttps://www.iqdfrequencyproducts.com/media/pg/1589/1495630251/gps-do.pdf\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"holdover-time\"\u003eHoldover time\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eTime to maintain the accuracy during the GPS is not locked\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"oxco-vs-tcxo\"\u003eOXCO vs. TCXO\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eOven Controlled Oscillator\n\u003cul\u003e\n\u003cli\u003eensure 8 microseconds of holdover from 8 to 24 hours,\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.eetimes.com/document.asp?doc_id=1278627#\"\u003ehttps://www.eetimes.com/document.asp?doc_id=1278627#\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eTCXO(Temperature-Compensated Crystal Oscillator)\u003c/li\u003e\n\u003c/ul\u003e","title":"Boundary Clock"},{"content":"Install microk8s MicroK8s - Fast, Light, Upstream Developer Kubernetes\n설치는 위 링크에 있는 공식 홈페이지에 있는 대로 snap 명령어 하나로 간단하게 설치할 수 있다.\ncychong@mini1:~$ sudo snap install microk8s --classic 2019-05-18T09:43:53+09:00 INFO Waiting for restart... microk8s v1.14.1 from Canonical✓ installed 설치된 microk8s의 정보를 확인하려면 snap info microk8s\ncychong@mini1:~$ sudo snap info microk8s name: microk8s summary: Kubernetes for workstations and appliances publisher: Canonical✓ contact: \u0026lt;https://github.com/ubuntu/microk8s\u0026gt; license: unset description: | MicroK8s is a small, fast, secure, single node Kubernetes that installs on just about any Linux box. Use it for offline development, prototyping, testing, or use it on a VM as a small, cheap, reliable k8s for CI/CD. It's also a great k8s for appliances - develop your IoT apps for k8s and deploy them to MicroK8s on your boxes. commands: - microk8s.config - microk8s.ctr - microk8s.disable - microk8s.enable - microk8s.inspect - microk8s.istioctl - microk8s.kubectl - microk8s.reset - microk8s.start - microk8s.status - microk8s.stop services: microk8s.daemon-apiserver: simple, enabled, active microk8s.daemon-apiserver-kicker: simple, enabled, active microk8s.daemon-containerd: simple, enabled, active microk8s.daemon-controller-manager: simple, enabled, active microk8s.daemon-etcd: simple, enabled, active microk8s.daemon-kubelet: simple, enabled, active microk8s.daemon-proxy: simple, enabled, active microk8s.daemon-scheduler: simple, enabled, active snap-id: EaXqgt1lyCaxKaQCU349mlodBkDCXRcg tracking: stable refresh-date: today at 09:44 KST channels: stable: v1.14.1 2019-04-18 (522) 214MB classic candidate: v1.14.1 2019-04-15 (522) 214MB classic beta: v1.14.1 2019-04-15 (522) 214MB classic edge: v1.14.2 2019-05-17 (604) 217MB classic 1.15/stable: – 1.15/candidate: – 1.15/beta: – 1.15/edge: v1.15.0-alpha.3 2019-05-08 (578) 215MB classic 1.14/stable: v1.14.1 2019-04-18 (521) 214MB classic 1.14/candidate: v1.14.1 2019-04-15 (521) 214MB classic 1.14/beta: v1.14.1 2019-04-15 (521) 214MB classic 1.14/edge: v1.14.2 2019-05-17 (603) 217MB classic 1.13/stable: v1.13.5 2019-04-22 (526) 237MB classic 1.13/candidate: v1.13.6 2019-05-09 (581) 237MB classic 1.13/beta: v1.13.6 2019-05-09 (581) 237MB classic 1.13/edge: v1.13.6 2019-05-08 (581) 237MB classic 1.12/stable: v1.12.8 2019-05-02 (547) 259MB classic 1.12/candidate: v1.12.8 2019-05-01 (547) 259MB classic 1.12/beta: v1.12.8 2019-05-01 (547) 259MB classic 1.12/edge: v1.12.8 2019-04-24 (547) 259MB classic 1.11/stable: v1.11.10 2019-05-10 (557) 258MB classic 1.11/candidate: v1.11.10 2019-05-02 (557) 258MB classic 1.11/beta: v1.11.10 2019-05-02 (557) 258MB classic 1.11/edge: v1.11.10 2019-05-01 (557) 258MB classic 1.10/stable: v1.10.13 2019-04-22 (546) 222MB classic 1.10/candidate: v1.10.13 2019-04-22 (546) 222MB classic 1.10/beta: v1.10.13 2019-04-22 (546) 222MB classic 1.10/edge: v1.10.13 2019-04-22 (546) 222MB classic installed: v1.14.1 (522) 214MB classic Enable services(microk8s) cychong@mini1:~$ sudo microk8s.enable dashboard registry dns Enabling dashboard secret/kubernetes-dashboard-certs created serviceaccount/kubernetes-dashboard created deployment.apps/kubernetes-dashboard created service/kubernetes-dashboard created service/monitoring-grafana created service/monitoring-influxdb created service/heapster created deployment.extensions/monitoring-influxdb-grafana-v4 created serviceaccount/heapster created configmap/heapster-config created configmap/eventer-config created deployment.extensions/heapster-v1.5.2 created dashboard enabled Enabling the private registry Enabling default storage class deployment.extensions/hostpath-provisioner created storageclass.storage.k8s.io/microk8s-hostpath created Storage will be available soon Applying registry manifest namespace/container-registry created persistentvolumeclaim/registry-claim created deployment.extensions/registry created service/registry created The registry is enabled Enabling DNS Applying manifest service/kube-dns created serviceaccount/kube-dns created configmap/kube-dns created deployment.extensions/kube-dns created Restarting kubelet DNS is enabled 서비스 상태는 microk8s.status로 확인 가능\ncychong@mini1:~$ sudo microk8s.status [sudo] password for cychong: microk8s is running addons: jaeger: disabled fluentd: disabled gpu: disabled storage: enabled registry: enabled ingress: disabled dns: enabled metrics-server: disabled prometheus: disabled istio: disabled dashboard: enabled Basic kubectl commands Node 상태 확인 cychong@mini1:~$ sudo microk8s.kubectl get node NAME STATUS ROLES AGE VERSION mini1 Ready \u0026lt;none\u0026gt; 13m v1.14.1 namespace 상태 확인 cychong@mini1:~$ sudo microk8s.kubectl get namespace NAME STATUS AGE container-registry Active 179m default Active 3h2m kube-node-lease Active 3h2m kube-public Active 3h2m kube-system Active 3h2m cychong@mini1:~$ sudo microk8s.kubectl get all NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 10.152.183.1 \u0026lt;none\u0026gt; 443/TCP 15m 모든 namespace를 보고 싶을 때\ncychong@mini1:~$ sudo microk8s.kubectl get all --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE container-registry pod/registry-7d65c894c-z5nv6 1/1 Running 0 12m kube-system pod/heapster-v1.5.2-5c5498f57c-wztz5 4/4 Terminating 0 12m kube-system pod/heapster-v1.5.2-6b5d7b57f9-4q9rd 4/4 Running 0 10m kube-system pod/heapster-v1.5.2-89b48dff-g9hqj 4/4 Terminating 0 10m kube-system pod/hostpath-provisioner-6d744c4f7c-gxksl 1/1 Running 0 12m kube-system pod/kube-dns-6bfbdd666c-t6f74 3/3 Running 0 12m kube-system pod/kubernetes-dashboard-6fd7f9c494-48dnz 1/1 Running 0 12m kube-system pod/monitoring-influxdb-grafana-v4-78777c64c8-c5jk4 2/2 Running 0 12m NAMESPACE NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE container-registry service/registry NodePort 10.152.183.138 \u0026lt;none\u0026gt; 5000:32000/TCP 12m default service/kubernetes ClusterIP 10.152.183.1 \u0026lt;none\u0026gt; 443/TCP 15m kube-system service/heapster ClusterIP 10.152.183.196 \u0026lt;none\u0026gt; 80/TCP 12m kube-system service/kube-dns ClusterIP 10.152.183.10 \u0026lt;none\u0026gt; 53/UDP,53/TCP 12m kube-system service/kubernetes-dashboard ClusterIP 10.152.183.236 \u0026lt;none\u0026gt; 443/TCP 12m kube-system service/monitoring-grafana ClusterIP 10.152.183.146 \u0026lt;none\u0026gt; 80/TCP 12m kube-system service/monitoring-influxdb ClusterIP 10.152.183.137 \u0026lt;none\u0026gt; 8083/TCP,8086/TCP 12m NAMESPACE NAME READY UP-TO-DATE AVAILABLE AGE container-registry deployment.apps/registry 1/1 1 1 12m kube-system deployment.apps/heapster-v1.5.2 1/1 1 1 12m kube-system deployment.apps/hostpath-provisioner 1/1 1 1 12m kube-system deployment.apps/kube-dns 1/1 1 1 12m kube-system deployment.apps/kubernetes-dashboard 1/1 1 1 12m kube-system deployment.apps/monitoring-influxdb-grafana-v4 1/1 1 1 12m NAMESPACE NAME DESIRED CURRENT READY AGE container-registry replicaset.apps/registry-7d65c894c 1 1 1 12m kube-system replicaset.apps/heapster-v1.5.2-5c5498f57c 0 0 0 12m kube-system replicaset.apps/heapster-v1.5.2-6b5d7b57f9 1 1 1 10m kube-system replicaset.apps/heapster-v1.5.2-89b48dff 0 0 0 10m kube-system replicaset.apps/hostpath-provisioner-6d744c4f7c 1 1 1 12m kube-system replicaset.apps/kube-dns-6bfbdd666c 1 1 1 12m kube-system replicaset.apps/kubernetes-dashboard-6fd7f9c494 1 1 1 12m kube-system replicaset.apps/monitoring-influxdb-grafana-v4-78777c64c8 1 1 1 12m System Pod 확인 namespace를 kube-system으로 지정하면 됨. namespace는 microk8s.kubectl get all --all-namespaces 명령의 출력에 나오는 NAMESPACE에서 알 수 있음\ncychong@mini1:~$ sudo microk8s.kubectl get pod No resources found. cychong@mini1:~$ sudo microk8s.kubectl get pod --namespace=kube-system NAME READY STATUS RESTARTS AGE heapster-v1.5.2-5c5498f57c-wztz5 4/4 Terminating 0 16m heapster-v1.5.2-6b5d7b57f9-4q9rd 4/4 Running 0 15m heapster-v1.5.2-89b48dff-g9hqj 4/4 Terminating 0 15m hostpath-provisioner-6d744c4f7c-gxksl 1/1 Running 0 16m kube-dns-6bfbdd666c-t6f74 3/3 Running 0 16m kubernetes-dashboard-6fd7f9c494-48dnz 1/1 Running 0 16m monitoring-influxdb-grafana-v4-78777c64c8-c5jk4 2/2 Running 0 16m 특정 pod에 대한 정보만 보고 싶을 때는 pod 명령 뒤에 pod name을 지정한다.\n``` cychong@mini1:~$ sudo microk8s.kubectl get pod kubernetes-dashboard-6fd7f9c494-48dnz --namespace=kube-system NAME READY STATUS RESTARTS AGE kubernetes-dashboard-6fd7f9c494-48dnz 1/1 Running 0 20m cychong@mini1:~$ sudo microk8s.kubectl get pod kubernetes-dashboard-6fd7f9c494-48dnz --namespace=kube-system -o wide NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES kubernetes-dashboard-6fd7f9c494-48dnz 1/1 Running 0 19m 10.1.1.6 mini1 \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; Service 확인 cychong@mini1:~$ sudo microk8s.kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.152.183.1 \u0026lt;none\u0026gt; 443/TCP 33m cychong@mini1:~$ sudo microk8s.kubectl cluster-info [sudo] password for cychong: Kubernetes master is running at https://127.0.0.1:16443 Heapster is running at https://127.0.0.1:16443/api/v1/namespaces/kube-system/services/heapster/proxy KubeDNS is running at https://127.0.0.1:16443/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy Grafana is running at https://127.0.0.1:16443/api/v1/namespaces/kube-system/services/monitoring-grafana/proxy InfluxDB is running at https://127.0.0.1:16443/api/v1/namespaces/kube-system/services/monitoring-influxdb:http/proxy To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'. Example. Ngnix container replicaset을 만들고 service로 expose Deploy Lightweight Kubernetes with MicroK8s and Snap - Computing for Geeks\n# microk8s.kubectl run nginx --replicas 2 --image nginx deployment.apps/nginx created # microk8s.kubectl get deployments NAME READY UP-TO-DATE AVAILABLE AGE nginx 2/2 2 2 39s # microk8s.kubectl get pods NAME READY STATUS RESTARTS AGE nginx-7db9fccd9b-7662b 1/1 Running 0 61s nginx-7db9fccd9b-87z6d 1/1 Running 0 61s # microk8s.kubectl expose deployment nginx --port 80 --target-port 80 \\ --type ClusterIP --selector=run=nginx --name nginx service/nginx exposed # microk8s.kubectl get services NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE kubernetes ClusterIP 10.152.183.1 443/TCP 27m nginx ClusterIP 10.152.183.54 80/TCP 104s # microk8s.kubectl delete deployment nginx deployment.extensions \u0026quot;nginx\u0026quot; deleted # microk8s.kubectl delete service nginx service \u0026quot;nginx\u0026quot; deleted Setup Ghost Setup volume ghost의 DB를 sqlite3를 사용하고 있어 DB 파일이 저장될 위치인 공간을 node에 생성한다.\nvolume.yaml kind: PersistentVolume apiVersion: v1 metadata: name: ghost-pv-volume labels: type: local spec: storageClassName: manual capacity: storage: 12Gi accessModes: - ReadWriteOnce hostPath: path: \u0026quot;/home/cychong/Dropbox/Apps/ghost/content\u0026quot; cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl apply -f volume.yaml [sudo] password for cychong: persistentvolume/ghost-volume created cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-volume 12Gi RWO Retain Available manual 17s pvc-942cf467-7906-11e9-8f0b-00264a162bca 20Gi RWX Delete Bound container-registry/registry-claim microk8s-hostpath 28h 특정 volume 정보만 확인하려면 get pv 뒤에 volume 이름을 지정한다.\ncychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get pv ghost-volume NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-volume 12Gi RWO Retain Available manual 24s 특정 volume 삭제하려면 delete pv [volume-name]을 사용한다.\ncychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-pv-volume 12Gi RWO Retain Available manual 4s ghost-volume 12Gi RWO Retain Available manual 20m pvc-942cf467-7906-11e9-8f0b-00264a162bca 20Gi RWX Delete Bound container-registry/registry-claim microk8s-hostpath 28h cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl delete pv ghost-volume persistentvolume \u0026quot;ghost-volume\u0026quot; deleted cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get pv NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-pv-volume 12Gi RWO Retain Available manual 112s pvc-942cf467-7906-11e9-8f0b-00264a162bca 20Gi RWX Delete Bound container-registry/registry-claim microk8s-hostpath 28h Volume Claim volume-claim.yaml\nPod에서 PV를 사용하려면 PVC(Persistent Volume Claim)을 설정한다. 앞에서 본 volume.yaml과 유사하지만 requests를 통해 일정 크기(아래는 10G)를 요청한다.\nkind: PersistentVolumeClaim apiVersion: v1 metadata: name: ghost-pv-claim labels: type: local spec: storageClassName: manual accessModes: - ReadWriteOnce resources: requests: storage: 10Gi cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl apply -f volume-claim.yaml persistentvolumeclaim/ghost-pv-claim created Claim 된 Volume의 상태 확인 get pv 명령으로 volume의 상태를 확인하면 이전에는 STATUS가 Available이었던 것이 Bound로 변경된 것을 알 수 있다.\ncychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get pv ghost-pv-volume NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE ghost-pv-volume 12Gi RWO Retain Bound default/ghost-pv-claim manual 3m40s get pvc 명령으로 확인하면 claim된 volume에 대한 정보를 확인할 수 있다.\ncychong@mini1:~$ sudo microk8s.kubectl get pvc NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE ghost-pv-claim Bound ghost-pv-volume 12Gi RWO manual 146m Deploy 이제 실제 container를 이용한 Pod를 구성한다.\nPod를 직접 생성하고 Container를 실행할 수도 있지만, 이 경우 Pod의 상태를 확인하여 다시 실행해 주는 kubernetes의 관리 기능을 이용할 수 없다.\ndeployment.yaml 동시에 하나의 ghost container만 띄우면 되므로 아래와 같이 replicas를 1로 지정한다.\n그 외 deploy할 때 항상 최신 docker image를 다운 받도록 imagePullPolicy를 Always 로 설정한다.\nContainer에 넘길 환경 변수 등은 env 항목을 통해 넘길 수 있고, 위에서 생성한 volume cliam을 ghost-content라는 이름으로 지정한 후 mountPath를 이용하여 container의 특정 위치에 마운트되도록 한다.\n즉 ghost-pv-volume → ghost-pv-claim → ghost-content→ ghost\napiVersion: apps/v1 kind: Deployment metadata: name: ghost labels: app: ghost spec: replicas: 1 selector: matchLabels: app: ghost template: metadata: labels: app: ghost spec: containers: - name: ghost image: ghost imagePullPolicy: Always ports: - containerPort: 2368 env: - name: url value: http://sosa0sa.com:2368 - name: NODE_ENV value: production volumeMounts: - mountPath: /var/lib/ghost/content name: ghost-content volumes: - name: ghost-content persistentVolumeClaim: claimName: ghost-pv-claim cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl apply -f deployment.yaml [sudo] password for cychong: deployment.apps/ghost created cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get pods NAME READY STATUS RESTARTS AGE ghost-79b8c8979d-7m7fm 0/1 ContainerCreating 0 9s cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get deploy NAME READY UP-TO-DATE AVAILABLE AGE ghost 0/1 1 0 71s 시간이 지나면 READY 상태가 1/1로 변경되고, AVAILABLE 값이 역시 0에서 1로 변경된다.\ncychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get pods NAME READY STATUS RESTARTS AGE ghost-79b8c8979d-7m7fm 1/1 Running 0 90s cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get deploy NAME READY UP-TO-DATE AVAILABLE AGE ghost 1/1 1 1 92s 이제 Pod/container는 정상적으로 실행이 된 상태\n만일 ghost라고 명명된 Pod이 비정상 상태가 되면 자동으로 다른 Pod를 실행시킨다.\ncychong@mini1:~/work/ghost-in-k8s$ sudo microk8s.kubectl get pods NAME READY STATUS RESTARTS AGE default-http-backend-5769f6bc66-jpcfj 1/1 Terminating 0 27h ghost-79b8c8979d-7m7fm 1/1 Running 0 29h cychong@mini1:~/work/ghost-in-k8s$ sudo microk8s.kubectl delete pod ghost-79b8c8979d-7m7fm pod \u0026quot;ghost-79b8c8979d-7m7fm\u0026quot; deleted ^Z [1]+ Stopped sudo microk8s.kubectl delete pod ghost-79b8c8979d-7m7fm cychong@mini1:~/work/ghost-in-k8s$ bg [1]+ sudo microk8s.kubectl delete pod ghost-79b8c8979d-7m7fm \u0026amp; cychong@mini1:~/work/ghost-in-k8s$ sudo microk8s.kubectl get pod NAME READY STATUS RESTARTS AGE default-http-backend-5769f6bc66-jpcfj 1/1 Terminating 0 27h ghost-79b8c8979d-468d2 1/1 Running 0 76s ghost-79b8c8979d-7m7fm 1/1 Terminating 0 29h 위 예에서는 기존에 동작하고 있던 pod을 삭제하니(정상적으로 삭제가 되지 않아 STATUS가 Terminating 상태로 표시되고 있다. 확인 필요)\nkind: Pod or kind: deployment?\nPod를 직접 생성하는 yaml 파일을 만들어 사용할 수도 있지만 상용에서는 직접 pod를 만들기 보다 deployment를 통해 pod를 생성하고 pod를 관리한다.\nIn kubernetes what is the difference between a pod and a deployment?\nService ghost는 Cluster 외부에서 접속이 필요한 블로그 서비스이므로 외부에서 접속이 가능하도록 external IP를 가질 수 있게 service를 구성한다.\nservice.yaml apiVersion: v1 kind: Service metadata: name: ghost spec: type: LoadBalancer selector: app: ghost ports: - protocol: TCP port: 2368 targetPort: 2368 type:LoadBalancer를 적용하면 외부 통신에 대해 Load Balancer를 사용하여 자동으로 EXTERNAL-IP가 설정된다고 한다.\nhttps://kubernetes.io/docs/concepts/services-networking/service/#publishing-services-service-types\nLoadBalancer: Exposes the service externally using a cloud provider’s load balancer. NodePort and ClusterIP services, to which the external load balancer will route, are automatically created.\nHow to install Kubernetes dashboard on external IP address?\n하지만 위 파일을 적용했는데 EXTERNAL-IP 정보가 pending으로 나온다.\ncychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl apply -f service.yaml service/ghost created cychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get service NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE ghost LoadBalancer 10.152.183.119 \u0026lt;pending\u0026gt; 2368:30126/TCP 3s kubernetes ClusterIP 10.152.183.1 \u0026lt;none\u0026gt; 443/TCP 32h 웹 브라우저를 이용해서 Cluster 외부에서 접속(ghost Pod가 deploy된 mini1 머신의 IP로 접속)을 시도해 보지만 접속이 안된다.\n아무래도 저 pending 상태로 나오는 게 이상한데 혹시나 하고 검색을 해 보니 역시나 저렇게 되면 외부에서 접속이 안된다고. 그 이유로 처음에 사용한 service 파일에서 사용된 LoadBalancer type이 microk8s에서는 지원되지 않기 때문이라고 한다. 추가로 load balancer를 설치해도 여전히 안된다고\u0026hellip;\nktsakalozos commented on Nov 23, 2018 Hi @khteh , Kubernetes does not provide a loadbalancer. It is assumed that loadbalancers are an external component [1]. MicroK8s is not shipping any loadbalancer but even if it did there would not have been any nodes to balance load over. There is only one node so if you want to expose a service you should use the NodePort service type.\nmicrok8s does not support LoadBalancer nginx loadbalancer service EXTERNAL-IP is always in \u0026ldquo;pending\u0026rdquo; state · Issue #200 · ubuntu/microk8s\nkubernetes service external ip pending\nPublishing Service Type 변경 service.yaml 파일의 Publishing Service Type을 microk8s에서 지원되는 NodePort로 변경한 후 다시 appy한 후 다시 접속을 시도하지만 여전히 접속이 되지 않는다.\nService 수정해서 External IP 강제 지정 Node의 EXTERNAL-IP 정보가 여전히 빈칸으로 나온다.\ncychong@mini1:~/Dropbox/working/kubernetes$ sudo microk8s.kubectl get nodes -o wide NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME mini1 Ready \u0026lt;none\u0026gt; 35h v1.14.1 192.168.1.100 \u0026lt;none\u0026gt; Ubuntu 18.04.2 LTS 4.15.0-48-generic containerd://1.2.5 원래(?) service 에서 NodePort 타입으로 지정하고 port 만 지정하면 Cluster 외부에서 접속이 되어야 하는데 이것 때문에 안되는 듯 하다.\n그래서 결국 임시로 service.yaml 수정해서 external IP를 강제로 지정했다. exteranlIPs이므로 배열 형태로 지정 한다.\napiVersion: v1 kind: Service metadata: name: ghost spec: type: NodePort externalTrafficPolicy : Local externalIPs : [192.168.1.100] selector: app: ghost ports: - protocol: TCP port: 2368 targetPort: 2368 변경된 service.yaml을 적용한 후 service 내용을 확인하면 EXTERNAL-IP 정보가 변경된 것을 확인할 수 있다.\ncychong@mini1:~/work/ghost-in-k8s$ sudo microk8s.kubectl get svc -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR ghost NodePort 10.152.183.119 192.168.1.100 2368:30126/TCP 4h54m app=ghost kubernetes ClusterIP 10.152.183.1 \u0026lt;none\u0026gt; 443/TCP 37h \u0026lt;none\u0026gt; 이제 Cluster 외부에서도 node의 EXTERNAL-IP를 이용해서 접속할 수 있다.\nmetalLB를 사용하는 것이 대안일까? ingress 서비스를 enable하고, ngnix를 추가로 설치한다.\nhttps://kndrck.co/posts/microk8s_ingress_example/\ngithub 위에서 사용된 모든 YAML 파일은 아래 위치에서 확인할 수 있다.\ncychong47/ghost-in-k8s\n","date":"2019-05-20T16:00:56+09:00","permalink":"https://cychong47.github.io/post/2019/setup-ghost-in-microk8s-2/","summary":"\u003ch1 id=\"install-microk8s\"\u003eInstall microk8s\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://microk8s.io/\"\u003eMicroK8s - Fast, Light, Upstream Developer Kubernetes\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e설치는 위 링크에 있는 공식 홈페이지에 있는 대로 \u003ccode\u003esnap\u003c/code\u003e 명령어 하나로 간단하게 설치할 수 있다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecychong@mini1:~$ sudo snap install microk8s --classic\n2019-05-18T09:43:53+09:00 INFO Waiting for restart...\nmicrok8s v1.14.1 from Canonical✓ installed\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e설치된 \u003ccode\u003emicrok8s\u003c/code\u003e의 정보를 확인하려면 \u003ccode\u003esnap info microk8s\u003c/code\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ecychong@mini1:~$ sudo snap info microk8s\nname:      microk8s\nsummary:   Kubernetes for workstations and appliances\npublisher: Canonical✓\ncontact:   \u0026lt;https://github.com/ubuntu/microk8s\u0026gt;\nlicense:   unset\ndescription: |\n  MicroK8s is a small, fast, secure, single node Kubernetes that installs on just about any Linux\n  box. Use it for offline development, prototyping, testing, or use it on a VM as a small, cheap,\n  reliable k8s for CI/CD. It's also a great k8s for appliances - develop your IoT apps for k8s and\n  deploy them to MicroK8s on your boxes.\ncommands:\n  - microk8s.config\n  - microk8s.ctr\n  - microk8s.disable\n  - microk8s.enable\n  - microk8s.inspect\n  - microk8s.istioctl\n  - microk8s.kubectl\n  - microk8s.reset\n  - microk8s.start\n  - microk8s.status\n  - microk8s.stop\nservices:\n  microk8s.daemon-apiserver:          simple, enabled, active\n  microk8s.daemon-apiserver-kicker:   simple, enabled, active\n  microk8s.daemon-containerd:         simple, enabled, active\n  microk8s.daemon-controller-manager: simple, enabled, active\n  microk8s.daemon-etcd:               simple, enabled, active\n  microk8s.daemon-kubelet:            simple, enabled, active\n  microk8s.daemon-proxy:              simple, enabled, active\n  microk8s.daemon-scheduler:          simple, enabled, active\nsnap-id:      EaXqgt1lyCaxKaQCU349mlodBkDCXRcg\ntracking:     stable\nrefresh-date: today at 09:44 KST\nchannels:\n  stable:         v1.14.1         2019-04-18 (522) 214MB classic\n  candidate:      v1.14.1         2019-04-15 (522) 214MB classic\n  beta:           v1.14.1         2019-04-15 (522) 214MB classic\n  edge:           v1.14.2         2019-05-17 (604) 217MB classic\n  1.15/stable:    –\n  1.15/candidate: –\n  1.15/beta:      –\n  1.15/edge:      v1.15.0-alpha.3 2019-05-08 (578) 215MB classic\n  1.14/stable:    v1.14.1         2019-04-18 (521) 214MB classic\n  1.14/candidate: v1.14.1         2019-04-15 (521) 214MB classic\n  1.14/beta:      v1.14.1         2019-04-15 (521) 214MB classic\n  1.14/edge:      v1.14.2         2019-05-17 (603) 217MB classic\n  1.13/stable:    v1.13.5         2019-04-22 (526) 237MB classic\n  1.13/candidate: v1.13.6         2019-05-09 (581) 237MB classic\n  1.13/beta:      v1.13.6         2019-05-09 (581) 237MB classic\n  1.13/edge:      v1.13.6         2019-05-08 (581) 237MB classic\n  1.12/stable:    v1.12.8         2019-05-02 (547) 259MB classic\n  1.12/candidate: v1.12.8         2019-05-01 (547) 259MB classic\n  1.12/beta:      v1.12.8         2019-05-01 (547) 259MB classic\n  1.12/edge:      v1.12.8         2019-04-24 (547) 259MB classic\n  1.11/stable:    v1.11.10        2019-05-10 (557) 258MB classic\n  1.11/candidate: v1.11.10        2019-05-02 (557) 258MB classic\n  1.11/beta:      v1.11.10        2019-05-02 (557) 258MB classic\n  1.11/edge:      v1.11.10        2019-05-01 (557) 258MB classic\n  1.10/stable:    v1.10.13        2019-04-22 (546) 222MB classic\n  1.10/candidate: v1.10.13        2019-04-22 (546) 222MB classic\n  1.10/beta:      v1.10.13        2019-04-22 (546) 222MB classic\n  1.10/edge:      v1.10.13        2019-04-22 (546) 222MB classic\ninstalled:        v1.14.1                    (522) 214MB classic\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"enable-servicesmicrok8s\"\u003eEnable services(microk8s)\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003ecychong@mini1:~$ sudo microk8s.enable dashboard registry dns\nEnabling dashboard\nsecret/kubernetes-dashboard-certs created\nserviceaccount/kubernetes-dashboard created\ndeployment.apps/kubernetes-dashboard created\nservice/kubernetes-dashboard created\nservice/monitoring-grafana created\nservice/monitoring-influxdb created\nservice/heapster created\ndeployment.extensions/monitoring-influxdb-grafana-v4 created\nserviceaccount/heapster created\nconfigmap/heapster-config created\nconfigmap/eventer-config created\ndeployment.extensions/heapster-v1.5.2 created\ndashboard enabled\nEnabling the private registry\nEnabling default storage class\ndeployment.extensions/hostpath-provisioner created\nstorageclass.storage.k8s.io/microk8s-hostpath created\nStorage will be available soon\nApplying registry manifest\nnamespace/container-registry created\npersistentvolumeclaim/registry-claim created\ndeployment.extensions/registry created\nservice/registry created\nThe registry is enabled\nEnabling DNS\nApplying manifest\nservice/kube-dns created\nserviceaccount/kube-dns created\nconfigmap/kube-dns created\ndeployment.extensions/kube-dns created\nRestarting kubelet\nDNS is enabled\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e서비스 상태는 \u003ccode\u003emicrok8s.status\u003c/code\u003e로 확인 가능\u003c/p\u003e","title":"Setup Ghost in microk8s"},{"content":"ghost blog를 구성해서 사용한 게 벌써 2014년 이다. 당시 0.x 버전 이었던 초반에는 얼마 못 가고 사라지지 않을까 걱정했는데 한참을 1.0버전을 발표하지 않더니 벌써 2.x 버전이다.\n그동안 내가 ghost 블로그를 운용하는 방식도 몇 번의 변화를 가졌다.\n시즌 1 - brew \u0026amp; tar-ball 처음에는 매뉴얼 대로 직접 Node.js와 ghost 소스를 이용해서 직접 OS X에 설치해서 운용했다.\n시즌 2 - Docker 그러다 Node.js 버전이 꼬이는 것도 그렇고, docker를 쓰면 ghost 버전이 새로 나왔을 때 편할 듯 해서 docker를 쓰는 방식으로 변경했다. 이 시점에 docker의 stateless 속성을 이용하고, 데이터의 백업도 고려해서 ghost content는 Dropbox에 두고, docker 실행할 때 volume으로 마운트 하는 방식을 사용했다. 그 당시 ghost보다 먼저 운용하고 있던 wordpress도 함께 docker로 실행 환경을 바꿨다. wordpess는 ghost와 달리 MySql을 필요로 해서 docker-compose를 이용해서 두 개의 container를 연동해서 실행했다.\n시즌 3 - Ansible로 remote deploy 이 당시에 ghost 블로그가 실행되는 mac mini 2011이 아닌 MacBookPro 2017에서 주로 작업을 하고 있던 터라 MacBookPro에서 mac mini에 로그인해서 작업하는 것도 귀찮아 원격(?)으로 ghost 업데이트를 하기 위해 ansible을 이용해서 ghost를 deploy 할 수 있게 했다.\n시즌 4 - Deploy with kubernetes docker, ansible로 실행 환경을 구성해 놓은 덕에 ghost와 wordpress를 기존에 Mac OS X의 docker for Mac을 사용하던 mini2 에서 Ubuntu를 설치한 mini1으로 별 다른 문제 없이 쉽게 옮길 수 있었다.\nDocker for Mac 보다 훨씬 안정적인 docker 덕에 아무런 문제 없이 쓰고 있었는데 괜히 kubernetes 환경으로 꾸며보고 싶었다. 개인 블로그라 특별한 장점이 있을까 싶긴 하지만, kubernetes 공부도 할 겸해서 바꿔보기로 했다. 눈으로만 익히고 입개발만 하기 보다는 직접 해보는 게 남는 게 많을 거라 내가 가진 환경에서 kubernetes를 운용할 수 있는 방법부터 찾아 봤다.\n내 환경\n집에 있는 머신 들은 다음과 같다.\nMac mini1 2009 - Ubuntu 18.04 LTS. 현재 ghost, wordpress 블로그 운용 중 Mac mini2 2011 - OS X HP mini PC - Windows 10 MacBook Pro 2017 - OS X kubernetes의 기본 환경 구성이 Master와 Node라 대개 2개의 머신을 기본으로 요구한다. 한 대의 머신으로도 kubernetes를 구성할 수 있는 MiniKube등이 있지만 VM을 기반으로 하는 거라 벌써 연식이 10년이 넘은 mini1에서 돌리기에는 부담이 되보였다. 그래서 Docker for Mac이 설치되어 있는 mini2를 master로 하고, mini1을 node로 사용하는 방법을 생각하고 시도해봤다. 하지만 아직 Docker for Mac은 node를 추가하는 건 지원하지 않는다고. 그럼 worker node를 mini2에서 돌려야 한다는 건데 굳이 다시 mini2으로 container 실행 환경을 돌리고 싶지는 않았다.\n그래서 mini2만으로 kubernetes를 구성할 수 있는 방법을 찾아 보다 microk8s를 적용해 보기로 했다. Canonical에서 공개한 kubernetes 실행 환경인데 local machine에서 실행할 수 있도록 경량화 한 것이 특정이라고 한다.\nIt’s not elastic, but it is on rails. Use it for offline development, prototyping, testing, or use it on a VM as a small, cheap, reliable k8s for CI/CD. Makes a great k8s for appliances - develop your IoT apps for k8s and deploy them to MicroK8s on your boxes.\n기본적인 설치는 snap 을 이용하는데 https://microk8s.io/ 페이지에 있는 명령을 이용하면 간단하게 kubernetes 환경 구성이 가능하다.\nGhost를 kubernetes에 설치하는 것이 내가 처음은 아닐 듯 해서 검색해 보니 How to run Ghost in Kubernetes 이런 글이 나왔다. 2018년 12월 글이라 크게 달라진 점은 없을 듯 해서 kubernetes.io의 글과 이 글을 이용해서 하나 하나 따라갔다. 결론적으로 내가 구성한 환경 역시 이 분이 작성하신 것과 큰 차이가 없지만 한가지 차이점 때문에 몇 시간을 헤매야 했다. 이글은 Digital Ocean 환경에서 제공하는 kubernetes를 이용하여 ghost를 구성했는데 내가 구성한 환경은 microk8s였다. 가장 큰 차이점 중 하나가 microk8s는 외부에 서비스를 expose할 때 사용할 수 있는 방식 중 LoadBalancer를 원하지 않는다는 점이다.\n자세한 설치기는 to be continued\u0026hellip;\n","date":"2019-05-19T12:45:58+09:00","permalink":"https://cychong47.github.io/post/2019/ghost-deployment-season-4/","summary":"\u003cp\u003eghost blog를 구성해서 사용한 게 벌써 2014년 이다. 당시 0.x 버전 이었던 초반에는 얼마 못 가고 사라지지 않을까 걱정했는데 한참을 1.0버전을 발표하지 않더니 벌써 2.x 버전이다.\u003c/p\u003e\n\u003cp\u003e그동안 내가 ghost 블로그를 운용하는 방식도 몇 번의 변화를 가졌다.\u003c/p\u003e\n\u003ch3 id=\"시즌-1---brew--tar-ball\"\u003e시즌 1 - brew \u0026amp; tar-ball\u003c/h3\u003e\n\u003cp\u003e처음에는 매뉴얼 대로 직접 Node.js와 ghost 소스를 이용해서 직접 OS X에 설치해서 운용했다.\u003c/p\u003e\n\u003ch3 id=\"시즌-2---docker\"\u003e시즌 2 - Docker\u003c/h3\u003e\n\u003cp\u003e그러다 Node.js 버전이 꼬이는 것도 그렇고, docker를 쓰면 ghost 버전이 새로 나왔을 때 편할 듯 해서 \u003ca href=\"http://sosa0sa.com:2368/move-to-docker/\"\u003edocker를 쓰는 방식으로 변경했다\u003c/a\u003e. 이 시점에 docker의 stateless 속성을 이용하고, 데이터의 백업도 고려해서 ghost content는 Dropbox에 두고, docker 실행할 때 volume으로 마운트 하는 방식을 사용했다.\n그 당시 ghost보다 먼저 운용하고 있던 \u003ca href=\"http://sosa0sa.com:2368/install-wordpress-with-docker/\"\u003ewordpress도 함께 docker로 실행 환경을 바꿨다\u003c/a\u003e. wordpess는 ghost와 달리 MySql을 필요로 해서 docker-compose를 이용해서 두 개의 container를 연동해서 실행했다.\u003c/p\u003e","title":"ghost deployment season 4"},{"content":"Kubernetes Networks in google docs\n이거 보면 IPv6를 사용해야 하는 경우 선택할 수 있는 CNI는 Calico, Cillium, Contiv, Tungsten Fabric 정도로 좁혀지네\n","date":"2019-05-16T14:07:53+09:00","permalink":"https://cychong47.github.io/post/2019/kubernetes-networks/","summary":"\u003cp\u003e\u003ca href=\"https://docs.google.com/spreadsheets/d/1qCOlor16Wp5mHd6MQxB5gUEQILnijyDLIExEpqmee2k/edit?fbclid=IwAR0tlnpZ694c674Tmri3N3vgpaq4jH4zzPSA-RgFz1o4C49NgurHCezPDGo#gid=0\"\u003eKubernetes Networks in google docs\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e이거 보면 IPv6를 사용해야 하는 경우 선택할 수 있는 CNI는 Calico, Cillium, Contiv, Tungsten Fabric 정도로 좁혀지네\u003c/p\u003e","title":"Kubernetes Networks"},{"content":"https://zaverome.wordpress.com/2019/01/09/%EC%95%84%EB%A7%88%EC%A1%B4-3%EB%85%84-%EC%B6%9C%EA%B7%BC%EA%B8%B0-1-%ED%95%98%EB%A3%A8-%EC%9D%BC%EA%B3%BC-%EB%B0%8F-%EC%9A%94%EC%95%BD/\n인상적인 내용들\n매일 하는 스탠드업 미팅(데일리 스크럼)은 오후 4시입니다.\n오후 4시에 하는 데일리 미팅이라. 신기하다. 보통 오늘 할 일과, 이슈 등을 이야기하는 것이 잘 알려진 daily meeting의 practice인데 오후에 한다니. 아래 내용을 보면 야근도 안 한다는데. 흠.. 신기하네\n아마존에서 일한 이래 일이 많아서 사무실에 늦게까지 남아 야근을 한 일은 한 번도 없습니다. 일년에 두 세번 정도 일이 좀 남아서 퇴근 후에 집에서 한 두시간 정도 일을 한 적은 있습니다.\n어떻게 이게 가능할까? 정말 업무를, 과제를 팀 능력에 맞게 잘 계획해서?\n시장(?)이나 어떤 이유로 인해 빠른 개발을 요구받는 경우도 없나? 분명히 야근은 없다고 했는데. 아마도 B2B지만, 고객의 기능, 일정 요구에 맞춰서 개발을 진행하는 것이 아니라 우리 팀의 개발 일정에 맞게 진행해서 그런 것이 아닌가 싶다. 그게 아니라면 어떻게 가능할까??\n이런 걸 신기하다고 생각하는 나, 내가 속한 조직이 이상한 걸까? 아니면 저런 조직이 특이한 걸까? 지난 번에 샌프란시스코에서 본 후배도 비슷하게 일하는 걸 보면 아마존만 이상하거나 특이한 건 아닌 듯 한데. 그렇다고 내가 속한 조직만 그런 건 아니고 옆, 그 옆 그리고 그 옆옆 부서도 그런 걸 보면 적어도 내가 있는 건물에 있는 우리 회사는 대부분 저 아마존하고 다른 건 확실한데.\n코드 리뷰에 열심히 참여할 수록 팀에서의 영향력이 증가합니다.\n중요한 내용이네. 코드를 많이 알수록 팀의 업무를 많이 알게 되는 거라 그 만큼 할 수 있는 일이 많아진다는 뜻인 듯.\n시니어 엔지니어일 수록 본인이 직접 코드를 작성하는 시간보다 아키텍쳐 리뷰, 디자인 리뷰, 코드 리뷰 등을 통해 간접적으로 코드를 작성하는 시간이 길어지게 됩니다. 참고로, 아마존의 최상위 엔지니어 등급인 프린시플 엔지니어들은 대부분의 시간을 문서 리뷰 혹은 멘토링에 할애한다고 합니다.\n우리와는 다른 의미의 prinipal engineer. 아무튼 경력/경험이 많아질 수록 리뷰하는데 많은 시간을 보낸 다는 것. 우리 회사도 그렇기는 한 듯.\n팀의 분위기는 스타트업과 비슷합니다. 신규 서비스이기 때문에 개발팀 스스로 요구사항을 정의하고, 사용자 패턴을 상상해 서비스를 만들어 나가고 있습니다.\n글을 쓴 사람이 속한 팀 성격이 새로운 서비스를 만드는 팀이라서 그렇다고 하네. 여기서 말하는 서비스가 어떤 정도의 크기인지는 잘 모르겠지만, 새로운 캐시카우가 되길 바란다는 정도면 그래도 하나의 단독적인 서비스라고 생각이 되지만 우리 회사가 일하는 과제보다는 사이즈가 작지 않을까 하는 예상.\n13 포인트가 한 사람이 한 스프린트에서 수행할 수 있는 최대 포인트로 상정하고 이에 기반해 팀 토론을 거쳐 사이즈를 예측합니다. 또한, 단일 이슈가 13포인트 이상이 되면 세부 이슈로 나눕니다.\nSprint 주기를 2주라고 했는데 그럼 하나의 이슈가 2주일 짜리도 가능하다는 이야기인가? 그리고 여기서 말하는 13포인트는 어디서 나온 걸까? 피보나치 수에서 가져왔다고 하는데(scrum에서 흔히 사용하는 story point인 듯 하긴 하네, https://wormwlrm.github.io/2018/09/09/Scrum-tutorial-for-adapting-agile-methodologies.html, https://ko.popularhowto.com/estimating-end-of-scrum-projects-with-fibonacci-numbers-and-story-points) 좀 더 공부해 봐야 할 듯.\n스프린트가 종료되면 각자가 해당 스프린트에서 완료한 작업을 간단히 시연합니다. 또한, 해당 스프린트 동안 잘 된일, 개선할 수 있는 일들을 논의하고, 액션 아이템을 도출합니다.\n요즘 시연을 하는 게 별로 없었는데 다시 좀 활성화시키면 좋겠다. 다들 개발자다 보니 뭔가 동작하는 걸 만들면 조금 더 성취감을 느끼지 않을까?\n아마존의 개발팀은 시니어 엔지니어와 매니저(팀장)가 이끈다고 볼 수 있습니다. 팀장과 시니어 엔지니어 모두 부장 정도의 레벨이라고 보면 될 것 같습니다. 이 중 시니어 엔지니어는 일을 ‘어떻게’ 할 것인지(컴포넌트 구성, 소프트웨어 디자인, 인터페이스 등)를 결정한다면, 매니저는 ‘무엇을’ 할 것인지를 결정합니다. 주로 일의 우선 순위 관리가 이에 해당하겠지요. 그렇기 때문에 매니저는 기술적인 구현에 거의 관여하지 않고, 시니어 엔지니어가 이를 주도합니다. 팀장의 큰 역할 중 하나는 팀내 개발자들의 ‘관리’입니다. 개별 개발자가 본인의 일을 잘 할 수 있도록 불필요한 일들을 치워 주거나, 다른 팀의 역할이 필요한 경우 해당 팀을 설득하거나 혹은 개발자가 성장할 수 있도록 적절한 일을 맡기는 등의 일입니다.\n아무래도 난 매니저로서의 시니어 엔지니어가 그나마 더 가망이 있어 보이는데. 아직도 개발자 마인드가 크게 남아 있어 여전히 전략적으로 말하지 못하고(물어보면 신나서 아는 거 다 이야기하는 개발자 속성) 설득력있는 논리를 만드는 능력이 부족하다. 때(?)로는 만들어진 논리가 순리를 이기는 경우가 많은 데 아직도 \u0026lsquo;옳은 게 맞는 거다\u0026rsquo;라는 생각을 버리지 못한다.\n하지만 개발이던 매니징이던 다 잘하는 사람이 있는 걸 보면 그냥 이건 핑계일 뿐, 내 능력이 부족해서 그런거라\u0026hellip;\n오늘도 한숨 100번 하고\n","date":"2019-05-16T11:54:25+09:00","permalink":"https://cychong47.github.io/post/2019/amazon-daily-work/","summary":"\u003cp\u003e\u003ca href=\"https://zaverome.wordpress.com/2019/01/09/%EC%95%84%EB%A7%88%EC%A1%B4-3%EB%85%84-%EC%B6%9C%EA%B7%BC%EA%B8%B0-1-%ED%95%98%EB%A3%A8-%EC%9D%BC%EA%B3%BC-%EB%B0%8F-%EC%9A%94%EC%95%BD/\"\u003ehttps://zaverome.wordpress.com/2019/01/09/%EC%95%84%EB%A7%88%EC%A1%B4-3%EB%85%84-%EC%B6%9C%EA%B7%BC%EA%B8%B0-1-%ED%95%98%EB%A3%A8-%EC%9D%BC%EA%B3%BC-%EB%B0%8F-%EC%9A%94%EC%95%BD/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e인상적인 내용들\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e매일 하는 스탠드업 미팅(데일리 스크럼)은 오후 4시입니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e오후 4시에 하는 데일리 미팅이라. \u003cstrong\u003e신기\u003c/strong\u003e하다. 보통 오늘 할 일과, 이슈 등을 이야기하는 것이 잘 알려진 daily meeting의 practice인데 오후에 한다니. 아래 내용을 보면 \u003cstrong\u003e야근\u003c/strong\u003e도 안 한다는데. 흠.. 신기하네\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e아마존에서 일한 이래 일이 많아서 사무실에 늦게까지 남아 야근을 한 일은 한 번도 없습니다. 일년에 두 세번 정도 일이 좀 남아서 퇴근 후에 집에서 한 두시간 정도 일을 한 적은 있습니다.\u003c/p\u003e","title":"(펌글) 아마존 3년 출근기"},{"content":"최고령 Mac은 아니고 세 번째 고령 가장 오래된 Mac은 2005년에 구입한 Powerbook. PowerPc processor를 사용한 마지막 Apple의 laptop. 그 다음 오래된 것은 iMac 2007. 하지만 이 두 녀석들은 현재 꺼진 상태로 방치되고 있어, 현역은 Mac mini 2009라는. 당시에 리퍼를 구입했던 걸로 기억하는데 10년이 지난 2019년에도 유용하게 사용하고 있다는 게 너무 신기하다.\n한글 글꼴 Firefox 등에서 한글 글꼴이 없어 한글 페이지가 깨져서 나눔고딕을 설치 이것 저것 찾아보다 https://blog.inidog.com/p/20170131169 참고해서 한번에 해결했다.마지막 명령어 fc-cache -r 을 수행하는 도중 firefox의 한글 페이지에서 깨진 한글 글꼴이 예쁜 나눔고딕으로 변하는 모습은 감동(?)이었다\u0026hellip;\n# 폰트 설치 경로로 이동합니다. cd /usr/share/fonts/ # 나눔고딕 폰트 파일을 다운로드합니다. wget http://cdn.naver.com/naver/NanumFont/fontfiles/NanumFont_TTF_ALL.zip # 나눔고딕 폰트 파일의 압축을 해제합니다. unzip NanumFont_TTF_ALL.zip -d NanumFont # 사용이 끝난 압축파일을 삭제합니다. rm -f NanumFont_TTF_ALL.zip # 시스템 폰트 리스트를 갱신합니다. fc-cache -r ","date":"2019-02-10T14:42:07+09:00","permalink":"https://cychong47.github.io/post/2019/install-ubuntu-18-04-1-in-mac-mini-2009/","summary":"\u003ch2 id=\"최고령-mac은-아니고-세-번째-고령\"\u003e최고령 Mac은 아니고 세 번째 고령\u003c/h2\u003e\n\u003cp\u003e가장 오래된 Mac은 2005년에 구입한 Powerbook. PowerPc processor를 사용한 마지막 Apple의 laptop. 그 다음 오래된 것은 iMac 2007. 하지만 이 두 녀석들은 현재 꺼진 상태로 방치되고 있어, 현역은 Mac mini 2009라는. 당시에 리퍼를 구입했던 걸로 기억하는데 10년이 지난 2019년에도 유용하게 사용하고 있다는 게 너무 신기하다.\u003c/p\u003e\n\u003ch2 id=\"한글-글꼴\"\u003e한글 글꼴\u003c/h2\u003e\n\u003cp\u003eFirefox 등에서 한글 글꼴이 없어 한글 페이지가 깨져서 나눔고딕을 설치\n이것 저것 찾아보다 \u003ca href=\"https://blog.inidog.com/p/20170131169\"\u003ehttps://blog.inidog.com/p/20170131169\u003c/a\u003e 참고해서 한번에 해결했다.마지막 명령어 \u003ccode\u003efc-cache -r\u003c/code\u003e 을 수행하는 도중 firefox의 한글 페이지에서 깨진 한글 글꼴이 예쁜 나눔고딕으로 변하는 모습은 감동(?)이었다\u0026hellip;\u003c/p\u003e","title":"Install Ubuntu 18.04.1 in Mac mini 2009"},{"content":"https://doc.dpdk.org/guides-18.11/rel_notes/release_18_11.html\nNew Features Updated the C11 memory model version of the ring library. Added changes to decrease latency for architectures using the C11 memory model version of the ring library.\nOn Cavium ThunderX2 platform, the changes decreased latency by 27-29% and 3-15% for MPMC and SPSC cases respectively (with 2 lcores). The real improvements may vary with the number of contending lcores and the size of the ring.\nAdded support for device multi-process hotplug. Added support for hotplug and hot-unplug in a multiprocessing scenario. Any ethdev devices created in the primary process will be regarded as shared and will be available for all DPDK processes. Synchronization between processes will be done using DPDK IPC.\nAdded Event Ethernet Tx Adapter. Added event ethernet Tx adapter library that provides configuration and data path APIs for the ethernet transmit stage of an event driven packet processing application. These APIs abstract the implementation of the transmit stage and allow the application to use eventdev PMD support or a common implementation. Added Distributed Software Eventdev PMD.\nAdded Distributed Software Eventdev PMD. Added the new Distributed Software Event Device (DSW), which is a pure-software eventdev driver distributing the work of scheduling among all eventdev ports and the lcores using them. DSW, compared to the SW eventdev PMD, sacrifices load balancing performance to gain better event scheduling throughput and scalability.\nAdded Telemetry API. Added a new telemetry API which allows applications to transparently expose their telemetry in JSON via a UNIX socket. The JSON can be consumed by any Service Assurance agent, such as CollectD.\nRefer to https://doc.dpdk.org/guides-18.11/howto/telemetry.html\nKnown Issues AVX-512 support has been disabled for GCC builds [1] because of a crash [2]. This can affect native machine type build targets on the platforms that support AVX512F like Intel Skylake processors, and can cause a possible performance drop. The immediate workaround is to use clang compiler on these platforms. The issue has been identified as a GCC defect and reported to the GCC community [3]. Further actions will be taken based on the GCC defect result. [1]: Commit 8d07c82b239f (“mk: disable gcc AVX512F support”) [2]: https://bugs.dpdk.org/show_bug.cgi?id=97 [3]: https://gcc.gnu.org/bugzilla/show_bug.cgi?id=88096\n","date":"2019-01-07T14:57:59+09:00","permalink":"https://cychong47.github.io/post/2019/dpdk-18-11/","summary":"\u003cp\u003e\u003ca href=\"https://doc.dpdk.org/guides-18.11/rel_notes/release_18_11.html\"\u003ehttps://doc.dpdk.org/guides-18.11/rel_notes/release_18_11.html\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"new-features\"\u003eNew Features\u003c/h2\u003e\n\u003ch4 id=\"updated-the-c11-memory-model-version-of-the-ring-library\"\u003eUpdated the C11 memory model version of the ring library.\u003c/h4\u003e\n\u003cp\u003eAdded changes to decrease latency for architectures using the C11 memory model version of the ring library.\u003c/p\u003e\n\u003cp\u003eOn Cavium ThunderX2 platform, the changes decreased latency by 27-29% and 3-15% for MPMC and SPSC cases respectively (with 2 lcores). The real improvements may vary with the number of contending lcores and the size of the ring.\u003c/p\u003e\n\u003ch4 id=\"added-support-for-device-multi-process-hotplug\"\u003eAdded support for device multi-process hotplug.\u003c/h4\u003e\n\u003cp\u003eAdded support for hotplug and hot-unplug in a multiprocessing scenario. Any ethdev devices created in the primary process will be regarded as shared and will be available for all DPDK processes. Synchronization between processes will be done using DPDK IPC.\u003c/p\u003e","title":"DPDK 18.11"},{"content":"p12 학교 학습 vs. 야생 학습 야생 학습은 대부분 자료에 한정이 없다.\n야생 학습은 대부분 명확한 평가가 없다.\n야생 학습은 대부분 정답이 없다.\n야생 학습은 대부분 목표가 불분명하고 바뀌기도 한다.\n학습의 본질은 야생 학습에 더 가깝다고 생각. 현실 세계에서는 야생 학습이 더 많이 필요하다고 봅니다.\np23 구조화된 인터뷰(특별히 구조화된 행동중심적 인터뷰를 권함)와 실제 작업을 해보도록 하는 작업 샘플 테스트, 그리고 가능하다면 실제 업무를 주고 시험적으로 짧은 기간 동안 일을 해보게 하는 것 등을 권합니다.\np30 그는 상당한 시간을 자기 환자를 확인하는 데에 보내면서, 진단 시에 자신이 무얼 생각하는 지 많은 기록을 하고, 자신이 얼마나 정확한 지 나중에 확인을 하더군요. 자신이 만든 이 부차적 단계가 그를 자신의 동료들로부터 차별화되는 중요한 점입니다.\np31 일 년 회고를 할 때 항상 되짚어 보는 것 중 하나가 나 자신에게 얼마나 투자를 했나 하는 것입니다.\n자기계발이 왜 중요하나고 생각하냐면, 현재 나에게 무엇을 투자했느냐가 1년, 혹은 2년 후에 나를 결정한다고 느끼기 때문입니다.\np33 작업 구분 Douglas Engelbart - 작업을 세 가지 수준으로 구분.\nA작업 : 원래 그 조직이 하기로 되어 있는 일을 하는 것 B작업 : A작업을 개선하는 것. 제품을 만드는 사이클에서 시간과 품질을 개선하는 것. 제품을 만드는 시스템을 잘 설계하는 것도 포함 C작업 : B작업을 개선하는 것. 개선 사이클 자체의 시간과 품질을 개선하는 것. 개선하는 인프라를 설계하는 것. 개선하는 능력을 개선하는 것 우리가 더 잘하는 것을 더 잘하게 될수록 우리는 더 잘하는 걸 더 잘 그리고 더 빨리 하게 될 것이다.\nPeter Senge\nA작업 : 겉으로 가장 잘 드러나는 수준으로 한 회사의 제품과 서비스의 개발, 생산, 판매와 관련이 있다. 그 회사의 사람과 자원의 대부분은 이 수준에 초점이 맞춰져 있다. B작업 : 회사가 자신의 제품과 서비스를 개발, 생산, 판매하는 걸 가능케 해주는 시스템과 프로세스를 설계하는 것과 관련 C작업 : 우리의 사고방식과 상호 작용 방법을 개선. C작업의 품질이 우리가 설계하는 시스템과 프로세스의 품질을 결정짓고, 나아가 우리가 제공하는 제품과 서비스의 품질을 결정짓는다. p35 복리 조직이 일하는 구조 동일한 조직이 매달 동일한 수준의 결과를 만드는 것이 아니라 지난 달 보다 발전된 수준에서 결과물을 만들어 냄. 그 다음 달은 더 높은 수준에서 결과물을 만들어 냄.\n매일 내가 더 나은 내가 되어 감. 복리의 효과. 지수적 증가\n지수적 팀 자기 자신을 곱해나가는 팀.\n부분의 합보다 전체가 크려면 시너지가 필요함. 상호 협력적으로 일하기.\n가용 시간을 늘리고, 쓸데없이 낭비되는 시간을 줄이고, 잠자는 시간을 줄이는 것이 더하기적 사고라면, 집단의 지능을 높히는 것은 곱하기적 사고 . 집단의 지능을 높히면 모든 지적 활동의 효율이 좋아지기 때문에 전반적인 개선(B작업)이 일어나고, 특히나 개선 작업을 더 잘하게(C작업) 된다.\n자신의 평소 투자하는 비용을 한번 살펴본다. B작업, C작업에 투자하는 것이 거의 없다면 후퇴하는 셈이 된다.\n자신이 이미 갖고 있는 것들을 잘 활용한다. 새로운 것을 유입하는 데만 집중하지 말고. 책 권 수보다는 책에서 얻은 지식을 어떻게 활용하는 지 반성. 이미 가지고 있는 것들을 하이퍼링크로 서로 촘촘히 연결. 이미 습득한 지식, 기술, 경험 등을 서로 연결해서 시너지 효과가 나게 하고, 다른 영역 간을 넘나들기 수월하게 만들 것\n외부 물질을 체화 주기적이 외부 자극. 단 재빨리 자기화.\n자신을 개선하는 프로세스에 대해 생각 주기적으로 나의 A작업을 회고/반성. 나를 개선하는 과정(B 작업)을 어떻게 하면 개선할 수 있을 지 고민\n피드백을 자주 받을 것 사이클 타임을 줄일 것. 일찍, 자주 실패할 것. 실패에서 학습할 것.\n자신의 능력을 높여주는 도구와 환경을 점진적으로 만들 것 활용 가능한 환경/툴 등을 구축\np43 동일한 자극/조건이 주어졌을 때 누군가는 더 많은 학습과 성장의 기회를 찾고 오히려 그 조건을 자신에게 유리한 조건으로 생각하기도 한다.\n인공지능에서 살아남으려면 독창성 : 주어진 주제나 상황에 대해 특이하거나 독창적인 생각을 해내기. 혹은 문제를 해결하는 창의적인 방법을 만들기 사회적 민감성 : 타인의 반응을 알아차리고 그 사람들이 왜 그렇게 반응하는 지 이해하기 협상 : 사람들을 화해시키고 서로 간의 차이를 조정하려고 노력 설득 : 다른 사람들이 마음이나 행동을 바꾸게 설득하기 타인을 돕고 돌보기 자신이 주로 하는 일이 남이 시킨 대로 혼자 프로그램을 만드는 것이라면 그런 스킬과 경력만 계속 쌓일 것입니다.\n현재 자신의 업무 상황 속에서 창의적으로 그리고 사회적으로(다른 사람의 생각과 마음에 관심을 갖고 그들을 설득하고 협상하고 하는 것) 일하지 않는 기간이 계속된다면 결국 자신의 커리어에 막대한 손해가 될 수 있다는 점이다. 혼자서 딱 정해진 일만 할 수 있는 환경이 축복이 아니라 저주가 될 수 있다.\np65 제자리걸음에서 벗어나기 작업 난이도 * 실력\n지루함을 느끼는 경우(실력 \u0026gt; 난이도) 실력 낮추기 - 일부러 제약조건을 둠, 마우스 사용 불가. 디버거 안 쓰기 등 난이도를 높이기 - 요구 사항 상향, 안해도 되는 업무를 자신의 의지로 추가 - Job Crafting - 리펙토링, 자동화 테스트, 자신만의 도구 개발 등 불안함을 느끼는 경우 (난이도 \u0026gt; 실력) 실력 높이기 - 짝 프로그래밍, 도구 사용(좋은 디버거, 코드 분석툴 등), 난이도 낮추기 - 맡은 일의 가장 간단하면서 핵심적인 결과물을 첫번째 목표로 작업(What\u0026rsquo;s The Simpliest Thing That Could Possibly Work?) p74 팀장들은 팀원의 상태를 파악하고 그들이 몰입으로 가게 도와주는 것 자체가 고도의 의도적 수련이 될 수 있다.\n이상적으로는 그 사람의 실력에 맞는 난이도의 일을 나눠주는 걸 생각할 수 있겠지만 현실은 그렇게 딱딱 맞아떨어지지 않는다. 개개인이 자기 스스로 몰입 상태를 조정하는 능력을 키우게 도와주는 것이 더 바람직하지 않을까 싶습니다.\np90 두 가지의 실무 문화 행동 -\u0026gt; 실수 -\u0026gt; 결과\n실수 예방 : 행동 -\u0026gt; 실수 실수 관리 : 결과로부터 행동과 실수에 feedback 회사의 문화가 실수 에방보다 관리에 가까울수록 그 기업의 혁신 정도가 더 높다. 그리고 실수 관리 문화일 수록 회사의 수익성이 높아진다.\n실수를 없으면 학습하지 못한다. 이는 학습이론의 기본. 실수 관리를 하는 문화일수록 학습을 더 잘한다.\nhttp://agile.egloos.com/5774862 실수 관리 문화를 위한 개인과 조직 수준에서 할 수 있는 구체적인 팁들\nhttp://agile.egloos.com/5822712 음의 생산성\np101 신뢰가 깨어져 있는 상태에서는 어떤 행동을 해도 악의적으로 보인다\np102 뛰어난 소프트웨어 개발자일수록 타인과 인턴랙션에 더 많은 시간을 쓰며 https://www.researchgate.net/publication/225100027_What_we_have_learned_about_software_engineering_expertise\n함께 p131 팀 vs. 작업 그룹 팀과 작업 그룹은 경영학에서는 다른 개념으로 사용.\n팀은 구성원간의 소통/협력 네트워크가 그물망에 가까운 반면,\n작업 그룹은 그 네트워크가 중앙(팀장)에서 뻣어나가는 불가사리형\n작업 불확실성이 높을수록 작업 그룹보다는 팀이 좋은 성과를 냄.\nBusiness 불확실성이 높아지면서 대부분 조직이 팀을 표방하게 되었지만, 스스로를 팀이라고 부르는 집단도 실상은 작업 그룹인 경우가 많다.\np116 소프트웨어 개발 비용 항목 내용 개선 효과 도구 SW 개발에 사용하는 모든 종류의 도구. 컴퓨터 모니터, 버그 트래커, IDE, 하향/구조적 개발 기법 2.97 사람 사람들의 능력과 경험 10.55 시스템 제품 자체의 복잡도, 요구되는 신뢰성, DB 크기, target의 변화 가능성, 스케줄 제약 25.76 관리 사람을 배정하고 작업 분배를 조정하고 위임하는 것. 작업 모니터링, 동기를 고취하는 것. 작업 조건/환경을 개선하는 것. 자원의 준비, 리스크를 일찍 확인하고 적절한 조치를 취하는 것. 요구사항과 설계 스펙이 비준되게 돕는 것 64.00 관리자들이 선호하는 개선 노력은 효과 와 정반대\n추상화 워드 커닝햄이 개발한 wikiwiki의 중요성은 그 기술에 있지 않습니다. 기술이 만들어낸 사회 구조의 변화가 기술이 이끌어 낼 사람들 간의 대화에 있습니다. 그리고 그 대화는 우리가 혼자서는 생각하지 못했던 것들을 만들게 해 줄 것입니다.\np129 신뢰 신뢰 자산이 높은 조직은 커뮤니케이션 효율이나 생산성이 높다.\n신뢰를 쌓는 데 널리 사용되는 한 가지 방법은 투명성과 공유, 인터랙션이다.\n그러나 단순히 공유하는 것만으로는 신뢰가 쌓이지 않는다. 최소 공유(share one) 혹은 최고 공유(share best)인 경우에는 오히려 신뢰도를 떨어뜨린다. 복수 공유(shared multiple) 방식으로 자신이 가진 것으로 모두 공유하면 피드백에 대한 부담도 적어지고, 수용감도 높아진다.\n설득 남을 설득하려면 논리성과 객관성에 대한 환상을 버려야 한다. 그래야 현실적으로 설득이 가능하다.\n내가 설득하고 싶은 상대를 자주 만나서 신뢰를 쌓고, 그 사람이 무엇을 중요하게 여기는지, 어떤 설명 방식을 선호하는 지 이해해야 한다.\n출발은 결국 내가 설득하려는 사람에게서 하는 것이다. 자료에서 출발하는 것이 아니다.\n행동을 유도하는 대화 이것도 모르세요가 아니라 상대방의 개선 행동을 유도하는 대화\n\u0026lsquo;코치는 선수가 아니다\u0026rsquo;, 에릭 슈미트, 코치의 중요성\n구글이 밝힌 탁원할 팀의 비밀 구글 Aristole Project\n팀에 누가 있는 지 보다 팀원들이 서로 어떻게 상호작용하고 자신의 일을 바라보는지가 훨씬 중요 5가지 성공적 팀의 특징. 그 중 압도적으로 높은 예측력을 보인 변수는 팀의 심리적 안정감(Psychological Safety) 팀 토론 등 특별히 공용된 활동을 통해 심리적 안정감을 개선할 수 있다. Oxygen Project - 뛰어난 관리자의 특징을 찾는 연구(2008~)\ngTeam exercise, 10분간 5가지 성공적인 팀의 특징에 대해 팀원들이 답하고, 팀이 얼마나 잘하는지 요약 보고서를 보고 결과에 대해 면대면 토론을 하고, 팀이 개선하게 자원을 제공하는 것\n심리적 안전감\n내가 이 일에서 실수를 하면 그걸로 비난을 받는 경우가 많다. 이 조직에서 남들에게 도움을 구하기가 어렵다. 내 관리자는 내가 전에 한 번도 해보지 않은 걸 해내는 방법을 배우거나 혹은 새로운 일을 맡도록 격려하는 경우가 많다. 내가 만약 다른 곳에서 더 나은 일을 구하려고 이 회사를 떠날 생각이 있다면 나는 그에 대해 내 관리자랑 이야기를 나눌 것이다. 내가 나의 관리자에게 문제를 제기하면 그는 내가 해결책을 찾도록 도와주는 일에 그다지 관심을 보이지 않는 경우가 많다. 심리적 안전감을 높이려면 어떻게 해야 할까\n단순히 우리팀의 현상황에 대해 열린 대화를 시작하는 거만으로 변화가 시작될 수 있음 일상에서의 변확 생기고, 이런 것으로 신뢰가 조금씩 쌓이기 시작한다면, 위에서 나온 \u0026lsquo;특별히 고안된 활동\u0026rsquo;을 시도할 수 있다. 쾌속 학습 단순히 기술적 탁월함을 갖춘 사람보다는 학습 환경을 만들 수 있는 리더가 필요하다\n속도가 빠른 팀은(특히 리더가 중심이 되어) 새로운 수술 도입을 기술적 도전이라기보다 조직적 도전으로 받아들였다. 개개인이 새로운 기술을 획득해야 한다고 보지 않고, 함께 일하는 새로운 방법을 만들어야 한다고 생각했다. 속도라 빠른 팀은 심리적으로 보호가 되어 있다. 뭔가 새로운 것을 제안하고 시도하는 데에 열려 있었고, 실패에 관대했으며 잠재적 문제를 지적하고 실수를 인정하는 데에 부담을 느끼지 않았다.\n팀원들은 모두 팀 퍼포먼스를 높이기 위해 새로운 방식을 실험해 보는 걸 강조했다.\n속도가 빠른 팀은 도전 자체를 팀의 학습 능력에 대한 도전으로 받아들이고, 같이 학습해야 한다고 생각했다. 학습을 팀의 중요한 목표로 받아들였다.\n리더는 기회와 가능성, 큰 변화의 흐름에 동참하는 중요성과 즐거움을 강조\n반면 속도가 느리거나 낙오된 팀은 학습을 개인의 과제로 치부. 학습보다는 단기 퍼포먼스를 중요. 낙오의 위험성을 강조하고, 팀원들의 실력이 부족하다고 불평.\n애자일 고객에게 매일 가치를 전하라. 고객에게 우리의 진짜 고객은 누구인가? 매일 어덯게 점진적으로 가치를 전할 것인가? 어떻게 보다 일찍, 그리고 보다 자주 가치를 전할 것인가? 가치를 무엇이 가치인가? 지금 우리가 하고 있는 일이 정말 가치를 만드는 일인가? 지금 가장 높은 가치는 무엇인가? 비슷한 수준의 가치를 더 값싸게 전달하는 방법은? 전하라 가치를 우리가 갖고 있지 않고, 고객에게 정말 전달하고 있는가? 고객이 정말 가치를 얻고 있는가? 불확실성이 높을수록 빈도가 자주 있어야 한다.\np205 두려워도 중요한다면 시도해 봐야 하지 않을까? 전문가팀은 무섭고 두렵더라도 중요한 일이라면 그 일을 안하는 리스크를 인식하고 꾸준히 시도한다는 점에세 초보팀과 다르다.\np214 만일 ~ 하면 ~ 하라 자신이 관심 있는 분야에 \u0026ldquo;만약 ~하면 ~하라\u0026quot;라는 규칙이 있다면, 해당 분야는 \u0026lsquo;단순한 도메인\u0026rsquo;에 해당한다.\np216 애자일을 애자일스럽게 도입하기 도요타가 도요타일 수 있었떤 것은 칸반 같은 개별 best practice 가 아니라 그런 실천법들이 생겨날 수 있는 문화적 풍토와 생성적 과정 때문이었다. 우리가 배워야 할 것은 칸반 이면의 칸반이 나올 수 있었던 구조와 문화다.\n애자일을 진행하는 가운데 가장 빈번히 빚어지는 폐단은?\n애자일을 반애자일적으로 진행하는 것. 에컨대 애자일은 불확실한 상황에 대한 접근법인데, 애자일을 도입할 때 확실성 위에서 진행하려고 한다면 문제가 된다.\n애자일 방법론을 도입할 때 뭘 해야 할지 명확하게 알려달라고 한다. 근데 그 모습은 전혀 애자일적이지 않다. 찾아가는 모습이 애자일이다. 어차피 방법론 도입이라는 것이 매우 불확실한 것이기 때문에 정답이 있을 수 없다.\n","date":"2018-12-25T13:54:06+09:00","permalink":"https://cychong47.github.io/post/2018/grow-together/","summary":"\u003ch2 id=\"p12-학교-학습-vs-야생-학습\"\u003ep12 \u003ccode\u003e학교 학습\u003c/code\u003e vs. \u003ccode\u003e야생 학습\u003c/code\u003e\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e야생 학습은 대부분 자료에 한정이 없다.\u003cbr\u003e\n야생 학습은 대부분 명확한 평가가 없다.\u003cbr\u003e\n야생 학습은 대부분 정답이 없다.\u003cbr\u003e\n야생 학습은 대부분 목표가 불분명하고 바뀌기도 한다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e학습의 본질은 야생 학습에 더 가깝다고 생각. 현실 세계에서는 야생 학습이 더 많이 필요하다고 봅니다.\u003c/p\u003e\n\u003ch2 id=\"p23\"\u003ep23\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e구조화된 인터뷰(특별히 구조화된 행동중심적 인터뷰를 권함)와 실제 작업을 해보도록 하는 작업 샘플 테스트, 그리고 가능하다면 실제 업무를 주고 시험적으로 짧은 기간 동안 일을 해보게 하는 것 등을 권합니다.\u003c/p\u003e","title":"함께 자라기"},{"content":"http://sosa0sa.com:2368/use-jetpack-for-wordpress-5-0/ 의 연장선. Jetpack plugin의 최신 버전을 알아내서 자동으로 해당 바이너리 파일을 다운로드 받아 보자.\n몇 가지 module 을 사용하는데 필요한 module은 https://realpython.com/python-web-scraping-practical-introduction/ 을 참고해서 설치\n$ python3 -m venv venv $ . ./venv/bin/activate $ pip3 install requests BeautifulSoup4 webscrap.py from requests import get from requests.exceptions import RequestException from contextlib import closing from bs4 import BeautifulSoup from urllib.request import * \u0026#39;\u0026#39;\u0026#39; https://realpython.com/python-web-scraping-practical-introduction/ \u0026#39;\u0026#39;\u0026#39; def simple_get(url): \u0026#34;\u0026#34;\u0026#34; Attempts to get the content at `url` by making an HTTP GET request. If the content-type of response is some kind of HTML/XML, return the text content, otherwise return None. \u0026#34;\u0026#34;\u0026#34; try: with closing(get(url, stream=True)) as resp: if is_good_response(resp): return resp.content else: return None except RequestException as e: log_error(\u0026#39;Error during requests to {0} : {1}\u0026#39;.format(url, str(e))) return None def is_good_response(resp): \u0026#34;\u0026#34;\u0026#34; Returns True if the response seems to be HTML, False otherwise. \u0026#34;\u0026#34;\u0026#34; content_type = resp.headers[\u0026#39;Content-Type\u0026#39;].lower() return (resp.status_code == 200 and content_type is not None and content_type.find(\u0026#39;html\u0026#39;) \u0026gt; -1) def log_error(e): \u0026#34;\u0026#34;\u0026#34; It is always a good idea to log errors. This function just prints them, but you can make it do anything. \u0026#34;\u0026#34;\u0026#34; print(e) def download_file(base_url, filename): file_url = \u0026#39;%s/%s\u0026#39; %(base_url, filename) print(\u0026#34;Download %s\u0026#34; %(file_url)) try: from tqdm import tqdm except: urlretrieve(file_url, filename) return # use tqdm to display the progress but too slow file_response = get(file_url, stream=True) with open(filename, \u0026#39;wb\u0026#39;) as handle: for data in tqdm(file_response.iter_content()): handle.write(data) Jetpack plugin 페이지에 있는 버전 정보를 이용해서 플러그인 다운로드 하기 tqdm은 progress를 보여주는 모듈인데 그냥 사용하면 속도가 너무 너무 느리다. 몇 초면 다운 받을 수 있는 파일을 1분에 걸쳐 받는\u0026hellip;\nget_jetpack.py from webscrap import * \u0026#39;\u0026#39;\u0026#39; https://realpython.com/python-web-scraping-practical-introduction/ https://stackoverflow.com/questions/22676/how-do-i-download-a-file-over-http-using-python \u0026#39;\u0026#39;\u0026#39; if __name__ == \u0026#39;__main__\u0026#39;: jetpack_url=\u0026#39;https://wordpress.org/plugins/jetpack/\u0026#39; jetpack_ver = None response = simple_get(jetpack_url) if response is not None: html = BeautifulSoup(response, \u0026#39;html.parser\u0026#39;) for i,l1 in enumerate(html.select(\u0026#39;li\u0026#39;)): if l1.text.strip().find(\u0026#34;Version:\u0026#34;) == 0: jetpack_ver = l1.text.strip().split()[1] break if jetpack_ver is not None: filename = \u0026#39;jetpack.%s.zip\u0026#39; %jetpack_ver download_file(jetpack_url, filename) ","date":"2018-12-16T06:55:44+09:00","permalink":"https://cychong47.github.io/post/2018/get-the-latest-jetpack-plugin/","summary":"\u003cp\u003e\u003ca href=\"http://sosa0sa.com:2368/use-jetpack-for-wordpress-5-0/\"\u003ehttp://sosa0sa.com:2368/use-jetpack-for-wordpress-5-0/\u003c/a\u003e 의 연장선. Jetpack plugin의 최신 버전을 알아내서 자동으로 해당 바이너리 파일을 다운로드 받아 보자.\u003c/p\u003e\n\u003cp\u003e몇 가지 module 을 사용하는데 필요한 module은 \u003ca href=\"https://realpython.com/python-web-scraping-practical-introduction/\"\u003ehttps://realpython.com/python-web-scraping-practical-introduction/\u003c/a\u003e 을 참고해서 설치\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ python3 -m venv venv\n$ . ./venv/bin/activate\n$ pip3 install requests BeautifulSoup4\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"webscrappy\"\u003ewebscrap.py\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efrom requests import get\nfrom requests.exceptions import RequestException\nfrom contextlib import closing\nfrom bs4 import BeautifulSoup\nfrom urllib.request import *\n\n\u0026#39;\u0026#39;\u0026#39;\nhttps://realpython.com/python-web-scraping-practical-introduction/\n\u0026#39;\u0026#39;\u0026#39;\n\ndef simple_get(url):\n    \u0026#34;\u0026#34;\u0026#34;\n    Attempts to get the content at `url` by making an HTTP GET request.\n    If the content-type of response is some kind of HTML/XML, return the\n    text content, otherwise return None.\n    \u0026#34;\u0026#34;\u0026#34;\n    try:\n        with closing(get(url, stream=True)) as resp:\n            if is_good_response(resp):\n                return resp.content\n            else:\n                return None\n\n    except RequestException as e:\n        log_error(\u0026#39;Error during requests to {0} : {1}\u0026#39;.format(url, str(e)))\n        return None\n\n\ndef is_good_response(resp):\n    \u0026#34;\u0026#34;\u0026#34;\n    Returns True if the response seems to be HTML, False otherwise.\n    \u0026#34;\u0026#34;\u0026#34;\n    content_type = resp.headers[\u0026#39;Content-Type\u0026#39;].lower()\n    return (resp.status_code == 200\n            and content_type is not None\n            and content_type.find(\u0026#39;html\u0026#39;) \u0026gt; -1)\n\n\ndef log_error(e):\n    \u0026#34;\u0026#34;\u0026#34;\n    It is always a good idea to log errors.\n    This function just prints them, but you can\n    make it do anything.\n    \u0026#34;\u0026#34;\u0026#34;\n    print(e)\n\ndef download_file(base_url, filename):\n\tfile_url = \u0026#39;%s/%s\u0026#39; %(base_url, filename)\n\n\tprint(\u0026#34;Download %s\u0026#34; %(file_url))\n        \n\ttry:\n\t\tfrom tqdm import tqdm\n\texcept:\n\t\turlretrieve(file_url, filename)\n\t\treturn\n\n\t# use tqdm to display the progress but too slow\n\tfile_response = get(file_url, stream=True)\n\twith open(filename, \u0026#39;wb\u0026#39;) as handle:\n\t\tfor data in tqdm(file_response.iter_content()):\n\t\t\thandle.write(data)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eJetpack plugin 페이지에 있는 버전 정보를 이용해서 플러그인 다운로드 하기\ntqdm은 progress를 보여주는 모듈인데 그냥 사용하면 속도가 너무 너무 느리다. 몇 초면 다운 받을 수 있는 파일을 1분에 걸쳐 받는\u0026hellip;\u003c/p\u003e","title":"Get the latest jetpack plugin"},{"content":"Wordpress 5.0부터 기본 editor가 ghost와 같이 block editor 로 변경됨. Markdown을 사용하려면 이전과 동일하게 Jetpack을 사용해야 하는데 docker에서 wordpress를 돌리고 있는 내 경우 ftp를 통한 plugin 설치가 안되다는\u0026hellip;\n직접 설치는 안되므로 해결 방안은 Jetpack을 따로 받아 설치한 후 docker volume으로 jetpack 디렉토리를 plugins 디렉토리 밑에 마운트 시키는 방법.\n이번 기회에 최신 버전을 받는 방법을 포함해서 정리 해 보자.\nJetpack의 최신 버전 확인 방법 https://wordpress.org/plugins/jetpack/ 을 방문하면 오른쪽 plugin 정보란에서 다음과 같이 최신 버전 정보를 확인할 수 있다.\nVersion: 6.8.1 download wget https://downloads.wordpress.org/plugin/jetpack.6.8.1.zip 다운 받은 jetpack 파일을 적당한 위치에 풀어준다. 내 경우는 wordpress/plugins/jetpack.\nattach to docker ansible을 사용하고 있는 내 경우 다음과 같이 볼륨을 지정한다.\nvolumes: ... - \u0026#34;wordpress/plugins/jetpack:/var/www/html/wp-content/plugins/jetpack\u0026#34; ... restart wordpress docker 끝\u0026hellip;\ntodo Jetpack의 최신 버전 정보를 읽어와서 해당 버전을 다운로드 하는 script를 만들어 봐야겠다. beautifulsoup을 사용하면 되지 않을까?\n","date":"2018-12-10T15:04:29+09:00","permalink":"https://cychong47.github.io/post/2018/use-jetpack-for-wordpress-5-0/","summary":"\u003cp\u003eWordpress 5.0부터 기본 editor가 ghost와 같이 block editor 로 변경됨.  Markdown을 사용하려면 이전과 동일하게 Jetpack을 사용해야 하는데 docker에서 wordpress를 돌리고 있는 내 경우 ftp를 통한 plugin 설치가 안되다는\u0026hellip;\u003c/p\u003e\n\u003cp\u003e직접 설치는 안되므로 해결 방안은 Jetpack을 따로 받아 설치한 후 docker volume으로 jetpack 디렉토리를 plugins 디렉토리 밑에 마운트 시키는 방법.\u003c/p\u003e\n\u003cp\u003e이번 기회에 최신 버전을 받는 방법을 포함해서 정리 해 보자.\u003c/p\u003e\n\u003ch2 id=\"jetpack의-최신-버전-확인-방법\"\u003eJetpack의 최신 버전 확인 방법\u003c/h2\u003e\n\u003cp\u003e\u003ca href=\"https://wordpress.org/plugins/jetpack/\"\u003ehttps://wordpress.org/plugins/jetpack/\u003c/a\u003e 을 방문하면 오른쪽 plugin 정보란에서 다음과 같이 최신 버전 정보를 확인할 수 있다.\u003c/p\u003e","title":"Use jetpack for wordpress 5.0"},{"content":"Really good wiki adoption case in NASA\nhttp://enterprisemediawiki.github.io/slides/MeetingMinutes/#/\n","date":"2018-11-23T11:37:27+09:00","permalink":"https://cychong47.github.io/post/2018/how-nasa-uses-a-wiki-to-reduce-email/","summary":"\u003cp\u003eReally good wiki adoption case in NASA\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://enterprisemediawiki.github.io/slides/MeetingMinutes/#/\"\u003ehttp://enterprisemediawiki.github.io/slides/MeetingMinutes/#/\u003c/a\u003e\u003c/p\u003e","title":"How NASA uses a wiki to reduce email"},{"content":" 제품 책임자는 해결해야 할 문제가 무엇인지 제시합니다. 그리고 팀은 주어진 문제를 어떻게 해결할 지 결정하죠. 진정한 자율성이 있다면 팀의 일을 중복으로 확인할 필요가 없습니다. 그들이 결정하고 그들이 만들고 조직 모두가 결과를 확인합니다. 모두가 배우는 것이죠 개발팀은 1-2주에 해당하는 개발 주기를 거칠 때마다 제품 책임자와 함께 무엇을 완료해야 하는지 상의해야 합니다. 잘 \b작동하는 상태로 배포할 수 있는 피처들이 얼마나 \b되는지 구분합니다.\n이렇게 팀이 일을 끝낸 이후 \u0026ldquo;작동하는 소프트웨어를 보여주세요\u0026quot;라고 요구하면 됩니다.\n제품이 나아가야 할 목표를 함께 이해하는 자기 조직화된 팀을 만드는 것 또한 최고의 순간입니다.\n반복적인 개발 주기\n각 개발 주기를 사용할 수 있는 소프트웨어를 만드는 연습과정으로 여길 것 항상 무엇을 달성했는지 관찰할 것. 무엇이 일정을 지연시켰는지 기록하고 상황을 개선할 방법을 찾을 것 팀의 능력을 향상함으로써 조직 모두가 완벽하게 숙달할 때까지 나아갈 수 있다 제품이 나아가야 할 목표를 함께 이해하는 숙련된 자기 조직화 팀이 되는 것이 핵심 Five Card\n각 에픽은 한 줄의 문장으로 설명할 수 있어야 함 각 에픽 카드를 3-5개의 작은 카드로 쪼갤 것. 각 카드는 구체적이고 비지니스 측면에서도 가차기 있어야 함. 기술적인 아이디어가 아닌 실제로 작동하는 피쳐여야 함 ","date":"2018-10-18T14:53:53+09:00","permalink":"https://cychong47.github.io/post/2018/caeg-the-nature-of-software-development/","summary":"\u003cblockquote\u003e\n\u003cp\u003e제품 책임자는 해결해야 할 문제가 무엇인지 제시합니다. 그리고 팀은 주어진 문제를 어떻게 해결할 지 결정하죠. 진정한 자율성이 있다면 팀의 일을 중복으로 확인할 필요가 없습니다. 그들이 결정하고 그들이 만들고 조직 모두가 결과를 확인합니다. 모두가 배우는 것이죠\n개발팀은 1-2주에 해당하는 개발 주기를 거칠 때마다 제품 책임자와 함께 무엇을 완료해야 하는지 상의해야 합니다. 잘 \b작동하는 상태로 배포할 수 있는 피처들이 얼마나 \b되는지 구분합니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e이렇게 팀이 일을 끝낸 이후 \u0026ldquo;작동하는 소프트웨어를 보여주세요\u0026quot;라고 요구하면 됩니다.\u003c/p\u003e","title":"(책) The nature of Software Development"},{"content":"자료 \u0026ldquo;등록\u0026rdquo;\n미팅 노트건 어떤 주제에 대한 정리 노트건 \u0026ldquo;등록\u0026quot;이란 단어를 만나면 \u0026ldquo;공식적\u0026quot;이고, \u0026ldquo;뭔가 부담스러운\u0026rdquo; 자료가 되는 것 같다.\n그래서 자료(라고 쓰고 그냥 \u0026lsquo;정보\u0026rsquo;라고 부른다) 공유가 안되는 것이 아닌가 싶다.\n누군가 눈을 부릅뜨고 있는 단상에 자료를 올리는 작업은 부담스럽다. 그런 문화/상황/환경/분위기부터 없어지면 좀 더 편하게 자료를 공유하지 않을까?\nGoogler 들은 많은 자료를 자사 협업 툴인 Google docs등에서 작업할 듯 하다. 우리와는 다른 \u0026ldquo;일하는 환경\u0026quot;과 \u0026ldquo;사람들의 생각\u0026quot;이 그런 정보의 공유를 가능케 하는 게 아닐까 싶다.\n더 많은 자료를 편하게 \u0026ldquo;jot down\u0026quot;하자!!!!\n","date":"2018-10-18T03:00:13+09:00","permalink":"https://cychong47.github.io/post/2018/untitled-3/","summary":"\u003cp\u003e자료 \u0026ldquo;등록\u0026rdquo;\u003c/p\u003e\n\u003cp\u003e미팅 노트건 어떤 주제에 대한 정리 노트건 \u0026ldquo;등록\u0026quot;이란 단어를 만나면 \u0026ldquo;공식적\u0026quot;이고, \u0026ldquo;뭔가 부담스러운\u0026rdquo; 자료가 되는 것 같다.\u003c/p\u003e\n\u003cp\u003e그래서 자료(라고 쓰고 그냥 \u0026lsquo;정보\u0026rsquo;라고 부른다) 공유가 안되는 것이 아닌가 싶다.\u003c/p\u003e\n\u003cp\u003e누군가 눈을 부릅뜨고 있는 단상에 자료를 올리는 작업은 부담스럽다. 그런 문화/상황/환경/분위기부터 없어지면 좀 더 편하게 자료를 공유하지 않을까?\u003c/p\u003e\n\u003cp\u003eGoogler 들은 많은 자료를 자사 협업 툴인 Google docs등에서 작업할 듯 하다. 우리와는 다른 \u0026ldquo;일하는 환경\u0026quot;과 \u0026ldquo;사람들의 생각\u0026quot;이 그런 정보의 공유를 가능케 하는 게 아닐까 싶다.\u003c/p\u003e","title":"없어졌으면 하는 말"},{"content":"P40 업무 지시 -\u0026gt; 일을 맡아달라고 부탁\nP44 제조업에서는 정보 공유의 중요성이 높지 않다. 설계 -\u0026gt; 생산 분리 SW에서는 설계가 모든 상세 내역을 알 수 없고, 지속적인 변경 사항에 따른 변화를 모두 확인할 수 없다. 실리콘밸리에는 기획자라는 역할이 없다. 각자가 자신의 역할을 책임진다. 엔지니어 문화에서는 끊임없이 진화를 가정하고 시작한다. 아웃소싱은 설계 변경을 빠른 시간 내 반영하기 어려워 많이 사용하지 않는다.\n우리나라 기업 문화는 기술집약 제조업에 적합하다. Speed - Quality - Feature triangle\n직원들 각자가 전문가로서 매일 크고 작은 결정을 내리고 꾸준히 소통하는 조직 우리가 만드는 게 고객이 원하는 것인가를 끊임없이 고민\nP55\n내 레벨에 비추어 성과를 절대 평가 한다.\n엔지니어링 매니저 : 엔지니어가 효율적으로 일할 수 있도록 뭘 배워야 하고, 다른 팀과 문제가 없는 지 확인하는 역할을 수행.\n위계 조직 : 너 아니어도 일할 사람 많아 역할 조직 각자가 주어진 일에 갖혀있지 않고, 전문성을 최대한 살려서 목표를 이루고자 노력\n역할조직 소통이 가장 필요\n하지만 회의는 치소화 \u0026lt;- 각자 독립적으로 작업 -\u0026gt; 혼자 일할 시간을 최대한 확보 필요\nP85 구글의 미션과 핵심가치 구글이 말하는 훌륭한 인재는 똑똑하고 열심히 일하는 사람이 아님\nP91 Over communication is always better than less communication 실시간 소통은 근무시간 내로 한정\n근무시간 이후의 이메일은 답장을 기대하지 않음 전화 회의\nWork-Life-Balance는 직원들을 위한 것이 아니라 직원들이 최고의 성과를 낼 수 있도록 하기 위함 -\u0026gt; 회사에도 이득\nWiki or Cloud document 개발 가이드 라인, 테스트 방법론, 개발 환경 설정 등\n1~2주 마다 1:1 대화 Are you happy? Do you have any issue? What is on your mind?\nManager는 개인의 발전을 위해 어떤 공부를 하고, 어떤 프로젝트를 하면 좋을 지 의견 제시\n5시 이후에는 회식 X. 모임에는 매니저가 주도하지 않음. BrownBag meeting (누런색 종이 봉투) 점심을 먹으며 논의\n혁신은 뛰어난 한 사람이 아니라 작은 성공들을 공유하면서 서로 자극을 주고 전달한 정보가 씨앗이 되어 점진적으로 만들어진다.\nP204 Wikipedia -\u0026gt; portmortem 시간순으로 정리 잘한 점, 못한 점, 운 좋았던 점 (실마리를 우연히 찾는 것은 잘한 점이 아니므로)\n개선책 포함 전체 공유 Action Item 포함\nP218 Tesla는 가장 큰 시장용 제품인 Tesla 3 가 아닌 RoadStar를 제일 먼저 출시함 -\u0026gt; 시장의 범위를 좁혀 점진적으로 개선해 나감 -\u0026gt; Agile\nAgile은 빠르게 하는 것이 아니다 Agile은 변화에 빠르게 변화할 수 있기 위함이지 단순히 개발을 빠르게 하기 위함이 아니다.\nDaily meeting에서 종종 Burndown chart를 보면서 논의 단 자세한 내용을 Daily meeting에서 논의하지 말 것. 자세한 내용은 다른 방법(위키나 jira등의 task management tool)을 통해 평소에 공유할 것. 진행한 업무에 대해 이슈가 있고, 도움이 필요하면 요청.\nSprint Planning 미팅을 금요일에 진행\n9시 이후 에는 개인시간을 보냄. 아이는 재우고, 회사 일을 하거나, 책을 보거나, 영화를 보거나 등\n","date":"2018-09-23T06:34:35+09:00","permalink":"https://cychong47.github.io/post/2018/silicon-valley-illustrated/","summary":"\u003cp\u003eP40\n업무 지시 -\u0026gt; 일을 맡아달라고 부탁\u003c/p\u003e\n\u003cp\u003eP44\n제조업에서는 정보 공유의 중요성이 높지 않다. 설계 -\u0026gt; 생산 분리\nSW에서는 설계가 모든 상세 내역을 알 수 없고, 지속적인 변경 사항에 따른 변화를 모두 확인할 수 없다.\n실리콘밸리에는 기획자라는 역할이 없다. 각자가 자신의 역할을 책임진다.\n엔지니어 문화에서는 끊임없이 진화를 가정하고 시작한다.\n아웃소싱은 설계 변경을 빠른 시간 내 반영하기 어려워 많이 사용하지 않는다.\u003cbr\u003e\n우리나라 기업 문화는 \u003ccode\u003e기술집약 제조업\u003c/code\u003e에 적합하다.\n\u003ccode\u003eSpeed\u003c/code\u003e - \u003ccode\u003eQuality\u003c/code\u003e - \u003ccode\u003eFeature\u003c/code\u003e triangle\u003c/p\u003e","title":"(책) 실리콘밸리를 그리다"},{"content":"One day The Wordpress container does not work at all. docker ps로 확인하면 1분 주기로 restart를 반복하고 있다. 경험상 이건 wordpress 앱이 초기화 과정에서 문제가 있는 거라는 걸로 짐작된다. 로그를 확인해 보니 아래와 같은 에러만 출력.\n뭐가 문제일까 멀쩡히 잘 돌던 녀석들인데.\nmini2:html cychong$ docker logs -f f12c3b3a57ef ... Warning: mysqli::__construct(): Unexpected server respose while doing caching_sha2 auth: 109 in Standard input code on line 22 MySQL Connection Error: (2006) MySQL server has gone away Warning: mysqli::__construct(): MySQL server has gone away in Standard input code on line 22 Warning: mysqli::__construct(): (HY000/2006): MySQL server has gone away in Standard input code on line 22 Warning: mysqli::__construct(): Unexpected server respose while doing caching_sha2 auth: 109 in Standard input code on line 22 Warning: mysqli::__construct(): MySQL server has gone away in Standard input code on line 22 Warning: mysqli::__construct(): (HY000/2006): MySQL server has gone away in Standard input code on line 22 MySQL Connection Error: (2006) MySQL server has gone away Warning: mysqli::__construct(): Unexpected server respose while doing caching_sha2 auth: 109 in Standard input code on line 22 MySQL Connection Error: (2006) MySQL server has gone away Warning: mysqli::__construct(): MySQL server has gone away in Standard input code on line 22 Warning: mysqli::__construct(): (HY000/2006): MySQL server has gone away in Standard input code on line 22 Let’s debug 하지만 뭔가 달라진 게 있으니 갑자기 문제가 발생했겠지.\n하지만 좀처럼 실마리를 찾기가 어렵고 급한 서비스도 아니라서 제대로 파서 해결할 생각을 하지 않았다. 방문자도 없는 블로그인데 뭐 라는 생각에.\n그래도 책 읽을 때마다 책 제목을 적어두는 페이지가 이 블로그에 있어 책을 한 권 다 읽은 김에 시간을 내서 고쳐보기로 했다.\n이런 문제의 가장 쉬운 해결책 검색은 에러 메시지를 그대로 검색하는 것. 위 로그에 있는 에러 메시지 몇 가지를 넣어봤지만 쓸모있는 정보(해결책이나 실마리라도)가 담긴 글이 잘 나오질 않는다. 대부분 일반적인 mysql에 대한 에러 해결책인데 그런 문제는 아닌 듯 하고.\n이 전에 추측한 것이 그냥 wordpress container에서 mysql container로의 통신에 문제가 있는게 아닐까 싶었다. 마침 docker for mac을 edge 버전으로 사용하고 있어서 그런가 하는 생각도 들고. 그래서 docker for mac을 stable 버전으로 바꿔도 보고, mysql, wordoress container 삭제/생성을 수차례 반복했다. 하지만 백약이 무효였다.\nResolution 이것저것도 다 안되니 지푸라기라도 잡는 심정으로 mysql을 mariaDB등으로 바꿔볼까 라는 생각을 했다. 백업해 놓은 mysql db 파일은 mariaDB에 사용할 수 있는 걸까? 아니면 sqlite3로 바꿀까? 근데 이건 정보가 너무 없네. 몇 개 나오는 게 5-6년 전 내용이라 지금도 유요한 방법인 지 의심스러웠다.\n그러다 wordpress container의 초반에 나오는 로그를 이용해서 구글링을 해봤는데 마침 이런 글이 눈에 띄었다.\nWordpress latest does not works with mysql latest container · Issue #313 · docker-library/wordpress · GitHub\n바로 이거였다.\nMySQL 8 changed the password authentication method. You’re looking for the mysql_native_password plugin https://dev.mysql.com/doc/refman/8.0/en/native-pluggable-authentication.html So you’ll want to connect with mysql —default-auth=mysql_native_password -p Or you could use mysql 5.7\nmysql을 5.7 버전을 사용하거나 8버전을 사용하면서 인증 방식을 지정하면 된단다.\nDocker-compose를 사용하는 경우 이렇게 지정하면 된다고 한다.\nmysql: image: mysql:5.7 # or image: mysql:8 command: \u0026#39;--default-authentication-plugin=mysql_native_password\u0026#39; Ansible을 사용해서 container를 만들고 있는 나도 그냥 똑같이 해 봤다.\n--- - hosts: mini2 tasks: - name: Start mysql docker_container: name: mysql image: mysql command: \u0026#39;--default-authentication-plugin=mysql_native_password\u0026#39; docker-compose.yml 기준으로 옵션을 설명하고 있어 ansible에서도 같은 걸 사용하는 지 몰라 제대로 옵션이 적용되었는 지 확인해 보니 아래 Args에 있다\nmini2:html cychong$ docker inspect mysql [ { “Id”: “a6336d1ef9a428564ff91aff396d5fa60bfa4bff092980758fc656e303b24fb6”, “Created”: “2018-09-04T14:55:24.440551604Z”, “Path”: “docker-entrypoint.sh”, “Args”: [ “—default-authentication-plugin=mysql_native_password” ], Finally container들을 실행시킨 후 다시 docker logs wordpress 명령으로 확인해 보니 이제 그 지긋지긋한 mysql 관련 에러가 보이지 않는다.\nComplete! WordPress has been successfully copied to /var/www/html AH00558: apache2: Could not reliably determine the server’s fully qualified domain name, using 172.17.0.3. Set the ‘ServerName’ directive globally to suppress this message AH00558: apache2: Could not reliably determine the server’s fully qualified domain name, using 172.17.0.3. Set the ‘ServerName’ directive globally to suppress this message [Tue Sep 04 14:55:54.842454 2018] [mpm_prefork:notice] [pid 1] AH00163: Apache/2.4.25 (Debian) PHP/7.2.9 configured — resuming normal operations 그리고 블로그 접속해 보니 정상적으로 동작. 덕분에 15년 째 유지하고 있는 블로그가 다시 살아났다 :-)\n","date":"2018-09-05T14:10:39+09:00","permalink":"https://cychong47.github.io/post/2018/recovery-failed-wordpress-container/","summary":"\u003ch2 id=\"one-day\"\u003eOne day\u003c/h2\u003e\n\u003cp\u003eThe Wordpress container does not work at all. \u003ccode\u003edocker ps\u003c/code\u003e로 확인하면 1분 주기로 restart를 반복하고 있다. 경험상 이건 wordpress 앱이 초기화 과정에서 문제가 있는 거라는 걸로 짐작된다. 로그를 확인해 보니 아래와 같은 에러만 출력.\u003c/p\u003e\n\u003cp\u003e뭐가 문제일까 멀쩡히 잘 돌던 녀석들인데.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003emini2:html cychong$ docker logs -f f12c3b3a57ef\n...\n\nWarning: mysqli::__construct(): Unexpected server respose while doing caching_sha2 auth: 109 in Standard input code on line 22\n\nMySQL Connection Error: (2006) MySQL server has gone away\n\nWarning: mysqli::__construct(): MySQL server has gone away in Standard input code on line 22\n\nWarning: mysqli::__construct(): (HY000/2006): MySQL server has gone away in Standard input code on line 22\n\nWarning: mysqli::__construct(): Unexpected server respose while doing caching_sha2 auth: 109 in Standard input code on line 22\n\nWarning: mysqli::__construct(): MySQL server has gone away in Standard input code on line 22\n\nWarning: mysqli::__construct(): (HY000/2006): MySQL server has gone away in Standard input code on line 22\n\nMySQL Connection Error: (2006) MySQL server has gone away\n\nWarning: mysqli::__construct(): Unexpected server respose while doing caching_sha2 auth: 109 in Standard input code on line 22\n\nMySQL Connection Error: (2006) MySQL server has gone away\n\nWarning: mysqli::__construct(): MySQL server has gone away in Standard input code on line 22\n\nWarning: mysqli::__construct(): (HY000/2006): MySQL server has gone away in Standard input code on line 22\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"lets-debug\"\u003eLet’s debug\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e하지만 뭔가 달라진 게 있으니 갑자기 문제가 발생했겠지.\u003c/p\u003e","title":"Recover WordPress container"},{"content":"Motivation P39\n자신이나 다른 사람에게 동기를 부여하고 싶은 사람이라면 반드시 알아두어야 할 교훈이다. 결정권을 행사할 수 있는 일을 찾아내면 행동하려는 의지를 쉽게 불어일으킬 수 있기 때문이다.\n직접 결정할 수 있다는 생각이 우리를 흥분시킨다.\nTeams P71\n구글 인력 자원국의 기본적인 목표는 구글 직원들이 직장에서의 삶을 조금이라도 더 행복하고 생산적으로 꾸려 가도록 유도하는 것이었다\nP72\n산소 프로젝트 -\u0026gt; 훌륭한 관리자란?\n훌륭한 코치이고, 권한을 위임하고, 시시콜콜한 문제를 따지지 않으며, 부하 직원의 성공과 행복에 관심을 드러내고, 결과를 중시하고, 정보를 경청하고 공유하며, 경력 개발을 지원하고, 분명한 비전과 전략을 직원들에게 제시하며, 해당 비즈니스에 대한 중요한 핵심 능력을 지니고 있다. P75\nAristoteles Project -\u0026gt; 훌륭한 팀의 조건\n집단 규범 열정, 지원 충성심 P82\n직원들에게 아이디를 불쑥 내뱉지 말고 구체화한 후 제시하라고 말한다. 논리적인 것처럼 보이지만 결국에는 팀원의 능력을 떨어뜨린다.\n리더들은 팀원들에게 자신의 생각을 자유롭게 말하라고 독려하고 팀원들은 자신의 약점까지도 숨김없이 드러낼 수 있다고 생각하며 반박과 경멸이 있을 까 두려워하지 않고 어떤 아이디어라도 제시할 수 있으며, 가혹한 비판을 자제하는 문화가 형성되어 있다.\n모든 규범이 유대감을 조성하는 동시에 팀원들에게 무엇이든 과감하게 시도해 보라고 독려하는 행위였다. 이 공통된 속성을 *“심리적 안전감”*이라고 칭함(에이미 에드먼슨) ‘위험한 것을 시도할 수 있는 안전한 공간이자 팀원이 공유하는 믿음’ 심리적 안정감은 상호 신뢰와 상호 존중으로 요약되는 팀 문화의 특징. 요컨데 팀원들이 자신의 본래 모습대로 편안하게 행동할 수 있는 팀 문화를 뜻한다.\nP98\n훌륭한 팀의 두 가지 공통점\n모든 팀원이 거의 같은 비율로 발언. ‘대화 차례 분배의 균등성’ 팀원들의 사회적 감수성이 평균적으로 높음(서로 상대의 감정을 헤아리는 감성적인 면을 보임) P107\nAristoteles Project의 결론 훌륭한 팀의 다섯가지 핵심 규범\n팀원들은 자신에게 주어진 일이 중요하다고 굳게 믿어야 한다 팀원들은 자신에게 주어진 일이 조직 전체에는 물론 팀원 개개인에게도 중요하다고 믿어야 한다. 팀원들에게 팀의 분명한 목표와 개개인의 명확한 역할이 주어져야 한다 팀원들은 서로 신뢰할 수 있어야 한다 팀에 심리적 안전감이 있어야 한다. 심리적 안전감을 조성하기 위해서는 팀 리더가 적절한 행동의 본보기가 되어야 한다.\n리더는 팀원의 말을 도중에 끊지 말아야 한다 리더는 팀원이 발언을 끝내면 그 내용을 요약함으로써 귀담아 듣고 있다는 사실을 입증해 보여야 한다 리더는 모르는 것을 모른다고 흔쾌히 인정해야 한다 리더는 회사에서 모든 팀원에게 적어도 한번 이상의 발언 기회를 주어야 한다 리더는 곤경에 빠진 팀원에게 좌절감을 털어놓도록 독려하고 팀원들에게 개인적인 비판을 삼가도록 유도해야 한다 리더는 팀 내의 갈등을 공개적인 토론을 통해 해소해야 한다 P113\n론 마이클스는 이렇게 말했다 “내가 좋아하는 거요? 배우들이 어떤 꼭지를 완벽하게 연기해 내고, 그 꼭지를 쓴 작가들이 모니터 앞에 서서 서로 손바닥을 마주 치며 축하하고, 다음 차례를 기다리던 배우들도 깔깔대고 웃는 모습을 보면 정말 즐겁습니다. 다음번에는 등장인물들을 더 재미있게 꾸미는 방법을 고민하는 팀이 눈에 띄면 더더욱 즐겁지요. 팀 전체가 똑같은 것에서 일종의 영감을 받아 즐거워하면 모든 것이 제대로 돌아가고 있다는 뜻입니다. 그때는 팀원 전체가 서로 응원하고 팀원 개개인이 주인공이 된 듯한 기분일 테니까요” 득점 찬스에서 점수가 났을 때 덕아웃 분위기? 끝내기 안타를 친 야구팀의 덕아웃 분위기?\nFocus P144\n당신이 책상에 앉아 수행하려는 일을 가능한 한 구체적으로 상상하는 습관을 길러라. 그럼 당신이 머릿속에 그린 이야기와 현실의 작은 차이를 찾아내기가 쉬워진다. Amazon Way에 있던 내용과 유사. 과제가 성공했을 때 신문에 낼 기사를 적어봐라\nP154\n정보가 감당하기 힘들 정도로 너무 많이 유입되면 우리는 뭐가 중요한 지 제대로 파악하지 못합니다. 심성 모형(Mental Model)을 통해 상황에 대한 대비/준비\nP158\n심성 모형은 끊임없이 휘몰아치는 정보의 소용돌이로부터 우리를 지켜 주는 기준점이라고 할 수 있다. 또한 우리가 관심을 어디에 두어야 하는 가를 결정하는데 도움을 준다. 심성 모형이 머리속에 있을 때 우리는 단순히 반응하는 데 그치지 않고 선체적으로 결정을 내릴 수 있다. 회의 중 갑자기 의견을 물었을 때 미리 준비하고 있지 않으면 엉뚱한 말을 할 수 있다.\nP159\n무엇에 집중하고, 무엇을 무시해야 하는 지 정확히 판단하려면, 우리 삶을 이야기로 꾸미는 습관을 들여야 한다.\n자신의 주의력을 통제할 수 있어야 한다. 우리가 확고히 책임지는 심성 모형을 구축해야 한다. 자동차를 운전하며 출근할 때 일과를 머리속에 그려 본다. 회의실에 앉아있거나 점심 식사를 하려고 식당에 앉아 있는 동안에는 눈에 보이는 것을 구체적으로 묘사해 보고 그 의미까지 표현해 보라. 당신의 이론을 듣고 반박할 사람을 찾아보라 다음에는 어떤 일이 닥칠지 예상하는 습관을 길러라\nP160\n중요한 것은 생각하는 힘이다. 우리가 생각하는 힘을 유지하는 한 절반은 성공한 것이다\nGoal Setting P178\nGE의 Smart Goal\nSpecific Measurable Attainable Realistic Timeline 시야를 좁히고 즉각적인 결과를 얻는데 더 많은 시간을 할애한다. Agile에서 매 sprint나 각 task에만 집중하면 동일한 문제가 발생하지 않을까? Sprint와 Task들은 Product 개발의 목표나 일정을 고려해서 수립해야 한다.\nP184\n상대적으로 쉬운 과제를 선택하고 프로젝트를 어떻게든 마무리해야 한다는 강박관념에 시달릴 가능성이 크다. 스마트 목표에 집착하면 완료한 일을 업무 목록에서 지워 내는 것이 내가 올바른 방향으로 일하고 있는 지 의문을 품는 것보다 더 중요하다고 생각하는 사고 방식에 길들여진다\nP185\nWorkout - GE 직원이면 누구라도 GE가 마땅히 추구해야 한다고 생각하는 목표를 제안할 수 있어야 한다. 관리자들은 어떤 제안이든 신속하게 때로는 그 즉시 가부간에 결정을 내려 줘야 했다. “우리는 관리자가 어떤 제안이라도 흔쾌히 인정해 주는 분위기를 조성하고 싶었습니다. 직원들로 하여금 먼저 목표를 원대하게 세우고 계획은 나중에 구체화하도록 유도하면 결국에는 더 크게 생각하지 않을까 여긴 겁니다”\nP187\n당신이 성취 가능한 결과에 집중하라는 말을 반복해 듣는다면 성취 가능한 목표만을 생각할 것이고, 큰 꿈을 꾸지 않을 겁니다.\nP190\n신간센 이야기. 일본 철도청장의 고속 철도에 대한 집요한 요구 덕에 신간센 개발. 경제 발전에 기여 구체적이고 성취 가능하며 시의적절한 목표를 설정하는데 그치지 않고 도전적인 목표를 찾아낼 수 있어야 한다. 도전적인 목표는 처음에는 어떻게 성취해야 할 지 모를 정도로 야심적인 목표를 뜻한다.\nP192\n엔진 결함율 70% 감소 목표\n재교육(엔진 이론 교육 등) 우수인력 채용 -\u0026gt; 자율권 보장. Flexible time, 직원 채용 방법까지변경 -\u0026gt; 팀구성권 부여. 유연사고 방식 지녀야 해서 직원 채용 방법 변경 P194\n도전적인 목표\n집단의 열망을 인위적으로 크게 높임 조직의 에너지를 극단적으로 끌어올림 실험과 혁신, 폭넓은 조사와 신명 나는 업무를 통해 탐색 학습을 유도할 수 있다 도전적인 목표가 지나치면 조직원들을 공황 상태에 몰아넣으며 성공이 불가능하다는 확신을 심어 줄 수 있다. 그래서 도전적인 목표가 조직원들에게 용기를 북돋아 주려면 때로는 스마크 목표와 병행될 필요가 있다.\n도전적인 목표가 단순한 열망을 넘어서려면, 아득한 목표를 일련의 현실적인 단기적 목적들로 변환하는 방법을 조직원들에게 보여주는 절제된 태도와 마음가짐이 필요하다.\nP196\n원대하고 많은 생각이 필요한 보고서를 작성하는 대신 사소하고 하찮은 메일에 답장하며 많은 시간을 보내게 된다. 그렇게 하면 받은편지함을 깨끗하게 처리했다는 만족감을 얻기때문이다.\nP198\n목표 설정 절차\n도전적인 목표는 무엇인가? 구체적인 하위 목표는 무엇인가? 성공 여부를 어떻게 측정할 것인가? 이 하위 목표는 성취 가능한 것인가? 이 하위 목표는 현실적인가? 목표 성취를 위한 시간 계획표는 어떻게 되는가? Managing Others P208\n센티널(Sentinel)을 Agile 방식으로 개발\nP224\n헌신을 중시한 기업일 수록 직원을 선발할 때 충분한 시간을 두고, 자기 주도적 능력이 뛰어난 사람을 찾으려 하기 때문에 중간 관리자가 적고, 조직에 군살이 없었습니다.\nP229\n도요타 사장의 솔선수범이 직원들이 회사에 대한 신뢰와 심리적 안전감을 갖게 함\nP235\n픽사 방법론 앞으로 디즈니에서는 누구도 다른 사람이 문제를 해결해 주기를 기다릴 필요가 없다는 점을 강조했다. 잘못된 곳을 직접 수선할 권한을 주지 않는다면 굳이 똑똑한 사람을 채용할 필요가 있겠는가\n핵심적인 특징\n어떤 경우에나 의사 결정권이 문제를 가장 가까이서 경험하는 사람에게 위임되었다는 점 팀에 자주적 관리와 자주적 조직을 허용하는 동시에 협력을 독려하는 점 헌신과 신뢰 문화를 강조하는 점 P237\n누구나 멋진 아이디어가 떠으려면 서슴없이 제안해야 하고, 프로젝트가 잘못된 방향으로 가고 있다는 생각이 들면 누구라도 중단을 선언할 수 있으며, 문제에 가장 가까이 있는 사람이 일차적으로 그 문제를 책임지고 해결하는 게 규칙이라고 알렸다\nDecision Making P281\nBayesian cognition 베이즈 심리학 - 패턴을 직감하는 능력 Bayes’ rule - 자료가 지극히 적더라고 어떤 식으로든 추정한 후 우리가 세상에서 관찰한 결과를 바탕으로 그 추정을 조절하면 미래를 예측할 수 있다\nP295\n확률적으로 생각하려면 미래를 다양한 관점에서 상상하고, 모순된 것처럼 보이는 현상들도 동시에 일어날 수 있다는 가능성을 열어 두며, 성공만이 아니라 실패까지 폭넓게 경험하고, 어떤 예측이 실현될 가능성을 가늠하는 직관력을 키워야 한다\nInnovation P327\nSpinning - 특에 박혀 프로젝트를 다른 관점에서 더 이상 보지 못할 때 스피닝이 일어난다\nP340\n창의적 과정 창의성을 발휘하도록 지원하는 조건은 인위적으로 조성할 수 있다. 기존 개념들을 새로운 방식으로 결합하면 혁신을 이루어 낼 가능성이 더 높다는 것은 이미 잘 알려진 사실\n조직의 창의적 과정에서 생산성을 높이고 싶다면\n당신 자신의 경험에 주목하라. 주변 현상을 당신이 어떻게 생각하고 어떻게 느끼는지 유심히 관찰해 보라. 그래야 상투적인 것과 진정한 통찰을 구분할 수 있다 당신이 뭔가를 창조하려고 할 때마다 스트레스와 두려움에 시달린다고 모든 것이 끝났다고 자책하고 좌절할 필요는 없다. 오히려 그런 두려움과 스테레스를 긍정적인 방향으로 활용하면 새로운 것을 찾아내는 융통성을 발휘할 수 있다. 창조적 과정에서 돌파구를 마련했을 때의 안도감은 지극히 달콤하지만 우리에게 다른 대안들을 무시하고 잊게 할 수도 있다는 걸 반드시 기억해야 한다. 우리가 지금 만들어 내고 있는 것으로부터 일정한 거리를 유지하는 게 중요하다. 하나의 아이디어가 경쟁적 관계에 있는 다른 아이디어들을 신속하게 몰아낸다. Absorbing Data P347\n자료는 변화를 유도할 수 있지만 그런 자료를 사용하는 방법을 교사가 아는 경우에만 가능하다 빅데이터와 유사(?) 데이터를 가공할 줄 알아야 데이터로부터 의미있는 정보를 찾을 수 있다는\nP349\n구글과 인터넷을 통해 언제라도 충분한 정보를 확보할 수 있어 우리는 거의 모든 것에 대한 대답을 순식간에 찾아낼 수 있습니다. 하지만 사우스 애번데일은 대답을 찾는 것과 대답이 무엇을 뜻하는지 이해하는 것은 엄연히 다르다는 사실을 보여 주었지요\nP377\n조직원들이 각자의 경험을 새로운 관점에서 접근하도록 지원하는 방법으로는 미리 정해진 일련의 질문표나 공학 설계 과정처럼 단계적 의사 결정 시스템을 가르치는 게 가장 효과적인 듯하다. 이 방법을 사용하면 이분법적 결정에 익숙한 뇌의 습관에서 벗어날 수 있다\n","date":"2018-09-04T14:26:37+09:00","permalink":"https://cychong47.github.io/post/2018/smarter-faster-better/","summary":"\u003ch2 id=\"motivation\"\u003eMotivation\u003c/h2\u003e\n\u003cp\u003eP39\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e자신이나 다른 사람에게 동기를 부여하고 싶은 사람이라면 반드시 알아두어야 할 교훈이다. 결정권을 행사할 수 있는 일을 찾아내면 행동하려는 의지를 쉽게 불어일으킬 수 있기 때문이다.\u003c/p\u003e\n\u003cp\u003e직접 결정할 수 있다는 생각이 우리를 흥분시킨다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"teams\"\u003eTeams\u003c/h2\u003e\n\u003cp\u003eP71\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e구글 인력 자원국의 기본적인 목표는 \u003cem\u003e구글 직원들이 직장에서의 삶을 조금이라도 더 행복하고 생산적으로 꾸려 가도록 유도하는 것이었다\u003c/em\u003e\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eP72\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e산소 프로젝트 -\u0026gt; 훌륭한 관리자란?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e훌륭한 코치이고,\u003c/li\u003e\n\u003cli\u003e권한을 위임하고,\u003c/li\u003e\n\u003cli\u003e시시콜콜한 문제를 따지지 않으며,\u003c/li\u003e\n\u003cli\u003e부하 직원의 성공과 행복에 관심을 드러내고,\u003c/li\u003e\n\u003cli\u003e결과를 중시하고,\u003c/li\u003e\n\u003cli\u003e정보를 경청하고 공유하며,\u003c/li\u003e\n\u003cli\u003e경력 개발을 지원하고,\u003c/li\u003e\n\u003cli\u003e분명한 비전과 전략을 직원들에게 제시하며,\u003c/li\u003e\n\u003cli\u003e해당 비즈니스에 대한 중요한 핵심 능력을 지니고 있다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eP75\u003c/p\u003e","title":"(책) 1등의 습관 Smarter, Faster, Better"},{"content":"팀원이 안전하다고 느끼는가?\n구글 * 지위에 연연하지 않음. * 누가 책임질 지 고민하지 않음 * 어려운 문제를 풀기 위해 모든 집단을 토론시킴 미사일리어 * 미국의 미사일기지 근무 군인들의 만족도가 크게 떨어짐 * 우리가 이어져 있나? * 우리에게 미래가 있나? * 우리는 안전한가? 피드백 * 기대치가 높다 * 당신이면 기대를 충분히 달성할 수 있을 있을 거라고 믿는다 경청하라. 또 경청하라 * 높은 자리에 오를수록 먼저 약점을 드러내라 * 불편한 목소리도 포용 * 구체적인 미래상 제시 * 공치사는 과장될수록 좋다 * 서로 부딪칠 수 있는 공간을 마련하라 * 각자의 목소리를 내게 하라. Toyota(Action Code), Pixar(Details), google, It’s your ship(해군 함장) * 벤폴트호를 타면 제일 좋은 점은? * 제일 마음에 들지 않는 점은? * If you’re captain, what do you change? * 하찮은 일일수록 솔선수범 * 샌드위치식 feedback은 피할 것 * 칭찬 - 질책 - 칭찬 X * 칭찬과 질책을 분리 * 유쾌한 분위기를 만들것 IDEO * 나를 제일 들뜨게 하는 것은? * 별로 들뜨게 하지 않는 이유는? * 이 프로젝트에서 개선하고 싶은 것은? Google Laszlo Bock * Work rules * 지금 하는 일 중에 계속 하고 싶은 일은? * 좀 더 자주 하면 좋겠다고 생각하는 일은? * 내가 어떻게 해야 직원들이 효율적으로 일할 수 있을까? 협동을 부추기는 계기 배드 뉴스는 개인적으로 전달 #book\n","date":"2018-08-25T10:08:40+09:00","permalink":"https://cychong47.github.io/post/2018/the-secret-of-highly-successful-groups/","summary":"\u003cp\u003e팀원이 \u003ccode\u003e안전\u003c/code\u003e하다고 느끼는가?\u003c/p\u003e\n\u003ch2 id=\"구글\"\u003e구글\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e* 지위에 연연하지 않음.\n* 누가 책임질 지 고민하지 않음\n* 어려운 문제를 풀기 위해 모든 집단을 토론시킴\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"미사일리어\"\u003e미사일리어\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e* 미국의 미사일기지 근무 군인들의 만족도가 크게 떨어짐\n* 우리가 이어져 있나?\n* 우리에게 미래가 있나?\n* 우리는 안전한가?\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"피드백\"\u003e피드백\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e* 기대치가 높다\n* 당신이면 기대를 충분히 달성할 수 있을 있을 거라고 믿는다\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"경청하라-또-경청하라\"\u003e경청하라. 또 경청하라\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e* 높은 자리에 오를수록 먼저 약점을 드러내라\n* 불편한 목소리도 포용\n* 구체적인 미래상 제시\n* 공치사는 과장될수록 좋다\n* 서로 부딪칠 수 있는 공간을 마련하라\n* 각자의 목소리를 내게 하라.  Toyota(Action Code), Pixar(Details), google, It’s your ship(해군 함장)\n\t* 벤폴트호를 타면 제일 좋은 점은?\n\t* 제일 마음에 들지 않는 점은?\n\t* If you’re captain, what do you change?\n* 하찮은 일일수록 솔선수범\n* 샌드위치식 feedback은 피할 것\n\t* 칭찬 - 질책 - 칭찬 X\n\t* 칭찬과 질책을 분리\n* 유쾌한 분위기를 만들것\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"ideo\"\u003eIDEO\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e* 나를 제일 들뜨게 하는 것은?\n* 별로 들뜨게 하지 않는 이유는?\n* 이 프로젝트에서 개선하고 싶은 것은?\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"google-laszlo-bock\"\u003eGoogle Laszlo Bock\u003c/h2\u003e\n\u003cpre\u003e\u003ccode\u003e* Work rules\n* 지금 하는 일 중에 계속 하고 싶은 일은?\n* 좀 더 자주 하면 좋겠다고 생각하는 일은?\n* 내가 어떻게 해야 직원들이 효율적으로 일할 수 있을까?\n\u003c/code\u003e\u003c/pre\u003e\n\u003cul\u003e\n\u003cli\u003e협동을 부추기는 계기\u003c/li\u003e\n\u003cli\u003e배드 뉴스는 개인적으로 전달\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e#book\u003c/p\u003e","title":"(책) 최고의 팀은 무엇이 다른가"},{"content":"p15\n사람들에게 제대로 집중해서 일을 하고자 할 때 어디로 갈거냐고 물었을 때 “사무실”이라고 답하는 사람은 별로 없다.혹은 “다른 직원들이 출근하기 전 아침 일찍” 또는 “다른 직원들이 퇴근하고 난 후의 사무실” 또는 “주말에 아무도 없는 사무실”\np18\n출퇴근 시간 1.5시간/하루 * 5일 * 4 * 11 month = 330 시간.400시간은 베이스캠프를 개발자들이 프로그래밍하는데 걸린 시간\np22\n엄청난 기술이 필요한 것은 아니다. 하지만 과거의 유산을 내려놓고 미래로 가는 배에 올라 탈 굳은 의지를 갖추어야만 한다.\np24\n동시적 협업에서 비동기 협업 체제로 바뀌는 것 원격근무가 아니더라도 시간대가 다른 부서와 협업하는 것만 해도 비동기 협업의 중요성이 높아진다. 동시성 협업은 극히 제한되고, 공간과 언어의 제약으로 인해 효율이 극히 낮아진다.\np48\n출근하지만, 막상 사무실에서는 마치 모두가 원격근무하는 것처럼 일을 한다. 이메일, 메시징앱으로 일하면서 혼자 일하는 시간을 달라고 한다. 출근길에 생각해 보자. 과연 오늘 사무실로 출근하는 것이 그럴 만한 가치가 있었나? 회사 업무를 살펴보라. 어떤 업무가 외부에서 일어나고 있는지, 또는 반대로 반드시 대면해서 해야 하는 업무가 어떤 것이 있는 지. 아마 생각보다 많은 업무가 원격으로 진행되고 있다는 것에 놀라게 될 것이다.\np53\n신뢰에 문제가 있다면, 그것은 채용 당시 의사결정에 문제가 있었다는 것을 뜻한다. 팀원 중 좋은 결과를 내지 못하거나, 스스로 일정관리와 업무량을 조절할 수 없는 사람과는 계속 일할 수 없다. 스스로 일정을 관리하고 조직에 의미 있는 기여를 하는 전문가와 일하기를 원한다. 관리자는 직원 옆에 진종일 붙어서 보모 역할을 하는 사람이 아니다.\np55\n리차드 브랜슨경은 원격근무에 대해 이렇게 말했다. “다른 사람들과 성공적으로 협업하려면 서로 신뢰가 있어야 한다. 관리감독이 없는 상황에서도 동료가 제 몫을 해낼 것이라는 믿음이 필요하다”\np66\n생산성에 대한 이야기를 할 때는 대기업을 예로 들지 않는 것이 현명하다.\np72\n최선의 문화는 사람들의 행동에서 나타나는 것이지, 사훈에 적는 문구가 아니다.신입사원들은 의사결정이 어떻게 이루어지는지, 회사가 어떤 것에 신경을 쓰는지, 문제를 어떻게 해결하는 지 등을 지켜보면서 문화를 익힌다. 원격근무를 하게 되면 기업문화란 사람 간의 사회적 교류를 통해서 만들어진다는 허상을 깨닫게 된다. 그리고 기업문화란 업무를 정의하고 실행하는 방법이라는 것을 알게 된다.\np74\nMail, Chat, call 등 긴급성에 따라 다른 방식으로 연락할 것\np95\n모든 정보를 공개하라.원격근무인 경우 발생하는 시차로 인한 정보 공유 문제를 해결하려면(4시간 시차가 있는 사람들에게 정보를 얻기 위해 4시간을 기다린다는 것은 말이 안되는 일) 가급적 모든 정보를 공개된 공간에 모아야 한다.\np98\n다양한 챗 채널을 사용.업무 뿐만 아니라 잡담용 채널 등도 사용하여 유대감을 만들 것. 이런 낭비가 필요하다\np102\n팀장보다 팀원을 속이기가 더 어렵다.다른 개발자들에게 정보가 모두 공개되면 거짓은 금방 들통 나기 마련이다.모두가 업무진행 상황을 공유할 때 좋은 결과가 나온다.\np104\n“오늘 무슨 일을 했나요?라고 묻지 말고 ”오늘 한 일을 보여주세요”라고 묻자.업무결과물과 관계없는 나머지는 무시하면 된다.\np120\n매일 업무를 마치면서 스스로에게 질문해 보자. “오늘은 업무 성과가 좋았나?”\np158\n베이스캠프처럼 일감을 자동으로 관리하고 보고하는 시스템은 누가 무슨 일을 하는 지, 얼마나 걸리는 지 투명하게 보여준다.이런 시스템은 전통적인 사무실 업무환경에서 소외받던 조용하게 일 잘 하는 사람들을 돋보이게 한다. 원격근무 환경에서는 자신이 한 업무에 대해 자랑질을 하지 않아도 된다. 이미 모두에게 공개되어 있고 주의 깊게 살펴보고 있다. 일은 안하고 허풍만 떨다 보면 동료들 모두가 금방 그 사실을 알아챌 것이다.\np161\n글쓰기는 원격근무의 시작이다. 원격근무를 잘하려면 쓰기를 잘해야 한다.On Writing WellThe Elements of StyleRevising Prose\np165\n미니프로젝트는 의미 있는 일이라야 한다. 현재 회사가 가지고 있는 문제를 해결하는 과제여야 한다.\np192\n직원들에게 스스로 의사결정 권한을 주어라. 회사에 층층히 쌓인 관리자의 승인이 있어야만 의사결정을 할 수 있다면 회사에는 잘못된 사람들만 있는 것이다.사람들은 의사결정 내리기를 두려워한다. 왜냐면 그들은 처벌과 원망을 받을까 두렵기 때문이다. 이런 문화는 원격근무와 어울리지 않는다.직원들이 일하는데 필요한 것들을 쉽게 획득할 수 있도록 해야 한다. 하지만 대부분의 회사는 정확히 반대로 하고 있다.조직이 군과 관련되어 있거나, 일급비밀정보를 다루는 일이 아니라면 정보 접근을 제한하는 장벽들은 직원들이 업무를 하는데 방해가 될 뿐이다.\np195\n장기적으로 좋은 직원은 지속 가능한 업무를 하는 사람이다. 모자라지도, 넘치지도 않게 딱 적당히 일하는 것이 좋다. 우리 경험으로는 일주일에 40시간 정도가 평균적으로 적절했다.\nremote에 대해 다른 사람이 쓴 글\n","date":"2018-08-25T09:30:07+09:00","permalink":"https://cychong47.github.io/post/2018/remote/","summary":"\u003cp\u003ep15\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e사람들에게 제대로 집중해서 일을 하고자 할 때 어디로 갈거냐고 물었을 때 “사무실”이라고 답하는 사람은 별로 없다.혹은 “다른 직원들이 출근하기 전 아침 일찍” 또는 “다른 직원들이 퇴근하고 난 후의 사무실” 또는 “주말에 아무도 없는 사무실”\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003ep18\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e출퇴근 시간 1.5시간/하루 * 5일 * 4  * 11 month  = 330  시간.400시간은 베이스캠프를 개발자들이 프로그래밍하는데 걸린 시간\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003ep22\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e엄청난 기술이 필요한 것은 아니다. 하지만 과거의 유산을 내려놓고 미래로 가는 배에 올라 탈 굳은 의지를 갖추어야만 한다.\u003c/p\u003e","title":"(책) 리모트"},{"content":"기대와는 많이 달랐던 책\u0026hellip;\n인생은 바꿔 말하면 ‘시간’입니다. 그 시간을 보내는 ‘공간’이야말로 그 사람의 행복으로 이어집니다.\n","date":"2018-08-16T14:46:20+09:00","permalink":"https://cychong47.github.io/post/2018/why-danish-bought-a-chair-with-the-first-time-salary/","summary":"\u003cp\u003e기대와는 많이 달랐던 책\u0026hellip;\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e인생은 바꿔 말하면 ‘시간’입니다. 그 시간을 보내는 ‘공간’이야말로 그 사람의 행복으로 이어집니다.\u003c/p\u003e\n\u003c/blockquote\u003e","title":"(책) 덴마크 사람들은 왜 첫 월급을 받으면"},{"content":"31\nPO의 역할 A,B, C의 우선 순위를 결정하는 수동적인 역할 더 창의적으로 생각해보면 전혀 다른 D라는 일을 텅해 A,B, C의 문제를 한꺼번에 해결 할 수도. 사고의 폭이 넓으면 PO가 할 일은 무한정 많아지기도 한다.\n관리자와 같은 입장인 듯. 2018년 8월 내가 갖는 고민, 상황에 딱 드러맞는 말.\n240\n쿠팡 대표 이사, 김범석\n\u0026ldquo;제발 위에서 시키니까 한다는 소리 좀 하지 마세요. 그거 제가 제일 싫어하는 말이예요\u0026rdquo;\n\u0026ldquo;무엇이 옳고 합리적인지\u0026quot;를 묻는 것은 다양성을 존중하는 수평적인 조직문화의 토대가 될 수 있다. 좀 더 타당한 논리와 근거를 갖춘 의견을 우선시하는 분위기가 갖춰진다면 사람들이 자유롭게 자신의 주장을 펼치기가 더 쉬워질 것이다.\n251\n생각하는 바가 있으면 그냥 구현에 제약이 없다고 간주하고 비전을 제시\n260\n수평조직이라 권한을 위임받은 사람이 없다. 조직(원)간 설득과 협의를 통해 일을 진행해 나가야 한다.\n수직적인 조직에 비해 일 진행이 더디기도\u0026hellip;\n289\n\u0026ldquo;어떻게 할까요?\u0026rdquo; \u0026ldquo;어떻게 해야 한다고 생각하세요?\u0026rdquo;\n295\n\u0026ldquo;큰 배를 만들게 하고 싶으면 바다에 대한 동경을 심어줘라\u0026rdquo; 이렇게 하면 모든 이가 스스로 배 만드는 법을 찾을까? \u0026ldquo;그래서 배의 설계도는 대체 어디에 있나?\u0026rdquo;\n\u0026ldquo;큰 배를 만들면 나한테 무슨 이득이 있나?\u0026rdquo;\n","date":"2018-08-05T11:09:34+09:00","permalink":"https://cychong47.github.io/post/2018/coupang-the-reason-of-innovation/","summary":"\u003cp\u003e31\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003ePO의 역할\nA,B, C의 우선 순위를 결정하는 수동적인 역할\n더 창의적으로 생각해보면 전혀 다른 D라는 일을 텅해 A,B, C의 문제를 한꺼번에 해결 할 수도.\n사고의 폭이 넓으면 PO가 할 일은 무한정 많아지기도 한다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e관리자와 같은 입장인 듯. 2018년 8월 내가 갖는 고민, 상황에 딱 드러맞는 말.\u003c/p\u003e\n\u003cp\u003e240\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e쿠팡 대표 이사, 김범석\u003cbr\u003e\n\u0026ldquo;제발 위에서 시키니까 한다는 소리 좀 하지 마세요. 그거 제가 제일 싫어하는 말이예요\u0026rdquo;\u003c/p\u003e\n\u003cp\u003e\u0026ldquo;무엇이 옳고 합리적인지\u0026quot;를 묻는 것은 다양성을 존중하는 수평적인 조직문화의 토대가 될 수 있다.\n좀 더 타당한 논리와 근거를 갖춘 의견을 우선시하는 분위기가 갖춰진다면 사람들이 자유롭게 자신의 주장을 펼치기가 더 쉬워질 것이다.\u003c/p\u003e","title":"(책) 쿠팡 우리가 혁신하는 이유"},{"content":"p17 술과 구라를 즐기되 항상 혀를 조심하라. 어느 장소에서나 어느 주제에 대해서나 할 말을 다하는 자는 불행한 자이니 말하고 싶을 때마다 세 번을 더 깊이 들어라 특히 나이가 들어서는 혀를 잘 묶어두어야 한다. 고약한 늙은이 옆에는 사람이 없으니 외로움이 끝없으리라 배워서 알고 싶은 것을 다 쓰지 못하고 가는 것은 서운한 일이나\n친구는 들어주는 사람 곁에 모이는 것이니 하나를 말하고 둘을 들어라.\np27 여러분이 놓치고 있는 것이 있습니다. 바로 이 하얀 종이 말입니다. 인생에서, 비즈니스에서, 가정에서 개인적인 일에서나 공적인 일에서 우리는 바로 이 검은 점 하나와 같은 작은 실수와 실패 때문에 온통 마음이 심란해집니다. 그러나 중요한 것은 아무것도 그려져 있지 않은 이 하얀 여백입닏. 이곳이 바로 우리가 꿈을 그려 넣을 자리입니다.\np33 창의성의 시작은 질문으로부터 온다. 철학은 ‘만물의 근원은 무엇일까’를 묻는 질문에서부터 시작되었다. 답이 중요한 것이 아니다. 좋은 질문이 위대하다. 우리 교육의 가장 큰 문제는 질문할 수 있는 호기심과 자유의 힘을 빼앗은 것이다. 너무도 빨리 정말 알고 싶은 것들을 제쳐두고, 아직 절실하지 않은 세상의 대답들을 외우게 함으로써 질문의 힘을 죽여버린다.\n그러나 사회에 나오는 순간 학생들은 이 세상에 정답이란 애초에 없는 것임을 알게 된다. 그때그때 가능한 복수의 답들 중에서 하나를 선택하거나 몇 개의 가능한 답들을 융합해 새로운 답을 찾아내야 한다는 것을 깨닫는다. 답을 찾아가는 가장 중요한 과정은 적절하게 질문할 수 있는 힘이다. 질문이야말로 멋진 답으로 가는 마법의 길이다.\np37 ‘이보게, 세상에 뜻대로 안 되는 것이 열에 여덟아홉이라고 하지 않나. 그러니 뜯대로 되는 기분 좋은 일 한 둘을 늘 생각하고 그 일을 넓혀가시게. 그러면 삶이 즐겁지 않겠는가?”\np60 “일할 때는 가족 생각을 하고, 가족과 있을 때는 일을 생각하는 사람들은 아무것도 성취할 수 없다. 그들은 온전히 어느 순간도 즐기지 못한다. 단지 떠돌이일 뿐이다”\n지금, 여기에 모두 다 걸어라. 실천이 목표를 얻기 위한 수단이라 생각하지 마라. 실천은 지금을 즐기는 것이다. 즐기지 못하면 목표만 남고 삶은 사라진다.\np66 조지 버나드 쇼 “인생은 너 자신을 발견하고 찾아가는 것이 아니다. 네가 원하는 모습대로 너를 창조내는 것이다”\np85 태평스럽게 살 수 있다면 그나마 다행이다. 그러나 이제 그만한 소시민적 평화를 바라기 어렵게 되었다. 처음 시작한 직장에서 적당한 자부심을 느끼며 평생을 지낼 수 있는 이제 드문 은총이 되었따. 어디에도 적절한 자리가 없는 것이 지금의 40대다.\np86 안쪽 깊은 곳에 새로운 삶을 만들어갈 수 있는 힘이 남아있다.아직 며칠 더 절실하게 푸를 수 있고 뜨거울 수 있다. 살면서 한 가지의 흔적을 남길 수 있을 거라는 오만을 떨 수 있는 며칠이 남아 있다. 겸손한 가을이 오기까지 아직 조금의 시간이 있다. 참으로 작고 보잘것 없는 나라는 열매 속에 엄청난 에너지를 채워 넣을 수 있는 찬란한 여름의 며칠이 남아 있다. 그래서 이때는 모든 40대들에게 아주 절박한 시기다.\n변화는 절박함을 인식할 수 있는 능력이다. 절박함을 스슷로에게 설득시킬 수 있다면 변화의 반은 성공한다. 그러나 절실하지 못한 사람은 자기를 바꾸는데 성공할 수 없다….절실하다는 것은 것은 그것을 생존의 문제로 인식한다는 것을 뜻한다. 지금이 결단의 시기이며, 지금 시작하지 않으면 마지막 기회를 놓치고 말 것이라는 자기 암시이며 주술이다.\n40이 넘은 사람들에게 여름은 이제 며칠 안 남았다. 변화의 절박함을 인식할 수 있는 사람은 도움을 받을 수 있다. 그러나 절박하지 않은 사람은 누구도 도와줄 수 없다.\n절박함은 스스로 부여하는 것이다. 이 자발성은 변화가 무엇인지를 이해하는 것으로부터 온다. 변화는 움직임이다. 한 점에서 다른 한 점으로 움직여가는 것이다. 따럿 변화에는 한 순간에 적어도 두 개의 점이 필요하다. 지금 서 있는 곳과 도달할 목적지를 나타내는 두 개의 좌료를 찍을 수 있어야 한다.\np89 절박함은 그러므로 꿈이 있는 사람에게만 생겨난다. 현실과 꿈 사이의 간격에서 꿈을 향해 움직여갈 때 생겨난다. 현실밖에 없는 사람은 절박하지 않다. 그들에게 삶은 그저 지루하고 짜증스러운 반복과 연속일 뿐이다. 그들에게는 꿈, 즉 도달해야 할 점이 없다. 오직 현실이라는 한 점밖에 존재하지 않기 때문에 움직일 수 없다. 그래서 스스로의 변화는 불가능하다. 외부의 변화가 밀려오면 속수무책으로 당할 수밖에 없다. 그런가 하면 꿈밖에 없는 사람도 있다. 그들도 변화할 수 없다. 그들에게는 현실이 없기 때문에 ‘이룬다’는 개념도없다. 그저 취해서 살 뿐이다.\n변화에 성공하기 위해서는 늘 ‘또 하나의 점’이 필요하다. 그것도 스스로가 자발적으로 찍은 ‘또 하나의 점’이 중요하다. 스스로 찍지 못하면 대개의 경우, 다른 사람들이 찍어놓은 곳으로의 이행을 강요당하게 된다. 강요된 스피드로 강요된 곳을 향해 몰려가지 못하면 도태되거나 원하지 않는 곳에 도달하게 된다. 삶이 불만족스러운 것은 바로 이 비자발성에 기인한다.\n지금 서 있는 곳에서 꿈꾸는 곳으로의 이동은 힘든 과정이다. 그 간격을 극복하는 것은 산을 오륻르듯 높은 곳으로 움직여가는 것이기 때문에 많은 에너지를 필요하다. 힘은 밖에서 오지 않는다.. 그래서 힘은 안으로부터 온다.\n안으로부터 오는 힘은 단지 의지와 인내를 통해 얻어지는 것이 아니다. 참고 견디는 것은 고통스럽다. 자기 마음이 흐르는 대로 따름으로써 그 내면적 힘을 얻어낼 수 있다. 좋아하는 일을 하는 것은 즐거움이다. 수련과정에 포함되는 반복과 연습 그리고 땀은 자부심을 높여주고 행복하게 해준다.\np97 꿈을 이루려면 ‘꾸는’ 것만으로는 턱도 없다. 이 대목에서 우리는 시간의 문제를 해결해야 한다. 하루에 두 시간은 자신이 좋아하서 선택한 일에 써야 한다. .. 시간해서 6개월 이내에 스스로 변화를 감지하고 확신을 가지하면 하루에 적어도 두 시간은 써야 한다. 변화를 시작해서 6개월이 지나도록 변화로 인한 보람과 의미를 발견하지 못하게 되면 지칠 수 있다. 인간은 증거를 필요로 한다.\np105 삶을 꾸려가는 강령 7가지\n생긴 대로 살아라 학생으로 계속 남아라. 과거를 그리워하거나 자랑하지 마라. 역사는 자랑하기 위해 있는 것이 아니다. 역사는 오늘의 문제를 풀기 위한 지혜로 존재하는 것이다. 과거에 기초에 정체성을 만들어내서는 안 된다. 잠재성 또한 나의 정체성을 결정해야 한다. 잠재성이란 발현되지 않았지만 이미 내가 갖고 있는 것들이다. 젊은 사람들과 밥그릇을 놓고 경쟁하자 마라 리스크를 지고 살아라. 예측된 위험을 피하지 마라. 모험이 없는 인생은 재미없다. 삶을 관조와 관찰로 대체하지 마라. 삶과 조금 격리되어 삶을 관조하는 조용한 옵저버가 되지 마라. 삶은 뜨거운 것이다. 살아봐야 삶이 된다. 자연과 하나가 되라. 인간관계를 부드럽게 하는 강령 7가지 사람을 있는 그대로 받아들여라. 부탁하지 않았다면 충고하려 하지 마라. 현재의 관점에서 이해하라. 과거는 우리가 어떤 사람을 판단하는 중요한 기준이다. 과거에 지나치게 많은 비중을 두지 않는 것이 좋다. 사람들에게는 많은 사연이 있고, 그때 그 상황헤 처하지 않고는 정확하게 이해하기 어렵다. 더욱이 사람은 변한다. 직접 경험한 것이 아니라면 소문과 풍문으로 다른 사람을 판단하는 것은 금물이다. 현재의 자세와 태도 그리고 전문성으로 판단하라. 성과보다 존재에 고마워하라. 칭찬을 할 때는 성과에 대한 칭찬보다는 그 사람의 존재에 대한 칭찬을 해주는 것이 효과적이다. 감정의 70퍼센트 정도는 표현하려고 애써라. 자기 감정의 3분의 2 정도는 자기답게 표현하는 비법을 터득할 필요가 있다. 나머지 3분의 1은 마음속에 묻어두는 것이 좋다. 묻어가는 법도 반드시 터득할 기술이다. 휴먼 네트워크를 만들어라. 들으면 친해진다. 묻고 잘 들어라. 자신이 떠드는 것보다 상대방의 말을 더 많이 듣는 것이 언제나 이문이 남는 거래다. 일에 대한 강령 7가지 의식적으로 문제의식을 가져라. 문제의식이 없으면 일은 단순 반복된다. 어제의 방식으로 오늘의 일이 처리되고, 내일의 일 역시 어제의 방식으로 처리될 것이다. 반복이 재생산될 때 개선과 혁신은 없다. 혁신의 능력 없이는 지식사회에서 성장하고 번영할 수 없다. 어제의 방식을 의심하라. 어제의 방식으로 오늘의 일을 처리하는 것을 퇴보라 생각하고 부끄러워하라. 실험하고 모색하라. 실패를 두려워하면 실험하기 어렵다. 실패는 아주 잘 배우느느 또 하나의 방법일 뿐이다. 알아주지 않아도 계속하라. 긍정적인 자긍심을 가져라. 자긍심은 자신을 좋아하는 마음이다. 남이 시키는 대로 하거나 하는 일에 대해 자신의 이유를 찾지 못하면서 자긍심을 가질 수 는 없다. 따라서 먼저 자신이 매일 하고 있는 일을 자신의 언오로 규정해보자. 자신만의 방식을 찾아라. 전문가의 세계에서 중요한 것은 차별성이다. 1인기업이라 생각하라. 자신의 지적 자산을 형상하라. 지적사회의 재산은 지식이다. 지식은 만들어져야 하고 저장되어야 하고 유통되어야 하며 활용되어야 한다. 매일 자신의 실험과 모색의 과정을 올려 회원들과 공유하도록 하라. 운이 좋아지는 강령 7가지 호의를 배풀어라. 잘난척 하지 않고 똑똑하게 보여라. 상대방의 말에 반박하고 싶거나 꼭 한마디 해주고 싶어 못 견딜 때는 의견을 말하기 전에 반드시 질문을 하라. 좋은 질문은 훌륭한 반복보다 훨씬 부드럽고 창조적이다. 답변이 부족하면 상대방이 스스로 무너지고 답변이 훌륭하면 당신은 황금같은 조언을 듣게 되는 것이다. 더욱이 당신은 꼭 필요한 대목에서 꼭 필요한 질문을 한 현명한 사람으로 기억될 것이다. 변명하거나 남에게 원망을 돌리지 마라. 일이 잘못된 책임을 다른 사람에게 전가하는 것은 쪽박을 깨는 바보짓이다. 결코, 책임으로부터 자유로워질 수도 없고, 비난을 전가한 상대방과 적이 될 뿐이다. 책임을 인정하되 주눅 들지 마라. 같은 실수를 하면 바보라고 스스로 비웃어줘라. 그러나 다른 실수를 하면 창조적 행위의 일환이라고 스스로 위로하라. 검증된 방식은 안전하나 보상도 적다. 새로운 바식의 모색은 실수를 동반하나 도약과 대박이 가능하다. 한 해 동안 꼭 하고 싶은 일을 한두 개 골라라. * 꼭 하고 싶은 일을 하면 인생이 즐겁다. 과거의 자신과 경쟁하라 . 자신의 과거와 경쟁하는 것은 적을 만들지 않고, 스스로 나아지는 방식이다. 가장 어려운 싸움은 자신과의 싸움이며 가장 가치 있는 진보는 자신의 어제보다 나아지는 것이다. 다른 사람에게 공을 돌려라. 복수하지 마라. 자기계발 강령 7가지 자신의 기질과 재능을 찾아내라. 노력의 8할을 자신의 특성에 집중하라. 하루 한두 시간의 해방구를 만들어라. 매일 해야 이룰 수 있다. 독학 없는 배움은 없다. 스승을 구하고 파트너를 찾아라. 기록하지 않는 것은 사라진다. 기록된 하루는 조금씩 다르지만 기록되지 않은 하루는 모두 같아 구별되지 않는다. 퇴직 강령 준비하라 자신에게 맞는 일을 유일한 방식으로 제공하라. ‘뭘 하면 먹고 살 수 있을까’라는 생각에 빠지면 절대로 먹고 살 수 없다. ‘내가 잘할 수 있는 가슴 뛰는 일은 무엇일까’ 이 질문의 끈을 놓지 말아야 한다. 자신의 기질과 재능과 경험을 연결해 차별화하라. 그리고 그 일에 전력을 다하고 즐겨라. p125 변화는 불행한 사람들의 주제다. ‘지금의 나’와 ‘내가 바라는 나’ 사이의 간격을 인식하는 불행한 자각으로부터 변화는 시작한다. 이 간격을 못 견디는 절박한 사람만이 이 길을 선택한다. 변화는 에너지를 많이 요구하는 작업이다. 자신에 대한 창조적 증오 없이는 이 에너지를 공급받을 곳이 마땅치 않다.\n그러나 변화가 더욱 매력적인 이유는 그것이 ‘내가 바라는 나’로 향하는 여정이기 때문이다.\n129 노동은 심심함을 이기는 아주 생산적인 일이긴 하지만, 노동이 바쁨을 만들어내면 우리는 석고처럼 된다. 바쁨은 새로움의 천적이다. 머리는 죽고 손발은 헉헉대는 것이 바로 바쁨의 모습이다. 바쁨은 전염성이 아주 강하다. 휴가조차 바쁘게 하고 쉼조차 바쁨으로 가득 채운다. 결국 심심한 것을 참을 수 없게 만든다. 사람들은 그렇게 해서 모두 똑같아지는 것같다.\np134 아이들이 커서 자신의 일에 몰두하게 되면, 가족 여행조차 함께하기 어렵기 때문에 아이들이 자라나는 십여 년 정도는 기쁨을 추억으로 간직할 수 있도록 해야 한다는 것이다. 여행은 사람들이 가장 좋아하는 기쁨 중의 하나다. … 그러나 중요한 것은 우선순위다.\np147 우리는 실패를 두려워한다. 그렇기 때문에 삶이라는 경기장에서 졸렬한 축구를 하는 것이다. 현란한 드리블도 멋진 패스도 강력한 슛도 해보지 못한 채, 그저 공을 기다리고 모처럼 공이 오면 내놓지 않으려 한다. 그 많은 시도, 그것을 실패라고 부르지 말자. 그 실패를 지금부터 시도라고 부르자.\np148 머리속에 남은 것이 없다면 독서 방식에 변화를 주어야 한다. 밑줄을 치면서 ㅇ릭자. 다 읽고 나서 밑줄 친 부분을 컴퓨터에 옮기면서 다시 음미하자. 강렬하게 다가오는 구절은 따로 떼어내 ‘나를 움직인 한마디’라는 파일에 넣어두자. 그리고 응용하자. PT에도 인용하고, 팸플릿을 만드 때도 인용하고, 편지 쓸 때도 인용하자. 그러면서 독서는 훨씬 흥미진진한 사상과 언어의 채집 과정이 된다. 모든 배움과 훈련은 그 과정에 대한 진화를 요구하며, 방식의 변화에 따라 효과는 급증하게 마련이다. 실패한 방법을 답습하면서 여전히 좋은 결과를 기대한다면 우둔한 것이다. 현명한 사람은 성공할 때까지 방법을 달리해본다.\np163 특히 재능이 많은 살마들은 한곳에 몰입하기 어렵다. 이 일도 좋아 보이고 저 일도 재밍ㅆ어 보이면 어떤 하나도 경지에 이르기 어려워진다. 하나에 전념하라. 이것이 바로 경영의 기초인 ‘선택과 집중’이다. 이때 유의할 점은 무엇을 선택하더라도 그 수준은 예술적 경지를 추구해야 한다는 것이다. 예술이란 사물을 더 잘 만드는 것이다. 예술은 필요를 넘어선다. 더할 수 없는 경지, 즉 완벽을 향해 나가야 한다. 그러면 그 일이 무엇이든 그 살마은 그 분야의 예술가가 된다. 예술이야말로 가장 화려한 변모의 체험이다.\np170 부지런하다는 것은 미덕이다. 분명하다. 그런데 나는 필요에 따라 이 금면을 몰아 쓰는 것이 전략적으로 훨씬 더 유용하다는 것을 깨닫게 되었다.\n똑같은 일을 반복하기 위해 매일 아주 많은 야근을 하고 있다면 그 부지런함은 격무를 몸으로 때우고 있다는 반증에 지나지 않는다. 끝없는 야근을 종료하려면 지금의 프로세스에 도전해야 한다. 새로운 프로세스는 다른 살마이 만들어주지 않는다. 내가 나서서 만들어내야 한다. 시키는 일을 마치는 것, 이것이 내 직무의 전부가 아니다. 내가 해야 할 일을 잘해내기 위해서 가장 좋은 ㅂ아법을 찾아내는 것 역시 내 직무의 영역이다. 바로 이런 인식의 고양이 주도적 리더십의 핵심이다. 이때 손발의 부지런함은 두뇌의 활동으로 확장되며, 매일 반복되는 저부가가치의 일이 일의 방식을 바꾸는 프로세스의 혁신 프로젝트로 전환된다.\n일을 잘하느냐 못하느냐의 기준에는 크게 네 가지 수준의 차원이 있다.\n가장 초보적인 단계가 초보적 부지런함의 단계다. 성실한 초보의 단계. 노동의 차원 시키는 일, 즉 과업을 달성하는 새로운 방법을 찾아내는 차원. 프로세스 혁신. How. 일을 연결과 접속의 차원으로 인식하는 실험의 차원. 지금까지 해오던 일을 하는 대신 새로운 개념이 할 일을 찾아내는 차원. 일 자체는 전환. What. 가장 창의적인 집단의 구성원들이 지니는 자세. 일이 즐거움이 되는 놀이의 차원. 일이 예술의 경지에 이르는 차원. 일은 필요를 충족시키는 것이 아니라 영혼의 웰빙이 기여하는 수준에 도달. p177 직장에서의 생활이 내가 깨어 있는 시간의 3분의 2를 차지한다는 간단한 을 사실을 각성.\n","date":"2018-07-29T21:36:14+09:00","permalink":"https://cychong47.github.io/post/2018/i-am-going-to-be/","summary":"\u003ch3 id=\"p17\"\u003ep17\u003c/h3\u003e\n\u003cp\u003e술과 구라를 즐기되 항상 혀를 조심하라.\n어느 장소에서나 어느 주제에 대해서나 할 말을 다하는 자는\n불행한 자이니 말하고 싶을 때마다 세 번을 더 깊이 들어라\n특히 나이가 들어서는 혀를 잘 묶어두어야 한다.\n고약한 늙은이 옆에는 사람이 없으니 외로움이 끝없으리라\n배워서 알고 싶은 것을 다 쓰지 못하고 가는 것은 서운한 일이나\u003cbr\u003e\n친구는 들어주는 사람 곁에 모이는 것이니\n하나를 말하고 둘을 들어라.\u003c/p\u003e\n\u003ch3 id=\"p27\"\u003ep27\u003c/h3\u003e\n\u003cp\u003e여러분이 놓치고 있는 것이 있습니다. 바로 이 하얀 종이 말입니다. 인생에서, 비즈니스에서, 가정에서 개인적인 일에서나 공적인 일에서 우리는 바로 이 검은 점 하나와 같은 작은 실수와 실패 때문에 온통 마음이 심란해집니다. 그러나 중요한 것은 아무것도 그려져 있지 않은 이 하얀 여백입닏. 이곳이 바로 우리가 꿈을 그려 넣을 자리입니다.\u003c/p\u003e","title":"(책) 나는 이렇게 될것이다."},{"content":"p21 사람들이 업무의 인간적인 측면보다 기술적인 측면에 주로 매달리는 가장 큰 이유는 기술적인 부분이 더욱 중요하기 때문이 아니라 거기에 매달리는 것이 훨씬 더 쉽기 때문이다.\np24 실수를 허용하지 않는 분위기는 직원들에게 방어적인 태도를 양산할 뿐이다. 즉 직원들로 하여금 실패할 것 같은 일은 아예 시도조차 하지 않게 만드는 것이다. 개발 프로세스를 체계화하려고 하거나 엄격한 방법론을 강요하면서, 팀원들이 확실한 성공을 보장할 수 없는 것들에 대해 중요한 결정들을 내리지 못하게 한다면 그들은 점점 더 소극적이고 방어적인 태도를 취한다. 실수를 허용하지 않는 분위기로 인해 평균적인 기술 수준은 약간 향상될지도 모르지만, 팀은 위기에 처하게 될 것이다.\np25 그들을 닦달해서 억지로 움직이게 할 수 있을지는 몰라도, 그들이 창의적이고 창조적이며 풍부한 사고를 하도록 만드는 것은 불가능하다. 사람들의 옆구리를 찔러서 단기 생산성을 올릴 수 있을지는 모르지만 장기적인 관점에서 그런 방법은 효과적이지 않다. 스스로의 동기가 아니라 상사가 강요한 동기에 의해 일한다는 사실만큼 직원들의 사기를 떨어뜨리는 것은 없을 것이다.\np28 사람들은 새로운 프로젝트의 가치를 주로 수치에 의존하는 경향이 있다. 팀원들이 얼마나 많은 코드들을 만들어 낼 수 있는 가 혹은 얼마나 많은 문헌 조사가 이루어졌는가에 대해서는 관심을 가지면서도, 팀웍 전체가 개발 과정에서 어떠한 역동적인 역할들을 담당하고 있는가에 대해서는 관심을 갖지 않는다.\np65 샤론은 천성적으로 뛰어난 관리자적 자질을 가진 사람들이 그렇듯이 다음 사실을 알고 있었다. “관리자가 진정 해야 하는 일은 사람들에게 일을 시키는 것이 아니라 그들이 일에 전념할 수 있는 환경을 만들어 주는 것이다”\np75 직원들이 근무 시간의 양을 늘이기 위해서라기보다는 근무 시간의 평균적인 질을 향상시키기 위해 초과근무라는 수단을 택한다는 것이다. (다른 사람이 없는 새벽이나 늦은 시간에 집중할 수 있어서)\np85 상위 집단의 업무 공간은 조용하고 프라이버시가 보장되며 불필요한 방해로부터 차단되어 있다.\np105 사람들이 진짜 일하는 시간은 바로 혼자서 일하는 때이기 때문이다.\np113 직원들은 매일 머리를 쓰는 작업을 하러 출근하는 것이다. 일터가 조금이라도 조용하고 차분해진다면 그들은 아무 조건없이 두뇌를 사용하여 자기 일을 열심히 할 수 있을 것이다.\np121 문제는 기술이 아니라 습관을 바꾸는 것에 있다.\np129 우뇌가 배경 음악을 듣느라 바쁘다면 창의적인 도약 과정이 생겨날 기회는 사라진다.\np141 사람들은 창문이 없는 집에서 산다는 것은 상상도 못하면서, 낮 시간의 대부분을 창문이 없는 사무실에서 보낸다.\np149 꼭 필요한 사람들을 뽑아라. 그들이 떠나지 않도록 행복하게 만들어라. 그들을 자유롭게 풀어 주어라. p193 업무의 도전적 성격은 중요하다. 하지만 그 자체로 중요한 것은 아니다. 그것이 중요한 이유는 사람들이 함께 초점을 맞출 수 있게 하는 것들을 제공하기 때문이다. 도전은 함께함을 위한 도구일 뿐이다. 즐겁게 일하고 최대한의 능력을 발휘하는 최고이 작업 그룹에서, 팀의 상호 작용은 무엇보다도 중요하다. 그것이 바로 사람들이 끝까지 노력하고, 모든 것을 일에 투자하고, 엄청난 장애를 극복하는 이유이다.\np197 경영 위원회에서 이익의 증대를 위해 열을 올리고 있는 동안, 그 목표는 하부에서 일하는 사람들에게는 별로 큰 소득을 가져다 주지 않는 것이다. ‘십억 달러 수익성 증대’, ‘회사의 기록적인 분기 실적’과 같은 목표에 하위 직원들은 관심도 갖지 않는다. … 그들은 목적을 달성하는 기쁨을 함께 느끼며 공동의 성공을 위해 팀 내에 속해 있었다. 회사의 이익에 대한 관심을 환기시키는 것은 전혀 도움이 되지 않는다. 그것은 단지 성공을 사소하고 의미 없는 것으로 만들어 버렸다.\np220 관리자들이 팀에 대해 유일하게 신경 쓸 때는 팀을 깨려고 할 때 뿐이다.\np225 스파케티 회식. 바로 관리자가 팀원들이 함께 성공을 거둘 수 있는 작은 업무들을 끊임없이 제공한다는 것이다.\np241 팀 형성 기법을 갖고 있는 관리자들은 전체 업무를 부분적으로 완성하여 보여 줄 수 있는 것들로 나누려고 애쓴다…. 팀의 구성원들은 중간 확인 작업을 해야 할 때가 되면 준비하고 있다가 진짜 목표를 향해 전력질주할 것이다. 중간 확인 작업이 성공하면 다음 목표에 쓸 에너지는 재충전된다. 또한 그렇게 함으로써 팀은 서로 더욱 가깝게 느끼게 된다.\np310 존슨은 ‘신뢰는 하지만 의문을 제기하는 사람들’만이 변화에 진정으로 동참시킬 만한 유일한 집단이라고 주장한다. 이들을 설득할 때는 카드놀이를 할 때 처럼 논리를 따라서는 안된다. 이 의심의 양단에 서서 같은 편이 될지 안 될지 확실하지 않은 사람들은 기존의 방법보다 새로 도입할 방법이 엄청나게 나을 거라고 논리적으로 설득해 봐야 전혀 흔들리지 않을 것이다. 당신이 사람들에게 변화를 요구하려고 할때마다 항상 주문처럼 반복해서 말해야 할 것이 있다.\n변화에 대한 사람들의 반응은 본질적으로 이성적인 것이 아니라 감정적인 것이다.\n윌리엄 브리지스는 그의 저서 \u0026lt;변화 관리\u0026gt;에서 절대로 기존의 방식을 폄하하는 발언을 해서는 안된다고 말한다. 대신 우리는 기존의 체계를 새로운 변화를 일으키는 데 도움이 되는 것으로 치켜세워야 한다.\np313 낡은 현상태 -\u0026gt;(생소한 요소)-\u0026gt; 카오스 -\u0026gt;(생각의 변화)-\u0026gt; 실행과 융합 -\u0026gt; 새로운 현상태\n","date":"2018-07-29T21:35:10+09:00","permalink":"https://cychong47.github.io/post/2018/peopleware/","summary":"\u003ch2 id=\"p21\"\u003ep21\u003c/h2\u003e\n\u003cp\u003e사람들이 업무의 인간적인 측면보다 기술적인 측면에 주로 매달리는 가장 큰 이유는 기술적인 부분이 더욱 중요하기 때문이 아니라 거기에 매달리는 것이 훨씬 더 쉽기 때문이다.\u003c/p\u003e\n\u003ch2 id=\"p24\"\u003ep24\u003c/h2\u003e\n\u003cp\u003e실수를 허용하지 않는 분위기는 직원들에게 방어적인 태도를 양산할 뿐이다. 즉 직원들로 하여금 실패할 것 같은 일은 아예 시도조차 하지 않게 만드는 것이다. 개발 프로세스를 체계화하려고 하거나 엄격한 방법론을 강요하면서, 팀원들이 확실한 성공을 보장할 수 없는 것들에 대해 중요한 결정들을 내리지 못하게 한다면 그들은 점점 더 소극적이고 방어적인 태도를 취한다. 실수를 허용하지 않는 분위기로 인해 평균적인 기술 수준은 약간 향상될지도 모르지만, 팀은 위기에 처하게 될 것이다.\u003c/p\u003e","title":"(책) 피플웨어"},{"content":"30 생산성의 증가가 오히려 일자리를 필요없게 만든다. 사람의 노동력을 대체할 것들이 등장하기 때문이다.\n31 지나친 생산성은 고용의 안정성을 해지며, 높아진 생산성만큼 사회와 경제가 성장하지 않으면 안 된든다는 압력으로 작용한다.\n33 거대한 생산성과 효율성을 바탕으로 하는 소비자 중심의 과소비 사회가 종말을 맞이하려고 한다. 과소비를 통해 외형이 성장하고, 이를 맞추기 위한 생산성의 독려와 일자리를 유지했던 성장의 순환 사이클이 그 동력을 잃고 있다.\n52 지식노동자의 주된 역할은 정보를 다루고, 찾아내며, 컴퓨터가 계산한 내용을 바탕으로 새로운 지식을 만들어 내고 분석하는 일이라 할 수 있다. 그러나 이러한 것들이 새로운 기술에 의해 대체가 가능해지는 미래에는 결국 판단과 비판적인 사고, 공감 등 기계로 대체하기 어려운 더욱더 새로운 기술이 필요하게 된다. 지식노동자가 비지니스를 어떻게 관리하고 운영하는지 알았다면, 인사이트 노동자나는 비지니스가 어떻게 그리고 왜 필요한 지에 대한 근본적인 의문에 답할 수 있어야 한다.\n62 “물질이 저의 인생을 의미 있게 만드는 데 아무런 도움이 되지 않는다는 결론에 도달했습니다”\n67 자신이 집에 돌아갈 때 어떤 마음을 가지고 가는지를 생각했다. 자존심이 상했거나 기분이 나쁜 날이면 집으로 돌아가 자녀들을 만났을 때 잘 대하기 어렵다. 반면 성취를 이루고 인정받은 날은 기분 좋게 가족들을 만날 것이고, 행복감을 느낄 것이다. 이처럼 그녀는 배우자이자 부모로서의 개개인의 역할과 긍정적인 여향에 대해 고민했고, 그렇기에 직장에서의 건강한 마인드는 가정, 그리고 결국은 사회를 이끄는 힘이 된다고 믿었다. 이러한 그녀의 시각은 크리스텐슨 교수에게도 관리와 경영의 소중함에 대해 다시 한 번 되새기게 했다.\n68 시간과 재능, 그리고 에너지를 어떻게 쓸 것인가에 대해서만 고민하지, 인생에 대한 목적에 대해서는 그 중요성을 놓치기 때문이다.\n70 반복되는 문제와 대응은 문화를 만들고, 관행과 본능에 따라 문화를 따르게 된다. MIT Edgar Shein 교수 아이가 어렸을 때 공감을 통해 문제를 해결하고, 부모를 존경하고, 옳은 일을 따라 결정을 내리는 문화를 형성하였다면, 자녀가 청소년기가 되었을 때 겪게 되는 통제의 어려움은 덜하게 될 것이다.\n73 기업가 Oliver Segovia HBR “ 행복은 내가 사랑하고, 잘하고, 세상이 원하는 것의 교차점에 있다. Happiness comes from the intersection of what you love, what you’re good at, and what the world needs”\n행복은 열심히 찾기만 한다고 미소 짓지 않는다. 역설적이게도 “행복해야 하는데”라는 걱정을 덜 하는 것이 가장 행복해지는 법이라는 말도 있다. 세상과 하나 되어 나 자신의 역할을 묵묵하게 수행하면서, 진정한 사회적 가치를 만들어 낼 때 내가 행복할 뿐만 아니라 세상에 행복을 전파하는 사람이 될 수 있다. 나 자신이 가장 잘할 수 있는 것을, 열정을 가지고, 사회적 가치로 만들어 낼 때 기회가 주어질 것이다.\n82 배워야 한다는 의무가 아닌, 호기심에서 시작된 학습은 그 효과가 이처럼 확연히 드러난다. “아이들은 스스로 학습 환경을 만들 수 있는 여견을 제공한다면, 누구나 스스로 배울 수 있습니다”\n##84 미래에는 결국 많은 사람과 소통하고 나누며 자신의 일을 행복하게 하는 사람이 성공한다.\n정보가 넘치는 세상이다. 아이들의 재능을 꽃피우게 할 방법과 이렇게 가지게 된 재능을 어떤 방식으로 자신들의 삶과 연결시킬 것인지에 대해 부모도 같이 고민할 수 있다. 이를 생업과 직업으로 연결시키기 위해서는 단순히 아이가 좋아하는 분야를 찾고 해당되는 재능을 찾는 것만으로는 안 될 것이다. 소통 능력이나 사회관계, 경제에 대한 개념, 또는 과학이나 수학 같은 것들이 필요할 수도 있다. 그렇다면 아이들은 자신의 꿈을 위해 공부해야 하는 당위성을 파악하게 되는 것이다.\n부모는 미래를 읽을 수 있는 혜안을 가지려는 노력을 게을리해서는 안 된다.\n92 수렴적 사고 (Covergent Thinking) 여러가지를 종합하고 분석하는 능력 발산적 사고 (Divergent Thinking) 엉뚱한 곳으로 튀는 경향 수렴적 사고와 발산적 사고를 자유롭게 전환하는 연습도 필요한데, 종종 새로운 정보를 과거의 정보나 지나간 아이디어와 결합시키거나 잠시 말도 안되는 엉뚱한 아이디어들을 계속 내놓다가 이를 정리하고 단단하게 만드는 작업을 반복하면 창의력을 키울 수 있다.\n94 자유롭게 노는 것을 좋아하는 아이들의 성향과 공부 습관을 기르는 것이 서로 다른 영역이기 때문에 아이들이 괴로워하고 고생하는 경우가 많다. 이럴 때 중요한 것은 부모와 선생님의 역할이다. 공부하는 습관을 가지도록 격려하고 도와주면서, 동시에 가끔씩 특별 프로글매이나 독특한 시도를 허용하며, 호기심을 자극할 수 있도록 지도하면 아이들은 훨씬 쉽게 창의력을 기르고 융합적 사고를 할 수 있게 된다. 또한 공부 과정에도 창의성을 발휘해 자신ㅇ만의일과와 공부 일정을 세우고, 공부할 학습지를 스스로 찾게 하는 것도 좋다. 이 과정을 실패하면, 공부하는 습관을 들이지 못하고 시간을 낭비하거나 자신의 미래에 대한 비전을 잃고 수동적으로 공부하는 등 잠재되어 있는 자신의 뛰어난 기량을 꽃피우지 못하게 된다.\n106 기본적으로 내놓기보다는 지키는 것에 익숙하며, 자신들이 원하는 것을 가져가려고만 하는 경우가 많다. 이런 기업이나 사람들은 네트워크에 참여하기 어렵고, 참여해도 적응하기 어렵다.\n이런 변화에 적응하는 것은 쉬운 일이 아니다. 그렇지만 비교적 위험성이 덜한 지식자산부터 내놓고, 조금씩 신뢰를 쌓아 나가는 것이 중요하다. 그리고 흐름의 네트워크를 통해 자연스럽게 해당 지식 자산의 가치가 상승하는 것을 관찰하면 이런 새로운 흐름의 원리를 파악할 수 있다. 네트워크의 신뢰도가 올라가고 참여자들도 보다 많은 것을 내놓기 시작하면 이 네트워크는 선순환의 고리를 돌기 시작할 것이다. 보다 높은 가치가 있는 지식이 공유되고, 이들이 결합하여 더 높은 부가가치를 가진 형태로 변화된다면 점진적 혁신이 이루어진다. 이렇게 한 단계 업그레이드한 지식자산은 또다시 공유되면서 새로운 발전의 원천이 될 수 있다. 세상의 변화 양상은 주입식으로 공부하고 개인이 지식을 많이 쌓아 나가는 것보다는, 지식과 경험을 공유하고 소통을 통해 그 가치를 높여 나가면서 실질적인 협업을 통해 눈에 보이는 성과를 창출하길 원한다. 이를 통해 지식과 경험의 흐름을 요구하고, 또 그런 능력을 가진 인재를 필요로 하고 있다.\n120 사람들은 일하지 않으면 논다고 생각한다. 그러나 놀이의 반대는 ’일’이 아니라 ‘우울’이다.\n140 아이들에게 추천하는 좋은 게임.\n게임하는 시간에 제한. 온라인 게임은 시키지 않음. 게임의 완성도가 있으면서 명확한 끝이 있어 매일 적당한 시간을 투자해서 정복해 나가는 게임(젤다의 전설). 사용자가 자유롭게 게임 속 세계를 만들 수 있어 창의성과 성취감을 높일 수 있는 게임(마인크래프트). 가족들이 함께 몸을 쓰며 즐기는 게임(위) 역사에 대한 괏미을 고조시킬 수 있는 패키지 게임(에이지오브엠파이어) 아이들에게 틈틈이 게임을 어떻게 즐기고 있고, 어떤 면이 좋았는 지 질문. 세다가 다르고 세상의 규칙이 달라지고 있는데, 기성세대의 선입견만 가지고 모든을 것을 제약하려는 시도는 어쩌면 아이들을 편하게 관리하려는 어른들의 이기심에서 비롯된 것일 지 모른다. 본인들은 아이들을 이해하려고 노력하지 않으면서, 아이들이 말을 듣지 않고 게임만 한다고 한탄하고, 아이들을 죄인으로 만드는 법을 자꾸만 만드는 것이 과연 옳은 것인지 잘 생각해 볼 문제다.\n게임에 대한 부모들의 시각에 따라 게임을 대하는 아이들의 자세도 달라진다. 막는다고 막아지는 것도 아니다. 숨어서 몰래하거나 또는 억지로 참게 하기보다, 건강하게 즐기고 게임이 주는 유익을 누리는 방법을 찾을 때다.\n158 외국어 능력의 중요성을 아이들에게 각인시키는 것이다. 무엇보다 자신의 필요에 의해 외국어에 매진할 수 있도록 동기부여를 한다면, 그 열정에 의해 외국어 능력은 일취월장하게 되어 있다.\n외국 게임. 공부하지 않으면 안되는 게임으로 아이들의 학습을 유도. 세계사를 공부해야 게임을 잘할 수 있는 에이지오브엠파이어, 토탈워, 문명. 영문판을 사서 매일 시간 제한. 단 해당 게임을 마스터하기 위해 공부하는 시간에는 특별히 제한을 두지 않음. 그랬더니 아이들이 영어사전을 이용해서 매뉴얼과 인터넷에 공개된 다양한 외국어 사이트를 뒤지면서 자료를 찾았고, 이러한 과정을 통해 영어 공부를 두려워하지 않게 되었다.\nStencil Works History Channel EBS 다큐멘터리 174 휴대폰과 PC, 게임과 인터넷 등은 정해진 시간만큼 이용하도록 한다. 매주 하루 반나절은 휴대폰과 PC, 게임과 인터넷을 하지 않는다. 부모와 아이들이 함께 산책하면서 진중하고도 소소한 이야기를 나눌 기회를 가진다. 한 달에 한 번은 가까운 공공도서관에 가서 책 속에 파묻혀 몇 시간을 보낸다. 일주일에 하루는 부모와 아이들이 함께 게임하는 시간을 가진다. ","date":"2018-07-29T21:33:47+09:00","permalink":"https://cychong47.github.io/post/2018/the-future-of-my-children/","summary":"\u003ch2 id=\"30\"\u003e30\u003c/h2\u003e\n\u003cp\u003e생산성의 증가가 오히려 일자리를 필요없게 만든다. 사람의 노동력을 대체할 것들이 등장하기 때문이다.\u003c/p\u003e\n\u003ch2 id=\"31\"\u003e31\u003c/h2\u003e\n\u003cp\u003e지나친 생산성은 고용의 안정성을 해지며, 높아진 생산성만큼 사회와 경제가 성장하지 않으면 안 된든다는 압력으로 작용한다.\u003c/p\u003e\n\u003ch2 id=\"33\"\u003e33\u003c/h2\u003e\n\u003cp\u003e거대한 생산성과 효율성을 바탕으로 하는 소비자 중심의 과소비 사회가 종말을 맞이하려고 한다. 과소비를 통해 외형이 성장하고, 이를 맞추기 위한 생산성의 독려와 일자리를 유지했던 성장의 순환 사이클이 그 동력을 잃고 있다.\u003c/p\u003e\n\u003ch2 id=\"52\"\u003e52\u003c/h2\u003e\n\u003cp\u003e지식노동자의 주된 역할은 정보를 다루고, 찾아내며, 컴퓨터가 계산한 내용을 바탕으로 새로운 지식을 만들어 내고 분석하는 일이라 할 수 있다. 그러나 이러한 것들이 새로운 기술에 의해 대체가 가능해지는 미래에는 결국 판단과 비판적인 사고, 공감 등 기계로 대체하기 어려운 더욱더 새로운 기술이 필요하게 된다.\n지식노동자가 비지니스를 어떻게 관리하고 운영하는지 알았다면, 인사이트 노동자나는 비지니스가 어떻게 그리고 왜 필요한 지에 대한 근본적인 의문에 답할 수 있어야 한다.\u003c/p\u003e","title":"(책) 내 아이가 만날 미래"},{"content":"42 우리는 통제할 수 있는 것에 초점을 맞추되, 통제할 수 없는 것에는 마음을 편히 먹어야 한다.\n44 이제는 불평도 하지 않고, 남을 탓하지도 않을거야. 내 앞에 놓인 세상을 거부할 게 아니라, 있는 그대로의 세상에 뛰어들어서 내가 통제할 수 있는 것부터 시작할 거야. 무슨 일을 할 수 있을 지 찾아봐야겠어.\n50 자신의 지금 위치가 어디이든, 영향력의 원이 얼마나 크든 그 원의 밖이 아닌 안에서 변화를 일으키려 노력하라. 어차피 손을 쓸 수도 없는 큰 그림을 분석하고 해부하는데 소중한 에너지를 쓰지 말라. 대신 그 시간과 에너지를 손을 쓸 수 있는 것, 즉 영향력의 원 안에 있는 것에 써라. 그러다 보면 영향력의 원이 알아서 커질 것이다.\n53 우리 발목을 잡는 것은 ‘시스템’이 아니라 우리 자신의 ‘인식의 결함’이다. 통제할 수 없는 외부의 사건에 정신이 팔리면 통제할 수 있는 삶의 결함을 보지 못한다. 우리가 고통스러운 것은 세상이 불완전하기 때문이 아니라, 개인의 시스템이 불완전하기 때문이라는 것을 알지 못한다. 개인의 시스템은 충분히 개선할 수 있는데도 말이다. 삶의 사소한 부분까지 깐깐하게 살펴보야만 성공과 마음의 평화, 즉 자유를 손에 넣을 수 있다.\n57 품질 좋은 상품이나 서비스, 능력있는 직원, 수익성은 그것을 창출하는 훌륭한 시스템의 결과물이지 시스템이 아니라는 것이다.\n101 회사 생활과 개인 생활을 뜯어고치는 작업이 왜 막막하기만 했는 지 알 수 있을 것 같다. 그것들을 감히 손댈 수 없는 ‘불가항력의 존재’라고 생각했기 때문이다. 그것들을 단순한 하부 시스템으로 분해해서 하나씩 최적화할 수 있다는 생각은 한 번도 해본 적이 없었던 것이다. 잘못된 구조를 고치는 게 아니라, 보이지도 않는 잘못된 구조에서 비롯되는 문제들을 처리하느라 급급했던 것이다.\n103 센트라텔에 처음으로 거둔 가장 큰 성공은 내부 커뮤니케이션 시스템을 완성한 것이다. 매순간 모든 직원이 다른 부서에서 무슨 일이 일어나고 있는지를 알 수 있게 되었다.\n직원 2명이 시스템 방법론과 그에 따른 문서화 작업을 받아들이지 못한 것이다.\n107 근무시간 줄이기\n5킬로그램 감량하기\n카페인 음료 섭취 줄이기\n일주일에 최소 4회 이상 운동하기\n몸에 좋은 음식 먹기\n물 많이 마시기\n당분과 염분 섭취 줄이기\n3개월마다 혈액 검사하기\n혈액 검사 결과에 따라 필요한 영양제 먹기 일주일에 최소 1회 친구들 만나기\n가족과 일대일로 마주하는 횟수 늘리기\n매일 최소 1시간 이상 독서하기\n일주일에 단행본 1권, 잡지 6권 읽기\n158 시스템을 개선하는 관점, 즉 밖에서 그리고 위에서 바라보는 관점을 몸에 익혀야 한다. 비지니스와 직장, 개인 생활에서의 목표를 구체적으로 정한다음, 문서로 작성한다. 그 목표를 달성하기 위해 활용할 방법을 간략히 정의한다. 이것이 전략 목표 설정서이다. 자신만의 종합 운영 원칙을 만들고, 그것을 의사 결정의 지침으로 삼는다. 개선할 수 있는 시스템에 대해 구체적으로 적는다. 이때 이미 존재하는 시스템과 새로 만들어야 할 시스템을 포함시킨다. 그 외의 것들은 버릴 각오를 한다. 각 시스템을 가장 기본적인 구성 요소로 분해한다. 비니지스와 직장의 경우에는 각 단게를 1-2-3 단계 형식으로 문서화한다. 시스템을 하나하나 살펴보면서 각 단계의 효율성을 높인다. 이때 최대한 단순함을 추구해야 한다. 필요하면 순서를 바꾸고, 단계를 추가하거나 뺀다. 각 시스템을 작업 절차서에 기록하여 비지니스나 직장에서 시스템을 계속 유지할 수 있도록 한다. 새로운 작업 절차를 추구하고, 정기적으로 관리해야 한다. 필요에 따라 조정할 수 있다. ##198\n예외를 두지 말고 새로 마련한 절차서 모두를 시험해 보라. 절차서를 공개하기 전에 단계별 내용을 꼼꼼히 확인하고, 문제를 이해할 수 있는 직원에게 작성한 문서를 보여줘라.\n208 작업절차서는 상세하게 작성하되, 지나치지 않게 작성해야 한다. 원하는 결과를 계속 얻을 수 있을 정도로만 말이다. 그래서 현장을 모르는 일반인이 보고도 처리할 수 있을 수준이면 된다.\n211 당신은 불필요한 업무, 불필요한 정보에 집착하여 너무 많은 시간을 낭비하고 있지 않는가? 쓸모없는 세부적인 내용에 집중하고 있지 않은가?\n214 ‘당신이 무슨 말을 하건, 무슨 생각을 하건 상관없어! 중요한 건 ‘무엇을 하느냐’이지”\n219 직원들이 발전기 작동 과정에 대해 단계별로 ‘담당자 아니어도 이해할 수 있을 정도로’ 쉽게 작성해 두었다. 이 때문에 시험 운행할 때마다 늘 문서를 보고 가동한다. 흥미로운 점은 매달 시험 가동을 할 때마다 계속 작업 절차가 개선되었다는 점이다. 절차서는 살아 있는 생명체와도 같다. 급변하는 환경과 시험 가동 관리자의 개선안에 따라 계속 바뀌기 때문이다.\n227 POS(Point Of Sale) 방식.\n꾸물대지 말라. 지금 당장 실행해서 일을 마무리하라. 그 일을 직접 하건 위임하건, 내던져 버리건 이란 실행하라. 일을 자동화하고, 체계화해서 개인적으로 해야 할 일을 줄여라. 230 멀티태스킹 또는 동시에 여러 개의 시스템이 기능하도록 만드는 것은 컴퓨터를 완벽하게 응용하는 것이지 사람이 하는 것이 아니다. 멀티태스킹은 컴퓨터에 맡겨라.\n249 오늘날의 기업 문화 속에서 모든 활동 영역이 효율성을 갈구하고 있지만, 실상 서비스의 질은 상당히 떨어진다… 하지만 당신이 시스템을 만들고 유지하는 일에 초점을 맞춘다면, 시스템은 일관적인 품질을 보장해 주기 때문에 탁월한 서비스를 제공하는 일이 쉬울 수 있다. 다시 한번 강조하지만 내부의 시스템을 만들고, 유지하고, 개선하는 일이 관리자의 주된 목표가 되어야 한다.\n","date":"2018-07-29T21:32:37+09:00","permalink":"https://cychong47.github.io/post/2018/the-work-system/","summary":"\u003ch2 id=\"42\"\u003e42\u003c/h2\u003e\n\u003cp\u003e우리는 통제할 수 있는 것에 초점을 맞추되, 통제할 수 없는 것에는 마음을 편히 먹어야 한다.\u003c/p\u003e\n\u003ch2 id=\"44\"\u003e44\u003c/h2\u003e\n\u003cp\u003e이제는 불평도 하지 않고, 남을 탓하지도 않을거야. 내 앞에 놓인 세상을 거부할 게 아니라, 있는 그대로의 세상에 뛰어들어서 내가 통제할 수 있는 것부터 시작할 거야. 무슨 일을 할 수 있을 지 찾아봐야겠어.\u003c/p\u003e\n\u003ch2 id=\"50\"\u003e50\u003c/h2\u003e\n\u003cp\u003e자신의 지금 위치가 어디이든, 영향력의 원이 얼마나 크든 그 원의 밖이 아닌 안에서 변화를 일으키려 노력하라. 어차피 손을 쓸 수도 없는 큰 그림을 분석하고 해부하는데 소중한 에너지를 쓰지 말라. 대신 그 시간과 에너지를 손을 쓸 수 있는 것, 즉 영향력의 원 안에 있는 것에 써라. 그러다 보면 영향력의 원이 알아서 커질 것이다.\u003c/p\u003e","title":"(책) 시스템의 힘"},{"content":"꿈을 노트하라 꿈을 날짜와 함께 적어 놓으면 그것은 목표가 되고 목표를 잘게 나누면 그것은 계획인 되며, 그 계획을 실행에 옮기면 꿈을 이루게 되는 것이다.\np46 우리는 무거운 짐을 지고 살아간다. ‘등이 휠 것 같은 삶의 무게여’라는 가사도 있다. 내가 책임져야 할 가족과 도움을 필요로 한 친구들, 나에게 주어진 과중한 업무와 기대. 이 거추장스러운 짐들이 사실은 ‘내 인생의 날개’일 수도 있다.\np68 다른 사람과 한 약속을 지키는 것도 중요하지만 자기 자신과 한 약속을 지키는 것이 더 중요하다 세상과 타협하는 것도 위험하지만 자기 자신과 타협하는 것이 가장 위험하다\np75 누구나 할 수 있는 일이 아니라 나만이 할 수 있는 일을 계발해야 한다 언제든 대체 가능한 사람이 아니라 내가 아니면 안되는 능력을 가져야 한다는 것이다 세상은 네가 가진 그 한 가지의 재능을 인정할 것이다.\np79 우리가 정말 포기하는 이유는 불가능해서가 아니라 불가능할 것 같아서라고\n목표는 최고를 지향하되 계획은 최악을 가정하라\n함께 가라 빨기 가려거든 혼자 가라 멀리 가려거든 함께 가라 빨리 가려거든 직선으로 가라 멀리 가려거든 곡선으로 가라 외나무가 되려거든 혼자 서고 푸른 숲이 되려거든 함게 서라\n인디언 속담 p125 진짜 실력은 보이지 않는 데서 나온다. 눈가림은 언제나 들통이 난다. 자신에게 진실하고, 최선을 다할 때 그 결과는 돌아오기 마련이다.\np149 자기만 생각하는 사람과 남을 배려하는 사람은 삶의 스케일이 다르다. 자신만 바라보면 ‘우물 안 개구리’가 되고, 다른 사람을 돌아보면 온 우주를 품게 된다.\np158 세상을 보는 눈\n사람을 유익하게 꾸짖고 그의 잘못을 깨우쳐주려고 할 때는 그가 어떤 방향에서 사물을 보는가를 관찰할 필요가 있다. 왜냐하면 그 방향에서 보면 대체로 옳기 때문이다. 그리고 그에게 옳은 점은 인정하되 그것이 어떤 면에서 틀렸는가를 보여줘야 한다. 그는 이에 만족을 느낄 것이다. 왜냐하면 자기가 틀린 것이 아니라 단지 모든 면을 보지 못했다는 것을 알게 되기 때문이다. -파스칼 \u0026lt;팡세\u0026gt; 중에서\n지금이라는 의미\n사람은 이미 흘려보낸 되돌릴 수 없는 시간을 못내 아쉬워하고 연연해하면서 가장 뜻 깊고, 가장 중요한 ‘지금’이라는 시간을 소흘히 한다.\n","date":"2018-07-29T21:31:08+09:00","permalink":"https://cychong47.github.io/post/2018/just-now-dream-love-be-happy/","summary":"\u003cp\u003e꿈을 노트하라\n꿈을 날짜와 함께 적어 놓으면 그것은 목표가 되고\n목표를 잘게 나누면 그것은 계획인 되며,\n그 계획을 실행에 옮기면 꿈을 이루게 되는 것이다.\u003c/p\u003e\n\u003cp\u003ep46\n우리는 무거운 짐을 지고 살아간다. ‘등이 휠 것 같은 삶의 무게여’라는 가사도 있다. 내가 책임져야 할 가족과 도움을 필요로 한 친구들, 나에게 주어진 과중한 업무와 기대. 이 거추장스러운 짐들이 사실은 ‘내 인생의 날개’일 수도 있다.\u003c/p\u003e\n\u003cp\u003ep68\n다른 사람과 한 약속을 지키는 것도 중요하지만\n자기 자신과 한 약속을 지키는 것이 더 중요하다\n세상과 타협하는 것도 위험하지만\n자기 자신과 타협하는 것이 가장 위험하다\u003c/p\u003e","title":"(책) 지금 꿈꾸라, 사랑하라, 행복하라"},{"content":"신호 - 보상 - 반복행동 - 열망\n습관에 숨겨진 \u0026ldquo;열망\u0026quot;을 찾아야 한다. 담배를 습관적으로 피우는 사람도 담배를 피우는 이유가 니코틴 부족이 아니라 잠깐 동안의 여유를 주기 때문일 수 있다. 이때는 이 \u0026ldquo;여유\u0026quot;라는 열망을 담배가 아닌 산책 등으로 바꾸면 습관을 바꿀 수 있다. 이때 그 열망에 대한 \u0026ldquo;신호\u0026quot;와 \u0026ldquo;보상\u0026quot;을 알아야 한다. 그래서 담배가 주는 것과 유사한 담배껌, 팔굽혀 펴기, 스트레칭등의 새로운 반복행동을 선택하면 담배를 끊을 확률이 높아진다.\n믿음\n하느님이 아니더라도, 내 상황이 더 좋아질 거라는 믿음이 필요하다. 습관을 근절할 수는 없어도 바꿀 수는 있다. 또 \u0026lsquo;동일한 신호와 동일한 보상을 유지하면서 새로운 반복 행동을 더하라\u0026rsquo;는 습관 변화의 황금률을 사용하면 습관을 쉽게 바꿀 수 있는 것도 사실이다. 여기에 습관을 항구적으로 바꾸기 위해서는 변할 수 있다는 믿음이 필요하다.\np151\n폴 오닐 알코아를 변화시켜야 한다는 알았지만, 직원들에게 \u0026lsquo;명령\u0026rsquo;할 수는 없었죠. 명령을 받는다고 뇌가 작동하는 건 아니니까요. 그래서 처음에는 한 가지에 집중했습니다. 나쁜 습관 하나를 고칠 수 있다면 그에 따른 변화가 회사 전체에 파급될 것이라고 생각했습니다.\np156\n정부의 다른 분서를 분석할 때마다 정책의 성공과 실패를 구분 짓는 기준이 조직의 습관에 있다는 걸 확인할 수 있었습니다. 가장 효율적으로 운영되는 정부 기관들은 반복 행동의 중요성을 알고 있었습니다. 반면에 효율성이 떨어지는 기관들은 조직의 습관에 대해 고민하기는 커녕 \u0026lsquo;왜 조직원들이 명령을 따르지 않는가\u0026rsquo;라는 사실에만 골머리를 썩이는 사람들이 윗자리를 차지하고 있었습니다.\np157\n폴 오닐은 자신이 알코아의 최고 경영자가 되면 노동조합과 경영진 모두가 인정하는 것을 최우선 순위에 두어야 한다고 생각했다. 모든 조직원을 하나로 묶는 구심점, 또한 조직원들이 일하고 의사소통하는 방법을 바꿔 놓을 수 있는 수단을 그에게 안겨 줄 구심점이 무엇인지 알아내야 했다.\np162\n우리가 습관적으로 운동을 시작하면, 하다못해 일주일에 한 번씩이라도 운동을 시작하게 되면, 운동과 관계없는 삶의 다른 부분들까지 부지불식간에 바뀌기 시작한다. 운동을 시작하면 식습관이 좋아하지고, 생산성이 높아지는 경우가 대표적인 예다. 담배도 덜 피우고, 동료들과 가족들에 대한 인내심도 깊어진다. 신용 카드도 한층 절체해서 사용하고 스트레스도 덜 받는다고 한다. 저녁 식사를 함께하는 습관을 지닌 집안에서 자란 아이들은 숙제하는 능력이 뛰어나고 성적도 좋으며, 감정 조절도 잘하고 자신감이 넘친다. 매일 아침 자신의 손으로 침대를 정리하는 습관은 생산성, 행복 지수, 예산을 통제하는 절제력 등과 상관관계가 있다.\np177\n단번에 너무 많은 변화를 도모한 까닭에 하나도 제대로 해낼 수 없었던 것이다.\np191\n자제력이 강한 청소년이 지능 지수가 높은 청소년보다 학문적 성과가 높을 것이라 예측한다. 또한 꾸준히 성적이 향상될 확률이 높다. 따라서 지적 능력보다 자제력이 학문적 성과에 더 큰 영향을 미친다고 할 수 있다.\np199\n의지력은 무한한 것이 아니다. 다른 일에 의지력을 사용하면 그 만큼 의지력이 약해진다. (쿠기 먹지 말기 시험 + 문제 풀기)\np202\n아이들에게 피아노나 운동을 가르치는 게 무척 중요하다. 그 교육 자체가 아이를 훌륭한 음악가나 다섯 살배기 축구 스타로 만들지는 않는다. 하지만 피아오를 1시간 동안 연습하거나 운동장을 15바퀴 뛰는 방법을 어떻게든 습득하면 자신을 관리하는 힘을 키워 가기 시작한다. 다섯살에 축구공을 10분 동안 쫓아 다닐 수 있는 아이는 6학년이 되면 숙제를 제때 해낼 수 있게 된다.\n의지력. 스타벅스. 하워드 슐츠.\n\u0026ldquo;너는 우리 집안에서 대학에 진학하는 첫 번째 사람이 될 거다.\u0026rdquo; \u0026ldquo;오늘 밤에는 어떻게 공부할 거니? 내일은 무엇을 할 거니? 시험 준비는 다 했니? 그런 독려와 질문 덕분에 나는 습관적으로 목표를 세우게 됐습니다. \u0026ldquo;만약 당신이 누군가에게 성공하는데 필요한 것을 갖고 있다고 말해 주면 당신 말이 맞다는 걸 그 사람이 입증해 보일 거라고 나는 정말 진심으로 믿습니다.\u0026rdquo;\np216\n자제력이 필요한 일을 하라는 요구를 받을 때 그 일을 개인적인 이유로 한다고 생각하면, 다시 말해서 그 일을 즐긴다고 생걱하거나 그 일ㄹ로 누군가를 돕기 때문에 선택받은 사람이란 기분이 들면 그 일이 훨씬 덜 힘듭니다. 반면에 아무런 자율권도 없이 명령에 무조건 따라야 한다면 의지력 근육이 훨씬 빨리 피로해집니다.\np228\n조직 내의 파괴적인 습관은 수많은 산업체와 기업에서도 찾아볼 수 있다. 그런 파괴적인 습관은 문화에 대해 생각하지 않는 리더들의 무관심에서 비롯된다. 그 때문에 파괴적인 습관이 어떤 방해도 받지 않고 독버섯처럼 자라난다. 제도적인 습관이 없는 조직은 없다. 제도적인 습관이 계획적으로 형성된 조직과, 그런 습관이 우연히 형성된 조직이 있을 뿐이다. 적절한 기회를 포착해서 활용할 줄 아는 리더들은 파괴적인 습관까지 바꿔 갈 수 있으며, 때로는 위기가 닥쳤을 때 올바른 습관이 형성되기도 한다.\np230\n대부분의 기업은 신중한 의사 결정에 근거해서 합리적인 선택을 하는 듯하지만 실제로 그렇게 운영되는 기업은 그리 많지 않다. 오히려 기업의 행태는 조직 내에서 오랫동안 지속된 습관에 영향을 받으며, 그것은 직원들의 독자적인 결정에서 흔히 드러나다.\np248\n이들의 공통점은 위기에서 가능성을 포착했다는 것이다. 혼란이 닥쳤을 때야말로 책임을 부여하고 한층 공평한 세력 균형을 조성하는 방향으로 조직의 습관을 바꿀 수 있는 적기이다. 위기에 직면하면 조직의 습관이 유연해지기 때문이다. 때로는 어렴풋이 나타나기 시작한 재앙에 대한 인식을 자극하는 것이 덮어두는 것보다 백번 낫다. 이런 점에서 위기는 무척 유익하다.\np254\n무신경과 나태함에 물든 제도적 습관으로 조직을 위험에 빠뜨릴 수 있는 휴전이 지배하는 기업에서도 이런 변화는 얼마든지 가능하다. 그렇다고 부정적인 습관에 물든 기업이 리더의 명령 하나로 변하지는 않는다. 현명한 경영자라면 위기의 순간을 포착해서 혹은 위기의식을 조장해서라도 \u0026lsquo;뭔가 변해야 한다\u0026rsquo;라는 의식을 심어 주며, 모든 조직원이 일상적으로 행하는 패턴을 점검하도록 유도해야 한다.\np294\nYMCA 새로운 습관(이 경우에는 운동)을 팔기 위해서는 사람들이 이미 알고 좋아하는 것(친구를 사귀기 쉬운 곳으로 가려는 본능)으로 그 습관을 포장해야 한다.\np302\n첫번째 단계에서 사회 운동은 가까운 지인들 간의 우애와 강력한 연대감. 두번째 단계에서 사회 운동은 이웃과 집단을 하나로 묶는 약한 연대감과 공동체의 습관 덕분에 커져간다. 세번째 단계에서 사회 운동의 지도자들이 참여자들에게 새로운 습관을 심어준다. 변화된 정체성과 주인 의식을 잉태하는 새로운 습관의 영향으로 사회 운동은 지속된다.\np330\n어떤 생각이 구체화되어 공동체 넘어까지 확대되기 위해서는 자체의 추진력을 지녀야 한다. 이런 단계에 이르는 가장 확실한 방법은, 구성원들에게 자신의 힘으로 어디까지 갈 수 있는 지 생각해 내도록 유도하는 습관을 심어 주는 것이다.\np366\n\u0026lsquo;거의 성공\u0026rsquo;이 그들에게 한 번 더 배팅 하도록 유도하는 습관을 자극하기 때문이다.\np372\n습관을 바꾸기 위해서는 습관을 바꾸겠다는 결심이 먼저 있어야 한다. 습관의 반복 행동을 유도하는 신호와 보상을 알아내고, 대안을 찾으려는 의식적인 노력이 있어야 한다. 우리에게 통제 수단이 있다는 걸 깨닫고, 그 통제 수단을 의식적으로 활용할 수 있어야 한다. 습관을 바꿀 수 있다고 깨닫는 순간부터 우리는 언제라도 습관을 바꿀 수 있고, 그 책임은 우리 자신에게 있다. 습관이 개조될 수 있다는 걸 깨닫는 순간, 습관의 힘을 파악하기가 한결 쉬워진다. 그때부터 남는 과제는 습관을 바꾸겠다고 결심하고 실천하는 것이다.\np374\n제임스는 결단을 내렸다. 그는 자신과 운명을 통제하고 더 나아질 수 있으며, 무엇이든 바꿀 수 있다는 자유 의지가 있다고 믿으면서 12개월을 보냈다. 그런 믿음이 사실이란 증거는 어디에도 없었다. 현실은 그렇지 않았지만 그는 변화가 가능하다고 믿었다. 내 자유 의지에 따른 첫 행동은 자유 의지를 믿는 것이었다.\n","date":"2018-07-29T21:29:36+09:00","permalink":"https://cychong47.github.io/post/2018/power-of-habit/","summary":"\u003cp\u003e신호 - 보상 - 반복행동 - 열망\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e습관에 숨겨진 \u0026ldquo;열망\u0026quot;을 찾아야 한다. 담배를 습관적으로 피우는 사람도 담배를 피우는 이유가 니코틴 부족이 아니라 잠깐 동안의 여유를 주기 때문일 수 있다. 이때는 이 \u0026ldquo;여유\u0026quot;라는 열망을 담배가 아닌 산책 등으로 바꾸면 습관을 바꿀 수 있다.\n이때 그 열망에 대한 \u0026ldquo;신호\u0026quot;와 \u0026ldquo;보상\u0026quot;을 알아야 한다. 그래서 담배가 주는 것과 유사한 담배껌, 팔굽혀 펴기, 스트레칭등의 새로운 반복행동을 선택하면 담배를 끊을 확률이 높아진다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e믿음\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e하느님이 아니더라도, 내 상황이 더 좋아질 거라는 믿음이 필요하다.\n습관을 근절할 수는 없어도 바꿀 수는 있다. 또 \u0026lsquo;동일한 신호와 동일한 보상을 유지하면서 새로운 반복 행동을 더하라\u0026rsquo;는 습관 변화의 황금률을 사용하면 습관을 쉽게 바꿀 수 있는 것도 사실이다. 여기에 습관을 항구적으로 바꾸기 위해서는 변할 수 있다는 믿음이 필요하다.\u003c/p\u003e","title":"(책) 습관의 힘"},{"content":"p215 우리 사회가 뭔가 단단히 헷갈리고 있다. 정치, 경제, 사회 전반에서 국가의 강력한 통졔를 바란다면 헌법부터 뜯어고쳐야 할 것이다. 일단 자유민주주의의 \u0026lsquo;자유\u0026rsquo;와 \u0026lsquo;민주\u0026rsquo;는 빼야 할 것 같으니까. 대만민국의 국가적 정체성부터 다시 생각해봐야 할 일이다. 공산주의가 싫어 자유주의를 주장하는 거라면 작은 정부를 지향해야 옳다. 그리고 그 작은 정부가 왜 시장에 대한 규제 철폐만 주장하고, 사상, 언론, 표현, 결사 등의 영역에서는 작은 소리만 있어도 사회가 불안정하고 무질서해진다며 통제하려고 하는 지 합리적인 이유를 내 놓아야 한다. 큰 정부에 대한 막연한 환상에서 일단 벗어나, 국가와 시민의 기본적인 관계에 대해서부터 다시 고민해 볼 일이다.\np217 우리에게 부족한 것은 바로 이것이다. 국가와 개인의 관계에 대한 기본적인 관점 말이다. 우리 사회가 여전히, 전방위적으로 큰 정부, 더 나아가 제왕적 대통령을 그리워하는 이유는 \u0026lsquo;국가는 어떤 경우에도 개인의 기본적인 자유와 보편적 인권을 억압해서는 안 된다\u0026rsquo;는 자유민주주의의 원리가 실현되는 사회를 체험해 본 적도 만들어본 적도 없기 때문이다. 그래서 그게 무엇인지 잘 모르기 때문이다. 자유민주주의 국가를 표방한 지 60년이 넘은 지금도 말이다.\np219 그렇다고 가난한 사람들도 걱정만 할 필요는 없다. 정말 정부가 99%의 서민이 아닌 1%의 부자를 위한 정치를 하고 있다고 생각된다면, 정부를 갈아치우면 된다. 그런 상황에서는 다행히 부자보다 서민이 압도적으로 많을 테니 말이다. 다수결이니 모든 사람은 한 표씩 행사할 수 있다. 불만이 있으면 규합하고 집결해 투표하면 된다.\np237 진보주의자들이 좀 더 해야 할 고민은 가령 이런 것들이다. 어떻게 하면 대중을 설득할 수 있을까, 어떻게 하면 그들의 삶이 어려움에 처해 있다는 것을 느끼게 할 수 있을까, 어떻게 하면 내가 바로 당신을 위해 이 말을 하고 있다는 것을 그들이 공감할 수 있을까 하는 것이다. 하지만 이들은 그런 것보다 어떤 게 더 정확한 진보의 관점인가, 어떻게 말하는 게 내가 진보임을 더 확실히 보여줄 수 있을까, 어떻게 해야 내가 아군으로부터 쭉정이 회색분자로 찍히지 않을까를 더 고민하는 것 같다. 이렇게 \u0026lsquo;그들만의 리고\u0026rsquo;에 머물러 있는 그들, 멀리서 그들을 바라보던 시민들의 발길은 이미 멀어진 지 오래다.\np251 우리는 아직도 시스템을 더 좋게 바꿔야 한다고, 바꿀 수 있다고 생각한다. 좌파든 우파든 마찬가지다. 흔들림을 느끼는 것은 바꿀 수 있는 힘이 있다는 것을 믿기 때문이다. 다만 우리는 아직 충분히 경험하지 못했다. 그저 분노를 분출만 하는 게 아니라 제도 안에서 그 분노를 조직화하고, 그 조직을 통해 서로 정정당당하게 대결해 승패를 가르고, 그 결과에 따라 타협하고 더 좋은 시스템을 향해 앞으로 나아가는 합리적 민주주의의 경험을 아직 충분히 갖고 있지 못하다.\n","date":"2018-07-29T21:28:01+09:00","permalink":"https://cychong47.github.io/post/2018/i-want-to-live-in-a-different-korea/","summary":"\u003cp\u003ep215\n우리 사회가 뭔가 단단히 헷갈리고 있다. 정치, 경제, 사회 전반에서 국가의 강력한 통졔를 바란다면 헌법부터 뜯어고쳐야 할 것이다. 일단 자유민주주의의 \u0026lsquo;자유\u0026rsquo;와 \u0026lsquo;민주\u0026rsquo;는 빼야 할 것 같으니까. 대만민국의 국가적 정체성부터 다시 생각해봐야 할 일이다. 공산주의가 싫어 자유주의를 주장하는 거라면 작은 정부를 지향해야 옳다. 그리고 그 작은 정부가 왜 시장에 대한 규제 철폐만 주장하고, 사상, 언론, 표현, 결사 등의 영역에서는 작은 소리만 있어도 사회가 불안정하고 무질서해진다며 통제하려고 하는 지 합리적인 이유를 내 놓아야 한다.\n큰 정부에 대한 막연한 환상에서 일단 벗어나, 국가와 시민의 기본적인 관계에 대해서부터 다시 고민해 볼 일이다.\u003c/p\u003e","title":"(책) 나는 다른 대한민국에서 살고 싶다"},{"content":"p39 자신이 정말 좋아하는 일을 만날 수만 있다면, 인생의 절반은 성공한 것이다. 끔찍이 좋아하는 일이라면 남들이 말려도 다시 덤벼들어야 한다.\n지금 내가 쌓고 있는 스펙이 과연 10년, 20년 후에도 계속 하고 싶은 일에 도움이 될까? 다시 한번 생각해 보라.\np47 부디 이 땅의 청춘들이 자신을 괴롭게 하는 스펙 쌓기에 매달리지 않기를 바란다. 고통의 순간이 가면 즐거움의 시간이 오리라는 보장을 누가 해줄 것인가? 지금 나를 가장 즐겁게 하는 일, 뜨겁게 나를 느낄 수 있는 일에 열정을 쏟아부어야 진정한 퍼플피플로 성장할 수 있다.\np57 후회할까봐 미리 걱정하는 일은 선택 자체를 방해한다. 해본 후회와 안 해본 후회는 근본적으로 다르다. 해본 후회는 후회하는 순간부터 점점 줄어들지만, 해보지 않은 후회는 점점 커질 뿐이다. 그러니 목표가 생기면 되돌아보지 말고 뛰어야 한다. 그러다가 목표에 도달하면 한번 뒤돌아보고 크게 웃으면 된다.\np71 디자인은 신제품 개발의 과정뿐 아니라 생활의 불편함을 해소해 나가는 과정이기도 하다. 우리는 현실을 바꾸기도 하지만 현실에 순응하는 경우가 더 많다. 이는 마치 문화와 같다. 제품의 형태가 바뀌면 그것을 사용하는 우리의 생활도 바뀌지만 한번 변한 것은 한동안 그 속에서 머물 수도 있기 때문이다. 하지만 이 세상의 모든 혁신은 불편함을 참지 못하고 새로운 것을 파고드는 태도에서 출발했음을 잊어서는 안 된다.\np77 누군가 나에게 \u0026ldquo;예전에는 차가운 머리만으로 돈을 벌었는데 이제는 따뜻한 마음 없이는 돈을 벌 수 없다\u0026quot;고 말했다. 이제는 철저히 사용자 중심적인 상품이 아니면 환영받을 수 없는 시대다. 정보는 상품보다 빠르게 유통되고 있으며, 사용자들은 어떤 것이 자신을 위한 최선의 선택인지 훨씬 쉽게 판단할 수 있게 되었다. 자신의 취향이 아닌, 상대를 위한 취향을 담은 따뜻한 마음과 배려, 그것이 혁신의 시작이자 끝이다. 성공의 기회를 잡기 위해서는 그 위력과 가능성에 집중해야 한다.\np100 피카소는 \u0026ldquo;모든 아이들은 아티스트로 태어난다. 다만, 그들을 아티스트로 지키는 것이 문제다\u0026quot;라고 말했다. 따라서 어린이들이 타고난 상상력을 유지하는 일은 교육의 기본이 되어야 한다.\np105 아무리 새로운 아이디어라도 생각에만 머무르는 것은 창의성이 아니다. 창의성은 보고, 듣고, 느낄 수 있는 행동이다. 창의성을 이론적 방식으로 교육하기가 힘든 이유가 바로 여기에 있다. 창의성은 발견하는 것이 아니라 생존경쟁을 통해서 살아남기 위한 노력으로 진화된다. 타고난 재능을 낭비하는 사람도 있고, 끊임없는 노력으로 창의성을 재창조하는 사람도 있다. 결국 승부는 노력의 차이로 만들어진다. 우리가 누군가를 앞선다는 것은 생각에만 그치지 않고 그것의 가치를 확장시킬 만한 실행에 들어갔다는 뜻이다.\np106 간디. \u0026ldquo;이 세상에 있어서는 안되는 6가지\u0026rdquo;. \u0026lsquo;원칙 없는 정치\u0026rsquo;, \u0026lsquo;희생 없는 종교\u0026rsquo;, \u0026lsquo;양심 없는 상술\u0026rsquo;. \u0026lsquo;인성 없는 과학\u0026rsquo;, \u0026lsquo;도덕 없는 쾌락\u0026rsquo;, \u0026lsquo;땀 없는 부\u0026rsquo;\np109 우리가 자신과 가족을 우해 돈을 벌던 직장은 그것이 블루칼라건 화이트칼라건, 서서히 기술이 대체해 나갈 것이다. 간디가 그토록 경계하던 \u0026lsquo;인성 없는 과학\u0026rsquo;의 시대가 오고 있는 것이다.\np112 인간의 창의력은 7세 때가 절정기라는 이야기를 들은 적이 있다. 이 이론이 사실이라면 참 슬픈 이야기다. 창의력으로 세상에 이바지해야 할 성인기에 근접할수록 창의력은 고갈되어 간다는 말이 아닌가? 아이들이 타고난 창의력을 잃어가는 배경에는 교육과 사회적 접촉이 절대적인 영향을 미치니 이 또한 아이러니다.\np116 구글 에릭 슈미트. 2012년 5월 보스턴 대학교 졸업식장에서 \u0026lsquo;하루 한 시간, 컴퓨터 화면을 꺼라\u0026rsquo; \u0026ldquo;기술에는 심장이 없다\u0026quot;는 점을 강조하면서 컴퓨터 화면을 끈 한 시간 동안 눈앞에 있는 친구와 동료, 가족들과 대화하고, 생각하고, 웃으라고 덧붙였다.\np118 마리사 메이어, \u0026ldquo;구글에서는 아이디어가 생기면 우선 시도합니다. 완벽을 찾을 때까지 기다리기보다 남보다 빨리 시작하고, 재해석하고, 발전시킵니다. 시장에서 원하는 모습으로 진화시키는 것입니다. 바로 이것이 구글식 혁신입니다\u0026rdquo;\np120 혁신이란 창조를 행동으로 옮기는 일이다. 행동이 따르지 않는 창조는 아무런 가치가 없다. 멋진 생각이 떠올랐다면 반드시 그것을 지나치지 말고 잡아서 구현할 방법을 찾아야 한다. 이런 습관이야말로 퍼플피플로 진화하기 위한 디딤돌이다. 결과가 어찌 될 것인지를 미리 걱정할 필요는 없다. 중요한 것은 자신이 원하고, 자신이 좋아하는 일이라면 지금 당장 나가서 그것을 실행하는 용기다.\np136 농경시대의 가축을 다루듯 고용인을 당근과 채찍으로 다루는 기업 문화는 이미 사라진 지 오래다. 정보화 시대를 지나 감성의 시대를 살아가는 우리에게 가장 큰 동기 부여는 일을 즐기는 과정에서 얻는 성취감이다.\np144 소통의 기술을 몸에 익히고 미래 사회에서 활발하게 성장해 나가기 위해서는 청소년기부터, 아니 그보다 이른 유,아동기에 가정 내에서부터 생각을 공유하고 의견을 주고받는 습관을 길러야 한다. 체 내의 혈액이 탁해지고 순환이 나빠지면 동맥경화에 걸리는 것처럼 상호 간의 소통이 막히면 우리 사회 역시 필요한 양분과 산소를 제때 공급받지 못하고 병들고 만다. 사람과 사람, 조직과 조직 사이의 혈액을 씽씽 건강하게 돌리기 이해 소통의 기술을 익혀보자.\np146 기업이 발전하기 위해서는 조직도를 피라미드가 아닌 원형으로 만들어야 한다. CEO가 원이 중심에 자리를 잡고 임직원들은 CEO의 주위를 채우며 점차 큰 원을 만든다. 이 원은 시간이 흐를수록 나무의 나이테처럼 확장해 나간다. 이것이 바로 창의적 기업환경이며, 영속적으로 성장할 수 있는 건강한 기업의 구조다.\np152 그렇다고 해서 지금 조직에 \u0026lsquo;메기\u0026rsquo;를 풀어높으면 많은 어려움에 봉착하게 될 것이다. 변화를 받아들여야 한다는 인식은 어느 정도 생겼다 하더라도 오래 묵혀온 구태를 일순간에 벗어던지기는 어렵기 때문이다. 이미 조직 내에서 자리를 잡고 있는 사람들은 타성에 젖어서 기존의 업무방식을 고수하려 할 것이다. 그들에게 변화란 불편하고 귀찮은 일일 뿐이다. 그러니 작은 일 하나라도 바꿔보려고 하면 여러 가지 어려움이 있을 수 밖에 없다.\n조직 내에서 변화를 주도하고 리더가 되어보겠다는 사람은 혼자서 뭔가를 할 때보다 더 큰 도전정신이 필요하다. 그러다 보면 \u0026lsquo;엉뚱한 사람\u0026rsquo;, \u0026lsquo;이상을 쫓는 사람\u0026rsquo;으로 비칠 수도 있다. 하지만 조직을 변화시키고 진보시키는 것은 바로 이런 사람들이다. 시간이 좀 걸리고, 이겨내야 할 난관은 많겠지만 결국은 그들이 리더가 될 것이다.\n남들보다 더 먼 미래를 준비하려면 타성에 젖어 눈앞의 변화만을 쫓는 사람이 아니라, 변화를 주도해 나갈 수 있는 인재가 되어야 한다. 이는 기업은 인재가 능력을 발휘할 수 있는 환경을 제공하고 우리는 절대로 포기하기 않고 새로운 것에 도전하는 협업이 있어야만 가능하다.\np155 매니저는 직위가 만들지만, 리더는 따르는 사람이 만든다. 아무리 높은 자리에 있어도 따르는 사람들이 없다면 리더라고 불릴 수 없다. 반대로 직위가 높지 않아도 따르는 사람들이 많다면 바로 그가 리더다.\np158 대기업도 이제는 구멍가게 운영하듯이 장사해야 한다. 고객 한 사람 한 사람에게 얼마나 성실하고 정확하게 메시지를 전달하느냐가 고객을 확보하는 승부터가 될 것이기 때문이다.\np176 사람도 기업도 끝없는 자기반성과 도전을 통해 변화를 만들지 못하면 도태될 수 밖에 없다. 급격히 변화하는 산업 환경에서 살아남고 나아가 리더가 되기 위해서는 변화를 이끌고 혁신을 주도해야만 한다. 그것이 자신의 일생을 디자인하는 길이고 우리 사회의 일원으로서 부여받은 일익을 담당하는 방법이다.\np179 \u0026lsquo;편안함이 보장된 삶\u0026rsquo;이라는 울타리를 뛰어넘어 한 치 앞도 볼 수 없는 미래에 도전하는 것은 누구에게나 두려운 일이다. 하지만 어떤 새도 알 속에서 하늘을 나는 법을 배울 수는 없다. 성공이란 누군가 알을 깨주길 기다리는 것이 아니라 스스로 알을 깨고 나는 법을 배우는 것이다. 당신은 과연 나는 법을 배우고 있는가?\np220 산업시대의 유물인 당근과 채찍만으론 더 이상 동기부여가 되지 않는다. 직장인들은 이제 유연한 시간개념, 자유롭게 선택할 수 있는 과제, 일하는 즐거움, 성과를 인정해주는 보상을 기대한다. 그러니 사람을 고용할 때는 돈을 위해 당신을 돕는 사람이 아니라 그 일을 사랑하는 사람을 찾아야 한다. 개인도 마찬가지다. 많은 취업 준비생들이 연봉 높은 대기업에 목을 매지만 \u0026lsquo;대기업\u0026rsquo; 자체는 절대 꿈이 될 수 없다. 날마다 즐겁게 출근하고 싶거든 아침에 눈을 떴을 때 가슴 뛰게 하는 일을 찾아야 한다. 그것이 퍼플피플의 기본 자세다.\np223 시간의 지배를 받는 사람은 마감일에 자신의 능력을 맞춘다. 이런 사람은 같은 일이라도 시간을 많이 주면 천천히 한다. 시간을 지배하는 사람은 마감일에 무관하게 자신의 능력대로 일을 마치고 또 다른 일을 찾는다. 누가 더 성공하겠는가?\n제대로 된 시간과 용역의 관리를 위해서라면 주어진 기한에 얾매여서는 안된다. 작업에 필요한 시간과 에너지는 필요한 만큼만 쓰면 된다. 주어진 일을 조금이라도 빠르게 처리하고 남은 시간과 에어지는 또 다른 중요한 일에 사용하는 것이 효율적이다. 퍼플피플은 프리랜서처럼 시간을 자유롭게 사용하는 일에 종사할 가능성이 높기 때문에 시간 관리야말로 가장 중요한 능력이라 할 수 있다. 시간을 지배하는 자가 세상을 얻을 것이다.\n231 정말 하고 싶은 일이 무엇일까를 찾는 과정은 결코 쉽지 않았을 것이다. 하지만 무슨 일이 있어도 꼭 지켜야 할 세 가지 조건을 세우고 나니 자신이 선택해야 할 갈이 보였다고 한다. 첫째, 일하기 전부터 마음이 설레야 한다. 둘째, 일하는 동안에는 반드시 행복해야 한다. 셋째, 일을 마치고 나면 다른 사람에게도 기쁨을 주어야 한다.\n","date":"2018-07-29T13:53:11+09:00","permalink":"https://cychong47.github.io/post/2018/purple-people/","summary":"\u003cp\u003ep39\n자신이 정말 좋아하는 일을 만날 수만 있다면, 인생의 절반은 성공한 것이다. 끔찍이 좋아하는 일이라면 남들이 말려도 다시 덤벼들어야 한다.\u003c/p\u003e\n\u003cp\u003e지금 내가 쌓고 있는 스펙이 과연 10년, 20년 후에도 계속 하고 싶은 일에 도움이 될까? 다시 한번 생각해 보라.\u003c/p\u003e\n\u003cp\u003ep47\n부디 이 땅의 청춘들이 자신을 괴롭게 하는 스펙 쌓기에 매달리지 않기를 바란다.\n고통의 순간이 가면 즐거움의 시간이 오리라는 보장을 누가 해줄 것인가?\n지금 나를 가장 즐겁게 하는 일, 뜨겁게 나를 느낄 수 있는 일에 열정을 쏟아부어야 진정한 퍼플피플로 성장할 수 있다.\u003c/p\u003e","title":"(책) 퍼플피플"},{"content":"8p\n혼 : 가슴 벅차게 하는 비전이 사람을 움직인다. 창 : 끊임없이 \u0026ldquo;왜\u0026quot;라고 물어라, 그러면 열린다. 통 : 만나라, 또 만나라. 들어라 잘 들어라. 16p\nIBM, P\u0026amp;G, Cisco, CEMEX 이 기없들의 공통점은 무엇일까? 그렇다 공룡처럼 몸집이 큰 기업들이다. 공룡인데도 민첩하다. 한가지 공통점은 회사 전체가 보다 큰 가치, 가슴을 울렁이게 하는 원대한 비전을 공유한다는 사실이다. 하버드경영대학원의 로자베스모스 캔터 교수(Rosabeth Moss Kanter) \u0026ldquo;모든 직원이 보다 큰 가치를 공유하게 되면 일선에서 어떤 문제가 부딛쳐도, 혹은 본사로부터 아무리 떨어진 곳에서 일하더라도 자발적으로 문제의 해결을 주도하게 된다\u0026rdquo;\n17p\n손정의 소프트뱅크 회장은 비전의 중요성을 강조하면서 이렇게 말했다. \u0026ldquo;눈앞을 보기 때문에 멀미를 느끼는 것이다. 몇백 킬로미터 앞을 보라. 그곳은 잔잔한 물결처럼 평온하다. 나는 그런 장소에 서서 오늘을 지켜보고 사업을 하고 있기 때문에 전혀 걱정하지 않는다\u0026rdquo;\n18p\n현실에 만족하고 안주하는 순간, 창은 시들고 만다. 다른 사람들이 선택한 쉬운 길을 거부하고, 늘 \u0026ldquo;왜\u0026quot;라고 물으며 새롭고 어려운 길을 갈 때에야 비로소 창이 싹튼다. 창은 손이 진흙으로 더러워지는 것을 두려워하지 않는 실험정신이고, 실패를 찬양하는 도전정신이다.\n33p\n무언가 디지털화할 수 있는 것은 결국 공짜 버전이 나오고 만다. 결국 당신의 숙제는 어떻게 공짜와 경쟁할 수 있느냐는 것이다. 공짜 버전이 제공하지 못하는 것을 제공하라. \u0026lsquo;아이튠즈\u0026rsquo;가 제공한 것은 편리함이었다. 제품을 파는 시대에서 서비스를 파는 시대로 바뀌고 있다.\n43p\n많은 리더들이 \u0026lsquo;어떻게 하면 구성원들에게 동기를 부여해 스스로 일하게 만들 수 있을까?\u0026rsquo; 라는 문제를 고민한다. 돈은 결코 정답이 아니다. 물론 누구나 돈이 필요하긴 하지만, 돈으로 사람을 움직이는 데는 한계가 있는 법이다. 경영자라면 이해득실을 전부 버려도 포기해서는 안 되는 죽어도 지키고 싶은 무엇을 최소한 한 가지는 마음속 깊이 갖고 있어야 한다. 그래야 사람의 마음을 움직일 수 있다. 그것이 바로 철학이고 혼일 것이다. 혼은 \u0026lsquo;사람을 움직이는 힘\u0026rsquo;이다.\n46p\n나는 사람들이 어떻게 그렇게 사는 지 상상을 할 수 없어요. 내가 보기에 정말 미친 것 같거든요. 아무리 높은 연봉이라도 일상생활의 일부로서 즐거움이 없는 삶을 나는 살 수 없습니다. 자본주의 체계란 놀라울 정도로 못돼먹은 겁니다. 80%이상의 사람들이, 생계를 위해 하는 일에서 아무런 즐거움을 엊지 못한다고 합니다. 대부분 사람들의 인생이 그렇습니다. 정말 미쳤어요.\n49p\n케네디 토머스 \u0026lt;열정과 몰입의 방법, Intrinsic Motivation at work\u0026gt; 사람들은 4가지 조건이 충족될 경우 일에서 재미와 열정을 느낀다. 1. 자신이 가치있는 일을 하고 있다고 느낄 때 2. 그 일을 할 때 자신에게 선택권이 있다고 느낄 때 3. 그 일을 할 만한 기술과 지식이 있다고 느낄 때 4. 실제로 진보하고 있다고 느낄 때\n51p\n세계와 경쟁한다는 것이 진정 어떤 의미인지 알고 있는 지\u0026hellip;\n66p\n다른 사람들의 생각에 얽매이지 마십시오. 타인의 소리들이 여러분 내면의 진정한 목소리를 방해하지 못하게 하십시오. 그리고 가장 중요한 것은 여러분의 심장과 직관이 이끄는 대로 살아갈 수 있는 용기를 가지는 것입니다. 이미 여러분의 심장과 직관은 당신이 진짜로 원하는 것이 무엇인지를 알고 있습니다. 나머지는 다 부차적인 것입니다.\n70p\n나는 만약 어떤 일에서 재미와 즐거움을 더 이상 찾을 수 없다면 드디어 다른 일을 찾아야 할 때가 된 것이라고 믿는다. 행복하지 않게 시간을 보내기에는 인생이 너무 짧다. 아침에 일어나면서부터 스트레스를 견뎌야 하고, 비참한 기분으로 일터로 나간다면 삶에 대한 올바른 태도가 아니다.\n72p\n좋아하지 않는 직장이지만 그래도 계쏙 남아 일해야만 하는 사람에게는. 인생은 긍정적으로 바라보는 사람에게 문을 열어준다. 일을 하면서 만나게 되는 사람들과 함께 즐거움을 찾아야 한다.\n73p\n\u0026lsquo;나는 골치 아프고 힘든 일이 잔쯕 있을 때는 그 일이 해결되었을 때의 기쁨을 생각하면서 출근합니다\u0026rdquo; 개인은 일의 주인이 되어야 한다. 그래야 진정한 성공을 맛볼 수 있다. 기업은 조직원을 일의 주인으로 만들어야 한다. 그것이 조직원과 기업이 함께 성장하는 길이다.\n84p\n돈으로는 사람을 움직일 수 없습니다. 사람을 움직이려면 마음 깊은 곳에서 타오르는 동기를 부여해야 합니다. 이를 위해서는 이윤을 뛰어넘는 숭고한 경영철학과 경영자의 인격이 필요합니다.\n90p\n중요한 사실은 내발적 동기가 외발적 동기보다 더 지속성이 있고, 더 좋은 결과를 가져오며, 더 큰 심리적 안정을 가져온다는 점이다. 내발적 동기의 경우, 활동에 집중하는 것 자체가 보상이 되므로 언제까지나 높은 동기가 부여될 수 있고, 활동이 계쏙 유지돼 자연스럽게 좋은 성과를 내게 된다. 92p \u0026lsquo;당근과 채찍\u0026rsquo; 전략으로 상징되는 전통적인 기업의 보상 시스템은 종업원이 스스로 일하려는 동기, 즉 내발적 동기를 오히려 꺾을 수 있다는 점이다.\n95p\n천이유천 이란 중국 속담을 새기기 다닌다고 했다. 하늘 위에 또 하늘이 있다는 뜻이다. \u0026ldquo;제 성격에는 자만의 DNA가 흐르고 있습니다. 조금만 방심해도 우쭐해지기 쉬운 성격이죠. 그래서 늘 자만하지 않도록 스스로를 일깨우고 조심하고 있습니다\u0026rdquo;\n96p\n첫째가 중국의 개혁 개방 둘째가 높은 목표를 세우고 그것을 실현하기 위해 늘 노력한 갓 셋째가 언제나 공부하는 것\n96p\n간부는 큰 엔진이고, 그 밖의 모든 직원들은 큰 엔진과 함께 돌아가는 작은 엔진이 되어야 합니다. 밑의 직원들이 엔진에 따라 움직이는 기어가 되어서는 절대로 안됩니다. 어떻게 하면 일을 더 잘할 수 있을 지 스스로 생각하게 만들어야 합니다. 이렇게 해야 원동력이 더 커지게 됩니다.\n99p\n마케팅 1.0 소비자 머리에 호소 2.0 감성에 호소 3.0 영혼에 호소. 환경에 신경 쓰고 사회에 좋은 일도 하는 회사라면 내게 특별히 무엇을 주지 않더라도 그냥 좋다.\n104p\n혼은 \u0026lsquo;사람을 움직이는 힘\u0026rsquo;이며 \u0026lsquo;내가 여기에 있어야 하는 이유\u0026rsquo;이고 \u0026lsquo;개인을 뛰어넘는 대의\u0026rsquo;이다. 혼은 우리를 움직이게 하고, 버티게 하고, 극복하게 하는 근본적인 힘.\n119p\n사람들의 태도와 정신을 바꾸는 것이 중요합니다. 처음에는 불편해도 스스로에게 강제하고 단계적으로 반복 훈련을 하면 습관이 됩니다. 습관은 들이기는 어렵지만 나중에는 자연스럽고 편안해지죠. 개인뿐 아니라 조직이나 기관도 이런 식으로 변해야 합니다.\n127p\n끊임없이 노력해야 하고 아주 작은 디테일까지 세심한 주의를 기울여야 하며, 리스크를 감수하더라도 실행에 옮겨야 한다.\n129p\n다니엘 핑크 우리가 왜 새로워지고 창조적이지 않으면 안되는 지. 1. 아시아 - 아시아의 신흥시장 인력이 급성장한 경우, 루틴한 업무는 일상재가 될 것이다. 남들이 하지 않는 창조적인 일을 하지 않으면 안 된다. 2. 자동화 - 기계와 소프트웨어가 인간의 노동과 두뇌를 대신해가고 있다. 컴퓨터가 대체할 수 없는 인간의 우뇌만이 할 수 있는 창조적인 일을 하지 않으면 안된다. 3. 풍요 - 생활이 풍족해지면서 사람들의 새로운 욕구를 충족시키는 창의성 있는 인재가 날로 중요해진다. 당장은 사람들이 필요하다고 느끼지 못하지만, 사람들의 잠재된 욕구를 충족시킬 수 있는 상품을 개발하는 역량이 중요하다.\n136p\n다니엘 핑크 이제 우리에게는 펙트들이 너무나 넘쳐난다. 그런 팩트들을 스토리로, 문맥으로 엮어내지 못하면 팩트는 증발된다.\n139p\n마에다 총장은 권위적 리더쉽고, 창조적 리더쉽을 제시 권위적 리더쉽 - 채찍 중시, 위계질서 중시, \u0026lsquo;예스 혹은 노\u0026rsquo;의 명쾌함 중시, 옳은 판단인지 따지기, 장군처럼 생각하기, 실수 회피, 제한된 피드백만의 허용 창조적 리더쉽 - 당근 중시, 네트워크 중시, \u0026lsquo;아마도\u0026rsquo;와 같은 모호함 인정, 현실적 판단인지 따지기, 예술가처럼 생각하기, 실수로부터의 학습 환영, 무제한적 비판 허용\n144p\n이처럼 창을 얻기 위해서는 마음이 열려 있어야 한다. 우리는 어떤 결정을 내리면 자신의 생각이 틀릴 수도 있다는 생각에에 대해 개방적으로 되기 어렵다. 자신의 결정의 근거를 부정하는 모든 사실에 대해 마음을 닫기 쉽다. 그러나 창을 얻기 위해서는 다른 사람의 충고와 비판에 열려 있어야 한다.\n145p\n소설가 베르나르 베르베르 \u0026lsquo;풍부하고 다양한 호기심은 타고 나는 것이지만, 그 이후에는 끊임없이 정보와 지식을 습득하는 노력이 필요합니다. 나는 날마다 배웁니다. 뭔가 새로운 것을 하지 않은 날에는 \u0026lsquo;시간을 잃어버렸다\u0026rsquo;고 여깁니다.\n161p\n아마존 베조스의 선택 기준 Regret minimization framework 자신이 여든 살이 되었을 때를 가정해서 인생을 뒤돌아 보았을 때 후회할 일을 가장 줄이는 방법을 생각.\n164p\n큰 생각을 하려면 자신을 색다른 경험에 수없이 노출시켜보라.\n164p\n무용가 트와일라 타프는 사전에서 단어를 찾을 때, 그 단어 바로 앞, 뒷 단어도 함께 읽는 다고. 다음 번에 좋은 아이디어가 어디에서 올지 모르기 때문에. 한 번에 성격이 다른 여러 작품을 동시에 하고, 한 작품이 끝나면 그와 전혀 성격이 다른 작품에 도전하는 것도 창조성을 유지하는 그녀만의 노하우\n165p\n우뇌형 인간의 5가지 조건. 다니엘 핑크 1. 디자인이란 언어를 익히라. 2. 스토리를 만들라 3. 큰 그림으로 생각하라 4. 공감하라 5. Play하라\n168p\n미국 속담 에 \u0026lsquo;평소 알고 있던 악마가 낫다\u0026rsquo;. 그만큼 사람들은 변화를 싫어하는 보수적 본성이 있다.\n174p\n지식 e 시즌 4. 경로 의존성(Path Dep endency) 한 번 일정한 경로에 의존하기 시작하면 나중에 그 경로가 비효율적이라는 것을 알고도 여전히 그 경로를 벗어나지 못한다는 사고의 관습\n190p\n실패한 사람이 무엇을 해야 할 지 생각하지 않으면, 실패를 반복할 수 밖에 없다. 실패의 원인과 과정을 깊이 있게 생각하지 않으면, 실패는 실패의 어머니일 뿐이다. 실패는 도전과 발전을 위해 그 원잉늘 분석하고 거기서 창조적인 아이디어를 도출해낼 때, 비로소 가치가 있는 것이다. 부주의아 오판으로 똑같은 실수를 연발하는 것은 절대 용서받을 수 없는 실패다.\n195p\n창은 혼을 노력과 근성으로 치환하는 과정이며 매일 새로워지는 일이고 익숙한 것과의 싸움이다. 어느 날 갑자기 찾아오는 것이 아니라 노력하고 도전하는 하루하루가 쌓여야 비로소 발현되는 것이 창이다.\n239p\n호리바 마사오 \u0026lt;남의 말을 듣기 마라\u0026gt; 나와 같이 일하는 사람은 나와 다른 생각을 갖고 있어야만 존재 가치가 있는 법이다. 나와 똑같은 생각을 가지고 있다면 차라리 그 월급을 내게 달라\n244p\n조직 내의 진정한 소통은 위에서 아래로 흐르는 탑다운의 일방적 방식으로는 결코 이룰 수 없다. 진정한 소통은 아래에서 위로, 오른쪽에서 왼쪽으로 360도 어느 쪽에서든 자유롭게 흐르는 것이다. 톱다운 커뮤니케이션은 조직 전체를 톱, 한 사람의 능력 안에 머물게 한다. 그러나 360도 커뮤니케이션은 구성원 모두가 아이디어와 능력을 발휘할 수 있게 함으로써 조직 역량에 한계가 없어진다.\n245p\n가와시마 기요시 혼다 전 사장 최근 2~3년간 내가 말한 사항들이 사내에서 8할이나 통과됐다. 6할이 넘으면 원맨 경영의 폐해가 나타나는 위험신호라고 하는데, 그렇다면 지금 혼다가 위험하다는 얘기가 아닌가?\n246p\n지난 20년간 조사한 수백 명의 관리자 중 70%는 보스의 일이 실패하리라는 것을 알면서도 피드백이나 충고를 하지 않은 것으로 나탔다. 직원이 경영자에게 문제를 제기할 정도면 가볍게 하는 말이 결코 아닐 것이기 때문이다. 물이 흐르지 못하면 고여서 썩기 마련이듯, 소통이 원할하지 못한 조직은 결국 문제가 발생하기 마련이다. 이것이 경영자가 직원들이 자유롭게 말할 수 있는 환경과 분위기를 조성해야 하는 이유다. 직원 또한 소신껏 자신의 의견을 개진해야 하는 이유다.\n252p\n포스코 정준양 회장 리더는 VIP가 되어야 한다. 리더라면 Vision을 제시할 수 있어야 하고, Insight 통찰력과 철학 Philosophy를 갖고 있어야 한다고 주장했다.\n254p\n1977년부터 1997년 사이에 태어난 N세대의 특징은 - 선택의 자유를 최고의 가치로 여기고 - 협업에 익숙하며 - 사실 여부를 늘 검증하려고 하고 - 재미와 스피드를 추구한다.\n258p\n사일로(Silo) 바이오기업 몬산토 휴 그랜트 사장 무엇보다 연구 인력과 경영 관리 파트의 직원들이 함께 모여 일을 하기 시작했어요. 많은 기술 중심 회사들은 연구 인력과 경영 인력이 따로 근무하고, 별로 교류하지 않습니다. 그리고 위계 서열이 뚜렷하죠(경영 관리 인력이 주도권을 잡는다는 의미)\n269p\nSAS 좋은 복지 프로그램을 제공하면 직원들 스스로 회사를 다니는 일에 가치를 느끼고 만족해가기 때문이에요. 회사가 직원을 만족시키면 직원들은 좋은 제품을 개발해 외부 소비자를 만족시킨다. 고객을 행복하게 하려면 고객과 만나는 쌔스의 직원들이 행복해야 합니다.\n271p\n직원이 행복해야 고객이 행복할 수 있다는 점만은 어떤 조직에나 통용된다는 점이다. 직원이 행복하지 않은데, 어떻게 동기를 부여받을 거이며, 어떻게 스스로 열심히 일해 좋은 제품과 서비스를 창출할 것인가? 조직의 통은 조직원들의 만족과 행복을 끌어내고, 이것은 다시 고객의 만족과 행복으로 이어진다. 만족과 행복은 끊임없이 확대재생산되는 것이다.\n273p\n그렇다면 어떻게 해야 조직원이 위에서 내려오는 과업에 대해서도 마치 내발적 동기에 의해 하는 일처럼 스스로 신이 나서 열심히 하게 만들 수 있을가? 이와 관련해 에드워드 데시 교수를 비롯한 자기 결정성 이론 심리학자들이 개발한 개념이 내재화 Internalization이다. 즉 외부 요인에 의해 자극되거나 통제되는 행동의 경우에도 조직이 인간의 3가지 기본적 욕구를 충복만이 환경을 구축해 지원할 경우, 사람들은 일을 스스로의 것으로 내재화하고 통홥하게 된다는 것이다.\n275p\n데시 교수는 일견 재미없는 일일지라도 그것을 왜 해야 하는 지 근본적인 이유를 제시하고, 그 일에 대한 상대방의 관점과 느낌을 존중해주며, 스스로 선택하는 경험을 많이 할 수 있게 하고, 일에 대한 압력을 최소화하라고 조언한다.\n277p\n20세기 초반 이후로 관리자들의 임무란 \u0026lsquo;어떻게 하면 웬만한 실력의 기술자들을 데려와서 같은 일을 빠르고 정확히 반복하게 만들까\u0026quot;였죠. 기업의 경영 구조 자체가 혁신을 생상하도록 설계된 것이 아니라 같은 일을 반복하도록 설계돼 있기 때문입니다.\n278p\n리더의 역할은 직원 저마다가 가진 재능과 지식을 효율적으로 한데 모으는 것이지, 그들이 무작정 일을 더 열심히 하도록 만드는 게 아닙니다. 똑똑한 사람들이 일을 많이 하도록 하는 게 결코 중요한 문제가 아닌 거죠.\n279p\n피터 센게 교수 내가 보기에 아무도 도발하지 않는 조직은 가장 위험한 조직입니다. 깊은 곳에 문제점이 있는데도 자칫 계속 문제를 썩힐 수 도 있으니까요. 건강한 조직은 서로 속을 터놓고 애기하기 때문에 문제를 실시간으로 파악하고 해결할 수 있습니다. \u0026lsquo;내가 이런 말을 해서 일자리를 잃으면 어떻게 하지?\u0026rsquo;, \u0026lsquo;이 얘기를 했는데 누군가 나를 비웃으면?\u0026rsquo; 이라는 걱정들로 가득 찬 조직은 희망이 없는 조직이죠. 겉으로는 통제가 잘 되는 것처럼 보이기 때문에 CEO를 흐뭇하게 만들 수도 있지만, 수면 아래엔 문제점들이 그득할 것입니다. 센게 교수에 따르면 두려움으로 경영되는 조직은 방어직 사고에 의해 억압된 조직이라고 표현할 수 있다. 이런 조직 속에선 모든 사람들이 항상 다른 사람에게 \u0026lsquo;내가 그 문제에 대한 답을 갖고 있다\u0026rsquo;는 확신을 주기 위해 노력한다. 그렇기 때문에 어떤 상황에서도 자심감 찬 모습만을 보이기 위해 분투한다. 뿐만 아니라 자기 자신이나 다른 사람을 \u0026lsquo;부끄럽게 만드는\u0026rsquo; 이슈들을 제기하는 것을 매우 꺼리게 된다. 중요한 이슈이긴 하지만 어렵거나 당황스러운 주제에 대해 얘기하는 것을 피하는 것이다. 이런 폐해를 없애기 위해서는 모든 구성원이 비전을 공유하고, 같이 머리를 맞대=고, 함께 살아남기 위해 노력한다는 정신을 심어야 한다는 것이 그의 주장이다.\n282p\nGore사 상사나 부하가 없는 완전한 수평 조직이어서 모두가 동료(Associate)로 불리운다. 빌 고어는 더글러스 맥그리거 Douglas McGregors의 Y이론에 대한 믿음을 바탕으로 독특한 조직을 만들었다. Y이론이란 성선설로 인간은 오락이나 휴식뿐 아니라 자존과 헌신에 대해서도 본성적으로 욕구가 있으므로, 자발적으로 일할 마음을 갖게 하면 능력의 극대화가 가능하다는 분석이다.\n288p\n리더의 책무는 매일 회사를 빠져나가는 그 90%의 중요 자산이 내일 다시 회사로 돌아와서 재미있게 일하도록 하는 것이다.\n","date":"2018-07-29T13:47:57+09:00","permalink":"https://cychong47.github.io/post/2018/hon-chang-tong/","summary":"\u003cp\u003e8p\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cul\u003e\n\u003cli\u003e혼 : 가슴 벅차게 하는 비전이 사람을 움직인다.\u003c/li\u003e\n\u003cli\u003e창 : 끊임없이 \u0026ldquo;왜\u0026quot;라고 물어라, 그러면 열린다.\u003c/li\u003e\n\u003cli\u003e통 : 만나라, 또 만나라. 들어라 잘 들어라.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e16p\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIBM, P\u0026amp;G, Cisco, CEMEX 이 기없들의 공통점은 무엇일까? 그렇다 공룡처럼 몸집이 큰 기업들이다. 공룡인데도 민첩하다. 한가지 공통점은 회사 전체가 보다 큰 가치, 가슴을 울렁이게 하는 원대한 비전을 공유한다는 사실이다.  하버드경영대학원의 로자베스모스 캔터 교수(Rosabeth Moss Kanter) \u0026ldquo;모든 직원이 보다 큰 가치를 공유하게 되면 일선에서 어떤 문제가 부딛쳐도, 혹은 본사로부터 아무리 떨어진 곳에서 일하더라도 자발적으로 문제의 해결을 주도하게 된다\u0026rdquo;\u003c/p\u003e","title":"(책) 혼창통"},{"content":"p52 \u0026ldquo;당신의 삶입니다. 당신의 사람을 이야기하라는데 가족을 위해 사는 게 전부라. 생활비만 제대로 해결된다면 가족에게 당신은 없어도 되는 존재라는 말이군요. 그런 현금 지급기와 같은 삶을 원한다면 더 이야기하는 것도 \u0026lsquo;시간낭비\u0026rsquo;군요\u0026rdquo;\np89 파울로 코엘료의 \u0026lt;순례자\u0026gt;에서는 꿈들을 죽일 때 나타나는 첫 번째 징후가 \u0026lsquo;시간이 없다\u0026rsquo;라고 말하는 것이라고 했습니다.\np97 가장 먼저 해야 할 일은 진지하게 고민하며 한발 내딛는 일입니다. 어디로든 상관없습니다. 자신을 둘러싸고 있는 경계를 벗어나기만 하면 새로운 사람들과 새로운 경험이 당신을 기다리고 있을 겁니다. 그렇게 보내는 시간, 시간을 쪼개는 게 아니라, 스스로를 탐구하고 찾기 위해 가치있게 쓰는 시간.\np116 인간은 자신의 삶에 만족하지 못할수록 자꾸 \u0026lsquo;적\u0026rsquo;을 찾게 됩니다. 가령, 회사에서 같이 일을 할 \u0026lsquo;동료\u0026rsquo;를 찾아야 하는데 스트레스를 주는 \u0026lsquo;적\u0026rsquo;을 발견하게 되는 것과 같죠. 적을 발견한 후로부터는 그 적에 대해 생각하는 데 시간을 낭비하게 됩니다. 적에게 나의 시간을 낭비하는 것은 너무 아까운 일입니다.\np136 빅터 프랑클 \u0026lt;죽음의 수용소에서\u0026gt; 세상이 내 모든 것을 빼앗고 나에게 최악의 상황을 주었더라도 나에게는 절대 빼앗길 수 없는 한 가지가 있음을 기억해야 한다. 그것은 바로 그 상황을 어떻게 받아들일 것인지에 대한 내 선택권이다.\np143 회사와 가정을 위해서는 일했지만, 자신을 위해서는 아무것도 하지 않은 하루죠. 자신을 위해서 아무것도 하지 않았다면 그 하루는 쉬어도 되는 하루가 아닙니다. 아직 할 일이 남은 하루죠. 지금 당장 3시간이 주어졌을 때 무슨 일을 할 것인가. 이것에 대한 고밍는 그동안 나만의 시간에 대해 고민하지 않았기 때문에 생기는 것 입니다.\np173 시간을 돈으로 계산하는 일은 인생에 매우 중요합니다. 지나면 다시 돌아오지 않을 시간을 정작 중요한 일이 아닌, 불필요한 일에 쏟고 있지는 않은지 알아보기 위함입니다. 가령 필요하지도 않은 물건에 들어가는 돈을 줄인다면 그만큼 시간을 버는 것과 같죠. 시간을 만들라는 건 쓸데없는 데 들어가는 시간과 비용을 줄여서 시간을 확보하라는 말입니다. 필요 없는 물건을 사서 카드 값을 갚느라 괜히 야근하지 말고.\np176 첫째, 스스로 미칠 수 있꼬, 둘째, 다른 사람보다 월등히 말할 자신이 있으면 됩니다. 셋째, 그것을 하면서 돈을 벌지 못하더라도 다른 사람들과 비교하며 부끄럽지 않을 수 있으면 된 거죠.\np182 중요한 건 \u0026lsquo;종료 시점\u0026rsquo;을 정하는 일입니다. 당신의 꿈에는 기한이 있어야 합니다. 그렇지 않으면 막연하게 늘어질 뿐입니다.\n\u0026lsquo;언젠가\u0026rsquo;는 절대로 찾아오지 않습니다. 우리에게 주어지는 건 항상 또 다른 오늘이죠. 과거는 우리의 힘으로 바꿀 수 없습니다. 미래는 그 모습을 상상하는 것조차 어려운 일이고요. 우리가 우리를 평가하고 이해할 수 있는 시간은 바로 오늘뿐입니다.\n","date":"2018-07-29T13:44:37+09:00","permalink":"https://cychong47.github.io/post/2018/your-time/","summary":"\u003cp\u003ep52\n\u0026ldquo;당신의 삶입니다. 당신의 사람을 이야기하라는데 가족을 위해 사는 게 전부라. 생활비만 제대로 해결된다면 가족에게 당신은 없어도 되는 존재라는 말이군요. 그런 현금 지급기와 같은 삶을 원한다면 더 이야기하는 것도 \u0026lsquo;시간낭비\u0026rsquo;군요\u0026rdquo;\u003c/p\u003e\n\u003cp\u003ep89\n파울로 코엘료의 \u0026lt;순례자\u0026gt;에서는 꿈들을 죽일 때 나타나는 첫 번째 징후가 \u0026lsquo;시간이 없다\u0026rsquo;라고 말하는 것이라고 했습니다.\u003c/p\u003e\n\u003cp\u003ep97\n가장 먼저 해야 할 일은 진지하게 고민하며 한발 내딛는 일입니다. 어디로든 상관없습니다. 자신을 둘러싸고 있는 경계를 벗어나기만 하면 새로운 사람들과 새로운 경험이 당신을 기다리고 있을 겁니다. 그렇게 보내는 시간, 시간을 쪼개는 게 아니라, 스스로를 탐구하고 찾기 위해 가치있게 쓰는 시간.\u003c/p\u003e","title":"(책) 당신의 시간"},{"content":"p32 너무 효율적인 사람은 너무나도 바쁘기 때문에, 무언가 새로운 일이 일어나는 경우 그 일에 즉시 대응할 수가 없게 된다.\np37 사실 효율성을 높이는 일은 매우 어렵다. 효율성 개선에는 엄청난 노력과 진정한 독창성이 필요하기 때문이다. 조직은 항상 스스로를 더욱 효율적으로 만들기 위해 끊임없이 노력해 왔기 때문에 조직을 더 효율적으로 만들기란 결코 쉬운 일이 아니다.\np38 짧은 시간안에 조직의 개선을 보여주어야 하는 효율성 전문가에게 유욯나 지름길은 무엇일까? 가장 자주 채택되는 지름길은 바로 각각의 직원을 모두 완전한 대체물이라고 가정하는 것이다.\np57 영리 조직에서 일하는 사람들은 급여를 받기 때문에 어느 정도의 자율성을 기꺼이 포기하고 어느 정도의 지시를 받아들인다는 점이다. 그렇다고 해서 자율성을 완전히 포기하는 것은 아니다. 사람들이 자율성을 완전히 포기할 만큼 충분한 급여를 제공할 수는 없다.\np59 조직도의 계층 구조는 권위의 경로이고, 의사 소통에 필요한 모든 정보를 유통하기에는 너무 좁다. 소통이 오직 조직도의 선을 통해서만 일어난다면 관리자들이 모든 통제권을 가지려 한다는 명백한 증거인 셈이다.\np60 여러분에게 주어진 지위만으로 여러분이 선택한 방법을 강요할 수 있을 것이라고 결코 기대하지 말아야 한다. 신뢰는 여러분이 자주 간섭할수록 금세 바닥나 버리고 만다.\np65 만약 변화가 변화 전문가의 지도에 의해서만 이루어질 수 있다면, 그 조직은 죽음이 코 앞에 와있다고 볼 수 있다. 변화할 수 있는 능력은 유기적으로 죽음이 코앞에 와있다고 볼 수 있다. 변화할 수 있는 능력은 유기적으로 조직의 일부가 되어야만 한다. 변화는 언제 어디서든 진행되어야 하는 것이다. 변화는 모든 사람의 일이 되어야 한다.\np66 직원들이 자신의 자율성을 포기하게 되면 결국 조직이 피해를 입게 된다는 사실이다.\n그 이유는 지식근로자의 업무에 투입되는 핵심 역량 중 하나가 도메인 지식이기 때문이다. (1) 일련의 기술들과 더불어 (2) 해당 업무 분야에 어떠한 기술들을 사용해야 하는지에 대한 명쾌한 지식을 갖고 있다. 기술만으로는 충분하지 못하다. 도메인 지식 역시 중요하다. 도메인 지식이 중요하면 할수록 그 사람은 더욱 대체하기 어려워진다. 그 직원이 기업을 떠나게 되면 그 자산 역시 사라진다.\np75 R\u0026amp;D 지출은 투자이기 때문이다. 그것을 줄이는 것은 미래의 이익을 올해로 옮겨오는 것과 같다. 그렇게 함으로써 비록 올해의 이익을 높일 수는 있겠지만 내년과 다음 여러 해의 이익이 감소하게 될 것이다.\np82 지식근로자들에 대한 인센티비는 그들을 어떻게 관리해야 할지 모른다는 슬픈 고백일 뿐이다.\n직원들에게 압박감을 주기 위해 행하는 대부분의 일들은 어떤 형태로든 그들의 행동을 의미 있는 방향으로 변화시키지 못한다.\np84 압력을 가하면 성과가 향상되며, 최고의 성과는 오직 최고의 압력을 가할 때에만 가능하다는 기업의 미신이 점점 확산되어 가고 있다.\np87 시간 압력을 받는다고 더 빠르게 생각할 수 있는 건 아니다. - 팀 리스터\np88 건강한 지식 조직에서 일하는 사람들은 실제로 많은 시간을 낭비하지 않는다. 왜냐하면 낭비되는 시간이 관리자에게 모욕적인 것이듯이, 지식근로자 스스로에게도 모욕이기 때문이다.\np91 압박감이 생산성과 완전히 무관한 것은 아니다. 하지만 그것은 분명히 우리 대부분이 이루려고 애쓰는 최종적인 목표는 아니다.\np92 공격적인 일정이라는 말을 마치 프로젝트의 실패를 부르는 일종의 주문이라고 생각한다.\np94 매우 공격적인(사실은 불가능한) 납기를 위해 노력하는 것이 비록 실제로 그 일자를 달성하지는 못하더라도 크게 손해 볼 것이 없다는 생각이 깔려있다. 예를 들어 프로젝트를 12개월 내에 완료하도록 결정해 놓고서 실제로는 18개월이 걸렸더라도 스스로에게 이렇게 말하면서 위안을 삼는다. \u0026ldquo;공격적인 일정 덕분에 다행히도 빨리 끝낸 거야. 그런 일정이 아니었으면 어리석게도 여전히 일을 하고 있을지도 몰라\u0026rdquo;\n많은 프로젝트 관리자들이 신참 관리자 시절에 최대한 불가능한 일정을 수립하고 분투하는 것이 결코 손해 볼 게 없는 행동이라고 교육받는다.\np96 관리자 대부분은 잘못된 일정 같은 건 존재하지 않는다고 믿기 때문에, 납기일을 못 맞추는 이유가 오직 직원들이 일을 제대로 못한 탓이라고 생각한다.\np97 잘못된 일정은 계획을 수립한 사람의 탓이지 일을 수행하는 사람의 탓이 아니다.\np100 스프린팅. 비정기적인 단기간의 초과근무. 모두가 함께 어떤 일을 하고 그 결과로 소중한 성공을 공유할 때 조직의 문화에 무언가 심오한 변화가 생긴다. 그렇게 만들어진 에너지는 격렬했던 주말이 지나간 후에도 오랫동안 지속된다.\n모든 사람을 하나로 묶을 수 있는 지도나로서의 타고난 재능을 갖추고 있다. 엄청난 신뢰가 축적되어 있어야 한다. 특별한 초과근무를 요구 받는 것이 정말 예외적인 상황이며 그러한 노력이 의미 없이 소진되거나 정기적으로 발생하지 않을 것이라는 믿음이 있어야 한다.\np103 장기간의 초과근무는 생산성을 감소시키는 탁월한 기술이다.\np107 과도한 일중독과 그에 따른 피로가 결합됨으로써 개인의 정신 역량이 감소된다는 점이다. 마약 사고이 질이 중요하다면 초과근무는 훌륭한 처방이 아니다.\n사람들은 동료가 밤늦게까지 계속 일할 것임을 알기 때문에 \u0026lsquo;정상 근무시간\u0026rsquo;에 난잡하게 맘 내키는 대로 동료들을 방해한다.\np122 우리는 지금까지 오버헤드의 성격을 가진 사람들을 줄이는 데에 너무 집중해왔기 때문에, 비싼 급여를 받는 많은 지식근로자와 관리자들이 업무 시간 중 4분의 1을 단순 작업에 낭비하는 조직을 만들고 말았다. 이것이 정말 경제적인 것일까?\np133 관리는 어렵다. 해야 할 일이 너무 많기 때문이 아니라 관리 기술이라는 게 본질적으로 숙련되기 어렵기 때문이다.\np139 분노한 관리자는 패배자다. 사람들을 어떻게 이끌어야 할 지 전혀 모르는 채 스스로 감당할 수 없는 일을 하고 있는 불행한 무능력자다.\np159 테일러 주의. 사람이 교환 가능한 부품이라는 관점을 일찍이 제시하였다. 테일러주의는 지식근로는 적합하지 않다.\np163 자동화가 새롭게 도입되면 전체 작업에서 사람이 할 일은 즐어들게 되지만, 남은 일은 더 힘든 일 뿐이다. 자동화는 업무를 더욱 어렵게 만들지 쉽게 만드는 게 아니라는 점이 바로 자동화의 역설이다.\np165 프로세스 소유권은 업무를 하는 사람의 손에 쥐어주어야 한다.\np166 실패에 대응하는 논리로써 표준 프로세스는 일종의 무기가 되는 것이다. 실패에 대해 더 많이 걱정할수록 더 강력한 무기를 지니려고 노력하게 된다. 그러나 그러한 무기들은 언제나 기동성을 감소시킨다.\np174 품질 프로그램은 품질의 손쉽고 실행 가능한 측면에만 집중하고 그 외의 나머지 내용들은 무시한다. 품질 프로그램은 실제 품질에서 대체로 부수적인 부분에만 집중하고 진짜 중요한 문제를 외면한다. 물론 아무것도 하지 않는 것보다야 무언가 하는 게 좋지 않냐고 생각할 수도 있다.\np179 품질 개선을 위해 가장 중요한 활동은 중요하지 않는 제품이나 부분을 과감히 버리는 것이다.\np182 스트레스가 과도한 조직은 효율을 강조하느라 바쁜 나머지, 효과적인 조직이 되는 법을 잊어버리게 된다. 어떤 일을 최소한의 낭비로 해내는 것을 효율적(efficient)이라고 하며, 그 일을 제대로 해내는 것을 효과적(effective)이라고 한다. 효과적이지만 효율적이지 못한 조직은 (비록 빠르지는 않을지라도) 목표를 향해 착실하게 나아간다. 목표에 대해 얼마만크의 진도를 보이는가는 효율의 문제이다. 효율적이지만 효과적이지 못한 조직은 엉뚱한 방향으로 나아간다.\np190 MBO는 상태가 계쏙 유지될 것이라는 기대에 의존한다. 기업의 부서처럼 크고 복잡한 대상의 순기여도를 하나의 지표로 합리적이고 정확하게 측정할 수 있다고 생각한다는 점이다. MBO는 어떻게든 단순한 숫자로 표현하라고 말한다.\np193 MBO(Management by Objectives)는 1950년에 일시적으로 유행했던 경영기법으로 지금은 평판이 매우 떨어지는 기법이다\u0026hellip;.. MBO형 기업들은 분기 결과가 나쁘면 더 많은 MBO를 시행하는 방법으로 대응한다.\n목표관리 또는 목표에 의한 관리라고 한다. 직원 스스로 혹은 상사와의 협의를 통해 양적으로 측정가능하고 구체적이고 단기적인 성과 목표를 설정하고, 스스로 그러한 성과 목표 달성의 정도를 평가해서 그 업적을 보고하게 하는 기법이다. 국내 기업에서도 폭넓게 활용되고 있다\np204 리더십은 여러분의 의제에 다른 사람을 동참시키는 능력이다.\np207 충분한 권한이 리더십의 필수 조건은 결코 아니다. 충분한 권한이라는 건 사실 존재하지 않는다. 리더십이란 충분한 권한이 주어지지 않은 상황에서 성공할 수 있는 역량이다.\np215 변화는 항상 포기를 수반한다. 여러분이 포기해야 하는 것은 일을 처리하는 오래된 기존 방식이다. 친숙한 방식, 숙달된 방식. 변화란 직원들에게 일에 대한 지배력을 포기하고 다시금 초보자로 돌아가 하위 계급이 되라는 것과 마찬가지인 것이다.\n사람들은 그런 종류의 변화를 이루어낼 수 있지만 그것은 오직 안전하다고 느낄 때만 가능하다. 불안전한 환경에 놓인 사람들은 경험하지 않은 분야로 자신을 떠미는 행동을 하려고 하지 않는다. 그런 상황에 그들은 변화를 거부할 것이며 여러분이 아무리 설득을 하더라도 변화에 불참하려는 그들의 생각을 바꿀 수 없을 것이다.\np224 신뢰를 받은 사람은 거의 자발적인 반응으로 충성심을 제공하낟. 무엇보다 나를 신뢰한 사람에게 절대 실망을 안겨주지 않을 것이라고 다짐했다.\n부하직원이 신뢰할 만한 지 알기 전에 먼저 얼마간의 신뢰를 주라는 것이다. 하지만 너무 많이 주어서도 안 된다. 리더에게는 부하직원이 얼마나 준비된 사람인가를 파악할 수 있는 확실한 감각이 있어야 한다. 신뢰할 만한 사람인지 알기 전에 신뢰를 주는 일은 위험을 수반한다.\np220 신뢰를 획득하지 않고서는 리더가 존재할 수 없고 진정한 변화도 불가능하다.\n일을 하기 전에 신뢰를 미리 얻어내기 위해서는 풍부한 인간적 매력이 필요하다는 사실을 알 수 있다. 신뢰를 잘 얻어내는 리더들은 생각이 분명하고, 발랄하며, 매력이 있꼬, 짓궃은 유머를 잘 하는 경향이 있다.\np226 변화의 타이밍에 대한 잘못된 상식. \u0026quot; 고장 나지 않았다면 고치지 말자\u0026quot;는 생각이다.\np232 중간관리자의 핵심 역할은 바로 재창조다.\n슬랙이 없다면 재창조에시간을 쓰기에 너무나 바쁜 상태라서 오로지 일상의 업무적 기능만 할 수 있을 뿐 재창조 수행이 불가능해진다.\np251\n지식근로자들이 일하는 조직에서 건전한 경쟁과 같은 것은 존재할 수 없다. 모든 내부 경쟁은 파괴적이다. 지식근로는 협업을 기반으로 한다.\n","date":"2018-07-29T13:42:11+09:00","permalink":"https://cychong47.github.io/post/2018/slack/","summary":"\u003cp\u003ep32\n너무 효율적인 사람은 너무나도 바쁘기 때문에, 무언가 새로운 일이 일어나는 경우 그 일에 즉시 대응할 수가 없게 된다.\u003c/p\u003e\n\u003cp\u003ep37\n사실 효율성을 높이는 일은 매우 어렵다. 효율성 개선에는 엄청난 노력과 진정한 독창성이 필요하기 때문이다. 조직은 항상 스스로를 더욱 효율적으로 만들기 위해 끊임없이 노력해 왔기 때문에 조직을 더 효율적으로 만들기란 결코 쉬운 일이 아니다.\u003c/p\u003e\n\u003cp\u003ep38\n짧은 시간안에 조직의 개선을 보여주어야 하는 효율성 전문가에게 유욯나 지름길은 무엇일까? 가장 자주 채택되는 지름길은 바로 각각의 직원을 모두 완전한 대체물이라고 가정하는 것이다.\u003c/p\u003e","title":"(책) Slack"},{"content":"p65 효율적인 팀들은 한결같이 매우 구체적으로 논쟁을 벌였습니다. 팀원들간의 신뢰도가 매우 높은 팀에서도 흔히 논쟁이 벌어지더군요.\np114 전반전이 끝나고 라커룸으로 들어가는 농구코치를 상상해 봅시다. 그는 팀의 센터포워드를 자기 방으로 불러서 전반전에 대해 일대일로 대화합니다. 그러곤 포인트가드, 슈팅가드, 스몰포워드, 파워포워드를 차례로 불러서 똑같은 행동을 반복합니다. 선수들 중 누구도 코치가 다른 선수들에게 무슨 얘기를 했는 지 알 수 없는 상태에서 후반전이 시작됩니다. 후반전에서 그들은 더 이상 팀이 아닙니다. 그건 단지 개인들을 한데 모아놓은 것에 불과하죠.\np122 정치란 사람들이 말과 행동을 할 때 자신이 생각하는 대로 하지 않고 다른 사람들이 어떻게 반응할 것인가에 따라 하는 것을 말합니다.\np126 만약 우리가 서로를 신뢰하지 않는다면 우리는 충돌의 상황에 뛰어들지 않을 겁니다. 그 상황이 개방적이고 건설적일지라도 말입니다. 그리고 겉으로 보기에 융화된 것처럼 행동하면서 아무 문제없이 잘 지내게 되겠죠.\np127 긴장관계가 형성되어 있긴 하지만 건설적인 충돌은 거의 일어나지 않고 있습니다. 수동적이고 냉소적인 비난은 내가 말하는 충돌에 속하지 않습니다.\np148 모든 것이 다 중요하다면 아무것도 중요하지 않은 것과 같다.\np215 열심히 일하고 있는 사람을 비판하는 건 어려운 일이죠. 하지만 그건 좋은 변명이 아니예요. \u0026hellip;. 좀 더 분명하게 업무의 우선순위를 매겼어야 했어요. 그리고 자신의 요구에 따르지 않은 조직 내의 사람들에게 명확히 문제를 제기했어야 합니다.\np216 \u0026lsquo;신뢰\u0026rsquo;란 모두가 내 편이라는 생각과는 다른 겁니다. 서로 신뢰한다고 해서 상대에게 압박을 가할 필요가 없다고 생각해서는 안됩니다. 신뢰란 팀의 구성원이 언제 동료를 압박해야 할 지 그때를 정확히 아는 것입니다. 팀에 애정을 갖고 있기 때문에 그 일을 하는 것입니다.\n압박을 하되 존중하는 마음이 있어야 합니다. 그리고 내가 아니어도 누군가는 그렇게 했을 것이라는 생각을 염두에 두어야 하고요.\n팀을 위기에 빠뜨리는 5가지 함정\n첫번째 함정(신뢰의 결핍) 신뢰의 결핍은 팀원들이 동료의 비판을 기꺼이 받아들일 준비가 되어 있지 않을 때 생긴다. 진심으로 서로에게 마음을 열고, 상대방의 실수와 약점을 이야기할 수 없는 팀의 구성원들은 신뢰의 기반을 쌓기가 쉽지 않기 때문이다.\n두번째 함정(충돌의 두려움) 신뢰 구축의 실패는 충돌의 두려움을 불러온다. 신뢰가 없는 팀은 상대방의 생각에 대해 거리낌없이 비판을 하는 논쟁을 벌일 수 없기 때문이다. 그들은 솔직하지 못한 토론과 자기방어적인 수사법에만 의존하게 된다.\n세번째 함정(헌신의 결핍) 건전한 충돌의 결핍은 헌신의 결핍을 가져온다. 개방적이면서 치열한 충돌 속에서 서로의 의견을 조율하지 못한다면, 주어진 결정사항을 진심으로 받아들여 매진하기 어렵기 때문이다. 물론 회의 중에 동의한다는 의사는 얼마든지 꾸며 낼 수 있지만 말이다.\n네 번째 함정(책임의 회피) 헌신을 다해 팀의 목표에 매진하지 않는 사람은, 자기 자신이 결과에 책임지지 않는 것은 물론이고 팀의 목표에 어긋나는 결과를 불러일으킨 동료에게 책임을 추궁할 수 없게 된다.\n다섯 번째 함정(결과에 대한 무관심) 서로에 대한 책임을 묻지 못한다면 다섯 번째 함정에 빠지게 된다. 팀원들이 자신의 경력이나 대외 인지도 등 개인적 욕구를 공통 목표보다 우위에 놓을 때 결과에 대한 무관심이 발생한다.\n팀을 성공으로 이끄는 5가지 법칙 첫 번째 법칙. 팀원간에 서로를 신뢰한다. 두번째 법칙. 논쟁이 벌어졌을 때 거리낌 없이 의견 충돌을 일으킨다. 세번째 법칙. 한번 내려진 결정과 실행 계획에 헌신을 다해 노력한다. 네번째 법칙. 정해진 계획에 어긋나는 행동을 했을 경우 책임을 묻는다. 다섯째 법칙. 공동의 목표를 이루는 데 초점을 맞춘다.\n신뢰가 결여된 팀워들의 행동방식 자신의 약점과 실수를 동료에게 감춘다. ","date":"2018-07-29T13:11:31+09:00","permalink":"https://cychong47.github.io/post/2018/five-traps-team-can-fall-into/","summary":"\u003cp\u003ep65\n효율적인 팀들은 한결같이 매우 구체적으로 논쟁을 벌였습니다. 팀원들간의 신뢰도가 매우 높은 팀에서도 흔히 논쟁이 벌어지더군요.\u003c/p\u003e\n\u003cp\u003ep114\n전반전이 끝나고 라커룸으로 들어가는 농구코치를 상상해 봅시다. 그는 팀의 센터포워드를 자기 방으로 불러서 전반전에 대해 일대일로 대화합니다. 그러곤 포인트가드, 슈팅가드, 스몰포워드, 파워포워드를 차례로 불러서 똑같은 행동을 반복합니다. 선수들 중 누구도 코치가 다른 선수들에게 무슨 얘기를 했는 지 알 수 없는 상태에서 후반전이 시작됩니다. 후반전에서 그들은 더 이상 팀이 아닙니다. 그건 단지 개인들을 한데 모아놓은 것에 불과하죠.\u003c/p\u003e","title":"(책) 팀이 빠지기 쉬운 5가지 함정"},{"content":"p64 해결점까지 분명한 길이 있는 경우의 보상은 앞만 바라보며 더 빨리 나아가게 해주기 때문에 도움이 되지만, 양초 문제처럼 도전적인 상황에서 \u0026lsquo;만약-그러면\u0026rsquo;의 조건적 동기유인제는 효력을 발휘하지 못한다. 보상은 사람들의 시야를 좁히며, 기존 물건의 새로운 쓰임새를 볼 수 있는 포괄적인 시야를 흐리게 한다.\np65 다른 사람을 위해 작업할 때면 항상 그런 것은 아니지만 많은 경우에 작업이 즐거움보다는 일에 가까워진다. 반면 나 자신을 위해 작업할 때는 창조한다는 순전한 즐거움을 느끼면서 밤을 새는지도 모르고 일하기도 한다. 의뢰받은 작업의 경우는 스스로를 억제하고 고객의 요구를 따르기 위해 정신을 바짝 차려야 한다.\n헌열에 대한 보상 시험\np75 유치원 지각을 금전으로 보상하게 하자 부모와 교사간의 친밀한 유대관계가 순전한 계약으로 변질되었다.\np77 쓰레기를 버리면 용돈을 주겠다고 아들에게 제안했다고 가정해보자. 그 후 아들은 용돈을 받지 않으면 절대로 쓰레기를 버리지 않을 것이다. 더욱이 처음에 제시했던 돈의 흥분이 가라앉은 후에는 액수를 늘려야마 순응을 요구할 수 있다.\n보상은 제공되는 순간 중독성을 띤다. 대리인은 조건적인 보상을 제시받은 후에는 그와 비슷한 일이 생길 때마다 보상을 기대하게 된다. 그 후 주동자는 계속해서 보상을 이용하게 된다. 기존의 보상으로는 더 이상 만족할 수 없는 상황이 곧 발생하고, 보상은 보너스가 아니라 당연한 것으로 여겨진다. 그렇기 때문에 동일한 효과를 얻으려면 주동자가 그 이상의 보상을 제공해야만 한다.\np83 책을 3권 읽으면 상을 준다고 제시하면 많은 학생들이 네 번째 책을 읽기 않을 것이며, 평생 독서의 길에 들어서지도 않을 것이다.\n조건적인 보상이 연루되지 않거나 인센티브가 적절하게 이용되면 성과가 향상되고 이해력이 깊어진다. 위대함과 근시안은 양립하지 못한다. 자신의 시야를 들어 올려서 수평선까지 밀고 나갈 때 비로소 의미 있는 업적에 다다를 수 있는 법이다.\np88 그다지 흥미로지 않고 창의적인 사고도 별로 필요하지 않는 기계적인 일에서 보상은 해로운 부작용 없이 동기유발제 역할을 한다. 단, 이 일이 왜 필요한지 이론적 근거를 제시한다. 일이 따분하다는 사실을 인정한다. 사람들이 자기 방식대로 일을 완성하게 자율성을 허용한다.\np95 보상의 필수 조건 외부의 보상은 전혀 예상치 못한 것이어야 하며, 일이 완성된 후에 제시되어야 한다. \u0026lsquo;만약-그러면\u0026rsquo;에서 \u0026lsquo;이제-했으니까\u0026rsquo;로 전환\n그러나 \u0026lsquo;이제-했으니까\u0026rsquo; 보상도 반복되면 결국 \u0026lsquo;만약-그러면\u0026rsquo;으로 인식된다.\n칭찬과 피드백을 제시한다. 사람들을 통제하기보다는 유용한 정보를 제공한다.\np184 칙센트미하이는 아이들을 자기 마음대로 하게 놔두면 피할 수 없는 자연의 법칙에 따라 결국 몰입을 추구하게 된다고 말한다. 우리 모두 그렇게 해야 한다.\n","date":"2018-07-29T12:45:25+09:00","permalink":"https://cychong47.github.io/post/2018/drive/","summary":"\u003cp\u003ep64\n해결점까지 분명한 길이 있는 경우의 보상은 앞만 바라보며 더 빨리 나아가게 해주기 때문에 도움이 되지만, 양초 문제처럼 도전적인 상황에서 \u0026lsquo;만약-그러면\u0026rsquo;의 조건적 동기유인제는 효력을 발휘하지 못한다.  보상은 사람들의 시야를  좁히며, 기존 물건의 새로운 쓰임새를 볼 수 있는 포괄적인 시야를 흐리게 한다.\u003c/p\u003e\n\u003cp\u003ep65\n다른 사람을 위해 작업할 때면 항상 그런 것은 아니지만 많은 경우에 작업이 즐거움보다는 일에 가까워진다. 반면 나 자신을 위해 작업할 때는 창조한다는 순전한 즐거움을 느끼면서 밤을 새는지도 모르고 일하기도 한다. 의뢰받은 작업의 경우는 스스로를 억제하고 고객의 요구를 따르기 위해 정신을 바짝 차려야 한다.\u003c/p\u003e","title":"(책) 드라이브 - 다니엘 핑크"},{"content":"AVX2가 지원되지 않는 머신에서 쓸데없이 ACL library 빌드할 때 AVX2를 이용해서 빌드하려는 문제를 확인했다. 지금까지 아무도 고치지 않은 게 이상하긴 한데 그래도 내가 생각한 수정 방법이 제대로 동작하는 듯 해서 패치를 한번 보내보기로 했다.\n수정사항은 비교적 간단하다. ACL 라이브러리 빌드할 때 AVX2를 이용해서 빌드해야 하는 경우인지를 검사하는 코드가 lib/librte_acl/Makefile에 정의되어 있는데 여기서 항상 -march=core-avx2 옵션을 사용해서 AVX2가 지원되지 않는 머신에서도 AVX2를 사용해서 gcc가 빌드하도록 하는 걸로 보였다. 다른 코드 빌드할 때는 문제가 없는데 유독 ACL library에서만 이런 문제가 나서 보다 보니 아무래도 Makefile이 잘못된 듯 하다.\nhttps://www.dpdk.org/contribute/ 페이지 내용을 참고해서\ngit clone git://dpdk.org/dpdk 코드 수정\n$ git commit --signoff mk: Detect AVX2 capability based on the target CPU architecture AVX2 support check should be based on the target CPU architecure. For this, -march option should be $(RTE_MACHINE) instead of core-avx2. commit comment 를 수정하려면\n$ git commit --amend 이제 patch를 생성해 보자. 최근 1개의 commit으로 패치 파일을 만드려면 - 옵션을 사용한다.\n$ git format-patch -1 패치 파일 내용 확인해 보고\n$ cat 0001-mk-Detect-AVX2-capability-based-on-the-target-CPU-ar.patch From 7bed8881339afee9bbef31638d3f15dad27efb87 Mon Sep 17 00:00:00 2001 From: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt; Date: Sat, 21 Jul 2018 22:51:19 +0900 Subject: [PATCH] mk: Detect AVX2 capability based on the target CPU architecture AVX2 support check should be based on the target CPU architecure. For this, -march option should be $(RTE_MACHINE) instead of core-avx2. Cc: stable@dpdk.org Signed-off-by: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt; --- lib/librte_acl/Makefile | 2 +- 1 file changed, 1 insertion(+), 1 deletion(-) diff --git a/lib/librte_acl/Makefile b/lib/librte_acl/Makefile index ea5edf00a..c756eaeb2 100644 --- a/lib/librte_acl/Makefile +++ b/lib/librte_acl/Makefile @@ -44,7 +44,7 @@ ifeq ($(findstring RTE_MACHINE_CPUFLAG_AVX2,$(CFLAGS)),RTE_MACHINE_CPUFLAG_AVX2) CC_AVX2_SUPPORT=1 else CC_AVX2_SUPPORT=\\ -\t$(shell $(CC) -march=core-avx2 -dM -E - \u0026lt;/dev/null 2\u0026gt;\u0026amp;1 | \\ +\t$(shell $(CC) -march=$(RTE_MACHINE) -dM -E - \u0026lt;/dev/null 2\u0026gt;\u0026amp;1 | \\ grep -q AVX2 \u0026amp;\u0026amp; echo 1) ifeq ($(CC_AVX2_SUPPORT), 1) ifeq ($(CONFIG_RTE_TOOLCHAIN_ICC),y) -- 2.18.0 git에서 바로 패치 내용을 전송할 수 있는데 그러려면 SMTP 관련 설정을 해 봐야 한다. 관련 파일은 ~/.gitconfig 이거나 git repo에 있는 .git/config\n[sendemail] from = Chaeyong Chong \u0026lt;cychong@gmail.com\u0026gt; smtpserver = smtp.gmail.com smtpuser = cychong@gmail.com smtpencryption = tls smtppass = XXXXXXX chainreplyto = false smtpserverport = 587 이제 보내볼까?\nmbpr15:dpdk cychong$ git send-email --to konstantin.ananyev@intel.com --cc dev@dpdk.org 0001-mk-Detect-AVX2-capability-based-on-the-target-CPU-ar.patch 0001-mk-Detect-AVX2-capability-based-on-the-target-CPU-ar.patch (mbox) Adding cc: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt; from line \u0026#39;From: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt;\u0026#39; (body) Adding cc: stable@dpdk.org from line \u0026#39;Cc: stable@dpdk.org\u0026#39; (body) Adding cc: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt; from line \u0026#39;Signed-off-by: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt;\u0026#39; From: Chaeyong Chong \u0026lt;cychong@gmail.com\u0026gt; To: konstantin.ananyev@intel.com Cc: dev@dpdk.org, Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt;, stable@dpdk.org Subject: [PATCH] mk: Detect AVX2 capability based on the target CPU architecture Date: Sat, 21 Jul 2018 23:06:23 +0900 Message-Id: \u0026lt;20180721140623.1293-1-cychong@gmail.com\u0026gt; X-Mailer: git-send-email 2.18.0 The Cc list above has been expanded by additional addresses found in the patch commit message. By default send-email prompts before sending whenever this occurs. This behavior is controlled by the sendemail.confirm configuration setting. For additional information, run \u0026#39;git send-email --help\u0026#39;. To retain the current behavior, but squelch this message, run \u0026#39;git config --global sendemail.confirm auto\u0026#39;. Send this email? ([y]es|[n]o|[e]dit|[q]uit|[a]ll): y Can\u0026#39;t locate Net/SMTP/SSL.pm in @INC (you may need to install the Net::SMTP::SSL module) (@INC contains: /usr/local/Cellar/git/2.18.0/share/perl5 /Applications/Xcode.app/Contents/Developer/Library/Perl/5.18/darwin-thread-multi-2level /Library/Developer/CommandLineTools/Library/Perl/5.18/darwin-thread-multi-2level /Library/Perl/5.18/darwin-thread-multi-2level /Library/Perl/5.18 /Network/Library/Perl/5.18/darwin-thread-multi-2level /Network/Library/Perl/5.18 /Library/Perl/Updates/5.18.2 /System/Library/Perl/5.18/darwin-thread-multi-2level /System/Library/Perl/5.18 /System/Library/Perl/Extras/5.18/darwin-thread-multi-2level /System/Library/Perl/Extras/5.18 .) at /usr/local/Cellar/git/2.18.0/libexec/git-core/git-send-email line 1497. 무슨 에러가 난다. Perl 관련 에러로 보이는데 마땅한 해결책이 없나 보다. 인터넷을 뒤져 해결책을 찾아 적용해봤지만 백약이 무효\n원인을 찾아 보니 위 에러 메시지의 마지막에 있는 것처럼 git-send-email 파일 1497 라인에서 Net/SMTP/SSL.pm을 찾는 데 못찾고 있다는 거. 근데 그냥 perl로 확인해 보면 멀쩡히 @INC 경로에 포함되어 있다는 사실\n흥미로운 건 어디에 있는 perl을 쓰느냐에 따라 모듈 위치가 달라진 다는 거\n이건 OS X에 기본 내장된 perl을 사용한 경우\n$/usr/bin/perl -e \u0026#39;print \u0026#34;@INC\u0026#34;;\u0026#39; /Library/Perl/5.18/darwin-thread-multi-2level /Library/Perl/5.18 /Network/Library/Perl/5.18/darwin-thread-multi-2level /Network/Library/Perl/5.18 /Library/Perl/Updates/5.18.2 /System/Library/Perl/5.18/darwin-thread-multi-2level /System/Library/Perl/5.18 /System/Library/Perl/Extras/5.18/darwin-thread-multi-2level /System/Library/Perl/Extras/5.18 . 이건 homebrew로 설치한 perl이 찾는 위치\nmbpr15:dpdk cychong$ perl -e \u0026#39;print \u0026#34;@INC\u0026#34;;\u0026#39; /usr/local/Cellar/perl/5.28.0/lib/perl5/site_perl/5.28.0/darwin-thread-multi-2level /usr/local/Cellar/perl/5.28.0/lib/perl5/site_perl/5.28.0 /usr/local/Cellar/perl/5.28.0/lib/perl5/5.28.0/darwin-thread-multi-2level /usr/local/Cellar/perl/5.28.0/lib/perl5/5.28.0 /usr/local/lib/perl5/site_perl/5.28.0/darwin-thread-multi-2level /usr/local/lib/perl5/site_perl/5.28.0 그리고 git send-email 명령이 못찾고 있는 SSL.pm의 위치는 이미 /usr/bin/perl이 아닌 그냥 perl(실제는 /usr/local/bin/perl의 모듈 경로에 이미 포함되어 있다는\nmbpr15:dpdk cychong$ find / -name SSL.pm find: /usr/sbin/authserver: Permission denied /usr/local/Cellar/perl/5.28.0/lib/perl5/site_perl/5.28.0/Net/SMTP/SSL.pm 그래서 /usr/local/Cellar/git/2.18.0/libexec/git-core/git-send-email 이 brew 버전의 perl을 사용하도록 변경 후 다시 git send-email 시도\nSend this email? ([y]es|[n]o|[e]dit|[q]uit|[a]ll): a Need MIME::Base64 and Authen::SASL todo auth at /usr/local/Cellar/git/2.18.0/libexec/git-core/git-send-email line 1521. 이것 쯤이야 이젠 쉽게(?) 해결\nmbpr15:dpdk cychong$ sudo -H cpan MIME:Base64 ... mbpr15:dpdk cychong$ sudo -H cpan Authen::SASL ... 이젠 정말 되겠지?\nSend this email? ([y]es|[n]o|[e]dit|[q]uit|[a]ll): y 5.7.9 Application-specific password required. Learn more at 5.7.9 https://support.google.com/mail/?p=InvalidSecondFactor q81-v6sm10686681pfd.15 - gsmtp 음.. 깔끔하게 되었다는 말은 안 나오지만 그래도 이 메시지는 일단 메일 전송 요청을 받은 gmail server에서 보낸 걸로 보아 전송에 필요한 git 관련 이슈는 없나 보다. 이제 이 문제만 해결하면 이메일을 보낼 수 있겠다. 구글에서 gmail Application-specific password required 로 찾은 내용을 참고해서 gmail에 대해 mac에서 전송할 때 사용할 암호를 따로 지정. 왜 이렇게 해야 하는 지도 설명되어 있지만 일단 보내고 보자.\nmbpr15:dpdk cychong$ git send-email --to konstantin.ananyev@intel.com --cc dev@dpdk.org 0001-mk-Detect-AVX2-capability-based-on-the-target-CPU-ar.patch 0001-mk-Detect-AVX2-capability-based-on-the-target-CPU-ar.patch (mbox) Adding cc: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt; from line \u0026#39;From: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt;\u0026#39; (body) Adding cc: stable@dpdk.org from line \u0026#39;Cc: stable@dpdk.org\u0026#39; (body) Adding cc: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt; from line \u0026#39;Signed-off-by: Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt;\u0026#39; From: Chaeyong Chong \u0026lt;cychong@gmail.com\u0026gt; To: konstantin.ananyev@intel.com Cc: dev@dpdk.org, Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt;, stable@dpdk.org Subject: [PATCH] mk: Detect AVX2 capability based on the target CPU architecture Date: Sat, 21 Jul 2018 23:53:42 +0900 Message-Id: \u0026lt;20180721145342.6503-1-cychong@gmail.com\u0026gt; X-Mailer: git-send-email 2.18.0 The Cc list above has been expanded by additional addresses found in the patch commit message. By default send-email prompts before sending whenever this occurs. This behavior is controlled by the sendemail.confirm configuration setting. For additional information, run \u0026#39;git send-email --help\u0026#39;. To retain the current behavior, but squelch this message, run \u0026#39;git config --global sendemail.confirm auto\u0026#39;. Send this email? ([y]es|[n]o|[e]dit|[q]uit|[a]ll): a OK. Log says: Server: smtp.gmail.com MAIL FROM:\u0026lt;cychong@gmail.com\u0026gt; RCPT TO:\u0026lt;konstantin.ananyev@intel.com\u0026gt; RCPT TO:\u0026lt;dev@dpdk.org\u0026gt; RCPT TO:\u0026lt;cychong@samsung.com\u0026gt; RCPT TO:\u0026lt;stable@dpdk.org\u0026gt; From: Chaeyong Chong \u0026lt;cychong@gmail.com\u0026gt; To: konstantin.ananyev@intel.com Cc: dev@dpdk.org, Chaeyong Chong \u0026lt;cychong@samsung.com\u0026gt;, stable@dpdk.org Subject: [PATCH] mk: Detect AVX2 capability based on the target CPU architecture Date: Sat, 21 Jul 2018 23:53:42 +0900 Message-Id: \u0026lt;20180721145342.6503-1-cychong@gmail.com\u0026gt; X-Mailer: git-send-email 2.18.0 Result: 250 mbpr15:dpdk cychong$ Result 250은 SMTP result code로 정상적으로 전송되었다는 의미란다.(https://www.greenend.org.uk/rjk/tech/smtpreplies.html)\n드디어 끝났다.\n","date":"2018-07-21T15:02:14+09:00","permalink":"https://cychong47.github.io/post/2018/submit-patch-to-dpdk-with-git/","summary":"\u003cp\u003eAVX2가 지원되지 않는 머신에서 쓸데없이 ACL library 빌드할 때 AVX2를 이용해서 빌드하려는 문제를 확인했다. 지금까지 아무도 고치지 않은 게 이상하긴 한데 그래도 내가 생각한 수정 방법이 제대로 동작하는 듯 해서 패치를 한번 보내보기로 했다.\u003c/p\u003e\n\u003cp\u003e수정사항은 비교적 간단하다.\nACL 라이브러리 빌드할 때 AVX2를 이용해서 빌드해야 하는 경우인지를 검사하는 코드가 \u003ccode\u003elib/librte_acl/Makefile\u003c/code\u003e에 정의되어 있는데 여기서 항상 \u003ccode\u003e-march=core-avx2\u003c/code\u003e 옵션을 사용해서 AVX2가 지원되지 않는 머신에서도 AVX2를 사용해서 gcc가 빌드하도록 하는 걸로 보였다. 다른 코드 빌드할 때는 문제가 없는데 유독 ACL library에서만 이런 문제가 나서 보다 보니 아무래도 Makefile이 잘못된 듯 하다.\u003c/p\u003e","title":"2nd patch submit to DPDK"},{"content":"임백준. 2016.5\n96) dead code로 인한 사고 신규 기능을 위해 현재 지금은 disable로 설정된 변수를 재활용. 코드 변경을 깜빡하고 설정만 변경하여 잠자고 있던 예전 코드가 동작(예측 불가능한 동작) 사용하지 않는 코드는 소스 코드에서 삭제할 것. If 문으로 회피하는 것은 상당히 나쁘고 위험한 습관 소프트웨어의 전개 과정이 정확한 설명을 담고 있는 문서에 기반해야 함 효율성을 명목으로 코드의 간명함과 안정성을 해치는 행동은 피할 것 100) 오바마 케어 112) Detail 디테일이 살아 있고 빠르고 안정감 있게 동작하는 코드를 작성하는 것은 \u0026lsquo;능력\u0026rsquo;이 문제인 경우가 많지만 \u0026lsquo;태도\u0026rsquo;의 문제이기도 디테일과 사소함을 혼동하지 말 것 점 하나에 따라서 코드 전체의 의미가 달라질 수 있는 프로그래밍의 세계에서 디테일은 덤이 아니라 생명 121) 지식이 아니라 메타지식 전문성 보다는 부족한 정보를 토대로 최선의 판단을 내리는 적응력이 중요. 새로운 지식을 빨리 흡수해서 자기 것으로 만드는 능력이 더 중요. 131) 나이는 짐인가 훈장인가 노력하지 않는 사람에게 나이는 짐이고, 노력하는 사람에게 나이는 훈장이다. 167) Actor model 208) MS API, Bot MS같은 회사가 인공지능을 개발하고 API를 통해 기능을 제공할 테니 여러분은 그런 플랫폼 위에서 앱을 개발하라. Bot 212) 팀 내 가장 실력이 낮은 사람이 되라 배울 것이 없는 팀에서 오래 머물지 말라 216) 내가 아는 언어의 한계 비드겐슈타인 내가 아는 언어의 한계가 곧 내가 사는 세상의 한계 http://code.org 263) LESS Learn - 배우믄 즐겁고 재밌는 놀이. 그게 아니면 노동 Enjoy Solve - 문제를 해결하지 못하면 개발자가 아니다. Share - 즐김을 위한 수단 269) 무지의 인지가 공부의 시작 더 많이 알수록 자기가 모르는 것이 얼마나 많은지 알게 되는 것이 개발자의 숙명 그 많은 내용을 다 알고 있는 사람이 존재하지 않는다는 사실을 깨달을 것. 자기가 알아야 한다고 생각하는 것의 1%라도 제대로 알고 있는 사람도 별로 없다. 이런저런 것을 알아야 할 것 같은데 나는 언제 그걸 공부하지라고 생각한 사람은 이미 대부분의 사람보다 많은 것을 알고 있는 사람이라는 뜻(하지만 실제 행동하지 않으면 소용없음) 287) 비동기성 Erik Meijer 지금까지의 SW는 동시성과 블로킹을 기반으로 동작하는데 익숙 async, await agile은 관리자가 개발자를 통제하기 위한 수단에 불과하다 280) 10가지 철학 개발자가 회사에 기여하는 정도와 개발자가 실제로 받는 급여 사이에는 커다른 차이가 개발자와 개발자의 작업 숙 동일하지 않다. Egoless 운에 기대지 말라. 매일 노력하라. 계획보다는 행동이다 bias for action (Amazon), Move fast and break things (Facebook) 말하지 말고 행동하라. 사람들이 나의 말을 듣지 않는 이유는 말 그 자체는 행동이 아니기 때문이다 \u0026lsquo;최악\u0026rsquo;은 제한되어 있다. 도전하라. 한국의 현실은\u0026hellip; 10 Philosophies for Engineers http://traffic.libsyn.com/sedaily/10_philosophies.mp3 301) No Stackoverflow in Korean 자신감 결여. 수동적으로 닥치고 듣기만 하는 교육 방식에 길들여져 있어 질문하는 것이 불안하고 불편 여유 없음. 매일 야근인데 한가하게 질문에 답이나 달고 있을 시간이 있을리가 경쟁 하나의 특정한 기술로 평생을 살려는 사람은 시대착오적이다. ","date":"2018-07-15T13:41:48+09:00","permalink":"https://cychong47.github.io/post/2018/developer-culture/","summary":"\u003cp\u003e임백준. 2016.5\u003c/p\u003e\n\u003ch2 id=\"96-dead-code로-인한-사고\"\u003e96) dead code로 인한 사고\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e신규 기능을 위해 현재 지금은 disable로 설정된 변수를 재활용. 코드 변경을 깜빡하고 설정만 변경하여 잠자고 있던 예전 코드가 동작(예측 불가능한 동작)\u003c/li\u003e\n\u003cli\u003e사용하지 않는 코드는 소스 코드에서 삭제할 것. If 문으로 회피하는 것은 상당히 나쁘고 위험한 습관\u003c/li\u003e\n\u003cli\u003e소프트웨어의 전개 과정이 정확한 설명을 담고 있는 문서에 기반해야 함\u003c/li\u003e\n\u003cli\u003e효율성을 명목으로 코드의 간명함과 안정성을 해치는 행동은 피할 것\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"100-오바마-케어\"\u003e100) 오바마 케어\u003c/h2\u003e\n\u003ch2 id=\"112-detail\"\u003e112) Detail\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e디테일이 살아 있고 빠르고 안정감 있게 동작하는 코드를 작성하는 것은 \u0026lsquo;능력\u0026rsquo;이 문제인 경우가 많지만 \u0026lsquo;태도\u0026rsquo;의 문제이기도\u003c/li\u003e\n\u003cli\u003e디테일과 사소함을 혼동하지 말 것\u003c/li\u003e\n\u003cli\u003e점 하나에 따라서 코드 전체의 의미가 달라질 수 있는 프로그래밍의 세계에서 디테일은 덤이 아니라 생명\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"121-지식이-아니라-메타지식\"\u003e121) 지식이 아니라 메타지식\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e전문성 보다는 부족한 정보를 토대로 최선의 판단을 내리는 적응력이 중요.\u003c/li\u003e\n\u003cli\u003e새로운 지식을 빨리 흡수해서 자기 것으로 만드는 능력이 더 중요.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"131-나이는-짐인가-훈장인가\"\u003e131) 나이는 짐인가 훈장인가\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e노력하지 않는 사람에게 나이는 짐이고, 노력하는 사람에게 나이는 훈장이다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"167-actor-model\"\u003e167) Actor model\u003c/h2\u003e\n\u003ch2 id=\"208-ms-api-bot\"\u003e208) MS API, Bot\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eMS같은 회사가 인공지능을 개발하고 API를 통해 기능을 제공할 테니 여러분은 그런 플랫폼 위에서 앱을 개발하라.  \u003ccode\u003eBot\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"212-팀-내-가장-실력이-낮은-사람이-되라\"\u003e212) 팀 내 가장 실력이 낮은 사람이 되라\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e배울 것이 없는 팀에서 오래 머물지 말라\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"216-내가-아는-언어의-한계\"\u003e216) 내가 아는 언어의 한계\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e비드겐슈타인 \u003ccode\u003e내가 아는 언어의 한계가 곧 내가 사는 세상의 한계\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://code.org\"\u003ehttp://code.org\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"263-less\"\u003e263) LESS\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eLearn - 배우믄 즐겁고 재밌는 놀이. 그게 아니면 노동\u003c/li\u003e\n\u003cli\u003eEnjoy\u003c/li\u003e\n\u003cli\u003eSolve - 문제를 해결하지 못하면 개발자가 아니다.\u003c/li\u003e\n\u003cli\u003eShare - 즐김을 위한 수단\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"269-무지의-인지가-공부의-시작\"\u003e269) 무지의 인지가 공부의 시작\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e더 많이 알수록 자기가 모르는 것이 얼마나 많은지 알게 되는 것이 개발자의 숙명\u003c/li\u003e\n\u003cli\u003e그 많은 내용을 다 알고 있는 사람이 존재하지 않는다는 사실을 깨달을 것. 자기가 알아야 한다고 생각하는 것의 1%라도 제대로 알고 있는 사람도 별로 없다.  \u003ccode\u003e이런저런 것을 알아야 할 것 같은데 나는 언제 그걸 공부하지\u003c/code\u003e라고 생각한 사람은 이미 대부분의 사람보다 많은 것을 알고 있는 사람이라는 뜻(하지만 실제 행동하지 않으면 소용없음)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"287-비동기성\"\u003e287) 비동기성\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eErik Meijer\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e지금까지의 SW는 동시성과 블로킹을 기반으로 동작하는데 익숙\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003easync\u003c/code\u003e, \u003ccode\u003eawait\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eagile\u003c/code\u003e은 관리자가 개발자를 통제하기 위한 수단에 불과하다\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"280-10가지-철학\"\u003e280) 10가지 철학\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e개발자가 회사에 기여하는 정도와 개발자가 실제로 받는 급여 사이에는 커다른 차이가\u003c/li\u003e\n\u003cli\u003e개발자와 개발자의 작업 숙 동일하지 않다. \u003ccode\u003eEgoless\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e운에 기대지 말라. 매일 노력하라.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003e계획보다는 행동이다\u003c/strong\u003e \u003ccode\u003ebias for action\u003c/code\u003e (Amazon), \u003ccode\u003eMove fast and break things\u003c/code\u003e (Facebook) 말하지 말고 행동하라. 사람들이 나의 말을 듣지 않는 이유는 말 그 자체는 행동이 아니기 때문이다\u003c/li\u003e\n\u003cli\u003e\u0026lsquo;최악\u0026rsquo;은 제한되어 있다. 도전하라. 한국의 현실은\u0026hellip;\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://softwareengineeringdaily.com/2016/02/12/10-philosophies-for-developers\"\u003e10 Philosophies for Engineers\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://traffic.libsyn.com/sedaily/10_philosophies.mp3\"\u003ehttp://traffic.libsyn.com/sedaily/10_philosophies.mp3\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"301-no-stackoverflow-in-korean\"\u003e301) No \u003ccode\u003eStackoverflow\u003c/code\u003e in Korean\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e자신감 결여. 수동적으로 \u003ccode\u003e닥치고 듣기만 하는\u003c/code\u003e 교육 방식에 길들여져 있어 질문하는 것이 불안하고 불편\u003c/li\u003e\n\u003cli\u003e여유 없음. 매일 야근인데 한가하게 질문에 답이나 달고 있을 시간이 있을리가\u003c/li\u003e\n\u003cli\u003e경쟁\u003c/li\u003e\n\u003cli\u003e하나의 특정한 기술로 평생을 살려는 사람은 시대착오적이다.\u003c/li\u003e\n\u003c/ul\u003e","title":"(책) 대살개문"},{"content":"Toward 5G RAN virtualization by Intel and Astri\nhttp://astri.oeg\nFlexible architecture Modular PHY processing architectures PDCP Split MAC/PHY Split - HARQ processing in RRU(How???) Lower PHY Split - High FB overhead but smallest packet latency. Good for JT and JR for COMP Good for Massive MIMO and Ultra low-latency communication(Why?) FAPI based MAC/PHY communication L1 adaptation layer for MAC/PHY split (and Lower PHY Split?) MAC/PHY split in one CPU MAC/PHY split in one machine but netrwork based MAC/PHY communication over OVS Virtual Cell A group of physical cells form a Virtual Cell which does not require HO between the physical cells. Technical Specification Commercial L1 reference design Artesyn MacCore\nXeon-D - 8 or 12 core/CPU * 2 CPU/slot * 15 slots https://www.artesyn.com/computing/products/product/max-core https://www.artesyn.com/computing/assets/maxcore_platform_ds_1484017329.pdf� ","date":"2018-07-15T12:03:00+09:00","permalink":"https://cychong47.github.io/post/2018/astri-vran/","summary":"\u003cp\u003e\u003ca href=\"https://builders.intel.com/docs/networkbuilders/towards_5g_ran_virtualization_enabled_by_intel_and_astri.pdf\"\u003eToward 5G RAN virtualization by Intel and Astri\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://astri.oeg\"\u003ehttp://astri.oeg\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"flexible-architecture\"\u003eFlexible architecture\u003c/h2\u003e\n\u003ch3 id=\"modular-phy-processing-architectures\"\u003eModular PHY processing architectures\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ePDCP Split\u003c/li\u003e\n\u003cli\u003eMAC/PHY Split - HARQ processing in RRU(How???)\u003c/li\u003e\n\u003cli\u003eLower PHY Split - High FB overhead but smallest packet latency.\n\u003cul\u003e\n\u003cli\u003eGood for JT and JR for COMP\u003c/li\u003e\n\u003cli\u003eGood for Massive MIMO and Ultra low-latency communication(Why?)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eFAPI based MAC/PHY communication\n\u003cul\u003e\n\u003cli\u003eL1 adaptation layer for MAC/PHY split (and Lower PHY Split?)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/2018/07/Screenshot-2018-07-15-20.51.59.png\" alt=\"Screenshot-2018-07-15-20.51.59\"\u003e\u003c/p\u003e\n\u003ch3 id=\"macphy-split-in-one-cpu\"\u003eMAC/PHY split in one CPU\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eMAC/PHY split in one machine but netrwork based MAC/PHY communication over OVS\n\u003cimg src=\"/images/2018/07/Screenshot-2018-07-15-20.56.12.png\" alt=\"Screenshot-2018-07-15-20.56.12\"\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"virtual-cell\"\u003eVirtual Cell\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eA group of physical cells form a \u003ccode\u003eVirtual Cell\u003c/code\u003e which does not require HO between the physical cells.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"technical-specification\"\u003eTechnical Specification\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eCommercial L1 reference design\n\u003cimg src=\"/images/2018/07/Screenshot-2018-07-15-21.02.00.png\" alt=\"Screenshot-2018-07-15-21.02.00\"\u003e\u003c/p\u003e","title":"Astri vRAN"},{"content":" 다양한 분야에 대한 조언 p20 목표가 명확하겨 정답이 있는 일을 하는 경주마에서 길 잃은 양으로\np22 지식을 더 많이 아는 것이 아닌 아는 지식으로 뭘 할 지 Learn by doing. 결과가 아닌 과정. 직접 해 본 사람 vs. 배워서 아는 사람 p34 끈기와 뚝심 별게 아닌게 아니다 끝까지 해내는 힘 John Williams - 매일 작곡. 영감-\u0026gt;작곡이 아니라 작곡을 하다보면 영감을 얻게 됨 p41 영어 강의 준비 -\u0026gt; 영어 발음을 보완하기 보다 강의 준비를 철저하게 함. 강점을 강조함. 강의 핵심은 영어가 아니다. 가장 잘하는 일 -\u0026gt; 장점을 강화해야 함 -\u0026gt; 나의 강점은 무엇인가? p47 기회는 공평하지 않다. 랑랑 pianist\np57 삼단 로켓 미련을 남기지 않을 만큼 하고, 다른 로켓을 찾자??? p67 인간의 생존은 적응력에서 옴\np70 불안을 다스리는 가장 완벽한 방법은 불안을 일으키는 일을 해 버리는 것 p79 차별화\n매일 한가지 새로운 일 하기 -\u0026gt; 사고가 예민해 짐\nBest one -\u0026gt; Only one\n독창성\n사고가 민감해짐\np86 메모\n메모 습관. 메모 행위 자체가 생각을 정리할 기회를 줌\n키워드, 개념 중심으로 정리하고, \u0026lsquo;자기 관점\u0026rsquo;을 담아 하나의 \u0026lsquo;문장\u0026rsquo;으로 만들라\np113 자율, 능동\n자율성을 빼앗기지 않는 버릇이 필요 상황에 다른 통제력을 자신에게 두는 생각이 필요. 업무 스트레스 - 업무 부담 보다는 통제력이 없는 경우에 더 큼\n능동성*\nPlan B p121 걷기\n매일 산책. 일에 쫓겨 마음이 조급해질 수록 산책\n\u0026lsquo;걷기 예찬\u0026rsquo; - 다비드 르 브르통\n\u0026lsquo;생각에 관한 생각\u0026rsquo; 행동 경제학, 다니엘 카너먼\np126 독서 손정의. 철학 - 역사, 지리, 인문. 인문은 기본을 질문하는 것. \u0026ldquo;옳다고 믿는 것들이 정말 옳은가?\u0026rdquo; 정보 \u0026laquo; 본질 하루에 한권 읽기 비록 실패했지만 속독, 독서 습관, 넓고 깊어진 시야를 갖게됨 속독 저자는 왜 이 이야기를 하려 하는가? 저자가 말하고자 하는 결론은 무엇인가? 나에게 어떤 의미를 주는 가? 습관 짬이 날 때마다 읽는 습관 넓고 깊어진 시야 p132 시어스로벅 \u0026laquo; 월마트 시어스로벅은 기존 고객을 충성 고객으로, 월마트는 새로운 고객을 목표로\np141 전문지식이 설득에세 결정적인 계기가 되는 것은 10% 미만. \u0026ldquo;상대가 긍정적인 의도를 품었다고 믿어라\u0026rdquo; Soft-skill 이 중요함 p155 Labor -\u0026gt; Work -\u0026gt; Play 평생 학습 필요 -\u0026gt; 주제별 3년간 독일회사 320만 중 200만이 1인 사업체 p205 지식 근로자 피터드러커 머리로 일하는 목표를 스스로 결정하고 달성하기 위해 노력. 시간을 효율적으로 사용해야 함. 더 바쁘게 -\u0026gt; 더 휴율적으로. 기록하고 체크 p215 정리의 원칙 -\u0026gt; 자료, 정리는 들어오는 즉시 바로바로 처리해서 머리 바깥으로\n목록 -\u0026gt; indexing\n제일 바쁜 사람에게서 제일 먼저 답신이 온다. 미루지 않고 바로 처리하는 습관 자투리 시간을 잘 활용할 것 p223 주어진 시간에 맞는 일을 배치. 2분, 5분, 10분, 30분짜리\np224 나만의 몰입시간 -\u0026gt; 자신만의 시간 30분\np226 혼자 있는 시간 -\u0026gt; 방해 받지 않고 혼자 보내는 시간\np228 자신만의 시간 30분 \u0026lsquo;일하는 시간\u0026rsquo;, \u0026lsquo;쉬는 시간\u0026rsquo; 이 아닌 \u0026lsquo;생각/사색하는 시간\u0026rsquo; ","date":"2018-07-07T15:00:28+09:00","permalink":"https://cychong47.github.io/post/2018/advice_from_tokyo_professor/","summary":"\u003cul\u003e\n\u003cli\u003e다양한 분야에 대한 조언\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"p20\"\u003ep20\u003c/h2\u003e\n\u003cp\u003e목표가 명확하겨 정답이 있는 일을 하는 경주마에서 길 잃은 양으로\u003c/p\u003e\n\u003ch2 id=\"p22\"\u003ep22\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e지식을 더 많이 아는 것이 아닌 아는 지식으로 뭘 할 지\u003c/li\u003e\n\u003cli\u003eLearn by doing.\n\u003cul\u003e\n\u003cli\u003e결과가 아닌 과정. 직접 해 본 사람 vs. 배워서 아는 사람\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"p34\"\u003ep34\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e끈기와 뚝심\n\u003cul\u003e\n\u003cli\u003e별게 아닌게 아니다\u003c/li\u003e\n\u003cli\u003e끝까지 해내는 힘\u003c/li\u003e\n\u003cli\u003eJohn Williams - 매일 작곡. 영감-\u0026gt;작곡이 아니라 작곡을 하다보면 영감을 얻게 됨\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"p41\"\u003ep41\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e영어 강의 준비 -\u0026gt; 영어 발음을 보완하기 보다 강의 준비를 철저하게 함.\u003c/li\u003e\n\u003cli\u003e강점을 강조함. 강의 핵심은 영어가 아니다.\u003c/li\u003e\n\u003cli\u003e가장 잘하는 일 -\u0026gt; 장점을 강화해야 함 -\u0026gt; 나의 강점은 무엇인가?\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"p47\"\u003ep47\u003c/h2\u003e\n\u003cp\u003e기회는 공평하지 않다.\n랑랑 pianist\u003c/p\u003e","title":"(책) 도쿄대 교수가 제자들에게 주는 쓴소리"},{"content":"세바시 였던가, 공개 강의 동영상을 통해 처음 알게 된 김민식 PD. 예전에 인기있었던 시트콤, ‘논스톱’을 만든 PD인데 MBC 파업과 관련되어 힘든 시간을 보내다 “영어책 한 권 외워봤니?”라는 독특한 제목의 영어 책으로 대중에 알려졌다. 그와 동시에 대입부터 시작해서 방송국 파업 때문에 경영진에 찍혀 고생하는 기간에 블로그를 통해 재기(?)에 성공한 특이한 이력을 가지고 있는데 시트콤 PD 답게 재밌는 입담을 통해 자신의 힘들었던 과거를 통해 의미있는 이야기를 많이 해줬던 걸로기억한다. 매일 아침 써봤니? 는 제목 그대로 저자가 하고 있다는 매일 아침 글쓰기를 통해 변화된 인생에 대해 이야기해주고 있다.\n저녁 약속을 잡지 않는다고 하면, 사회생활에 지장은 없느냐고 묻기도 합니다. 글쎄요, 저는 인생에서 무언가 더하고 싶은 게 있을 때 먼저 제 삶을 돌아봅니다. 지금 내 삶에서 뺄 수 있는 건 무엇일까? 아무것도 빼지 않고 그냥 더할 수는 없어요. 제 인생은 이미 ‘만땅’이거든요. 하나를 더하려면 하나를 빼야 합니다.\n아이가 어릴 때는 아이에게 집중하는 것이 맞습니다. 자기계발도 마찬가지예요. 하고 싶은 일이 있을 때는 지금 당장 해야 합니다.\n글자에는 주술적인 힘이 있어요. 머릿속 생각이나 말 한마디는 나를 붙들지 못하지만, 글로 남긴 약속은 인생을 바꾸는 마법의 주문이 됩니다.\n열심히 사는 게 능사가 아닙니다. 시대의 흐름을 읽어야 해요. 세상이 변화하는데 혼자 옛날 방식을 고집하는 사람은 일의 세계에서 살아남지 못합니다.지금 이 순간이 미디어의 격변기라는 게 온몸으로 느껴집니다. 이제 자신의 컨텐츠를 만드는게 경쟁력이 되는 시대입니다.\n공부를 잘하는 친구들은 의외로 단순하다네요. 그냥 지금 인 순간 자신이 하고 있는 공부 방식을 믿고 밀어붙인답니다. 공부는 방법보다 그냥 하는 게 가장 중요하거든요.영어 공부를 할 때도, 어떤 책을 어떤 방식으로 공부하느냐를 끊임없이 고민하는 것보다 그냥 밀어봍이는 편이 낫습니다. ‘무엇을 하느냐’ 또는 ‘어떻게 하느냐’ 보다 중요한 건 ‘왜 하느냐’ 입니다.\n재밌게 읽었지만 이런 글이 있는 지는 기억이 없다 -_-. 타이탄의 도구들 중 글을 인용한. 그래도 난 낮에 하는 일이나 밤에 (어쩌다) 공부하는 하는 거나 비슷한 주제라 다행이네.\n그들이 낮에 무슨 일을 하는지 상관없다. 중요한 것은 그들이 회사에서 퇴근해 무엇을 하느냐다. 우리는 그들의 낮 시간에는 관심 없다. 십중팔구 그들은 돈을 벌기 위해 회사에서 시키는 일들을 하고 있을 테니까. 우리가 집중하는 건 그들의 취미가 무엇이냐다.\n재능을 타고나지 못했다고 포기할 필요는 없어요. 재능이 있는지 없는지도 끈기를 발휘하기 전에는 알 수 없고요. 결국 재능이 없는 걸 깨듣게 된다 해도 끈기를 기른다면, 재능보다 더 소중한 능력을 갖추게 되는 겁니다. 재능보다 더 중요한 건 끈기입니다. 인공지능의 시대, 가장 필요한 역량이 독창성인데요, 독창성의 첫 번째 재료가 바로 끈기입니다.\n마침 오늘 프로야구에서 양준혁 선수가 가지고 있는 최다 안타 갯수 기록을 박용택 선수가 갱신했다.\n한 시즌에서의 최대 안타도 그렇긴 하지만 누적 최대 안타 개수는 정말 수년간(양준혁 선수는 18년, 박용택 선수는 17년 동안) 꾸준히 성적을 내야 가능한 기록이다. 그야말로 끈기가 필요한. 끈기를 가지고 암흑기를 버티고 이렇게 성적을 낸 박용택 선수는 특히 변화에 잘 적응하기 위해 노력한 선수로 알려져있다. 슬럼프가 오거나 나이를 먹음에 따라 체력 조건이 달라지는 것을 새로운 타격 폼 등으로 보상해 가면서 늘 공부하는 모습을 보여왔다. 그 덕분에 대한민국 야구 역사에 남을 기록을 만들 수 있고, 또 꾸준히 오랫동안 좋은 성적으로 정상급 실력을 보여주고 있는 거다.\n","date":"2018-07-01T12:03:47+09:00","permalink":"https://cychong47.github.io/post/2018/did-you-write-in-every-morning/","summary":"\u003cp\u003e세바시 였던가, 공개 강의 동영상을 통해 처음 알게 된 김민식 PD.\n예전에 인기있었던 시트콤, ‘논스톱’을 만든 PD인데 MBC 파업과 관련되어 힘든 시간을 보내다 “영어책 한 권 외워봤니?”라는 독특한 제목의 영어 책으로 대중에 알려졌다. 그와 동시에 대입부터 시작해서 방송국 파업 때문에 경영진에 찍혀 고생하는 기간에 블로그를 통해 재기(?)에 성공한 특이한 이력을 가지고 있는데 시트콤 PD 답게 재밌는 입담을 통해 자신의 힘들었던 과거를 통해 의미있는 이야기를 많이 해줬던 걸로기억한다.\n매일 아침 써봤니? 는 제목 그대로 저자가 하고 있다는 매일 아침 글쓰기를 통해 변화된 인생에 대해 이야기해주고 있다.\u003c/p\u003e","title":"(책) 매일 아침 써봤니?"},{"content":"오늘 회사에서 점심 시간에 배운 mindmap 활용법\niThoughtX를 OS X, iOS용으로 모두 구입할 만큼 마인드맵에 관심이 있긴 한데 생각을 풀어낼 때 다양한 framework을 활용할 수 있다는 건 몰랐다. 관련된 책을 한번 읽어보면 좋겠네.\n오늘 강의해준 신 분은 무려 자기 이름을 걸로 책을 낸 저자 동종성 님\n","date":"2018-06-20T14:00:06+09:00","permalink":"https://cychong47.github.io/post/2018/mindmap/","summary":"\u003cp\u003e오늘 회사에서 점심 시간에 배운 mindmap 활용법\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2018/06/mindmap.png\" alt=\"mindmap\"\u003e\u003c/p\u003e\n\u003cp\u003eiThoughtX를 OS X, iOS용으로 모두 구입할 만큼 마인드맵에 관심이 있긴 한데 생각을 풀어낼 때 다양한 framework을 활용할 수 있다는 건 몰랐다. 관련된 책을 한번 읽어보면 좋겠네.\u003c/p\u003e\n\u003cp\u003e오늘 강의해준 신 분은 무려 자기 이름을 걸로 책을 낸 저자 동종성 님\u003cbr\u003e\n\u003cimg src=\"/images/2018/06/8982500995_1-1.jpg\" alt=\"8982500995_1-1\"\u003e\u003c/p\u003e","title":"생각 정리의 기술"},{"content":"이상하게 wordpress 버전이 올라가면 docker용 wordpress 버전도 함께 올라갈 텐데 아무리 최신 docker image를 받아 container를 만들어도 wordpress admin 계정에 들어가면 wordpress를 업데이트 해야 한다고 한다. docket store(http://store.docker.com)에 가면 분명히 wordpress 최신 버전으로 패키징되어 있는 데\u0026hellip;\n혹시나 하고 ansible-playbook을 보니 /var/www/html에 마운트되는 위치에 이전 버전의 wordpress 파일들이 존재하고 있었다.\nvolumes: - \u0026#34;/Users/cychong/Documents/wordpress/html:/var/www/html\u0026#34; - \u0026#34;/Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads\u0026#34; - \u0026#34;/Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini\u0026#34; 바로 첫번째 줄이 문제를 유발하고 있는 곳\u0026hellip; 내가 왜 굳이 저렇게 했을까 생각해 보니 저 디렉토리에 바로 wp-content가 있고, 그 아래 themes와 plugins가 있다. 처음 docker로 wordpress를 띄울 때 이미 설치한 theme이나 plugin이 wordpress docker 버전이 올라가서 새로 container를 만들 때마다 다시 설치해야 하는 번거로움을 피하려고 저렇게 한 듯 하다. 지금 생각하면 참 바보같은\u0026hellip;\n이렇게 수정한 후에 정상적으로 최신 버전의 wordpress를 만날 수 있게 되었다.\nvolumes: - \u0026#34;/Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads\u0026#34; - \u0026#34;/Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini\u0026#34; - \u0026#34;/Users/cychong/Dropbox/Apps/wordpress/plugins/easy-video-player:/var/www/html/wp-content/plugins/easy-video-player\u0026#34; - \u0026#34;/Users/cychong/Dropbox/Apps/wordpress/plugins/jetpack:/var/www/html/wp-content/plugins/jetpack\u0026#34; - \u0026#34;/Users/cychong/Dropbox/Apps/wordpress/plugins/wordpress-importer:/var/www/html/wp-content/plugins/wordpress-importer\u0026#34; - \u0026#34;/Users/cychong/Dropbox/Apps/wordpress/themes/independent-publisher:/var/www/html/wp-content/themes/independent-publisher\u0026#34; ","date":"2018-06-14T15:13:52+09:00","permalink":"https://cychong47.github.io/post/2018/update-ansible-playbook-for-wordpress/","summary":"\u003cp\u003e이상하게 wordpress 버전이 올라가면 docker용 wordpress 버전도 함께 올라갈 텐데 아무리 최신 docker image를 받아 container를 만들어도 wordpress admin 계정에 들어가면 wordpress를 업데이트 해야 한다고 한다.\ndocket store(\u003ca href=\"http://store.docker.com\"\u003ehttp://store.docker.com\u003c/a\u003e)에 가면 분명히 wordpress 최신 버전으로 패키징되어 있는 데\u0026hellip;\u003c/p\u003e\n\u003cp\u003e혹시나 하고 ansible-playbook을 보니 \u003ccode\u003e/var/www/html\u003c/code\u003e에 마운트되는 위치에 이전 버전의 wordpress 파일들이 존재하고 있었다.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e      volumes:\n         - \u0026#34;/Users/cychong/Documents/wordpress/html:/var/www/html\u0026#34;\n         - \u0026#34;/Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads\u0026#34;\n         - \u0026#34;/Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini\u0026#34;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e바로 첫번째 줄이 문제를 유발하고 있는 곳\u0026hellip;\n내가 왜 굳이 저렇게 했을까 생각해 보니 저 디렉토리에 바로 \u003ccode\u003ewp-content\u003c/code\u003e가 있고, 그 아래 \u003ccode\u003ethemes\u003c/code\u003e와 \u003ccode\u003eplugins\u003c/code\u003e가 있다. 처음 docker로 wordpress를 띄울 때 이미 설치한 theme이나 plugin이 wordpress docker 버전이 올라가서 새로 container를 만들 때마다 다시 설치해야 하는 번거로움을 피하려고 저렇게 한 듯 하다. 지금 생각하면 참 바보같은\u0026hellip;\u003c/p\u003e","title":"Update ansible-playbook for wordpress"},{"content":"문제 블로그 보는 거 자체는 문제가 없는데 admin 계정으로 로그인 시도하면 반복해서 로그인 페이지로 redirect됨\nhttp://sosa0sa.com/wp-login.php?redirect_to=http://sosa0sa.com/wp-admin/\u0026amp;reauth=1 구글링을 하니 대부분 쿠키를 초기화하고, theme, plugin등을 초기화하라는 의견이 대부분. 모두 따라해 봤으니 제대로 동작하지 않는다\u0026hellip; -_-;;;\n마지막으로 wp_usermeta table에서 session_token 값을 초기화하라는 말이 있어 이것도 해 보기로. phpmyadmin을 설치해서 table의 값을 변경하라고 해서 phpmyadmin을 역시 docker로 설치해 보기로\nhttps://wordpress.org/support/topic/possible-fix-for-sudden-redirect-loop-at-wp-login-with-reauth1/\nPhpmyadmin docker 설치 Wordpress ansible-playbook 에 다음과 같이 추가\nlinks를 통해 mysql container와 연결하고 PMA_HOST를 해당 mysql container의 name으로 지정하는 것이 중요한 내용임. 처음에는 PMA_HOST를 “localhost”나 “127.0.0.1”로 지정하니 정상적으로 mysql에 로그인이 되지 않음\n- name: Start phpmyadmin docker_container: name: phpmyadmin image: phpmyadmin/phpmyadmin links: - mysql:mysql # always pull the latest image pull: no state: started recreate: yes restart_policy: \u0026#34;always\u0026#34; ports: - \u0026#34;8181:80\u0026#34; env: PMA_HOST: \u0026#34;mysql\u0026#34; MYSQL_USERNAME: \u0026#34;root\u0026#34; MYSQL_ROOT_PASSWORD: \u0026#34;root_password\u0026#34; 그런데 mysql로 접속했는데 mysql의 DB 내용이 정상적으로 나오지 않음. 그런데 phpmyadmin 을 설치한 후 주소(http://192.168.1.200:8181)를 접근하니 예전에 본것과 다르게 뭔가 허전한 화면만 나온다.\n아는 것도 없지만 그래도 혹시나 하고 docker에 bash로 접근해서 얼마전에 influxDB에서 사용해 본 명령어가 같을 듯 해서 입력해 봤는데 이것도 제대로 동작하지 않는다.\nmini2:~ cychong$ docker exec -it a7681c4ec35e bash root@a7681c4ec35e:/# mysql ERROR 1045 (28000): Access denied for user \u0026#39;root\u0026#39;@\u0026#39;localhost\u0026#39; (using password: YES) root@a7681c4ec35e:/# mysql -u root -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 39 Server version: 8.0.11 MySQL Community Server - GPL Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. mysql\u0026gt; show databases; ERROR 1449 (HY000): The user specified as a definer (\u0026#39;mysql.infoschema\u0026#39;@\u0026#39;localhost\u0026#39;) does not exist web으로 다시 phpmyadmin 화면에 접근했을 때 나온 에러 메시지를 찾아보기로 바로 이거\nThe user specified as a definer (\u0026#39;mysql.infoschema\u0026#39;@\u0026#39;localhost\u0026#39;) does not exist 구글링을 하니 역시나 흔한 문제인 듯. 다음과 같은 글을 찾을 수 있어 글에서 시킨대로 해봤다.\nhttps://stackoverflow.com/questions/49992868/mysql-errorthe-user-specified-as-a-definer-mysql-infoschemalocalhost-doe\n암호는 container 생성할 때 인자로 넣어주는 MYSQL_ROOT_PASSWORD값을 사용한다. wordpress.yaml 파일에서 확인 가능..\nroot@a7681c4ec35e:/var/log# mysql_upgrade -u root -p Enter password: Checking if update is needed. Checking server version. Running queries to upgrade MySQL server. Upgrading system table data. Checking system database. mysql.columns_priv OK mysql.component OK mysql.db OK mysql.default_roles OK mysql.engine_cost OK mysql.func OK mysql.general_log OK mysql.global_grants OK mysql.gtid_executed OK mysql.help_category OK mysql.help_keyword OK mysql.help_relation OK mysql.help_topic OK mysql.innodb_index_stats OK mysql.innodb_table_stats OK mysql.ndb_binlog_index OK mysql.password_history OK mysql.plugin OK mysql.procs_priv OK mysql.proxies_priv OK mysql.role_edges OK mysql.server_cost OK mysql.servers OK mysql.slave_master_info OK mysql.slave_relay_log_info OK mysql.slave_worker_info OK mysql.slow_log OK mysql.tables_priv OK mysql.time_zone OK mysql.time_zone_leap_second OK mysql.time_zone_name OK mysql.time_zone_transition OK mysql.time_zone_transition_type OK mysql.user OK Found outdated sys schema version 1.5.1. Upgrading the sys schema. Checking databases. sys.sys_config OK wordpress_db.wp_commentmeta OK wordpress_db.wp_comments OK wordpress_db.wp_links OK wordpress_db.wp_options OK wordpress_db.wp_postmeta OK wordpress_db.wp_posts OK wordpress_db.wp_term_relationships OK wordpress_db.wp_term_taxonomy OK wordpress_db.wp_termmeta OK wordpress_db.wp_terms OK wordpress_db.wp_usermeta OK wordpress_db.wp_users OK Upgrade process completed successfully. Checking if update is needed. root@a7681c4ec35e:/var/log# 이제 다시 phpmyadmin화면을 접근하니 이제 정상적인(?) 뭔가가 보인다.\n뭔가 제대로 되는 것 같다. 다시 wordpress admin 계정으로 로그인하니 이젠 된다!!! Finally\u0026hellip;\n그래도 안될때 (2019.02.28) wordpress가 5.1로 업데이트 되어 그걸 적용했더니 database 파일도 업그레이드를 해야 한다고. 그래서 해라 그랬더니 또 로그인이 안된다. 이번에는 위의 mysql_upgrade 명령을 써도 안되고\u0026hellip;.\n다행히 구글링에서 유용한 정보를 찾았다. 처음 본 순간 왠지 잘 될 것 같았는데 정말로 한번에 문제를 해결해줬다. https://www.fixrunner.com/cannot-login-wordpress-admin-area/\n한 줄 요약하면 mysql database에 저장되어 있는 로그인 암호를 직접 변경하는 것.\nwordpress database에서 wp_user라는 테이블의 user_pass라는 필드를 변경하는 거다. phpmyadmin으로 수정하는 창에서 보니 결국(?) 이런 sql 명령으로 변경할 수 있다고 한다. 아래 새 암호에 원하는 새로운 암호를 넣으면 그걸 md5 hash한 값을 user_pass 필드에 저장한다.\nUPDATE `wp_users` SET `user_pass` = MD5(\u0026#39;새 암호\u0026#39;) WHERE `wp_users`.`ID` = 1; 다행히 오랫동안 헤매지 않고 해결해서 다행이다.\n","date":"2018-06-14T14:21:13+09:00","permalink":"https://cychong47.github.io/post/2018/wordpress-admin-login-fail/","summary":"\u003ch2 id=\"문제\"\u003e문제\u003c/h2\u003e\n\u003cp\u003e블로그 보는 거 자체는 문제가 없는데 admin 계정으로 로그인 시도하면 반복해서 로그인 페이지로 redirect됨\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ehttp://sosa0sa.com/wp-login.php?redirect_to=http://sosa0sa.com/wp-admin/\u0026amp;reauth=1\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e구글링을 하니 대부분 쿠키를 초기화하고, theme, plugin등을 초기화하라는 의견이 대부분. 모두 따라해 봤으니 제대로 동작하지 않는다\u0026hellip; \u003ccode\u003e-_-\u003c/code\u003e;;;\u003c/p\u003e\n\u003cp\u003e마지막으로 wp_usermeta table에서 session_token 값을 초기화하라는 말이 있어 이것도 해 보기로. \u003ccode\u003ephpmyadmin\u003c/code\u003e을 설치해서 table의 값을 변경하라고 해서 \u003ccode\u003ephpmyadmin\u003c/code\u003e을 역시 docker로 설치해 보기로\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://wordpress.org/support/topic/possible-fix-for-sudden-redirect-loop-at-wp-login-with-reauth1/\"\u003ehttps://wordpress.org/support/topic/possible-fix-for-sudden-redirect-loop-at-wp-login-with-reauth1/\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"phpmyadmin-docker-설치\"\u003ePhpmyadmin docker 설치\u003c/h2\u003e\n\u003cp\u003eWordpress ansible-playbook 에 다음과 같이 추가\u003c/p\u003e\n\u003cp\u003elinks를 통해 mysql container와 연결하고 PMA_HOST를 해당 mysql container의 name으로 지정하는 것이 중요한 내용임.\n처음에는 PMA_HOST를 “localhost”나 “127.0.0.1”로 지정하니 정상적으로 mysql에 로그인이 되지 않음\u003c/p\u003e","title":"wordpress admin 계정 복구"},{"content":"Time-series data를 python을 이용해서 influxDB에 저장하고, Grafana로 그래프를 보여주는 예제\nhttps://github.com/cychong47/influxdb_example.git\nInstall Grafana and influxDB Install Grafana 직접 호스트에 설치할 수도 있지만, 세상 편하게 만들어준 docker를 이용해서 grafana, influxdb등을 설치하자.\nmbpr15:~ cychong$ docker pull grafana/grafana Using default tag: latest latest: Pulling from grafana/grafana f2aa67a397c4: Pull complete 89573effc7c8: Pull complete b55c103da375: Pull complete Digest: sha256:364bec4a39ecbec744ea4270aae35f6554eb6f2047b3ee08f7b5f1134857c32c Status: Downloaded newer image for grafana/grafana:latest Start grafana\nmbpr15:~ cychong$ docker run -d -p 3000:3000 —name grafana grafana/grafana 148894d7009259b02b04e1a98467f549400be91f9b055f8686557d69b9339e4b Install influxDB influxdb도 docker 명령어 하나로 설치\ninfluxdb | Docker Documentation\nmbpr15:~ cychong$ docker pull influxdb Using default tag: latest latest: Pulling from library/influxdb cc1a78bfd46b: Pull complete 6861473222a6: Pull complete 7e0b9c3b5ae0: Pull complete ef1cd6af9147: Pull complete 07d71592a7b6: Pull complete 4df1ab172fbc: Pull complete 6f607c73c187: Pull complete 3fd297f39292: Pull complete Digest: sha256:e3efb51395d630a912c3c24edb7567ec1ac01d3dfdc39f27f53ca0e15c3da797 Status: Downloaded newer image for influxdb:latest Install influxdb module for python python에서 직접 influxDB를 사용하려면 influxdb 모듈을 사용한다\nmbpr15:~ cychong$ pip3 install influxdb Collecting influxdb Downloading https://files.pythonhosted.org/packages/8d/79/7972c12e393080eda6920583c9c2ed2206771da7f6341c8971a2c02ff3d3/influxdb-5.0.0-py2.py3-none-any.whl (70kB) 100% |████████████████████████████████| 71kB 709kB/s Requirement already satisfied: requests\u0026gt;=2.17.0 in /usr/local/lib/python3.6/site-packages (from influxdb) (2.18.4) Collecting python-dateutil\u0026gt;=2.6.0 (from influxdb) Downloading https://files.pythonhosted.org/packages/cf/f5/af2b09c957ace60dcfac112b669c45c8c97e32f94aa8b56da4c6d1682825/python_dateutil-2.7.3-py2.py3-none-any.whl (211kB) 100% |████████████████████████████████| 215kB 2.9MB/s Collecting pytz (from influxdb) Downloading https://files.pythonhosted.org/packages/dc/83/15f7833b70d3e067ca91467ca245bae0f6fe56ddc7451aa0dc5606b120f2/pytz-2018.4-py2.py3-none-any.whl (510kB) 100% |████████████████████████████████| 512kB 5.0MB/s Requirement already satisfied: six\u0026gt;=1.10.0 in /usr/local/lib/python3.6/site-packages (from influxdb) (1.11.0) Requirement already satisfied: certifi\u0026gt;=2017.4.17 in /usr/local/lib/python3.6/site-packages (from requests\u0026gt;=2.17.0-\u0026gt;influxdb) (2017.11.5) Requirement already satisfied: idna\u0026lt;2.7,\u0026gt;=2.5 in /usr/local/lib/python3.6/site-packages (from requests\u0026gt;=2.17.0-\u0026gt;influxdb) (2.6) Requirement already satisfied: chardet\u0026lt;3.1.0,\u0026gt;=3.0.2 in /usr/local/lib/python3.6/site-packages (from requests\u0026gt;=2.17.0-\u0026gt;influxdb) (3.0.4) Requirement already satisfied: urllib3\u0026lt;1.23,\u0026gt;=1.21.1 in /usr/local/lib/python3.6/site-packages (from requests\u0026gt;=2.17.0-\u0026gt;influxdb) (1.22) hacking 1.0.0 has requirement flake8\u0026lt;2.6.0,\u0026gt;=2.5.4, but you’ll have flake8 3.5.0 which is incompatible. hacking 1.0.0 has requirement mccabe==0.2.1, but you’ll have mccabe 0.6.1 which is incompatible. hacking 1.0.0 has requirement pyflakes==0.8.1, but you’ll have pyflakes 1.6.0 which is incompatible. docker-compose 1.17.1 has requirement requests!=2.11.0,\u0026lt;2.12,\u0026gt;=2.6.1, but you’ll have requests 2.18.4 which is incompatible. Installing collected packages: python-dateutil, pytz, influxdb Successfully installed influxdb-5.0.0 python-dateutil-2.7.3 pytz-2018.4 Start influxdb Getting Started with Python and Influxdb | InfluxData\nmbpr15:working cychong$ mkdir influxdb mbpr15:working cychong$ cd influxdb/ mbpr15:influxdb cychong$ ls mbpr15:influxdb cychong$ docker run -d -p 8086:8086 -v $PWD:/var/lib/influxdb influxdb 5088889ce21c9c9e2249db701694aa0bd39429371b5dababcf6ebb8c2e7598d3 To have customized config file for influxdb. First generate the default configuration file and update it. Then restart influxdb with that config file.\nmbpr15:influxdb cychong$ docker run —rm influxdb influxd config \u0026gt; influxdb.conf Merging with configuration at: /etc/influxdb/influxdb.conf mbpr15:influxdb cychong$ docker run -d -p 8086:8086 -v $PWD:/var/lib/influxdb -v $PWD/influxdb.conf:/etc/influxdb/influxdb.conf influxdb -config /etc/influxdb/influxdb.conf 1d9ac4ffdca38b2c627da134273d7570c9c74182cb4bbedb8deebf09c3e5dc0a Influx db write error influxdb-python/tutorial.py at master · influxdata/influxdb-python · GitHub 샘플코드를 그대로 실행시키면 다음과 같은 에러를 만난다.\nmbpr15:influxdb cychong$ python3 influxdb-ex.py Create database: example Create a retention policy Switch user: smly Write points: [{\u0026#39;measurement\u0026#39;: \u0026#39;cpu_load_short\u0026#39;, \u0026#39;tags\u0026#39;: {\u0026#39;host\u0026#39;: \u0026#39;server01\u0026#39;, \u0026#39;region\u0026#39;: \u0026#39;us-west\u0026#39;}, \u0026#39;time\u0026#39;: \u0026#39;2009-11-10T23:00:00Z\u0026#39;, \u0026#39;fields\u0026#39;: {\u0026#39;Float_value\u0026#39;: 0.64, \u0026#39;Int_value\u0026#39;: 3, \u0026#39;String_value\u0026#39;: \u0026#39;Text\u0026#39;, \u0026#39;Bool_value\u0026#39;: True}}] Traceback (most recent call last): File \u0026#34;influxdb-ex.py\u0026#34;, line 73, in \u0026lt;module\u0026gt; main(host=args.host, port=args.port) File \u0026#34;influxdb-ex.py\u0026#34;, line 45, in main client.write_points(json_body) File \u0026#34;/usr/local/lib/python3.6/site-packages/influxdb/client.py\u0026#34;, line 468, in write_points tags=tags, protocol=protocol) File \u0026#34;/usr/local/lib/python3.6/site-packages/influxdb/client.py\u0026#34;, line 532, in _write_points protocol=protocol File \u0026#34;/usr/local/lib/python3.6/site-packages/influxdb/client.py\u0026#34;, line 312, in write headers=headers File \u0026#34;/usr/local/lib/python3.6/site-packages/influxdb/client.py\u0026#34;, line 271, in request raise InfluxDBClientError(response.content, response.status_code) influxdb.exceptions.InfluxDBClientError: 400: {\u0026#34;error\u0026#34;:\u0026#34;partial write: points beyond retention policy dropped=1\u0026#34;} 무슨 말인가 찾아보니 retention policy라는 건 db에 저장하는 데이터가 특정 기준이상으로 오래된 것이면 저장을 불허하기 때문에 이 policy에 걸려 write 동작이 실패했다는 것이다. points beyond retention policy !! what does this mean?? · Issue #9093 · influxdata/influxdb · GitHub\n참고로 예제에서는 retention policy를 3일로 지정하고 있는데 샘플용 json 데이터에 지정된 시각이 2009-11-10T23:00:00Z라 에러가 발생한 것.\nprint(\u0026#34;Create a retention policy\u0026#34;) client.create_retention_policy(\u0026#39;awesome_policy\u0026#39;, \u0026#39;3d\u0026#39;, 3, default=True) 샘플에서 time 필드를 현재 시간으로 변경한다. 이때 influxdb가 원하는 시간 형태로 표시해야 한다. python - How to use time field in adding metrics data to the influx db? - Stack Overflow을 참고하여 수정.\nfrom datetime import datetime current_time = datetime.utcnow().strftime(‘%Y-%m-%dT%H:%M:%SZ’) json_body[0][\u0026#39;time\u0026#39;] = datetime.utcnow().strftime(\u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) 수정 후 정상적으로 동작\nmbpr15:influxdb cychong$ python3 influxdb-ex.py Create database: example Create a retention policy Switch user: smly Write points: [{‘measurement’: ‘cpu_load_short’, ‘tags’: {‘host’: ‘server01’, ‘region’: ‘us-west’}, ‘time’: ‘2018-06-06T03:08:17Z’, ‘fields’: {‘Float_value’: 0.64, ‘Int_value’: 3, ‘String_value’: ‘Text’, ‘Bool_value’: True}}] Querying data: select value from cpu_load_short; Result: ResultSet({}) Switch user: root Drop database: example 주기적으로 데이터를 influxdb에 저장 이제 주기적으로 데이터를 db에 저장해서 말그래도 time-series data가 되도록 한다.\nimport argparse import time import random from datetime import datetime from influxdb import InfluxDBClient def setup_db(host, port): user = \u0026#39;root\u0026#39; password = \u0026#39;root\u0026#39; dbname = \u0026#39;example\u0026#39; dbuser = \u0026#39;smly\u0026#39; dbuser_password = \u0026#39;my_secret_password\u0026#39; client = InfluxDBClient(host, port, user, password, dbname) print(\u0026#34;Create database: \u0026#34; + dbname) client.create_database(dbname) print(\u0026#34;Create a retention policy\u0026#34;) client.create_retention_policy(\u0026#39;awesome_policy\u0026#39;, \u0026#39;3d\u0026#39;, 3, default=True) print(\u0026#34;Switch user: \u0026#34; + dbuser) client.switch_user(dbuser, dbuser_password) return client def add_data(client, dl_tp, ul_tp): json_body = [ { \u0026#34;measurement\u0026#34;: \u0026#34;throughput\u0026#34;, \u0026#34;tags\u0026#34;: { \u0026#34;host\u0026#34;: \u0026#34;server01\u0026#34;, \u0026#34;region\u0026#34;: \u0026#34;us-west\u0026#34; }, \u0026#34;time\u0026#34;: \u0026#34;2009-11-10T23:00:00Z\u0026#34;, \u0026#34;fields\u0026#34;: { \u0026#34;dl_tp\u0026#34; : 0, \u0026#34;ul_tp\u0026#34; : 0, } } ] json_body[0][\u0026#39;time\u0026#39;] = datetime.utcnow().strftime(\u0026#39;%Y-%m-%dT%H:%M:%SZ\u0026#39;) json_body[0][\u0026#39;fields\u0026#39;][\u0026#39;dl_tp\u0026#39;] = int(dl_tp) json_body[0][\u0026#39;fields\u0026#39;][\u0026#39;ul_tp\u0026#39;] = int(ul_tp) #print(\u0026#34;Write points: {0}\u0026#34;.format(json_body)) client.write_points(json_body) def main(host=\u0026#39;localhost\u0026#39;, port=8086): \u0026#34;\u0026#34;\u0026#34;Instantiate a connection to the InfluxDB.\u0026#34;\u0026#34;\u0026#34; client = setup_db(host, port) while True: dl_tp = random.uniform(150,200) ul_tp = random.uniform(50,70) add_data(client, dl_tp, ul_tp) time.sleep(1) def parse_args(): \u0026#34;\u0026#34;\u0026#34;Parse the args.\u0026#34;\u0026#34;\u0026#34; parser = argparse.ArgumentParser( description=\u0026#39;example code to play with InfluxDB\u0026#39;) parser.add_argument(\u0026#39;--host\u0026#39;, type=str, required=False, default=\u0026#39;localhost\u0026#39;, help=\u0026#39;hostname of InfluxDB http API\u0026#39;) parser.add_argument(\u0026#39;--port\u0026#39;, type=int, required=False, default=8086, help=\u0026#39;port of InfluxDB http API\u0026#39;) return parser.parse_args() if __name__ == \u0026#39;__main__\u0026#39;: args = parse_args() main(host=args.host, port=args.port) Influxdb에서 데이터 확인 influxdb container에 접속해서 cli 명령을 통해 db 내용을 확인해 본다.\nmbpr15:influxdb cychong$ docker exec -it 1d9ac4ffdca3 influx Connected to http://localhost:8086 version 1.5.3 InfluxDB shell version: 1.5.3 \u0026gt; use example Using database example \u0026gt; show field keys; name: throughput fieldKey fieldType -------- --------- dl_tp integer ul_tp integer \u0026gt; select * from throughput; name: throughput time dl_tp host region ul_tp ---- ----- ---- ------ ----- 1528255918000000000 0 server01 us-west 0 1528255919000000000 0 server01 us-west 0 1528255920000000000 0 server01 us-west 0 1528255921000000000 0 server01 us-west 0 1528255922000000000 0 server01 us-west 0 ... 1528256939000000000 199 server01 us-west 50 1528256940000000000 189 server01 us-west 62 1528256941000000000 163 server01 us-west 50 1528256942000000000 152 server01 us-west 52 1528256943000000000 182 server01 us-west 69 1528256944000000000 191 server01 us-west 55 1528256945000000000 190 server01 us-west 61 1528256946000000000 178 server01 us-west 68 \u0026gt; Grafana에서 influxdb에 저장된 정보 읽어오기 Grafana에서 data source로 influxdb 지정.(URL 필드에 http://localhost:8086 지정) 이상하게도 같은 머신에서 돌고 있는 influxdb의 주소를 localhost로 지정하면 연결이 안된다는 에러가 난다.\n머신에 할당된 다른 IP를 지정하면 정상적으로 설정(이때는 스타벅스에서 실행했는데 이때 할당된 IP가 172.20.10.3 이었다) Everything is working finally Tips for customizing grafana dashboard Metric 설정할 때는 FROM에서 influxDB의 measurement를 선택하면 아래 SELECT의 필드에 자동으로 선택할 수 있는 fields가 제시된다.\ninfluxDB에 정보를 저장할 때 사용한 json과 비교해 보면 fields 에 정의했던 키들이 제시된다. GROUP BY 는 데이터 중 특정 종류에 속하는 것만 보여주고 싶을 때 사용할 수 있다. 예를 들어 fields를 dl_tp와 ul_tp로 정의하지 않고, tags에 direction이라는 필드를 두고, fields는 그냥 tp로 정의할 수 있다. 즉 위 예제는 하나의 데이터 셋에 ul_tp와 dl_tp가 모두 있지만, UL tp만을 가진 데이터 셋과 DL tp만을 가진 데이터 셋으로 분리하여 influxdb에 저장할 수 있다. 이 경우 DL tp만을 가진 데이터 셋만으로 metric을 한정하려면 아래 있는 GROUP BY을 사용하여 tag(diretion)을 선택하면 되지 않을까? Axes 의 unit을 데이터에 맞는 적절한 것으로 선택하면 데이터의 특성을 강조할 수 있다. 아래는 data rate의 bits/sec를 선택한 경우이다.(데이터 값이 이미 Mbps로 전달된 경우에는 이를 고려하여 megabits/sec를 선택하면 된다)\n","date":"2018-06-06T04:33:06+09:00","permalink":"https://cychong47.github.io/post/2018/grafana-influxdb-and-python/","summary":"\u003cp\u003eTime-series data를 python을 이용해서 influxDB에 저장하고, Grafana로 그래프를 보여주는 예제\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/cychong47/influxdb_example.git\"\u003ehttps://github.com/cychong47/influxdb_example.git\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"install-grafana-and-influxdb\"\u003eInstall Grafana and influxDB\u003c/h1\u003e\n\u003ch2 id=\"install-grafana\"\u003eInstall Grafana\u003c/h2\u003e\n\u003cp\u003e직접 호스트에 설치할 수도 있지만, 세상 편하게 만들어준 docker를 이용해서 grafana, influxdb등을 설치하자.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:~ cychong$ docker pull grafana/grafana \nUsing default tag: latest\nlatest: Pulling from grafana/grafana\nf2aa67a397c4: Pull complete \n89573effc7c8: Pull complete \nb55c103da375: Pull complete \nDigest: sha256:364bec4a39ecbec744ea4270aae35f6554eb6f2047b3ee08f7b5f1134857c32c\nStatus: Downloaded newer image for grafana/grafana:latest\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eStart \u003ccode\u003egrafana\u003c/code\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:~ cychong$ docker run -d -p 3000:3000 —name grafana grafana/grafana \n148894d7009259b02b04e1a98467f549400be91f9b055f8686557d69b9339e4b\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"install-influxdb\"\u003eInstall influxDB\u003c/h2\u003e\n\u003cp\u003einfluxdb도 docker 명령어 하나로 설치\u003c/p\u003e","title":"Grafana, influxDB and python"},{"content":"Install Elastic Stack(ELK stack) with docker mbpr15:elk-wireshark cychong$ git clonehttps://github.com/deviantony/docker-elk.git git: \u0026#39;clonehttps://github.com/deviantony/docker-elk.git\u0026#39; is not a git command. See \u0026#39;git --help\u0026#39;. mbpr15:elk-wireshark cychong$ git clone https://github.com/deviantony/docker-elk.git Cloning into \u0026#39;docker-elk\u0026#39;... remote: Counting objects: 1235, done. remote: Total 1235 (delta 0), reused 0 (delta 0), pack-reused 1235 Receiving objects: 100% (1235/1235), 259.29 KiB | 77.00 KiB/s, done. Resolving deltas: 100% (470/470), done. mbpr15:elk-wireshark cychong$ cd elk mbpr15:elk-wireshark cychong$ cd docker-elk/ mbpr15:docker-elk cychong$ ls LICENSE\telasticsearch\tlogstash README.md\textensions docker-compose.yml\tkibana Install ELK with docker-compose mbpr15:docker-elk cychong$ docker-compose up -d Creating network \u0026#34;docker-elk_elk\u0026#34; with driver \u0026#34;bridge\u0026#34; Building elasticsearch Step 1/1 : FROM docker.elastic.co/elasticsearch/elasticsearch-oss:6.2.4 6.2.4: Pulling from elasticsearch/elasticsearch-oss 469cfcc7a4b3: Pull complete 8e27facfa9e0: Pull complete cdd15392adc7: Pull complete 19ff08a29664: Pull complete ddc4fd93fdcc: Pull complete b723bede0878: Pull complete Digest: sha256:2d9c774c536bd1f64abc4993ebc96a2344404d780cbeb81a8b3b4c3807550e57 Status: Downloaded newer image for docker.elastic.co/elasticsearch/elasticsearch-oss:6.2.4 ---\u0026gt; 3822ba554fe9 Successfully built 3822ba554fe9 Successfully tagged docker-elk_elasticsearch:latest WARNING: Image for service elasticsearch was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`. Building logstash Step 1/1 : FROM docker.elastic.co/logstash/logstash-oss:6.2.4 6.2.4: Pulling from logstash/logstash-oss 469cfcc7a4b3: Already exists b4cfa2eb1616: Pull complete ec994fa6fa7f: Pull complete ccf455902ac6: Pull complete 6d54f3767ae5: Pull complete af0dd1a720da: Pull complete 457dbabd3f63: Pull complete f2c481bd6da1: Pull complete d04342e2b9a1: Pull complete e8bca7e9b0d9: Pull complete d0096563f301: Pull complete Digest: sha256:28668a65f6b6a4f1e2abef7aa3fd3b9c8476a16aa5bebc1a9acf0f7de5b80eef Status: Downloaded newer image for docker.elastic.co/logstash/logstash-oss:6.2.4 ---\u0026gt; 0bade66b6bee Successfully built 0bade66b6bee Successfully tagged docker-elk_logstash:latest WARNING: Image for service logstash was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`. Building kibana Step 1/1 : FROM docker.elastic.co/kibana/kibana-oss:6.2.4 6.2.4: Pulling from kibana/kibana-oss 469cfcc7a4b3: Already exists 78e4c5fdc069: Pull complete d9ecdaefa1b8: Pull complete c8e48c8f74d7: Pull complete 1606c56cdbff: Pull complete 4e23ce1503d4: Pull complete d36b703b3f90: Pull complete da5da7625f92: Pull complete Digest: sha256:1d1f9bac326bf276010df82a2b4593619f48a5207619e8817c8b20d5a1bb3547 Status: Downloaded newer image for docker.elastic.co/kibana/kibana-oss:6.2.4 ---\u0026gt; 32510971af4e Successfully built 32510971af4e Successfully tagged docker-elk_kibana:latest WARNING: Image for service kibana was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`. Creating docker-elk_elasticsearch_1 ... done Creating docker-elk_kibana_1 ... done Creating docker-elk_logstash_1 ... done mbpr15:docker-elk cychong$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 4fc052e81fae docker-elk_logstash “/usr/local/bin/dock…” 9 minutes ago Up 9 minutes 5044/tcp, 0.0.0.0:5000-\u0026gt;5000/tcp, 9600/tcp docker-elk_logstash_1 46f049297c7b docker-elk_kibana “/bin/bash /usr/loca…” 9 minutes ago Up 9 minutes 0.0.0.0:5601-\u0026gt;5601/tcp docker-elk_kibana_1 8ff911ebab03 docker-elk_elasticsearch “/usr/local/bin/dock…” 9 minutes ago Up 9 minutes 0.0.0.0:9200-\u0026gt;9200/tcp, 0.0.0.0:9300-\u0026gt;9300/tcp docker-elk_elasticsearch_1 mbpr15:docker-elk cychong$ curl http://localhost:9200 { “name” : “npNAiWg”, “cluster_name” : “docker-cluster”, “cluster_uuid” : “7nY4KVvNS4epY4Z80NCUZw”, “version” : { “number” : “6.2.4”, “build_hash” : “ccec39f”, “build_date” : “2018-04-12T20:37:28.497551Z”, “build_snapshot” : false, “lucene_version” : “7.2.1”, “minimum_wire_compatibility_version” : “5.6.0”, “minimum_index_compatibility_version” : “5.0.0” }, “tagline” : “You Know, for Search” } Open http://localhost:5601 with browser install metricbeats with docker - check the latest version from elastic.co docker pull docker.elastic.co/beats/metricbeat:6.2.4 metricbeat 는 시스템 통계 정보를 수집해서 elasticsearch로 보내는 역할을 함. 다양한 모듈들이 modules.d 디렉토리 아래 위치하고, metricbeats.yml은 수집한 정보를 보낼 위치를 변경하는 정도면 기본적인 동작을 확인할 수 있음.\nmbpr15:metricbeat-6.2.4-darwin-x86_64 cychong$ tree -f modules.d/ modules.d ├── modules.d/aerospike.yml.disabled ├── modules.d/apache.yml.disabled ├── modules.d/ceph.yml.disabled ├── modules.d/couchbase.yml.disabled ├── modules.d/docker.yml.disabled ├── modules.d/dropwizard.yml.disabled ├── modules.d/elasticsearch.yml.disabled ├── modules.d/etcd.yml.disabled ├── modules.d/golang.yml.disabled ├── modules.d/graphite.yml.disabled ├── modules.d/haproxy.yml.disabled ├── modules.d/http.yml.disabled ├── modules.d/jolokia.yml.disabled ├── modules.d/kafka.yml.disabled ├── modules.d/kibana.yml.disabled ├── modules.d/kubernetes.yml.disabled ├── modules.d/logstash.yml.disabled ├── modules.d/memcached.yml.disabled ├── modules.d/mongodb.yml.disabled ├── modules.d/mysql.yml.disabled ├── modules.d/nginx.yml.disabled ├── modules.d/php_fpm.yml.disabled ├── modules.d/postgresql.yml.disabled ├── modules.d/prometheus.yml.disabled ├── modules.d/rabbitmq.yml.disabled ├── modules.d/redis.yml.disabled ├── modules.d/system.yml ├── modules.d/uwsgi.yml.disabled ├── modules.d/vsphere.yml.disabled ├── modules.d/windows.yml.disabled └── modules.d/zookeeper.yml.disabled 0 directories, 31 files 아래에서 hosts의 기본값은 localhost이므로, 필요한 경우 elasticisearch가 동작하고 있는 특정 서버의 IP로 변경한다.\n#-------------------------- Elasticsearch output ------------------------------ output.elasticsearch: # Array of hosts to connect to. hosts: [\u0026#34;192.168.1.70:9200\u0026#34;] MBPr15와 mini2 에서 각각 metricbeat를 실행해서 metric 정보를 elasticsearch로 보내도록 함. 아래는 기본 yml인 metricbeat.yml에서 위 output부분만 수정하여 memphis.yml로 저장후 사용\nmbpr15:metricbeat-6.2.4-darwin-x86_64 cychong$ sudo ./metricbeat -e -c memphis.yml mini2:metricbeat-6.2.4-darwin-x86_64 cychong$ ./metricbeat -e -c mini2.yaml 이렇게 하면 화면에 주기적으로 elasticsearch로 보내는 정보를 출력한다.(전체 정보는 아닐 듯\u0026hellip;.) 이렇게 옵션을 주면 화면에 별도의 로그 출력이 없다.\nsudo metricbeat -e \u0026gt; /dev/null 2\u0026gt;\u0026amp;1 \u0026amp; 이걸 하긴 했는데 굳이 따로 할 필요는 없는 듯. Kibana에 default dashboard를 생성하는 거라고 하는데(다시 확인해 보자)\nsudo ./metricbeat setup -c memphis.yml mbpr15:~ cychong$ curl -XGET \u0026#39;localhost:9200/_cat/indices?v\u0026amp;pretty\u0026#39; health status index uuid pri rep docs.count docs.deleted store.size pri.store.size yellow open metricbeat-6.2.4-2018.06.01 2WRn5ddLRAm5E7J56pwRXA 5 1 127340 0 35.8mb 35.8mb yellow open metricbeat-6.2.4-2018.05.31 8dsKJT4ASEadN9CD9-uQ-A 5 1 136 0 317.2kb 317.2kb green open .kibana tCI5Fu5BTda1gpDNm1cCeQ 1 0 126 14 316.8kb 316.8kb system 정보를 얻어오는 거라 root 권한이 필요할 듯 한데 지금은 MBPr15에서는 루트 권한으로 그리고 mini2에서는 그냥 개인 계정으로 실행 중\nKibana dashboard System overview Host overview - MBPr15 Host overview - mini2 xcode command line update하느라 힘든 mini2. 위 그림보다 CPU utilization이 올라갔다. On ubuntu Linux의 경우 deb이나 rpm 패키지를 이용해서 설치할 수 있다. 이 경우 패키지가 설치되면 아래 위치에서 beat 관련 파일을 확인할 수 있다.\n$ ls -al /usr/share/metricbeat/ total 228 drwxr-xr-x 4 root root 4096 6월 1 08:48 ./ drwxr-xr-x 404 root root 16384 6월 1 09:32 ../ drwxr-xr-x 2 root root 4096 6월 1 08:48 bin/ -rw-r--r-- 1 root root 41 4월 13 05:25 .build_hash.txt drwxrwxr-x 4 root root 4096 6월 1 08:48 kibana/ -rw-r--r-- 1 root root 583 4월 13 05:25 LICENSE.txt -rw-r--r-- 1 root root 190678 4월 13 05:25 NOTICE.txt -rw-r--r-- 1 root root 806 4월 13 05:25 README.md 참고 메트릭비트(metricbeat)로 시스템 모니터링 하기 | KWANGSIK LEE’s log A Metricbeat Tutorial: Getting Started A Filebeat Tutorial: Getting Started Installing the ELK Stack on Docker ","date":"2018-05-31T21:58:51+09:00","permalink":"https://cychong47.github.io/post/2018/install_elasticstack_and_metricbeat/","summary":"\u003ch2 id=\"install-elastic-stackelk-stack-with-docker\"\u003eInstall Elastic Stack(ELK stack) with docker\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:elk-wireshark cychong$ git clonehttps://github.com/deviantony/docker-elk.git\ngit: \u0026#39;clonehttps://github.com/deviantony/docker-elk.git\u0026#39; is not a git command. See \u0026#39;git --help\u0026#39;.\nmbpr15:elk-wireshark cychong$ git clone https://github.com/deviantony/docker-elk.git\nCloning into \u0026#39;docker-elk\u0026#39;...\nremote: Counting objects: 1235, done.\nremote: Total 1235 (delta 0), reused 0 (delta 0), pack-reused 1235\nReceiving objects: 100% (1235/1235), 259.29 KiB | 77.00 KiB/s, done.\nResolving deltas: 100% (470/470), done.\nmbpr15:elk-wireshark cychong$ cd elk\nmbpr15:elk-wireshark cychong$ cd docker-elk/\nmbpr15:docker-elk cychong$ ls\nLICENSE\t\t\telasticsearch\t\tlogstash\nREADME.md\t\textensions\ndocker-compose.yml\tkibana\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"install-elk-with-docker-compose\"\u003eInstall ELK with docker-compose\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:docker-elk cychong$ docker-compose up -d\nCreating network \u0026#34;docker-elk_elk\u0026#34; with driver \u0026#34;bridge\u0026#34;\nBuilding elasticsearch\nStep 1/1 : FROM docker.elastic.co/elasticsearch/elasticsearch-oss:6.2.4\n6.2.4: Pulling from elasticsearch/elasticsearch-oss\n469cfcc7a4b3: Pull complete\n8e27facfa9e0: Pull complete\ncdd15392adc7: Pull complete\n19ff08a29664: Pull complete\nddc4fd93fdcc: Pull complete\nb723bede0878: Pull complete\nDigest: sha256:2d9c774c536bd1f64abc4993ebc96a2344404d780cbeb81a8b3b4c3807550e57\nStatus: Downloaded newer image for docker.elastic.co/elasticsearch/elasticsearch-oss:6.2.4\n ---\u0026gt; 3822ba554fe9\nSuccessfully built 3822ba554fe9\nSuccessfully tagged docker-elk_elasticsearch:latest\nWARNING: Image for service elasticsearch was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.\nBuilding logstash\nStep 1/1 : FROM docker.elastic.co/logstash/logstash-oss:6.2.4\n6.2.4: Pulling from logstash/logstash-oss\n469cfcc7a4b3: Already exists\nb4cfa2eb1616: Pull complete\nec994fa6fa7f: Pull complete\nccf455902ac6: Pull complete\n6d54f3767ae5: Pull complete\naf0dd1a720da: Pull complete\n457dbabd3f63: Pull complete\nf2c481bd6da1: Pull complete\nd04342e2b9a1: Pull complete\ne8bca7e9b0d9: Pull complete\nd0096563f301: Pull complete\nDigest: sha256:28668a65f6b6a4f1e2abef7aa3fd3b9c8476a16aa5bebc1a9acf0f7de5b80eef\nStatus: Downloaded newer image for docker.elastic.co/logstash/logstash-oss:6.2.4\n ---\u0026gt; 0bade66b6bee\nSuccessfully built 0bade66b6bee\nSuccessfully tagged docker-elk_logstash:latest\nWARNING: Image for service logstash was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.\nBuilding kibana\nStep 1/1 : FROM docker.elastic.co/kibana/kibana-oss:6.2.4\n6.2.4: Pulling from kibana/kibana-oss\n469cfcc7a4b3: Already exists\n78e4c5fdc069: Pull complete\nd9ecdaefa1b8: Pull complete\nc8e48c8f74d7: Pull complete\n1606c56cdbff: Pull complete\n4e23ce1503d4: Pull complete\nd36b703b3f90: Pull complete\nda5da7625f92: Pull complete\nDigest: sha256:1d1f9bac326bf276010df82a2b4593619f48a5207619e8817c8b20d5a1bb3547\nStatus: Downloaded newer image for docker.elastic.co/kibana/kibana-oss:6.2.4\n ---\u0026gt; 32510971af4e\nSuccessfully built 32510971af4e\nSuccessfully tagged docker-elk_kibana:latest\nWARNING: Image for service kibana was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.\nCreating docker-elk_elasticsearch_1 ... done\nCreating docker-elk_kibana_1        ... done\nCreating docker-elk_logstash_1      ... done\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:docker-elk cychong$ docker ps\nCONTAINER ID        IMAGE                      COMMAND                  CREATED             STATUS              PORTS                                            NAMES\n4fc052e81fae        docker-elk_logstash        “/usr/local/bin/dock…”   9 minutes ago       Up 9 minutes        5044/tcp, 0.0.0.0:5000-\u0026gt;5000/tcp, 9600/tcp       docker-elk_logstash_1\n46f049297c7b        docker-elk_kibana          “/bin/bash /usr/loca…”   9 minutes ago       Up 9 minutes        0.0.0.0:5601-\u0026gt;5601/tcp                           docker-elk_kibana_1\n8ff911ebab03        docker-elk_elasticsearch   “/usr/local/bin/dock…”   9 minutes ago       Up 9 minutes        0.0.0.0:9200-\u0026gt;9200/tcp, 0.0.0.0:9300-\u0026gt;9300/tcp   docker-elk_elasticsearch_1\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:docker-elk cychong$ curl http://localhost:9200\n{\n  “name” : “npNAiWg”,\n  “cluster_name” : “docker-cluster”,\n  “cluster_uuid” : “7nY4KVvNS4epY4Z80NCUZw”,\n  “version” : {\n    “number” : “6.2.4”,\n    “build_hash” : “ccec39f”,\n    “build_date” : “2018-04-12T20:37:28.497551Z”,\n    “build_snapshot” : false,\n    “lucene_version” : “7.2.1”,\n    “minimum_wire_compatibility_version” : “5.6.0”,\n    “minimum_index_compatibility_version” : “5.0.0”\n  },\n  “tagline” : “You Know, for Search”\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"open-httplocalhost5601-with-browser\"\u003eOpen http://localhost:5601 with browser\u003c/h2\u003e\n\u003ch2 id=\"install-metricbeats-with-docker---check-the-latest-version-from-elasticco\"\u003einstall metricbeats with docker - check the latest version from elastic.co\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edocker pull docker.elastic.co/beats/metricbeat:6.2.4\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003emetricbeat 는 시스템 통계 정보를 수집해서 elasticsearch로 보내는 역할을 함.\n다양한 모듈들이 \u003ccode\u003emodules.d\u003c/code\u003e 디렉토리 아래 위치하고, metricbeats.yml은 수집한 정보를 보낼 위치를 변경하는 정도면 기본적인 동작을 확인할 수 있음.\u003c/p\u003e","title":"Elastic stack and Metricbeat"},{"content":"\n","date":"2018-01-30T15:44:01+09:00","permalink":"https://cychong47.github.io/post/2018/2018-01-home-network/","summary":"\u003cp\u003e\u003cimg src=\"/images/2018/01/Home-network-2018.png\" alt=\"Home-network-2018\"\u003e\u003c/p\u003e","title":"2018.01 home network"},{"content":"update homebrew mbpr15:mp3 cychong$ ansible all -m homebrew -a update_homebrew=yes localhost | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: true, \u0026#34;msg\u0026#34;: \u0026#34;Homebrew updated successfully.\u0026#34; } mini2 | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: true, \u0026#34;msg\u0026#34;: \u0026#34;Homebrew updated successfully.\u0026#34; } upgrade all packages mbpr15:mp3 cychong$ ansible all -m homebrew -a update_homebrew=yes -a upgrade_all=yes localhost | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: true, \u0026#34;msg\u0026#34;: \u0026#34;Homebrew upgraded.\u0026#34; } mini2 | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: true, \u0026#34;msg\u0026#34;: \u0026#34;Homebrew upgraded.\u0026#34; } install a package mbpr15:mp3 cychong$ ansible all -m homebrew -a name=neovim -a state=present mbpr15:~ cychong$ cat install_brew_neovim.yaml --- - hosts: all tasks: - name : install neovim in homebrew homebrew: name: neovim state: present mbpr15:~ cychong$ ansible-playbook install_brew_neovim.yaml PLAY [all] ***************************************************************************************************************************************************************** TASK [Gathering Facts] ***************************************************************************************************************************************************** ok: [localhost] ok: [mini2] TASK [install neovim in homebrew] ****************************************************************************************************************************************** changed: [localhost] changed: [mini2] PLAY RECAP ***************************************************************************************************************************************************************** localhost : ok=2 changed=1 unreachable=0 failed=0 mini2 : ok=2 changed=1 unreachable=0 failed=0 mbpr15:~ cychong$ which nvim /usr/local/bin/nvim 삭제는 state만 absent로 변경하면 된다.\nmbpr15:~ cychong$ diff -u install_brew_neovim.yaml uninstall_brew_neovim.yaml --- install_brew_neovim.yaml\t2017-12-30 08:57:36.000000000 +0900 +++ uninstall_brew_neovim.yaml\t2017-12-30 08:58:19.000000000 +0900 @@ -1,8 +1,8 @@ --- - hosts: all tasks: - - name : install neovim in homebrew + - name : uninstall neovim in homebrew homebrew: name: neovim - state: present + state: absent mbpr15:~ cychong$ ansible-playbook uninstall_brew_neovim.yaml PLAY [all] ***************************************************************************************************************************************************************** TASK [Gathering Facts] ***************************************************************************************************************************************************** ok: [localhost] ok: [mini2] TASK [uninstall neovim in homebrew] **************************************************************************************************************************************** changed: [localhost] changed: [mini2] PLAY RECAP ***************************************************************************************************************************************************************** localhost : ok=2 changed=1 unreachable=0 failed=0 mini2 : ok=2 changed=1 unreachable=0 failed=0 mbpr15:~ cychong$ which nvim mbpr15:~ cychong$ state head latest present absent linked unlinked ","date":"2017-12-30T02:34:39+09:00","permalink":"https://cychong47.github.io/post/2017/ansible-homebrew/","summary":"\u003ch2 id=\"update-homebrew\"\u003eupdate homebrew\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:mp3 cychong$ ansible all -m homebrew -a update_homebrew=yes\nlocalhost | SUCCESS =\u0026gt; {\n    \u0026#34;changed\u0026#34;: true,\n    \u0026#34;msg\u0026#34;: \u0026#34;Homebrew updated successfully.\u0026#34;\n}\nmini2 | SUCCESS =\u0026gt; {\n    \u0026#34;changed\u0026#34;: true,\n    \u0026#34;msg\u0026#34;: \u0026#34;Homebrew updated successfully.\u0026#34;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"upgrade-all-packages\"\u003eupgrade all packages\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:mp3 cychong$ ansible all -m homebrew -a update_homebrew=yes -a upgrade_all=yes\nlocalhost | SUCCESS =\u0026gt; {\n    \u0026#34;changed\u0026#34;: true,\n    \u0026#34;msg\u0026#34;: \u0026#34;Homebrew upgraded.\u0026#34;\n}\nmini2 | SUCCESS =\u0026gt; {\n    \u0026#34;changed\u0026#34;: true,\n    \u0026#34;msg\u0026#34;: \u0026#34;Homebrew upgraded.\u0026#34;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"install-a-package\"\u003einstall a package\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:mp3 cychong$ ansible all -m homebrew -a name=neovim -a state=present\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:~ cychong$ cat install_brew_neovim.yaml \n---\n- hosts: all\n  tasks:\n  - name : install neovim in homebrew\n    homebrew: \n      name: neovim\n      state: present\n\nmbpr15:~ cychong$ ansible-playbook install_brew_neovim.yaml \n\nPLAY [all] *****************************************************************************************************************************************************************\n\nTASK [Gathering Facts] *****************************************************************************************************************************************************\nok: [localhost]\nok: [mini2]\n\nTASK [install neovim in homebrew] ******************************************************************************************************************************************\nchanged: [localhost]\nchanged: [mini2]\n\nPLAY RECAP *****************************************************************************************************************************************************************\nlocalhost                  : ok=2    changed=1    unreachable=0    failed=0   \nmini2                      : ok=2    changed=1    unreachable=0    failed=0   \n\nmbpr15:~ cychong$ which nvim\n/usr/local/bin/nvim\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e삭제는 \u003ccode\u003estate\u003c/code\u003e만 \u003ccode\u003eabsent\u003c/code\u003e로 변경하면 된다.\u003c/p\u003e","title":"Ansible - Install homebrew"},{"content":"YAML file state:absent 는 현재 존재하는 container를 중지시키고, 삭제한다. 단순히 stop만 시키려면 state:stopped로 지정하면 된다.\npull: yes 옵션을 사용하면 항상 최신 image를 pull한다고 한다.\nrecreate Use with present and started states to force the re-creation of an existing container.\nmbpr15:ansible cychong$ cat recreate_container_ghost.yaml --- - hosts: mini2 tasks: - name: Stop and remove contianer docker_container: name: ghost state: absent - name: Create ghost Container docker_container: name: ghost image: ghost # always pull the latest image pull: yes state: started recreate: yes volumes: - \u0026#34;/Users/cychong/Dropbox/Apps/ghost/content/:/var/lib/ghost/content\u0026#34; - \u0026#34;/Users/cychong/Dropbox/Apps/ghost/config.production.json:/var/lib/ghost/config.production.json\u0026#34; ports: - \u0026#34;2368:2368\u0026#34; env: NODE_ENV: production mbpr15:ansible cychong$ ansible-playbook recreate_container_ghost.yaml PLAY [mini2] *************************************************************************************************************************************************************** TASK [Gathering Facts] ***************************************************************************************************************************************************** ok: [mini2] TASK [Stop and remove contianer] ******************************************************************************************************************************************* changed: [mini2] TASK [Create ghost Container] ********************************************************************************************************************************************** changed: [mini2] PLAY RECAP ***************************************************************************************************************************************************************** mini2 : ok=3 changed=2 unreachable=0 failed=0 ","date":"2017-12-30T02:31:41+09:00","permalink":"https://cychong47.github.io/post/2017/recreate-ghost-container/","summary":"\u003ch2 id=\"yaml-file\"\u003eYAML file\u003c/h2\u003e\n\u003cp\u003e\u003ccode\u003estate:absent\u003c/code\u003e 는 현재 존재하는 container를 중지시키고, 삭제한다.\n단순히 stop만 시키려면 \u003ccode\u003estate:stopped\u003c/code\u003e로 지정하면 된다.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003epull: yes\u003c/code\u003e 옵션을 사용하면 항상 최신 image를 pull한다고 한다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003erecreate\nUse with present and started states to force the re-creation of an existing container.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:ansible cychong$ cat recreate_container_ghost.yaml \n---\n- hosts: mini2\n  tasks:\n\n  - name: Stop and remove contianer\n    docker_container:\n      name: ghost\n      state: absent\n\n  - name: Create ghost Container\n    docker_container:\n      name: ghost\n      image: ghost\n      # always pull the latest image\n      pull: yes\n      state: started\n      recreate: yes\n      volumes:\n         - \u0026#34;/Users/cychong/Dropbox/Apps/ghost/content/:/var/lib/ghost/content\u0026#34;   \n         - \u0026#34;/Users/cychong/Dropbox/Apps/ghost/config.production.json:/var/lib/ghost/config.production.json\u0026#34;\n      ports:\n         - \u0026#34;2368:2368\u0026#34;\n      env:\n           NODE_ENV: production\n\u003c/code\u003e\u003c/pre\u003e\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:ansible cychong$ ansible-playbook recreate_container_ghost.yaml \n\nPLAY [mini2] ***************************************************************************************************************************************************************\n\nTASK [Gathering Facts] *****************************************************************************************************************************************************\nok: [mini2]\n\nTASK [Stop and remove contianer] *******************************************************************************************************************************************\nchanged: [mini2]\n\nTASK [Create ghost Container] **********************************************************************************************************************************************\nchanged: [mini2]\n\nPLAY RECAP *****************************************************************************************************************************************************************\nmini2                      : ok=3    changed=2    unreachable=0    failed=0   \n\u003c/code\u003e\u003c/pre\u003e","title":"Ansible - recreate ghost container"},{"content":"play The goal of a play is to map a group of hosts to some well defined roles, represented by things ansible calls tasks. At a basic level, a task is nothing more than a call to an ansible module\nplay는 명령을 수행할 대상과 수행할 명령을 모두 포함하고 있다.\nplaybook playbook은 하나 혹은 이상의 play들의 집합으로 정의한다.\nConventional template of playbook --- - hosts: XXX optoins.... tasks: -name: YYY MODULE_NAME : MODULE_ARGS -name : ZZZ MODULE_NAME: MODULE_ARGS ... 하나의 play는 “하나 혹은 이상의 목적지 그룹에 대해 수행되는 task들의 매핑”으로 정의된다. 즉 하나의 hosts 와 해당 hosts에서 수행할 tasks들 간의 매핑을 하나의 play로 정의한다. hosts 에는 접속 및 로그인에 관련된 옵션 들이 추가될 수 있다.\nremote_user : ssh 로그인 시 계정 become : sudo 사용 여부 vars: 변수들\u0026hellip; FIXME tasks에는 { name, MODULE_NAME}의 조합으로 순차적으로 수행할 명령어들이 기술된다.\n(FIXME 자주 사용되는 명령어 추가)\nexamples playbook --- - hosts: webservers vars: http_port: 80 max_clients: 200 remote_user: root tasks: - name: ensure apache is at the latest version yum: name=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf notify: - restart apache - name: ensure apache is running (and enable it at boot) service: name=httpd state=started enabled=yes handlers: - name: restart apache service: name=httpd state=restarted key=value 형태의 명령은 다음과 같이 multi-line으로도 표현 가능\n- name: write the apache config file template: src: /srv/httpd.j2 dest: /etc/httpd.conf notify: - restart apache examples playbook - multiple plays --- - hosts: webservers remote_user: root tasks: - name: ensure apache is at the latest version yum: name=httpd state=latest - name: write the apache config file template: src=/srv/httpd.j2 dest=/etc/httpd.conf - hosts: databases remote_user: root tasks: - name: ensure postgresql is at the latest version yum: name=postgresql state=latest - name: ensure that postgresql is started service: name=postgresql state=started Execute task with root permission ssh 로그인 후 login 계정이 아닌 다른 계정으로 명령을 수행하는 경우 task에 become 옵션을 준다. (FIXME 모든 task에 대해 동일하게 옵션을 지정하려면???)\ntasks: -name: update APT package w/o upgrade become: yes apt: update_cache=yes -name: upgrade to the latest package become: yes apt: upgrade=dist Or apt: name=“*” state=latest 위와 같이 become만 지정한 경우 기본적으로 root 권한으로 실행한다는 의미이다. 만일 root가 아닌 다른 계정으로 실행하고 싶은 경우 become_user: XXX와 같이 해당 계정을 지정한다.\n그리고 ansible-playbook 실행 시 -K 혹은 --ask-become-pass 을 지정한다.\nansible-playbook test.yaml -K Useful ansible play apt -name : install neovim apt: name: neovim force: yes state: present -name : uninstall neovim apt: name: neovim force: yes state: absent reference Intro to Playbooks — Ansible Documentation GitHub - ansible/ansible-examples: A few starter examples of ansible playbooks, to show features and how they work together. See http://galaxy.ansible.com for example roles from the Ansible community for deploying many popular applications. ","date":"2017-12-29T13:43:14+09:00","permalink":"https://cychong47.github.io/post/2017/ansible-playbook/","summary":"\u003ch2 id=\"play\"\u003e\u003ccode\u003eplay\u003c/code\u003e\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe goal of a play is to map a group of hosts to some well defined roles, represented by things ansible calls tasks. At a basic level, a task is nothing more than a call to an ansible module\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eplay는 명령을 수행할 대상과 수행할 명령을 모두 포함하고 있다.\u003c/p\u003e\n\u003ch2 id=\"playbook\"\u003e\u003ccode\u003eplaybook\u003c/code\u003e\u003c/h2\u003e\n\u003cp\u003eplaybook은 하나 혹은 이상의 play들의 집합으로 정의한다.\u003c/p\u003e\n\u003ch3 id=\"conventional-template-of-playbook\"\u003eConventional template of playbook\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e---\n- hosts: XXX\n  optoins....\n  \n  tasks:\n  -name: YYY\n   MODULE_NAME : MODULE_ARGS\n  -name : ZZZ\n   MODULE_NAME: MODULE_ARGS\n  ...\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e하나의 play는 “하나 혹은 이상의 목적지 그룹에 대해 수행되는 task들의 매핑”으로 정의된다. 즉 하나의 \u003ccode\u003ehosts\u003c/code\u003e 와 해당 hosts에서 수행할 \u003ccode\u003etasks\u003c/code\u003e들 간의 매핑을 하나의 play로 정의한다.\n\u003ccode\u003ehosts\u003c/code\u003e 에는 접속 및 로그인에 관련된 옵션 들이 추가될 수 있다.\u003c/p\u003e","title":"Ansible - basics of ansible-playbook"},{"content":"Create inventory(Ansible hosts) file mbpr15:Homebrew cychong$ cat /etc/ansible/hosts mini1 ansible_host=x.y.z.a ansible_ssh_user=cychong ansible_ssh_port=22 mini2 ansible_host=x.y.z.b ansible_ssh_user=cychong ansible_ssh_port=22 localhost ansible_connection=local ping ping 명령도 ansible이 제공하는 ping module을 이용하므로 -m 옵션을 사용한다.\nmbpr15:Homebrew cychong$ ansible all -m ping -k SSH password: localhost | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } mini2 | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } mini1 | UNREACHABLE! =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;timed out\u0026#34;, \u0026#34;unreachable\u0026#34;: true } ssh의 로그인 ID는 /etc/ansible/hosts에 기술하거나 명령어 옵션 —user=cychong으로 지정할 수 있다.\nshell module syntax -m MODULE_NAME -a MODULE_ARG [-u/--user] USER_ID [-sudo] 로그인 후 SUDO 권한으로 명령어 실행 [-sudo-user USER_ID] 로그인 후 특정 USER_ID 권한으로 명령어 실행 [-b] -sudo 옵션 대체 [--become-user USER_ID] -sudo-user 옵션 대체 example shell module의 명령어 df -k 실행 (df -h를 인자로 지정하면 -h가 ansible 명령의 —help 옵션으로 간주된다. 그러므로 이 경우에는 ”df -h”와 같이 따옴표로 module argument를 묶어준다)\nmbpr15:Homebrew cychong$ ansible all -m shell -a df -k SSH password: localhost | SUCCESS | rc=0 \u0026gt;\u0026gt; Filesystem 512-blocks Used Available Capacity iused ifree %iused Mounted on /dev/disk1s1 976490568 573048520 388412536 60% 1229764 9223372036853546043 0% / devfs 395 395 0 100% 684 0 100% /dev /dev/disk1s4 976490568 12582968 388412536 4% 6 9223372036854775801 0% /private/var/vm map -hosts 0 0 0 100% 0 0 100% /net map auto_home 0 0 0 100% 0 0 100% /home //cychong@DISKSTATION._afpovertcp._tcp.local/Shelter 7681886800 4548217416 3133669384 60% 568527175 391708673 59% /Volumes/Shelter //cychong@DISKSTATION._afpovertcp._tcp.local/media 1220947280 966911944 254035336 80% 120863991 31754417 79% /Volumes/media //cychong@DISKSTATION._afpovertcp._tcp.local/video 7681886800 4548217416 3133669384 60% 568527175 391708673 59% /Volumes/video //com.apple.idms.appleid.prd.4758655770614553526e3849724845577074615846773d3d@mini2._smb._tcp.local/cychong 249660000 199914656 49745344 81% 24989330 6218168 80% /Volumes/cychong mini2 | SUCCESS | rc=0 \u0026gt;\u0026gt; Filesystem 512-blocks Used Available Capacity iused ifree %iused Mounted on /dev/disk2s1 249660000 198640784 49745232 80% 1226230 9223372036853549577 0% / devfs 393 393 0 100% 682 0 100% /dev /dev/disk2s4 249660000 48 49745232 1% 0 9223372036854775807 0% /private/var/vm /dev/disk3s2 233769824 142965688 90804136 62% 757164 4294210115 0% /Volumes/120G /dev/disk1s2 1951845728 1515454904 436390824 78% 460710 4294506569 0% /Volumes/data map -hosts 0 0 0 100% 0 0 100% /net map auto_home 0 0 0 100% 0 0 100% /home map -fstab 0 0 0 100% 0 0 100% /Network/Servers /dev/disk4s2 976101344 523330000 452771344 54% 1596 4294965683 0% /Volumes/500G copy module Target host 들에게 파일을 보내는 경우(put)\nmbpr15:Homebrew cychong$ ansible all -m copy -a \u0026#34;src=~/.vimrc dest=/tmp\u0026#34; localhost | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: true, \u0026#34;checksum\u0026#34;: \u0026#34;052ddf17cff54f1fb8231c7a5930be30756456d3\u0026#34;, \u0026#34;dest\u0026#34;: \u0026#34;/tmp/.vimrc\u0026#34;, \u0026#34;gid\u0026#34;: 20, \u0026#34;group\u0026#34;: \u0026#34;staff\u0026#34;, \u0026#34;md5sum\u0026#34;: \u0026#34;f11f67ca155917ae34e4a459b2603562\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;0644\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;cychong\u0026#34;, \u0026#34;size\u0026#34;: 28, \u0026#34;src\u0026#34;: \u0026#34;/Users/cychong/.ansible/tmp/ansible-tmp-1514382698.5150971-237795226033898/source\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;file\u0026#34;, \u0026#34;uid\u0026#34;: 501 } mini2 | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: true, \u0026#34;checksum\u0026#34;: \u0026#34;052ddf17cff54f1fb8231c7a5930be30756456d3\u0026#34;, \u0026#34;dest\u0026#34;: \u0026#34;/tmp/.vimrc\u0026#34;, \u0026#34;gid\u0026#34;: 20, \u0026#34;group\u0026#34;: \u0026#34;staff\u0026#34;, \u0026#34;md5sum\u0026#34;: \u0026#34;f11f67ca155917ae34e4a459b2603562\u0026#34;, \u0026#34;mode\u0026#34;: \u0026#34;0644\u0026#34;, \u0026#34;owner\u0026#34;: \u0026#34;cychong\u0026#34;, \u0026#34;size\u0026#34;: 28, \u0026#34;src\u0026#34;: \u0026#34;/Users/cychong/.ansible/tmp/ansible-tmp-1514382698.5150971-84669710159236/source\u0026#34;, \u0026#34;state\u0026#34;: \u0026#34;file\u0026#34;, \u0026#34;uid\u0026#34;: 501 } 제대로 복사 되었는지 확인\nmbpr15:Homebrew cychong$ ansible all -m shell -a \u0026#34;ls -al /tmp/.vimrc\u0026#34; localhost | SUCCESS | rc=0 \u0026gt;\u0026gt; -rw-r--r-- 1 cychong staff 28 Dec 27 22:51 /tmp/.vimrc mini2 | SUCCESS | rc=0 \u0026gt;\u0026gt; -rw-r--r-- 1 cychong staff 28 Dec 27 22:51 /tmp/.vimrc 지원되는 모듈 Module Index — Ansible Documentation에서 참고\npip - Manages Python library dependencies. — Ansible Documentation\napt - Manages apt-packages — Ansible Documentation\nhomebrew - Package manager for Homebrew — Ansible Documentation\nyum - Manages packages with the yum package manager — Ansible Documentation\nat - Schedule the execution of a command or script file via the at command. — Ansible Documentation\nping - Try to connect to host, verify a usable python and return pong on success — Ansible Documentation\nFiles Modules — Ansible Documentation archive, copy, fetch, file, find, patch, replace, stat, temple, template, unarchive,\npause - Pause playbook execution — Ansible Documentation\nwait_for - Waits for a condition before continuing — Ansible Documentation\nwait_for_connection - Waits until remote system is reachable/usable — Ansible Documentation\nCommands Modules — Ansible Documentation command, expect, raw, script, shell, telnet\nMonitoring Modules — Ansible Documentation 몇가지 모니터링 툴(datadog, logstash, nagios, sensu, zabbix 등)\nnetconf_config - netconf device configuration — Ansible Documentation ncclient를 이용해서 Netconf 명령을 내리는 듯.\nDatabase Modules — Ansible Documentation - influxes, elasticsearch, redis, kibana, mongodb, mysql, postgresql,\nNetwork Modules — Ansible Documentation 이 정도로 원격으로 제어할 수 있도록 module이 제공되면 편할 듯. ONAP에서 원하는 게 이런 정도의 정리인 듯\nClustering Modules — Ansible Documentation consul, kubernetes\n","date":"2017-12-27T14:32:51+09:00","permalink":"https://cychong47.github.io/post/2017/ansible-exercise-1/","summary":"\u003ch2 id=\"create-inventoryansible-hosts-file\"\u003eCreate inventory(Ansible hosts) file\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:Homebrew cychong$ cat /etc/ansible/hosts\nmini1 ansible_host=x.y.z.a ansible_ssh_user=cychong ansible_ssh_port=22\nmini2 ansible_host=x.y.z.b ansible_ssh_user=cychong ansible_ssh_port=22\nlocalhost     ansible_connection=local\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"ping\"\u003eping\u003c/h2\u003e\n\u003cp\u003eping 명령도 ansible이 제공하는 \u003ccode\u003eping\u003c/code\u003e module을 이용하므로 \u003ccode\u003e-m\u003c/code\u003e 옵션을 사용한다.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:Homebrew cychong$ ansible all -m ping -k\nSSH password: \nlocalhost | SUCCESS =\u0026gt; {\n    \u0026#34;changed\u0026#34;: false,\n    \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34;\n}\nmini2 | SUCCESS =\u0026gt; {\n    \u0026#34;changed\u0026#34;: false,\n    \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34;\n}\nmini1 | UNREACHABLE! =\u0026gt; {\n    \u0026#34;changed\u0026#34;: false,\n    \u0026#34;msg\u0026#34;: \u0026#34;timed out\u0026#34;,\n    \u0026#34;unreachable\u0026#34;: true\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003essh의 로그인 ID는 /etc/ansible/hosts에 기술하거나 명령어 옵션 \u003ccode\u003e—user=cychong\u003c/code\u003e으로 지정할 수 있다.\u003c/p\u003e","title":"Ansible - ad-hoc or basic"},{"content":"Summary docker run --restart=always -e MYSQL_ROOT_PASSWORD=aqwe123 -e MYSQL_USER=wpuser -e MYSQL_PASSWORD=wpuser@ -e MYSQL_DATABASE=wordpress_db -v /Users/cychong/Dropbox/Apps/wordpress/database:/var/lib/mysql --name mysql -d mysql docker run --restart=always -e WORDPRESS_DB_USER=wpuser -e WORDPRESS_DB_PASSWORD=wpuser@ -e WORDPRESS_DB_NAME=wordpress_db -p 80:80 -v /Users/cychong/Documents/wordpress/html:/var/www/html -v /Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads -v /Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini --link mysql:mysql --name wpcontainer -d wordpress If required, import database to mysql (Once wordpress data is imported into mysql, upgrading mysql does not requires re-import ingof wordpress data)\nmysql install container cychong:~ cychong$ docker run --restart=always -e MYSQL_ROOT_PASSWORD=aqwe123 -e MYSQL_USER=wpuser -e MYSQL_PASSWORD=wpuser@ -e MYSQL_DATABASE=wordpress_db -v /Users/cychong/Dropbox/Apps/wordpress/database:/var/lib/mysql --name mysql -d mysql Unable to find image \u0026#39;mysql:latest\u0026#39; locally latest: Pulling from library/mysql aa18ad1a0d33: Pull complete a5745c3b8bcc: Pull complete 76375fcd129c: Pull complete 4f72cfb004cf: Pull complete 1d6a01e515fb: Pull complete a71e1163fa7e: Pull complete 8c1a568fa442: Pull complete e7a69cecc173: Pull complete 9759a0f979a1: Pull complete 3f71dac6110f: Pull complete 58f37de54392: Pull complete Digest: sha256:790b7b18b832822ef400e44ad9fac885a746db1a7028ec52325730cf9b831753 Status: Downloaded newer image for mysql:latest b1f54c680120898fc7ff16751048fe18ae461399d5d7f10308c156c68d40577b check container is started cychong:~ cychong$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES b1f54c680120 mysql \u0026#34;docker-entrypoint...\u0026#34; 13 seconds ago Up 10 seconds 3306/tcp mysql dea965b550e6 ghost:latest \u0026#34;docker-entrypoint...\u0026#34; 8 days ago Up 8 days 0.0.0.0:2368-\u0026gt;2368/tcp ghost check files are located where volume is mounted cychong:~/Dropbox/Apps/wordpress/database cychong$ ls auto.cnf\tib_buffer_pool\tmysql\tserver-key.pem ca-key.pem\tib_logfile0\tperformance_schema\tsys ca.pem\tib_logfile1\tprivate_key.pem\twordpress_db client-cert.pem\tibdata1\tpublic_key.pem client-key.pem\tibtmp1\tserver-cert.pem wordpress install container cychong:~ cychong$ docker run --restart=always -e WORDPRESS_DB_USER=wpuser -e WORDPRESS_DB_PASSWORD=wpuser@ -e WORDPRESS_DB_NAME=wordpress_db -p 80:80 -v /Users/cychong/Documents/wordpress/html:/var/www/html -v /Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads -v /Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini --link mysql:mysql --name wpcontainer -d wordpress 525ba1e4fff2caccc020960908e4f538be9512c2541e62a94c5a36a341e7ff3c cychong:~ cychong$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 525ba1e4fff2 wordpress \u0026#34;docker-entrypoint...\u0026#34; 44 seconds ago Up 42 seconds 0.0.0.0:80-\u0026gt;80/tcp wpcontainer b1f54c680120 mysql \u0026#34;docker-entrypoint...\u0026#34; 11 minutes ago Up 11 minutes 3306/tcp mysql dea965b550e6 ghost:latest \u0026#34;docker-entrypoint...\u0026#34; 8 days ago Up 8 days 0.0.0.0:2368-\u0026gt;2368/tcp ghost check containers cychong:~ cychong$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 8ea2303518ad wordpress \u0026#34;docker-entrypoint...\u0026#34; About a minute ago Up About a minute 0.0.0.0:80-\u0026gt;80/tcp wpcontainer b1f54c680120 mysql \u0026#34;docker-entrypoint...\u0026#34; 3 minutes ago Up 3 minutes 3306/tcp mysql dea965b550e6 ghost:latest \u0026#34;docker-entrypoint...\u0026#34; 8 days ago Up 8 days 0.0.0.0:2368-\u0026gt;2368/tcp ghost check files cychong:~ cychong$ ls Documents/wordpress/html/ index.php\twp-admin\twp-config.php\twp-links-opml.php\twp-settings.php license.txt\twp-blog-header.php\twp-content\twp-load.php\twp-signup.php readme.html\twp-comments-post.php\twp-cron.php\twp-login.php\twp-trackback.php wp-activate.php\twp-config-sample.php\twp-includes\twp-mail.php\txmlrpc.php mysql dump data is not imported. copy mysql dump file to mounted volume directory\ncychong:~ cychong$ cp wordpress.dump.0910 ~/Dropbox/Apps/wordpress/database Login to mysql container\ncychong:~ cychong$ docker exec -ti b1f54c680120 bash root@b1f54c680120:/# ls bin boot dev\tdocker-entrypoint-initdb.d entrypoint.sh etc\thome lib lib64 media mnt opt proc root run sbin srv sys tmp usr var root@b1f54c680120:/# cd /var/lib/mysql root@b1f54c680120:/var/lib/mysql# ls auto.cnf client-cert.pem ib_logfile0 ibtmp1\tprivate_key.pem server-key.pem\twordpress_db ca-key.pem client-key.pem ib_logfile1 mysql\tpublic_key.pem sys ca.pem\tib_buffer_pool ibdata1\tperformance_schema server-cert.pem wordpress.dump.0910 Import mysql dump file to mysql db\nroot@b1f54c680120:/var/lib/mysql# mysql -h localhost -u root -p wordpress_db \u0026lt; wordpress.dump.0910 Enter password: root@b1f54c680120:/var/lib/mysql# This should be from the DB schema. Still don\u0026rsquo;t know if data is imported properly\nroot@b1f54c680120:/var/lib/mysql# mysqlshow -u root -p wordpress_db Enter password: Database: wordpress_db +-----------------------+ | Tables | +-----------------------+ | wp_commentmeta | | wp_comments | | wp_links | | wp_options | | wp_postmeta | | wp_posts | | wp_term_relationships | | wp_term_taxonomy | | wp_termmeta | | wp_terms | | wp_usermeta | | wp_users | +-----------------------+ Install jetpack And enable markdown from Jetpack Setting \u0026gt; Writing\nDone\n#wordpress #docker\n","date":"2017-12-19T22:20:06+09:00","permalink":"https://cychong47.github.io/post/2017/install-wordpress-with-docker/","summary":"\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003edocker run --restart=always -e MYSQL_ROOT_PASSWORD=aqwe123 -e MYSQL_USER=wpuser -e MYSQL_PASSWORD=wpuser@ -e MYSQL_DATABASE=wordpress_db -v /Users/cychong/Dropbox/Apps/wordpress/database:/var/lib/mysql --name mysql -d mysql\n\ndocker run --restart=always -e WORDPRESS_DB_USER=wpuser -e WORDPRESS_DB_PASSWORD=wpuser@ -e WORDPRESS_DB_NAME=wordpress_db -p 80:80 -v /Users/cychong/Documents/wordpress/html:/var/www/html -v /Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads -v /Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini --link mysql:mysql --name wpcontainer -d wordpress\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIf required, import database to mysql\n(Once wordpress data is imported into mysql, upgrading mysql does not requires re-import ingof wordpress data)\u003c/p\u003e\n\u003ch2 id=\"mysql\"\u003emysql\u003c/h2\u003e\n\u003ch3 id=\"install-container\"\u003einstall container\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong:~ cychong$ docker run --restart=always -e MYSQL_ROOT_PASSWORD=aqwe123 -e MYSQL_USER=wpuser -e MYSQL_PASSWORD=wpuser@ -e MYSQL_DATABASE=wordpress_db -v /Users/cychong/Dropbox/Apps/wordpress/database:/var/lib/mysql --name mysql -d mysql\nUnable to find image \u0026#39;mysql:latest\u0026#39; locally\nlatest: Pulling from library/mysql\naa18ad1a0d33: Pull complete \na5745c3b8bcc: Pull complete \n76375fcd129c: Pull complete \n4f72cfb004cf: Pull complete \n1d6a01e515fb: Pull complete \na71e1163fa7e: Pull complete \n8c1a568fa442: Pull complete \ne7a69cecc173: Pull complete \n9759a0f979a1: Pull complete \n3f71dac6110f: Pull complete \n58f37de54392: Pull complete \nDigest: sha256:790b7b18b832822ef400e44ad9fac885a746db1a7028ec52325730cf9b831753\nStatus: Downloaded newer image for mysql:latest\nb1f54c680120898fc7ff16751048fe18ae461399d5d7f10308c156c68d40577b\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"check-container-is-started\"\u003echeck container is started\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong:~ cychong$ docker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES\nb1f54c680120        mysql               \u0026#34;docker-entrypoint...\u0026#34;   13 seconds ago      Up 10 seconds       3306/tcp                 mysql\ndea965b550e6        ghost:latest        \u0026#34;docker-entrypoint...\u0026#34;   8 days ago          Up 8 days           0.0.0.0:2368-\u0026gt;2368/tcp   ghost\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"check-files-are-located-where-volume-is-mounted\"\u003echeck files are located where volume is mounted\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong:~/Dropbox/Apps/wordpress/database cychong$ ls\nauto.cnf\t\tib_buffer_pool\t\tmysql\t\t\tserver-key.pem\nca-key.pem\t\tib_logfile0\t\tperformance_schema\tsys\nca.pem\t\t\tib_logfile1\t\tprivate_key.pem\t\twordpress_db\nclient-cert.pem\t\tibdata1\t\t\tpublic_key.pem\nclient-key.pem\t\tibtmp1\t\t\tserver-cert.pem\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"wordpress\"\u003ewordpress\u003c/h2\u003e\n\u003ch2 id=\"install-container-1\"\u003einstall container\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong:~ cychong$ docker run --restart=always -e WORDPRESS_DB_USER=wpuser -e WORDPRESS_DB_PASSWORD=wpuser@ -e WORDPRESS_DB_NAME=wordpress_db -p 80:80 -v /Users/cychong/Documents/wordpress/html:/var/www/html -v /Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads -v /Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini --link mysql:mysql --name wpcontainer -d wordpress\n525ba1e4fff2caccc020960908e4f538be9512c2541e62a94c5a36a341e7ff3c\n\ncychong:~ cychong$ docker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                    NAMES\n525ba1e4fff2        wordpress           \u0026#34;docker-entrypoint...\u0026#34;   44 seconds ago      Up 42 seconds       0.0.0.0:80-\u0026gt;80/tcp       wpcontainer\nb1f54c680120        mysql               \u0026#34;docker-entrypoint...\u0026#34;   11 minutes ago      Up 11 minutes       3306/tcp                 mysql\ndea965b550e6        ghost:latest        \u0026#34;docker-entrypoint...\u0026#34;   8 days ago          Up 8 days           0.0.0.0:2368-\u0026gt;2368/tcp   ghost\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"check-containers\"\u003echeck containers\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong:~ cychong$ docker ps\nCONTAINER ID        IMAGE               COMMAND                  CREATED              STATUS              PORTS                    NAMES\n8ea2303518ad        wordpress           \u0026#34;docker-entrypoint...\u0026#34;   About a minute ago   Up About a minute   0.0.0.0:80-\u0026gt;80/tcp       wpcontainer\nb1f54c680120        mysql               \u0026#34;docker-entrypoint...\u0026#34;   3 minutes ago        Up 3 minutes        3306/tcp                 mysql\ndea965b550e6        ghost:latest        \u0026#34;docker-entrypoint...\u0026#34;   8 days ago           Up 8 days           0.0.0.0:2368-\u0026gt;2368/tcp   ghost\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"check-files\"\u003echeck files\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong:~ cychong$ ls Documents/wordpress/html/\nindex.php\t\twp-admin\t\twp-config.php\t\twp-links-opml.php\twp-settings.php\nlicense.txt\t\twp-blog-header.php\twp-content\t\twp-load.php\t\twp-signup.php\nreadme.html\t\twp-comments-post.php\twp-cron.php\t\twp-login.php\t\twp-trackback.php\nwp-activate.php\t\twp-config-sample.php\twp-includes\t\twp-mail.php\t\txmlrpc.php\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"mysql-dump-data-is-not-imported\"\u003emysql dump data is not imported.\u003c/h3\u003e\n\u003cp\u003ecopy mysql dump file to mounted volume directory\u003c/p\u003e","title":"Install Wordpress with docker"},{"content":"pip3로는 설치가 안되네\nmbpr15:~ cychong$ pip3 install clientBBS Collecting clientBBS Could not find a version that satisfies the requirement clientBBS (from versions: ) No matching distribution found for clientBBS 그래서 그냥 github 링크에서 클론해서 실행\nmbpr15:working cychong$ git clone https://github.com/liza183/clienBBS.git Cloning into \u0026#39;clienBBS\u0026#39;... remote: Counting objects: 219, done. remote: Compressing objects: 100% (25/25), done. remote: Total 219 (delta 20), reused 23 (delta 9), pack-reused 185 Receiving objects: 100% (219/219), 33.96 MiB | 3.84 MiB/s, done. Resolving deltas: 100% (122/122), done. 실행해 보자\nmbpr15:working cychong$ cd clienBBS/ mbpr15:clienBBS cychong$ python3 clien.py Traceback (most recent call last): File \u0026#34;clien.py\u0026#34;, line 2, in \u0026lt;module\u0026gt; import urllib3 의존성을 가진 모듈들을 설치해야 하는 구나. 대부분 많이 사용하는 기본 모듈이긴 한데 python2에서 사용하는 이름하고 조금 다르네\npip3 install urllib3 pip3 install requests pip3 install BeautifulSoup4 pip3 install pillow pip3 install lxml 클리앙 개편에 맞추어 PC통신 느낌으로 클리앙 사용하는 clienBBS 업뎃 v0.32 https://github.com/liza183/clienBBS ","date":"2017-12-14T09:42:15+09:00","permalink":"https://cychong47.github.io/post/2017/clienbbs/","summary":"\u003cp\u003epip3로는 설치가 안되네\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:~ cychong$ pip3 install clientBBS\nCollecting clientBBS\n  Could not find a version that satisfies the requirement clientBBS (from versions: )\nNo matching distribution found for clientBBS\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e그래서 그냥 github 링크에서 클론해서 실행\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:working cychong$ git clone https://github.com/liza183/clienBBS.git\nCloning into \u0026#39;clienBBS\u0026#39;...\nremote: Counting objects: 219, done.\nremote: Compressing objects: 100% (25/25), done.\nremote: Total 219 (delta 20), reused 23 (delta 9), pack-reused 185\nReceiving objects: 100% (219/219), 33.96 MiB | 3.84 MiB/s, done.\nResolving deltas: 100% (122/122), done.\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e실행해 보자\u003c/p\u003e","title":"clienBBS"},{"content":"mac mini 2009에 windows 10을 무사히 설치.\n몇 가지 삽질을 적어보면\nmac mini는 windows 7까지만 지원하고, optic drive를 이용한 설치만 지원하기 때문에 그냥(?) 해서는 windows 10을 설치할 수 없음. 이를 해결하려면 Applications/Utilities에 있는 Boot camp assistant 앱을 복사해서 Contents 디렉토리에 있는 Info.plist 파일 내용을 수정해야 함. 대충 보면 Win7OnlyModels 하는 부분이랑 USBBootSupportedModels 부분을 아예 삭제하면 된다.\nBoot camp를 실행시켜 windows partition을 나누려고 했는데 이상하게 3조각으로 나뉘어지면서 윈도10용 설치 파티션을 만들 수 없다고 해서 결국 엘케피탄 설치 파일을 이용해서 다시 설치. 이 과정에서 이미 app store에서 숨겨진 El capitan 용 설치 SW 받기 위해 mas-cli라는 유틸리티를 알게 되서 활용(백투더맥 쵝오!)\nOSX 새로 설치한 후 boot camp 수정해서 설치를 진행하는데 이번엔 윈도 설치 과정에서 boot camp가 만들어 넣은 파티션에 설치를 못하겠다고 반항. 한번 실패하면 그냥 맥 리붓 후 alt 키로 부팅 매체 선택해서는 윈도 설치 과정이 제대로 실행되지 않아 다시 맥으로 부팅한 후 boot camp를 통해 다시 disk partition을 하나로 뭉쳤다 다시 분할해서 리붓이 되어야 제대로 윈도 부팅 화면으로 넘어감. 그런데 역시 다시 시도해도 윈도 파티션에 윈도를 설치하지 못하겠다는.\n클리앙에 질문을 올렸더니 USB에 연결된 거 다 빼보라고. 혹시나 하고 따라했는데 정말로 한방에 설치 진행. El capitan 다시 설치하느라 끼워둔 OS X 설치 USB때문이었다는.\n다 설치하고 나니 2009년 mac mini - Core2Duo 2Ghz, 4GB RAM, 120GB SSD인데 회사 컴퓨터보다 빠른 것 같은 착각이 막 든다. 반응성도 전혀 문제 없고(하긴 설치한 게 없으니) 은행용으로만 딱 쓸거라.\n이제 고민은 윈도 10용 라이센스를 살 것인가 아니면 HP mini PC에 SSD를 설치해서 사용할 것인가. 후자는 Windows 10 Pro 라이센스가 포함된 제품이라 SSD 7만원 투자하면 될 것 같은데 전자는?\n일단 예전에 어디 대란일때 사 둔 윈도 라이센스를 한번 적용해 볼까 싶은데\n","date":"2017-12-12T15:18:05+09:00","permalink":"https://cychong47.github.io/post/2017/mac-mini-e-windows-10-seolci/","summary":"\u003cp\u003emac mini 2009에 windows 10을 무사히 설치.\u003c/p\u003e\n\u003cp\u003e몇 가지 삽질을 적어보면\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003emac mini는 windows 7까지만 지원하고, optic drive를 이용한 설치만 지원하기 때문에 그냥(?) 해서는 windows 10을 설치할 수 없음. 이를 해결하려면 Applications/Utilities에 있는 Boot camp assistant 앱을 복사해서 Contents 디렉토리에 있는 Info.plist 파일 내용을 수정해야 함. 대충 보면 Win7OnlyModels 하는 부분이랑 USBBootSupportedModels 부분을 아예 삭제하면 된다.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBoot camp를 실행시켜 windows partition을 나누려고 했는데 이상하게 3조각으로 나뉘어지면서 윈도10용 설치 파티션을 만들 수 없다고 해서 결국 엘케피탄 설치 파일을 이용해서 다시 설치. 이 과정에서 이미 app store에서 숨겨진 El capitan 용 설치 SW 받기 위해 mas-cli라는 유틸리티를 알게 되서 활용(백투더맥 쵝오!)\u003c/p\u003e","title":"mac mini 에 windows 10 설치"},{"content":"Vagrant What is a Vagrant? Backend에 virtualbox를 사용(변경 가능) 하고, virtualbox를 이용해 VM을 생성하여 그 VM 내 원하는 환경(특정 OS부터 특정 library까지) 을 구성함.\n예전에 fd.io에서 빌드하는 vpp 개발 환경이 vagrant로 되어 있었는데 왜 그런가 싶었는데 이제 생각해 보니 vpp 동작에 필요한 OS, kernel module, DPDK SDK 와 패치 들 그리고 vpp code 까지 모든 걸 제어할 수 있도록 VagrantFile을 만들어서 개발 환경을 표준화하려는 것 이었다는.\nContainer와 달리 독립된 OS환경을 가질 수 있으므로 OS버전이 다르거나 , 커널 모듈 수정 등을 필요로 한 경우에 유용할 듯\nVirtualbox가 생각보다 가벼워서 유용한 듯 하다.\nVagrantFile을 이용해서 vagrant up한 후 vagrant box list로 생성된 VM instance 들을 확인한 후 vagrant ssh VM_NAME하면 해당 VM으로 접속. 그러므로 미리 VagrantFile을 통해 지정한 환경이 모두 구성되어 있다는.\nDocker와 유사하게 host와 volume을 공유할 수 있음.(이건 그냥 virtualbox가 지원하는 shared folder 기능을 활용하는 듯)\n그 외 사용 측면에서는 docker나 virsh 명령어 사용하는 것과 유사.\nInstall Vagrant on OS X mbpr15:~ cychong$ brew cask install vagrant ==\u0026gt; Satisfying dependencies ==\u0026gt; Downloading https://releases.hashicorp.com/vagrant/2.0.1/vagrant_2.0.1_x86_64.dmg ######################################################################## 100.0% ==\u0026gt; Verifying checksum for Cask vagrant ==\u0026gt; Installing Cask vagrant ==\u0026gt; Running installer for vagrant; your password may be necessary. ==\u0026gt; Package installers may write to any location; options such as --appdir are ignored. Password: ==\u0026gt; installer: Package name is Vagrant ==\u0026gt; installer: Installing at base path / ==\u0026gt; installer: The install was successful. 🍺 vagrant was successfully installed! Install vagrant-manager additionally\nmbpr15:~ cychong$ brew cask install vagrant-manager ==\u0026gt; Satisfying dependencies ==\u0026gt; Downloading https://github.com/lanayotech/vagrant-manager/releases/download/2.6.0/vagrant-manager-2.6.0.dmg ######################################################################## 100.0% ==\u0026gt; Verifying checksum for Cask vagrant-manager ==\u0026gt; Installing Cask vagrant-manager ==\u0026gt; Moving App \u0026#39;Vagrant Manager.app\u0026#39; to \u0026#39;/Applications/Vagrant Manager.app\u0026#39;. 🍺 vagrant-manager was successfully installed! Install Vagrant Box Virtualbox is already installed\nAdd Vagrant box which can be found from Vagrant Cloud\nmbpr15:~ cychong$ vagrant box add ubuntu/xenial64 https://app.vagrantup.com/ubuntu/boxes/xenial64 ==\u0026gt; box: Loading metadata for box \u0026#39;https://app.vagrantup.com/ubuntu/boxes/xenial64\u0026#39; ==\u0026gt; box: Adding box \u0026#39;ubuntu/xenial64\u0026#39; (v20171122.0.0) for provider: virtualbox box: Downloading: https://vagrantcloud.com/ubuntu/boxes/xenial64/versions/20171122.0.0/providers/virtualbox.box ==\u0026gt; box: Successfully added box \u0026#39;ubuntu/xenial64\u0026#39; (v20171122.0.0) for \u0026#39;virtualbox\u0026#39;! Initialize Vagrant mbpr15:~ cychong$ cd /Users/cychong/Public/working mbpr15:working cychong$ vagrant init ubuntu/xenial64 A `Vagrantfile` has been placed in this directory. You are now ready to `vagrant up` your first virtual environment! Please read the comments in the Vagrantfile as well as documentation on `vagrantup.com` for more information on using Vagrant. Start Vagrant It takes some time\nmbpr15:working cychong$ vagrant up Bringing machine \u0026#39;default\u0026#39; up with \u0026#39;virtualbox\u0026#39; provider... ==\u0026gt; default: Importing base box \u0026#39;ubuntu/xenial64\u0026#39;... ==\u0026gt; default: Matching MAC address for NAT networking... ==\u0026gt; default: Checking if box \u0026#39;ubuntu/xenial64\u0026#39; is up to date... ==\u0026gt; default: Setting the name of the VM: working_default_1511385943610_77718 ==\u0026gt; default: Clearing any previously set network interfaces... ==\u0026gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat ==\u0026gt; default: Forwarding ports... default: 22 (guest) =\u0026gt; 2222 (host) (adapter 1) ==\u0026gt; default: Running \u0026#39;pre-boot\u0026#39; VM customizations... ==\u0026gt; default: Booting VM... ==\u0026gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: ubuntu default: SSH auth method: password default: Warning: Connection reset. Retrying... default: Warning: Remote connection disconnect. Retrying... default: Warning: Connection reset. Retrying... default: Warning: Remote connection disconnect. Retrying... default: Warning: Connection reset. Retrying... default: Warning: Remote connection disconnect. Retrying... default: default: Inserting generated public key within guest... default: Removing insecure key from the guest if it\u0026#39;s present... default: Key inserted! Disconnecting and reconnecting using new SSH key... ==\u0026gt; default: Machine booted and ready! ==\u0026gt; default: Checking for guest additions in VM... default: The guest additions on this VM do not match the installed version of default: VirtualBox! In most cases this is fine, but in rare cases it can default: prevent things such as shared folders from working properly. If you see default: shared folder errors, please make sure the guest additions within the default: virtual machine match the version of VirtualBox you have installed on default: your host and reload your VM. default: default: Guest Additions Version: 5.0.40 default: VirtualBox Version: 5.2 ==\u0026gt; default: Mounting shared folders... default: /vagrant =\u0026gt; /Users/cychong/Public/working Login to Vagrant VM mbpr15:working cychong$ vagrant ssh Welcome to Ubuntu 16.04.3 LTS (GNU/Linux 4.4.0-101-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage Get cloud support with Ubuntu Advantage Cloud Guest: http://www.ubuntu.com/business/services/cloud 0 packages can be updated. 0 updates are security updates. _____________________________________________________________________ WARNING! Your environment specifies an invalid locale. The unknown environment variables are: LC_CTYPE=UTF-8 LC_ALL= This can affect your user experience significantly, including the ability to manage packages. You may install the locales by running: sudo apt-get install language-pack-UTF-8 or sudo locale-gen UTF-8 To see all available language packs, run: apt-cache search \u0026#34;^language-pack-[a-z][a-z]$\u0026#34; To disable this message for all users, run: sudo touch /var/lib/cloud/instance/locale-check.skip _____________________________________________________________________ ubuntu@ubuntu-xenial:~$ df -h Filesystem Size Used Avail Use% Mounted on udev 490M 0 490M 0% /dev tmpfs 100M 3.1M 97M 4% /run /dev/sda1 9.7G 858M 8.8G 9% / tmpfs 497M 0 497M 0% /dev/shm tmpfs 5.0M 0 5.0M 0% /run/lock tmpfs 497M 0 497M 0% /sys/fs/cgroup vagrant 466G 269G 197G 58% /vagrant tmpfs 100M 0 100M 0% /run/user/1000 /vagrant directory This directory is used to shared files between the host and VM and the size of this partition is same to the storage of host machine\nmbpr15:working cychong$ df -h . Filesystem Size Used Avail Capacity iused ifree %iused Mounted on /dev/disk1s1 466Gi 265Gi 197Gi 58% 1137732 9223372036853638075 0% / install tools as usual linux box ubuntu@ubuntu-xenial:/vagrant$ sudo apt install gcc Reading package lists... Done Building dependency tree Reading state information... Done The following additional packages will be installed: binutils cpp cpp-5 gcc-5 libasan2 libatomic1 libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libgcc-5-dev libgomp1 libisl15 libitm1 liblsan0 libmpc3 libmpx0 libquadmath0 libtsan0 libubsan0 linux-libc-dev manpages-dev Suggested packages: binutils-doc cpp-doc gcc-5-locales gcc-multilib make autoconf automake libtool flex bison gdb gcc-doc gcc-5-multilib gcc-5-doc libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg libasan2-dbg liblsan0-dbg libtsan0-dbg libubsan0-dbg libcilkrts5-dbg libmpx0-dbg libquadmath0-dbg glibc-doc The following NEW packages will be installed: binutils cpp cpp-5 gcc gcc-5 libasan2 libatomic1 libc-dev-bin libc6-dev libcc1-0 libcilkrts5 libgcc-5-dev libgomp1 libisl15 libitm1 liblsan0 libmpc3 libmpx0 libquadmath0 libtsan0 libubsan0 linux-libc-dev manpages-dev 0 upgraded, 23 newly installed, 0 to remove and 0 not upgraded. Need to get 27.6 MB of archives. After this operation, 99.7 MB of additional disk space will be used. Do you want to continue? [Y/n] y Get:1 http://archive.ubuntu.com/ubuntu xenial/main amd64 libmpc3 amd64 1.0.3-1 [39.7 kB] Get:2 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 binutils amd64 2.26.1-1ubuntu1~16.04.5 [2311 kB] Get:3 http://archive.ubuntu.com/ubuntu xenial/main amd64 libisl15 amd64 0.16.1-1 [524 kB] Get:4 http://archive.ubuntu.com/ubuntu xenial-updates/main amd64 cpp-5 amd64 5.4.0-6ubuntu1~16.04.5 [7786 kB] ... Processing triggers for libc-bin (2.23-0ubuntu9) ... ubuntu@ubuntu-xenial:/vagrant$ No need to install Linux manually The Ubuntu is installed manually and the second working_default_xfasfa is installed with Vagrant.\nIn summary brew cask install vagrant brew cask install vagrant-manager vagrant box add ubuntu/xenial64 https://app.vagrantup.com/ubuntu/boxes/xenial64 cd /Users/cychong/Public/working vagrant init ubuntu/xenial64 vagrant up vagrant ssh reference Vagrant | Mac OS X Setup Guide VirtualBox와 Vagrant의 기본 사용법 - 나만모르는 이야기 RORLAB | rBlog : Vagrant를 이용한 손쉬운 개발환경 구축 #vagrant #TIL\n","date":"2017-11-21T15:04:19+09:00","permalink":"https://cychong47.github.io/post/2017/vagrant-2/","summary":"\u003ch1 id=\"vagrant\"\u003eVagrant\u003c/h1\u003e\n\u003ch2 id=\"what-is-a-vagrant\"\u003eWhat is a Vagrant?\u003c/h2\u003e\n\u003cp\u003eBackend에 virtualbox를 사용(변경 가능) 하고, virtualbox를 이용해 VM을 생성하여 그 VM 내 원하는 환경(특정 OS부터 특정 library까지) 을 구성함.\u003c/p\u003e\n\u003cp\u003e예전에 fd.io에서 빌드하는 vpp 개발 환경이 vagrant로 되어 있었는데 왜 그런가 싶었는데 이제 생각해 보니 vpp 동작에 필요한 OS, kernel module, DPDK SDK 와 패치 들 그리고 vpp code 까지 모든 걸 제어할 수 있도록 VagrantFile을 만들어서 개발 환경을 표준화하려는 것 이었다는.\u003c/p\u003e\n\u003cp\u003eContainer와 달리 독립된 OS환경을 가질 수 있으므로 OS버전이 다르거나 , 커널 모듈 수정 등을 필요로 한 경우에 유용할 듯\u003c/p\u003e","title":"Vagrant"},{"content":"From Amdocs Preps \u0026lsquo;Carrier-Grade\u0026rsquo; Version of ONAP | Light Reading(http://www.lightreading.com/mobile/mec-(mobile-edge-computing)/amdocs-preps-carrier-grade-version-of-onap/d/d-id/738315)\n\u0026ldquo;We\u0026rsquo;re just about to make a big carrier [and] enterprise grade release of ONAP,\u0026rdquo; Angela Logothetis, VP and CTO of Amdocs Open Network, told Light Reading\nLogothetis says that Amdocs is working with Intel Corp. (Nasdaq: INTC) on edge computing proofs-of-concept. This involves understanding what content and data needs to cached and where exactly that should happen on the network.\nAmdoc 이 MEC에 관심을 갖고 있다. 어떤 의미일까? MEC에 올라가는 SW에 대한 platform을 제공하려는 걸까?\n\u0026ldquo;That\u0026rsquo;s an easy place to start,\u0026rdquo; Logothetis suggested, while noting the irony that standards around the 5G core are probably the \u0026ldquo;least defined\u0026rdquo; of the next-gen specification, because the 3rd Generation Partnership Project (3GPP) typically focuses on the radio access network (RAN).\nONAP Use case(in Amsterdam release) 는 Core 기반의 서비스가 많다고. 5G는 RAN에 대한 내용이 많은데. Core 기반으로 ONAP use case를 하기 쉬운 이유가 뭘까?\n​\nLogothetis says that amongst the next important task for the ONAP Project, which now numbers nearly 20 major global service providers and vendors among its members, is to understand AI. \u0026ldquo;The next interesting thing that comes around is artificial Intelligence and machine learning, which is new for all of us,\u0026rdquo; she said.\n역시 관심은 AI 와 ML 겸손(?)하게 자신들을 포함한 많은 SP들에게 새로운 분야라고.\nThe company is also looking at cloud RAN, which involves having virtualized basestation control functions running at the data center controlling distributed radioheads at the cellsite, and virtualized RAN. V-RAN involves \u0026ldquo;disaggregation\u0026rdquo; of the radio network, with some antenna functions eventually being run on white boxes at the cellsite.\nVRAN에 대해 Amdocs는 어떤 관심을 갖고 있는 걸까? Control function의 base를 ONAP으로 구현하려고? 아니면 Data center와 cell site등에 퍼져있는 다양한 장비를 관리하는 management system을 ONAP으로 만들려고?\n​ #amdocs #onap #edge #mec #vran\n","date":"2017-11-21T14:51:25+09:00","permalink":"https://cychong47.github.io/post/2017/amdocs-preps-carrier-grade-version-of-onap/","summary":"\u003cp\u003eFrom Amdocs Preps \u0026lsquo;Carrier-Grade\u0026rsquo; Version of ONAP | Light Reading(\u003ca href=\"http://www.lightreading.com/mobile/mec-(mobile-edge-computing)/amdocs-preps-carrier-grade-version-of-onap/d/d-id/738315\"\u003ehttp://www.lightreading.com/mobile/mec-(mobile-edge-computing)/amdocs-preps-carrier-grade-version-of-onap/d/d-id/738315\u003c/a\u003e)\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;We\u0026rsquo;re just about to make a big carrier [and] enterprise grade release of ONAP,\u0026rdquo; Angela Logothetis, VP and CTO of Amdocs Open Network, told Light Reading\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003eLogothetis says that Amdocs is working with Intel Corp. (Nasdaq: INTC) on edge computing proofs-of-concept. This involves understanding what content and data needs to cached and where exactly that should happen on the network.\u003c/p\u003e","title":"Amdocs Preps 'Carrier-Grade' Version of ONAP"},{"content":"1st release Amsterdam release which is due to November 16\nCritics It will not be stable enough to be used for product\nmisunderstanding That release will focus on providing support for three network functions or services \u0026ndash; a virtual firewall (vFW), virtual customer premises equipment (vCPE) and a voice-over-LTE service running on a virtual evolved packet core (vEPC)\nI think this is a misunderstanding. These are just an use case not the ONAP supports them only. Maybe that can be interpreted ONAP is verified for this cases. But still it does not mean ONAP supports only them\nBCE(Toronto) As a member of ONAP, we look forward to working with our international partners to begin the implementation of Version 1 later this year. That Operations Manager should support the deployment, management and operation of the ONAP platform and its component parts. It could feature in Release 2, codenamed Beijing and set to appear on May 24 next year.\nONAP Platform 자체를 쉽게 설치하고 관리할 수 있는 OOM에 대한 관심이 높음. OOM : ONAP Operations Manager\nEquinix - colocation service provider While we have no immediate plans to use the upcoming first release in production,\n(original news](http://www.lightreading.com/open-source/industry-bodies-groups/onap-takes-flak-as-telcos-prep-for-release-1/d/d-id/737906)\n","date":"2017-11-14T22:31:57+09:00","permalink":"https://cychong47.github.io/post/2017/onap-takes-flak-as-telcos-prep-for-release-1-light-reading/","summary":"\u003ch3 id=\"1st-release\"\u003e1st release\u003c/h3\u003e\n\u003cp\u003eAmsterdam release which is due to November 16\u003c/p\u003e\n\u003ch3 id=\"critics\"\u003eCritics\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIt will not be stable enough to be used for product\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"misunderstanding\"\u003emisunderstanding\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThat release will focus on providing support for three network functions or services \u0026ndash; a virtual firewall (vFW), virtual customer premises equipment (vCPE) and a voice-over-LTE service running on a virtual evolved packet core (vEPC)\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eI think this is a misunderstanding. These are just an use case not the ONAP supports them only. Maybe that can be interpreted ONAP is verified for this cases. But still it does not mean ONAP supports only them\u003c/p\u003e","title":"ONAP Takes Flak as Telcos Prep for Release 1 | Light Reading"},{"content":"\nbook from Amazon\n","date":"2017-10-29T01:38:23+09:00","permalink":"https://cychong47.github.io/post/2017/lead-or-step-aside/","summary":"\u003cp\u003e\u003cimg src=\"/images/2017/10/IMG_4262.JPG\" alt=\"IMG_4262\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://www.amazon.com/Lead-Follow-Get-Out-Way/dp/0812910044\"\u003ebook from Amazon\u003c/a\u003e\u003c/p\u003e","title":"Lead Follow or Get Out of the Way"},{"content":"구글이 연구한 \u0026lsquo;좋은 관리자가 가져야 할 8가지 덕목\u0026rsquo;.\n좋은 코치(coaches)다. 팀에게 권한을 양도하며 마이크로매니지를 하지 않는다. 팀원의 성공에 관심을 표명하며 개인적 삶에도 관심을 기울인다. 생산적이며 결과를 중심으로 사고한다. 훌륭한 커뮤니케이션 능력을 가지고 있다. 팀원들이 경력을 키워나가도록 도움을 준다. 팀을 위한 명확한 비전을 가지고 있다. 팀에게 조언을 해주기에 충분한 기술적인 능력을 갖추고 있다. 하나 하나 절대 쉬운 일이 없다.\n구글이 제시한 \u0026lsquo;관리자의 자격\u0026rsquo; .\n","date":"2017-10-28T15:34:55+09:00","permalink":"https://cychong47.github.io/post/2017/what-is-good-manager/","summary":"\u003cp\u003e구글이 연구한 \u0026lsquo;좋은 관리자가 가져야 할 8가지 덕목\u0026rsquo;.\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e좋은 코치(coaches)다.\u003c/li\u003e\n\u003cli\u003e팀에게 권한을 양도하며 마이크로매니지를 하지 않는다.\u003c/li\u003e\n\u003cli\u003e팀원의 성공에 관심을 표명하며 개인적 삶에도 관심을 기울인다.\u003c/li\u003e\n\u003cli\u003e생산적이며 결과를 중심으로 사고한다.\u003c/li\u003e\n\u003cli\u003e훌륭한 커뮤니케이션 능력을 가지고 있다.\u003c/li\u003e\n\u003cli\u003e팀원들이 경력을 키워나가도록 도움을 준다.\u003c/li\u003e\n\u003cli\u003e팀을 위한 명확한 비전을 가지고 있다.\u003c/li\u003e\n\u003cli\u003e팀에게 조언을 해주기에 충분한 기술적인 능력을 갖추고 있다.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e하나 하나 절대 쉬운 일이 없다.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://m.news.naver.com/read.nhn?mode=LSD\u0026amp;sid1=001\u0026amp;oid=092\u0026amp;aid=0002112310\"\u003e구글이 제시한 \u0026lsquo;관리자의 자격\u0026rsquo; \u003c/a\u003e.\u003c/p\u003e","title":"관리자는 '관리'업무를 하는 동료이다."},{"content":"Purpose 매일 낮 11시 부터 1시간 동안 CBS 뮤직 FM에서 진행되는 신영음을 듣고 싶다. 아주 오래 전 가장 좋아했던 라디어 프로가 정은임씨가 진행하던 영화음악 이었는데 한참 후에 알게된 신영음을 통해 내가 좋아하는 영화음악을 다시 들을 수 있게 되었다. 문제는 라디오 방송 시간. 어디서든 CBS FM 라디오를 들을 수 있는 공식 레인보우앱 이나 myTuner Pro 같은 앱을 쓰면 들을 수 있지만, 근무시간에 라디오를 듣기도 그렇고, 결정적으로 11시 30분에서 12시 사이에 점심 시간이 시작되어 제대로 듣기가 힘들었다.\n이를 해결(?)하기 위해 그냥 스트리밍을 녹음해서 듣는 걸로\nStep 1 - Find out the streaming URL 마이너 라디오 방송이라 그런지 의외로 streaming 주소가 쉽게 찾아지지 않았다. 그래도 myTuner Pro앱이나 Korea onAir 같은 OS X용 앱에서도 CBS를 들을 수 있는 걸 보면 분명히 어딘가에는 스트리밍 주소가 있을 거라는 생각에 찾다 드디어 제대로 동작하는 스트리밍 주소를 찾을 수 있었다.\nhttp://aac.cbs.co.kr/cbs939/_definst_/cbs939.stream/playlist.m3u8 Step 2 - register recording task to launchd crond를 사용해서 매일 오전 11시 부터 녹음되도록 할까 했는데 OS X에서는 crond를 대체하는 launchd를 사용하는 게 낫다는 글을 보고 한번 해보기로 했다.\n비교적 간단(?)하게 원하는 내용을 설정할 수 있는 crond와 달리 launchd는 plist 파일을 이용해서 원하는 작업을 정의해야 한다고 한다.\ncychong.record.plist file\n\u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;!DOCTYPE plist PUBLIC \u0026#34;-//Apple Computer//DTD PLIST 1.0//EN\u0026#34; \u0026#34;http://www.apple.com/DTDs/PropertyList-1.0.dtd\u0026#34;\u0026gt; \u0026lt;plist version=\u0026#34;1.0\u0026#34;\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Label\u0026lt;/key\u0026gt; \u0026lt;string\u0026gt;cychong.record.cbs\u0026lt;/string\u0026gt; \u0026lt;key\u0026gt;ProgramArguments\u0026lt;/key\u0026gt; \u0026lt;array\u0026gt; \u0026lt;string\u0026gt;/Users/cychong/Dropbox/working/mp3/record.py\u0026lt;/string\u0026gt; \u0026lt;/array\u0026gt; \u0026lt;key\u0026gt;StartCalendarInterval\u0026lt;/key\u0026gt; \u0026lt;dict\u0026gt; \u0026lt;key\u0026gt;Hour\u0026lt;/key\u0026gt; \u0026lt;integer\u0026gt;10\u0026lt;/integer\u0026gt; \u0026lt;key\u0026gt;Minute\u0026lt;/key\u0026gt; \u0026lt;integer\u0026gt;57\u0026lt;/integer\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/dict\u0026gt; \u0026lt;/plist\u0026gt; 이제 launchctl을 이용해 위 plist 파일을 등록한다.\n$ launchctl load cychong.record.cbs.plist 제대로 등록되었는 지 확인은 아래 명령어를 이용\nmbpr15:mp3 cychong$ launchctl list |grep cychong -\t0\tcychong.record.cbs 실제로 지정된 시간(11시 3분 전)에 실행되도록 한 script는 아래와 같다.\n#!/usr/bin/env python import os from time import localtime, strftime filename = strftime(\u0026#34;cbs_cinema_%Y%M%d.mp3\u0026#34;, localtime()) os.system(\u0026#34;/usr/local/bin/ffmpeg -y -t 3605 -i http://aac.cbs.co.kr/cbs939/_definst_/cbs939.stream/playlist.m3u8 /Users/cychong/Dropbox/working/mp3/%s\u0026#34; %filename) 생성된 파일 크기 size= 938kB time=00:01:00.00 bitrate= 128.1kbits/s speed=1.98x ffmpeg이 출력하는 정보를 보면 128.1kbps이므로 1분당 960.75KB(128.1/8*60) 의 파일 생성. 1시간 짜리를 녹음하면 대략 58MB정도의 파일을 생성할 수 있다.\n처음에는 podcast에 등록해서 매일 저녁에 자동으로 그날 녹음한 파일을 폰에 다운로드 받게 할까 했는데 파일 크기가 크지 않아 그냥 dropbox에 저장되도록 하고 dropbox app을 이용해서 들어보려고 한다.\nHow about mms streaming? It is not clear whether ffmpeg support the recording mms streaming. I recommend to check mimms\nbrew install mimms mimms -t 60 mms://STREAMING_ADDRESS Something is wrong 실제 사용해 보니 이상하게 mp3 파일이 1시간 짜리 58MB가 아니라 1.2MB 정도만 만들어지고 만다. 혹시나 해서 예약 시간을 옮겨서 눈을 부릅뜨고 실험해 봐도 정상적으로 동작하는데. 녹음된 1분 가량의 분량은 정상적으로 재생되는데.\n뭘까 뭘까 하다 든 생각이 power-saving. launchd를 통해 녹음 작업을 등록한 머신은 정상적으로 power-saving 기능이 기본 설정되어 있어 혹시 이와 관련된 게 아닌가 싶다. 그래서 동일한 plist 파일을 power saving 기능을 꺼 놓은 맥미니에 설정했더니 정상적으로 동작한다. 다행이다.\nReference launcha plist 파일을 만들어 주는 웹페이지 Mac OS X launchd examples (launchd plist example files) launchd.plist \u0026ndash; System wide and per-user daemon/agent configuration files. Schedule jobs using launchd launchd script to open webpage everyday at a certain time ","date":"2017-10-09T16:22:15+09:00","permalink":"https://cychong47.github.io/post/2017/record-cbs-fm-cinema-music/","summary":"\u003ch1 id=\"purpose\"\u003ePurpose\u003c/h1\u003e\n\u003cp\u003e매일 낮 11시 부터 1시간 동안 CBS 뮤직 FM에서 진행되는 \u003ccode\u003e신영음\u003c/code\u003e을 듣고 싶다. 아주 오래 전 가장 좋아했던 라디어 프로가 정은임씨가 진행하던 영화음악 이었는데 한참 후에 알게된 \u003ccode\u003e신영음\u003c/code\u003e을 통해 내가 좋아하는 영화음악을 다시 들을 수 있게 되었다.\n문제는 라디오 방송 시간. 어디서든 CBS FM 라디오를 들을 수 있는 공식 \u003ccode\u003e레인보우\u003c/code\u003e앱 이나 \u003ccode\u003emyTuner Pro\u003c/code\u003e 같은 앱을 쓰면 들을 수 있지만, 근무시간에 라디오를 듣기도 그렇고, 결정적으로 11시 30분에서 12시 사이에 점심 시간이 시작되어 제대로 듣기가 힘들었다.\u003c/p\u003e","title":"Record CBS Music Radio in every day"},{"content":"최적화(?) 중.\nLightroom으로 사진 관리 Apple Photos 앱이 아닌 Adobe Lightroom으로 사진 관리. 사진 파일은 DB에 포함시키지 않고, meta data만 DB에 저장하도록 import 방식을 사용. mbpr15:Lightroom cychong$ pwd /Users/cychong/Pictures/Lightroom mbpr15:Lightroom cychong$ ls -al total 55288 drwxr-xr-x 7 cychong staff 224 Oct 9 23:36 . drwx------+ 5 cychong staff 160 Oct 8 10:55 .. -rw-r--r--@ 1 cychong staff 6148 Oct 9 22:47 .DS_Store drwxr-xr-x 20 cychong staff 640 Oct 9 23:43 Lightroom Catalog Previews.lrdata -rw-r--r--@ 1 cychong staff 26193920 Oct 9 23:41 Lightroom Catalog.lrcat -rw-r--r-- 1 cychong staff 1687256 Oct 9 23:41 Lightroom Catalog.lrcat-journal -rw-r--r-- 1 cychong staff 55 Oct 9 18:58 Lightroom Catalog.lrcat.lock 1차 작업 공간은 500G SSD 백업 1차 백업 - Mac mini 2011 1TB 내장 하드에 백업 일단은 ditto app으로 일괄 복사.(incremental backup solution 찾아 적용 필요)\n주 작업 머신인 Mackbook Pro 15인치 2017에 mac mini 2011 1TB 하드 마운트(/Volumes/data) 후 작업\n$ ditto /Volumes/Samsung_T3/Pictures/2017/ /Volumes/data/Pictures/2017/ -v 2차 백업 - Mac mini 2011 2TB 외장 하드에 백업 (1차 백업과 동일한 이슈)\nMac mini 2011에 외장 하드 연결(/Volumes/ET) 후 작업\nmini2:/Volumes/ET/Pictures cychong$ mkdir 2017 mini2:/Volumes/ET/Pictures cychong$ ditto /Volumes/data/Pictures/2017/ ./2017/ 3차 백업 - NAS 4TB에 백업 - FIXME 원래 백업 대상이던 primary HDD가 볼륨 에러(고장)으로 사용 불가 상태라 primray HDD에 대한 backup용으로 사용하던 secondary HDD에 직접 복사하도록 작업 필요\nNAS 디렉토리 마운트 후 동일 작업 수행\n추가 고려사항) 2014/2015년에 구입한 하드라 secondary HDD도 고장이 날 수 있어 cloud backup 솔류션 확보 필요\nTODO Cloud backup solution 검토 백업 자동화 다수의 공간에 산재한 파일 들 정리 필요 ","date":"2017-10-09T15:41:52+09:00","permalink":"https://cychong47.github.io/post/2017/sajin-baegeob-2017-beojeon/","summary":"\u003cp\u003e최적화(?) 중.\u003c/p\u003e\n\u003ch2 id=\"lightroom으로-사진-관리\"\u003eLightroom으로 사진 관리\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eApple Photos 앱이 아닌 Adobe Lightroom으로 사진 관리.\u003c/li\u003e\n\u003cli\u003e사진 파일은 DB에 포함시키지 않고, meta data만 DB에 저장하도록 import 방식을 사용.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:Lightroom cychong$ pwd\n/Users/cychong/Pictures/Lightroom\nmbpr15:Lightroom cychong$ ls -al\ntotal 55288\ndrwxr-xr-x   7 cychong  staff       224 Oct  9 23:36 .\ndrwx------+  5 cychong  staff       160 Oct  8 10:55 ..\n-rw-r--r--@  1 cychong  staff      6148 Oct  9 22:47 .DS_Store\ndrwxr-xr-x  20 cychong  staff       640 Oct  9 23:43 Lightroom Catalog Previews.lrdata\n-rw-r--r--@  1 cychong  staff  26193920 Oct  9 23:41 Lightroom Catalog.lrcat\n-rw-r--r--   1 cychong  staff   1687256 Oct  9 23:41 Lightroom Catalog.lrcat-journal\n-rw-r--r--   1 cychong  staff        55 Oct  9 18:58 Lightroom Catalog.lrcat.lock\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"1차-작업-공간은-500g-ssd\"\u003e1차 작업 공간은 500G SSD\u003c/h2\u003e\n\u003ch2 id=\"백업\"\u003e백업\u003c/h2\u003e\n\u003ch3 id=\"1차-백업---mac-mini-2011-1tb-내장-하드에-백업\"\u003e1차 백업 - Mac mini 2011 1TB 내장 하드에 백업\u003c/h3\u003e\n\u003cp\u003e일단은 ditto app으로 일괄 복사.(incremental backup solution 찾아 적용 필요)\u003c/p\u003e","title":"사진 백업 2017 버전"},{"content":"When I call the homebrew modules for three hosts including the localhost, one host reports error.\nmbpr15:~ cychong$ ansible-playbook install_brew_ack.yaml --verbose No config file found; using defaults PLAY [all] ************************************************************************************************** TASK [Gathering Facts] ************************************************************************************** ok: [localhost] ok: [mini2] ok: [mini1] TASK [install ack in homebrew] ****************************************************************************** ok: [localhost] =\u0026gt; {\u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Package already installed: ack\u0026#34;} ok: [mini1] =\u0026gt; {\u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Package already installed: ack\u0026#34;} fatal: [mini2]: FAILED! =\u0026gt; {\u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: true, \u0026#34;msg\u0026#34;: \u0026#34;Warning: git 2.14.2 is already installed\\nError: Git must be installed and in your PATH!\\nxcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun\\nError: ack cannot be built with any available compilers.\\nInstall GNU\u0026#39;s GCC\\n brew install gcc\u0026#34;} to retry, use: --limit @/Users/cychong/install_brew_ack.retry PLAY RECAP ************************************************************************************************** localhost : ok=2 changed=0 unreachable=0 failed=0 mini1 : ok=2 changed=0 unreachable=0 failed=0 mini2 : ok=1 changed=0 unreachable=0 failed=1 This requires xcrun is not installed. (The following command will have a pop-up window to install command line tool).\n$ xcode-select --install After that, error is gone~\nReference https://apple.stackexchange.com/questions/254380/macos-sierra-invalid-active-developer-path ","date":"2017-10-08T17:25:43+09:00","permalink":"https://cychong47.github.io/post/2017/untitled-2/","summary":"\u003cp\u003eWhen I call the homebrew modules for three hosts including the localhost, one host reports error.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:~ cychong$ ansible-playbook install_brew_ack.yaml --verbose\nNo config file found; using defaults\n\nPLAY [all] **************************************************************************************************\n\nTASK [Gathering Facts] **************************************************************************************\nok: [localhost]\nok: [mini2]\nok: [mini1]\n\nTASK [install ack in homebrew] ******************************************************************************\nok: [localhost] =\u0026gt; {\u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Package already installed: ack\u0026#34;}\nok: [mini1] =\u0026gt; {\u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Package already installed: ack\u0026#34;}\nfatal: [mini2]: FAILED! =\u0026gt; {\u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: true, \u0026#34;msg\u0026#34;: \u0026#34;Warning: git 2.14.2 is already installed\\nError: Git must be installed and in your PATH!\\nxcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun\\nError: ack cannot be built with any available compilers.\\nInstall GNU\u0026#39;s GCC\\n  brew install gcc\u0026#34;}\n\tto retry, use: --limit @/Users/cychong/install_brew_ack.retry\n\nPLAY RECAP **************************************************************************************************\nlocalhost                  : ok=2    changed=0    unreachable=0    failed=0   \nmini1                      : ok=2    changed=0    unreachable=0    failed=0   \nmini2                      : ok=1    changed=0    unreachable=0    failed=1   \n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eThis requires xcrun is not installed. (The following command will have a pop-up window to install command line tool).\u003c/p\u003e","title":"Error in using homebrew module in ansible"},{"content":"It is gone finally\u0026hellip; [macOS Server 5.4 changes in High Sierra you need to know about!])https://www.imore.com/changes-macos-server-54-high-sierra)\nFile Transfer Protocol (FTP): A longtime a security risk, for example for sending password information in clear text, FTP support will be removed from macOS server if you upgrade.\nAs my xeros printer/scanner suppors only ftp or samba(which is much much slower than the ftp) I have to run my own ftp server in my mac mini.\nGoogling sugggest me to use pyftpdlib\nmini2:~ cychong$ pip install pyftpdlib Collecting pyftpdlib Downloading pyftpdlib-1.5.2.tar.gz (179kB) 100% |████████████████████████████████| 184kB 2.6MB/s Building wheels for collected packages: pyftpdlib Running setup.py bdist_wheel for pyftpdlib ... done Stored in directory: /Users/cychong/Library/Caches/pip/wheels/74/7c/3f/011ccb0b834d0bb28d1cebed7bd8178713d5b879129dd0b828 Successfully built pyftpdlib Installing collected packages: pyftpdlib Successfully installed pyftpdlib-1.5.2 The simple way is just running pyftplib with argument.\nsudo python -m pyftpdlib -d /Users/scan/Public/incoming -p 21 However, this does not allow to specify user ID(seems that)\nI just copy the sample from the pyftpdlib (https://github.com/giampaolo/pyftpdlib)\nIt just works.\nmini2:~/Documents cychong$ cat pyftp.py #!/bin/env python from pyftpdlib.authorizers import DummyAuthorizer from pyftpdlib.handlers import FTPHandler from pyftpdlib.servers import FTPServer # change the username and password username = \u0026#34;FIXME\u0026#34; password = \u0026#34;FIXME\u0026#34; home_dir = \u0026#34;FIXME\u0026#34; authorizer = DummyAuthorizer() authorizer.add_user(username, password, home_dir, perm=\u0026#34;elradfmw\u0026#34;) #authorizer.add_anonymous(\u0026#34;/home/nobody\u0026#34;) handler = FTPHandler handler.authorizer = authorizer server = FTPServer((\u0026#34;\u0026#34;, 21), handler) server.serve_forever() I changed the ftp port from 21 to something else not to use sudo to run this script.\n","date":"2017-10-07T00:19:27+09:00","permalink":"https://cychong47.github.io/post/2017/ftp-server-is-gone-from-high-siera-osx-server/","summary":"\u003cp\u003eIt is gone finally\u0026hellip;\n[macOS Server 5.4 changes in High Sierra you need to know about!])https://www.imore.com/changes-macos-server-54-high-sierra)\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eFile Transfer Protocol (FTP): A longtime a security risk, for example for sending password information in clear text, FTP support will be removed from macOS server if you upgrade.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eAs my xeros printer/scanner suppors only ftp or samba(which is much much slower than the ftp) I have to run my own ftp server in my mac mini.\u003c/p\u003e","title":"FTP server is gone from High Siera OSX Server"},{"content":"Install Easy Video Player\nOthers 7 Free WordPress Video Player Plugins of 2017\n","date":"2017-10-06T01:55:04+09:00","permalink":"https://cychong47.github.io/post/2017/wp-video-plugin/","summary":"\u003cp\u003eInstall \u003ca href=\"https://ko.wordpress.org/plugins/easy-video-player/\"\u003eEasy Video Player\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOthers \u003ca href=\"https://wpdean.com/wordpress-video-player-plugins/\"\u003e7 Free WordPress Video Player Plugins of 2017\u003c/a\u003e\u003c/p\u003e","title":"WP video plugin"},{"content":"Configuration ansible client A ansible target B, C In client Ansible targets(B,C) should be listed in the following file. If required additional parameters can be specified such as login account, ssh port and etc\n# /etc/ansible/hosts 192.168.1.100 ansible_ssh_user=cychong ansible_ssh_port=22 192.168.1.200 ansible_ssh_user=cychong ansible_ssh_port=22 In ansible targets A should be found on the following file\n# grep A .ssh/authorized_keys Test run from A # ansible all -m ping 192.168.1.200 | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } 192.168.1.100 | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: false, \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34; } Test run from A #2 mbpr15:~ cychong$ ansible all -a \u0026#34;/usr/bin/du -hs Downloads\u0026#34; 192.168.1.100 | SUCCESS | rc=0 \u0026gt;\u0026gt; 20G\tDownloads 192.168.1.200 | SUCCESS | rc=0 \u0026gt;\u0026gt; 11G\tDownloads Test run from A #3 mbpr15:~ cychong$ ansible all -a \u0026#34;/bin/df -h .\u0026#34; 192.168.1.200 | SUCCESS | rc=0 \u0026gt;\u0026gt; Filesystem Size Used Avail Capacity iused ifree %iused Mounted on /dev/disk2s1 119Gi 103Gi 12Gi 90% 1178609 9223372036853597198 0% / 192.168.1.100 | SUCCESS | rc=0 \u0026gt;\u0026gt; Filesystem Size Used Avail Capacity iused ifree %iused Mounted on /dev/disk0s2 115Gi 58Gi 57Gi 51% 15210230 14862623 51% / How ansible works Playbooks contain plays Play contain taks Task call modules Taks run sequentially Handlers are triggered by task, and run once at the end of play Playbooks YAML files describes the desired state of something Modules list up all modules $ ansible-doc -l Show man-page of a specific module $ ansible-doc MODULE_NAME $ ansible-doc homebrew Inventories Statc lines of servers ranges dynamic list of servers : AWS, Azure, GCP /etc/ansible/hosts\nmini1 ansible_host=192.168.1.100 ansible_ssh_user=cychong ansible_ssh_port=22 mini2 ansible_host=192.168.1.200 ansible_ssh_user=cychong ansible_ssh_port=22 localhost ansible_connection=local Test run check git version of each targets mbpr15:tmp cychong$ ansible all -m command -a \u0026#34;/usr/local/bin/git --version\u0026#34; 192.168.1.200 | SUCCESS | rc=0 \u0026gt;\u0026gt; git version 2.14.2 192.168.1.100 | SUCCESS | rc=0 \u0026gt;\u0026gt; git version 2.14.2 update remote (home)brew packages FIXME Have to use homebrew module\nWhy two machines returns different result?\nmbpr15:tmp cychong$ ansible all -m homebrew -a \u0026#34;update_homebrew=yes\u0026#34; --verbose No config file found; using defaults 192.168.1.200 | FAILED! =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: true, \u0026#34;msg\u0026#34;: \u0026#34;Warning: git 2.14.2 is already installed\\nError: Git must be installed and in your PATH!\u0026#34; } 192.168.1.100 | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Homebrew already up-to-date.\u0026#34; } update homebrew itself and upgrade all packages mbpr15:tmp cychong$ ansible all -m homebrew -a \u0026#34;update_homebrew=yes upgrade_all=yes\u0026#34; --verbose No config file found; using defaults mini2 | FAILED! =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: true, \u0026#34;msg\u0026#34;: \u0026#34;Warning: git 2.14.2 is already installed\\nError: Git must be installed and in your PATH!\u0026#34; } mini1 | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Homebrew packages already upgraded.\u0026#34; } localhost | SUCCESS =\u0026gt; { \u0026#34;changed\u0026#34;: true, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Homebrew upgraded.\u0026#34; } install ack homebrew package mbpr15:~ cychong$ cat install_brew_ack.yaml --- - hosts: all tasks: - name : install ack in homebrew homebrew: name: ack state: present run\nmbpr15:~ cychong$ ansible-playbook install_brew_ack.yaml --verbose No config file found; using defaults PLAY [all] ********************************************************************************** TASK [Gathering Facts] ********************************************************************** ok: [localhost] ok: [mini2] ok: [mini1] TASK [install ack in homebrew] ************************************************************** ok: [localhost] =\u0026gt; {\u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Package already installed: ack\u0026#34;} ok: [mini2] =\u0026gt; {\u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Package already installed: ack\u0026#34;} ok: [mini1] =\u0026gt; {\u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Package already installed: ack\u0026#34;} PLAY RECAP ********************************************************************************** localhost : ok=2 changed=0 unreachable=0 failed=0 mini1 : ok=2 changed=0 unreachable=0 failed=0 mini2 : ok=2 changed=0 unreachable=0 failed=0 After removing ack from mini2\nmini2\nmini2:~ cychong$ brew uninstall ack Uninstalling /usr/local/Cellar/ack/2.18... (4 files, 190.4KB) ack 2.14 1 is still installed. Remove all versions with `brew uninstall --force ack`. mini2:~ cychong$ brew uninstall --force ack Uninstalling ack... (3 files, 182.8KB) mini2:~ cychong$ ack -bash: ack: command not found Try again - install ack in mini2\nmbpr15:~ cychong$ ansible-playbook install_brew_ack.yaml --verbose No config file found; using defaults PLAY [all] ************************************************************************************************** TASK [Gathering Facts] ************************************************************************************** ok: [localhost] ok: [mini1] ok: [mini2] TASK [install ack in homebrew] ****************************************************************************** ok: [localhost] =\u0026gt; {\u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Package already installed: ack\u0026#34;} ok: [mini1] =\u0026gt; {\u0026#34;changed\u0026#34;: false, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Package already installed: ack\u0026#34;} changed: [mini2] =\u0026gt; {\u0026#34;changed\u0026#34;: true, \u0026#34;failed\u0026#34;: false, \u0026#34;msg\u0026#34;: \u0026#34;Package installed: ack\u0026#34;} PLAY RECAP ************************************************************************************************** localhost : ok=2 changed=0 unreachable=0 failed=0 mini1 : ok=2 changed=0 unreachable=0 failed=0 mini2 : ok=2 changed=1 unreachable=0 failed=0 Note that mini2 has changed as true(1) because ack is installed(state is changed).\nreference Asible 소개 Ansible Quick Guide https://github.com/ideasonpurpose/ansible-playbooks/tree/master/roles https://moonstrike.github.io/ansible/2016/09/22/Ansible-Playbooks.html http://docs.ansible.com/ansible/2.4/playbooks_reuse_roles.html http://docs.ansible.com/ansible/latest/playbooks.html ","date":"2017-10-04T00:22:48+09:00","permalink":"https://cychong47.github.io/post/2017/ansible/","summary":"\u003ch1 id=\"configuration\"\u003eConfiguration\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eansible client A\u003c/li\u003e\n\u003cli\u003eansible target B, C\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"in-client\"\u003eIn client\u003c/h2\u003e\n\u003cp\u003eAnsible targets(B,C) should be listed in the following file. If required additional parameters can be specified such as login account, ssh port and etc\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# /etc/ansible/hosts\n\u003c/code\u003e\u003c/pre\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e192.168.1.100 ansible_ssh_user=cychong ansible_ssh_port=22\n192.168.1.200 ansible_ssh_user=cychong ansible_ssh_port=22\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"in-ansible-targets\"\u003eIn ansible targets\u003c/h2\u003e\n\u003cp\u003eA should be found on the following file\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e# grep A .ssh/authorized_keys\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch2 id=\"test-run-from-a\"\u003eTest run from A\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e# ansible all -m ping\n192.168.1.200 | SUCCESS =\u0026gt; {\n    \u0026#34;changed\u0026#34;: false, \n    \u0026#34;failed\u0026#34;: false, \n    \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34;\n}\n192.168.1.100 | SUCCESS =\u0026gt; {\n    \u0026#34;changed\u0026#34;: false, \n    \u0026#34;failed\u0026#34;: false, \n    \u0026#34;ping\u0026#34;: \u0026#34;pong\u0026#34;\n}\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"test-run-from-a-2\"\u003eTest run from A #2\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:~ cychong$ ansible all -a \u0026#34;/usr/bin/du -hs Downloads\u0026#34;\n192.168.1.100 | SUCCESS | rc=0 \u0026gt;\u0026gt;\n 20G\tDownloads\n\n192.168.1.200 | SUCCESS | rc=0 \u0026gt;\u0026gt;\n 11G\tDownloads\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"test-run-from-a-3\"\u003eTest run from A #3\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:~ cychong$ ansible all -a \u0026#34;/bin/df -h .\u0026#34;\n192.168.1.200 | SUCCESS | rc=0 \u0026gt;\u0026gt;\nFilesystem     Size   Used  Avail Capacity iused               ifree %iused  Mounted on\n/dev/disk2s1  119Gi  103Gi   12Gi    90% 1178609 9223372036853597198    0%   /\n\n192.168.1.100 | SUCCESS | rc=0 \u0026gt;\u0026gt;\nFilesystem     Size   Used  Avail Capacity  iused    ifree %iused  Mounted on\n/dev/disk0s2  115Gi   58Gi   57Gi    51% 15210230 14862623   51%   /\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"how-ansible-works\"\u003eHow ansible works\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003ePlaybooks contain plays\u003c/li\u003e\n\u003cli\u003ePlay contain taks\u003c/li\u003e\n\u003cli\u003eTask call modules\u003c/li\u003e\n\u003cli\u003eTaks run sequentially\u003c/li\u003e\n\u003cli\u003eHandlers are triggered by task, and run once at the end of play\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"playbooks\"\u003ePlaybooks\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eYAML files describes the desired state of something\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"modules\"\u003eModules\u003c/h2\u003e\n\u003ch3 id=\"list-up-all-modules\"\u003elist up all modules\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ ansible-doc -l \n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"show-man-page-of-a-specific-module\"\u003eShow man-page of a specific module\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ ansible-doc MODULE_NAME\n$ ansible-doc homebrew  \n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"inventories\"\u003eInventories\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eStatc lines of servers\u003c/li\u003e\n\u003cli\u003eranges\u003c/li\u003e\n\u003cli\u003edynamic list of servers : AWS, Azure, GCP\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ccode\u003e/etc/ansible/hosts\u003c/code\u003e\u003c/p\u003e","title":"Play with Ansible"},{"content":"https://www.youtube.com/watch?v=tIN8BjHwpNs\nOther similar videos Architecture for fine-grain, high-resolution Telemetry for network elements. Jun 4 2015, Juniper Networks, Presented in NANOG\nVisualizing Cisco Telemetry Data using Elasticsearch, Logstash and Kibana\n","date":"2017-10-03T16:24:37+09:00","permalink":"https://cychong47.github.io/post/2017/series-4-10-lessons-from-telemetry/","summary":"\u003cp\u003e\u003ca href=\"https://www.youtube.com/watch?v=tIN8BjHwpNs\"\u003ehttps://www.youtube.com/watch?v=tIN8BjHwpNs\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eOther similar videos\n\u003ca href=\"https://www.youtube.com/watch?v=NVYqgc9RK2s\"\u003eArchitecture for fine-grain, high-resolution Telemetry for network elements. Jun 4 2015, Juniper Networks, Presented in NANOG\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.youtube.com/watch?v=9El0PCtNxtg\"\u003eVisualizing Cisco Telemetry Data using Elasticsearch, Logstash and Kibana\u003c/a\u003e\u003c/p\u003e","title":"(Series"},{"content":"출처 : sdxcentral, Feb 5, 2016\ntools presented in the video reference video ppt ","date":"2017-10-03T13:47:55+09:00","permalink":"https://cychong47.github.io/post/2017/cisco-ios-xr-and-signalfx-demo/","summary":"\u003cp\u003e출처 : \u003ca href=\"https://www.sdxcentral.com/resources/sdn-demofriday/cisco-ios-xr-signalfx-demo-monitoring-your-modern-network/\"\u003esdxcentral, Feb 5, 2016\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2017/10/Screenshot-2017-10-03-22.24.45.png\" alt=\"Screenshot-2017-10-03-22.24.45\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2017/10/Screenshot-2017-10-03-22.24.34.png\" alt=\"Screenshot-2017-10-03-22.24.34\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2017/10/Screenshot-2017-10-03-22.24.18.png\" alt=\"Screenshot-2017-10-03-22.24.18\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2017/10/Screenshot-2017-10-03-22.38.49.png\" alt=\"Screenshot-2017-10-03-22.38.49\"\u003e\u003c/p\u003e\n\u003ch2 id=\"tools-presented-in-the-video\"\u003etools presented in the video\u003c/h2\u003e\n\u003ch2 id=\"reference\"\u003ereference\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://player.vimeo.com/video/154632747\"\u003evideo\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.sdxcentral.com/wp-content/uploads/2016/02/cisco-signalfx-sdn-nfv-iosxr6-demo-slides.pdf\"\u003eppt\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"(Series"},{"content":"출처 : https://blogs.cisco.com/sp/streaming-telemetry-with-google-protocol-buffers\nSummary JSON, \u0026ldquo;compact\u0026rdquo; GPB and \u0026ldquo;Key-Value\u0026rdquo; GPB\n\u0026ldquo;Compact\u0026rdquo; GPB data on wire can be decoded without the decoder ring while \u0026ldquo;Key-Value\u0026rdquo; GPB data is Self-Describing. Compact GPB can be used with UDP(default) and TCP(optionally) \u0026ldquo;Key-value\u0026rdquo; GPB is only for TCP 833 bytes of compact GPB while more than 4000 bytes for Key-value GPB Compressed JSON(?) ","date":"2017-10-01T21:38:04+09:00","permalink":"https://cychong47.github.io/post/2017/streaming-telemetry-with-google-protocol-buffers/","summary":"\u003cp\u003e출처 : \u003ca href=\"https://blogs.cisco.com/sp/streaming-telemetry-with-google-protocol-buffers\"\u003ehttps://blogs.cisco.com/sp/streaming-telemetry-with-google-protocol-buffers\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cp\u003eJSON, \u0026ldquo;compact\u0026rdquo; GPB and \u0026ldquo;Key-Value\u0026rdquo; GPB\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u0026ldquo;Compact\u0026rdquo; GPB data on wire can be decoded without the \u003ccode\u003edecoder ring\u003c/code\u003e while \u0026ldquo;Key-Value\u0026rdquo; GPB data is Self-Describing.\u003c/li\u003e\n\u003cli\u003eCompact GPB can be used with UDP(default) and TCP(optionally)\u003c/li\u003e\n\u003cli\u003e\u0026ldquo;Key-value\u0026rdquo; GPB is only for TCP\u003c/li\u003e\n\u003cli\u003e833 bytes of compact GPB while more than 4000 bytes for Key-value GPB\u003c/li\u003e\n\u003cli\u003eCompressed JSON(?)\u003c/li\u003e\n\u003c/ul\u003e","title":"(Series"},{"content":"Seems that configuration and operation data are defined in a different yang file though it is not clear they are module or submodule\nThe models are in the .yang format. A model with: -oper in the model name indicates an operational model. For example, Cisco-IOS-XR-cdp-oper.yang is an operational model for Cisco Discovery Protocol (CDP). -cfg indicates a configuration model. For example, Cisco-IOS-XR-cdp-cfg.yang is a configuration model for CDP. -act indicates a NETCONF actions model. For example, Cisco-IOS-XR-ipv4-ospf-act.yang is an action model for OSPF.\nProgrammability Configuration Guide for Cisco NCS 5500 Series Routers, IOS XR Release 6.2.x\nComponents to use Data models\nChapter: Use Cases with Data Models\n","date":"2017-10-01T21:33:27+09:00","permalink":"https://cychong47.github.io/post/2017/cisco-yang-data-model/","summary":"\u003cp\u003eSeems that configuration and operation data are defined in a different yang file though it is not clear they are module or submodule\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eThe models are in the .yang format. A model with:\n-oper in the model name indicates an operational model. For example, Cisco-IOS-XR-cdp-oper.yang is an operational model for Cisco Discovery Protocol (CDP).\n-cfg indicates a configuration model. For example, Cisco-IOS-XR-cdp-cfg.yang is a configuration model for CDP.\n-act indicates a NETCONF actions model. For example, Cisco-IOS-XR-ipv4-ospf-act.yang is an action model for OSPF.\u003c/p\u003e","title":"CISCO Yang data model"},{"content":"Why You Should Care About Model-Driven Telemetry from CISCO blog\nSummary Periodic polling -\u0026gt; Pushing(Streaming) Model based data with YANG Use standard encoding such as JSON, Google Protocol Buffers Easy to manipulate, connect to analytic solutions 1-min poll is too slow For the last 25 years, network operators have heavily relied on SNMP polling and CLI screen-scraping to extract operational data from the network. But the new and automated demands of today’s networks have pushed these mechanisms to the breaking point.\nNetwork operators often poll data from their network on the order of every five to thirty minutes. With careful tuning and testing, the bravest can push that interval down to one minute. But with today’s speeds and scales, even that’s not low enough to capture important network events. And as we move to higher density platforms, the amount of important operational data becomes truly staggering.\nstreaming Network operators poll periodically because they want the data at regular intervals.\nInstead of pulling data off the network, sit back and let the network push it to you\nModel-driven Of course, it’s not enough to just push a lot of data off the device. Telemetry data must be structured in a sensible way to make it easy for monitoring tools to ingest. In other words, good telemetry data must be model-based. YANG,\nAnalytic friendly Telemetry data needs to be normalized for efficient consumption by Big Data tools. In the software world, encodings such as JSON and Google Protocol Buffers (GPB) are widely used to transfer data between software applications. These encodings have an abundance of open-source software APIs that make it easy to manipulate and analyze the data.\nModel-driven telemetry is your first step in a journey that will transform how you monitor and operate networks. With the power of telemetry, you’ll discover things you never imagined and begin to ask more and better questions.\nReferences cited in the article\nbigmuddy-network-telemetry-collector JSON or GPB(Google Protocol Buffer) based. Have to see how GPB based can be used in program CISCO XR6.0.0 GPB Telemetry Streaming Telemetry Collector Stacks Streamlined to ELK, prometheus, kafka bus Yang data model of some network equipments Model-Driven Telemetry in CISCO ","date":"2017-10-01T14:06:46+09:00","permalink":"https://cychong47.github.io/post/2017/model-driven-telemetry/","summary":"\u003cp\u003e\u003ca href=\"http://blogs.cisco.com/sp/why-you-should-care-about-model-driven-telemetry\"\u003eWhy You Should Care About Model-Driven Telemetry\u003c/a\u003e from CISCO blog\u003c/p\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003ePeriodic polling -\u0026gt; Pushing(Streaming)\u003c/li\u003e\n\u003cli\u003eModel based data with YANG\u003c/li\u003e\n\u003cli\u003eUse standard encoding such as JSON, Google Protocol Buffers\u003c/li\u003e\n\u003cli\u003eEasy to manipulate, connect to analytic solutions\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"1-min-poll-is-too-slow\"\u003e1-min poll is too slow\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003eFor the last 25 years, network operators have heavily relied on SNMP polling and CLI screen-scraping to extract operational data from the network. But the new and automated demands of today’s networks have pushed these mechanisms to the breaking point.\u003c/p\u003e","title":"(Series"},{"content":"Just for the record as some environments are mentioned\nmbpr15:working cychong$ brew install python ==\u0026gt; Installing dependencies for python: readline, sqlite, gdbm, openssl ==\u0026gt; Installing python dependency: readline ==\u0026gt; Downloading https://homebrew.bintray.com/bottles/readline-7.0.3_1.high_sierra.bottle.tar.gz ######################################################################## 100.0% ==\u0026gt; Pouring readline-7.0.3_1.high_sierra.bottle.tar.gz ==\u0026gt; Caveats This formula is keg-only, which means it was not symlinked into /usr/local, because macOS provides the BSD libedit library, which shadows libreadline. In order to prevent conflicts when programs look for libreadline we are defaulting this GNU Readline installation to keg-only.. For compilers to find this software you may need to set: LDFLAGS: -L/usr/local/opt/readline/lib CPPFLAGS: -I/usr/local/opt/readline/include ==\u0026gt; Summary 🍺 /usr/local/Cellar/readline/7.0.3_1: 46 files, 1.5MB ==\u0026gt; Installing python dependency: sqlite ==\u0026gt; Downloading https://homebrew.bintray.com/bottles/sqlite-3.20.1.high_sierra.bottle.tar.gz ######################################################################## 100.0% ==\u0026gt; Pouring sqlite-3.20.1.high_sierra.bottle.tar.gz ==\u0026gt; Caveats This formula is keg-only, which means it was not symlinked into /usr/local, because macOS provides an older sqlite3. If you need to have this software first in your PATH run: echo \u0026#39;export PATH=\u0026#34;/usr/local/opt/sqlite/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bash_profile For compilers to find this software you may need to set: LDFLAGS: -L/usr/local/opt/sqlite/lib CPPFLAGS: -I/usr/local/opt/sqlite/include ==\u0026gt; Summary 🍺 /usr/local/Cellar/sqlite/3.20.1: 11 files, 2.9MB ==\u0026gt; Installing python dependency: gdbm ==\u0026gt; Downloading https://homebrew.bintray.com/bottles/gdbm-1.13.high_sierra.bottle.tar.gz ######################################################################## 100.0% ==\u0026gt; Pouring gdbm-1.13.high_sierra.bottle.tar.gz 🍺 /usr/local/Cellar/gdbm/1.13: 19 files, 553.9KB ==\u0026gt; Installing python dependency: openssl ==\u0026gt; Downloading https://homebrew.bintray.com/bottles/openssl-1.0.2l.high_sierra.bottle.tar.gz ######################################################################## 100.0% ==\u0026gt; Pouring openssl-1.0.2l.high_sierra.bottle.tar.gz ==\u0026gt; Caveats A CA file has been bootstrapped using certificates from the SystemRoots keychain. To add additional certificates (e.g. the certificates added in the System keychain), place .pem files in /usr/local/etc/openssl/certs and run /usr/local/opt/openssl/bin/c_rehash This formula is keg-only, which means it was not symlinked into /usr/local, because Apple has deprecated use of OpenSSL in favor of its own TLS and crypto libraries. If you need to have this software first in your PATH run: echo \u0026#39;export PATH=\u0026#34;/usr/local/opt/openssl/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bash_profile For compilers to find this software you may need to set: LDFLAGS: -L/usr/local/opt/openssl/lib CPPFLAGS: -I/usr/local/opt/openssl/include ==\u0026gt; Summary 🍺 /usr/local/Cellar/openssl/1.0.2l: 1,709 files, 12.3MB ==\u0026gt; Installing python ==\u0026gt; Downloading https://homebrew.bintray.com/bottles/python-2.7.14.high_sierra.bottle.tar.gz ######################################################################## 100.0% ==\u0026gt; Pouring python-2.7.14.high_sierra.bottle.tar.gz ==\u0026gt; /usr/local/Cellar/python/2.7.14/bin/python2 -s setup.py --no-user-cfg install --force --verbose --single-v ==\u0026gt; /usr/local/Cellar/python/2.7.14/bin/python2 -s setup.py --no-user-cfg install --force --verbose --single-v ==\u0026gt; /usr/local/Cellar/python/2.7.14/bin/python2 -s setup.py --no-user-cfg install --force --verbose --single-v ==\u0026gt; Caveats This formula installs a python2 executable to /usr/local/bin. If you wish to have this formula\u0026#39;s python executable in your PATH then add the following to ~/.bash_profile: export PATH=\u0026#34;/usr/local/opt/python/libexec/bin:$PATH\u0026#34; Pip and setuptools have been installed. To update them pip2 install --upgrade pip setuptools You can install Python packages with pip2 install \u0026lt;package\u0026gt; They will install into the site-package directory /usr/local/lib/python2.7/site-packages See: https://docs.brew.sh/Homebrew-and-Python.html ==\u0026gt; Summary 🍺 /usr/local/Cellar/python/2.7.14: 3,517 files, 48.4MB ","date":"2017-10-01T13:44:47+09:00","permalink":"https://cychong47.github.io/post/2017/brew-install-python/","summary":"\u003cp\u003eJust for the record as some environments are mentioned\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003embpr15:working cychong$ brew install python\n==\u0026gt; Installing dependencies for python: readline, sqlite, gdbm, openssl\n==\u0026gt; Installing python dependency: readline\n==\u0026gt; Downloading https://homebrew.bintray.com/bottles/readline-7.0.3_1.high_sierra.bottle.tar.gz\n######################################################################## 100.0%\n==\u0026gt; Pouring readline-7.0.3_1.high_sierra.bottle.tar.gz\n==\u0026gt; Caveats\nThis formula is keg-only, which means it was not symlinked into /usr/local,\nbecause macOS provides the BSD libedit library, which shadows libreadline.\nIn order to prevent conflicts when programs look for libreadline we are\ndefaulting this GNU Readline installation to keg-only..\n\nFor compilers to find this software you may need to set:\n    LDFLAGS:  -L/usr/local/opt/readline/lib\n    CPPFLAGS: -I/usr/local/opt/readline/include\n\n==\u0026gt; Summary\n🍺  /usr/local/Cellar/readline/7.0.3_1: 46 files, 1.5MB\n==\u0026gt; Installing python dependency: sqlite\n==\u0026gt; Downloading https://homebrew.bintray.com/bottles/sqlite-3.20.1.high_sierra.bottle.tar.gz\n######################################################################## 100.0%\n==\u0026gt; Pouring sqlite-3.20.1.high_sierra.bottle.tar.gz\n==\u0026gt; Caveats\nThis formula is keg-only, which means it was not symlinked into /usr/local,\nbecause macOS provides an older sqlite3.\n\nIf you need to have this software first in your PATH run:\n  echo \u0026#39;export PATH=\u0026#34;/usr/local/opt/sqlite/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bash_profile\n\nFor compilers to find this software you may need to set:\n    LDFLAGS:  -L/usr/local/opt/sqlite/lib\n    CPPFLAGS: -I/usr/local/opt/sqlite/include\n\n==\u0026gt; Summary\n🍺  /usr/local/Cellar/sqlite/3.20.1: 11 files, 2.9MB\n==\u0026gt; Installing python dependency: gdbm\n==\u0026gt; Downloading https://homebrew.bintray.com/bottles/gdbm-1.13.high_sierra.bottle.tar.gz\n######################################################################## 100.0%\n==\u0026gt; Pouring gdbm-1.13.high_sierra.bottle.tar.gz\n🍺  /usr/local/Cellar/gdbm/1.13: 19 files, 553.9KB\n==\u0026gt; Installing python dependency: openssl\n==\u0026gt; Downloading https://homebrew.bintray.com/bottles/openssl-1.0.2l.high_sierra.bottle.tar.gz\n######################################################################## 100.0%\n==\u0026gt; Pouring openssl-1.0.2l.high_sierra.bottle.tar.gz\n==\u0026gt; Caveats\nA CA file has been bootstrapped using certificates from the SystemRoots\nkeychain. To add additional certificates (e.g. the certificates added in\nthe System keychain), place .pem files in\n  /usr/local/etc/openssl/certs\n\nand run\n  /usr/local/opt/openssl/bin/c_rehash\n\nThis formula is keg-only, which means it was not symlinked into /usr/local,\nbecause Apple has deprecated use of OpenSSL in favor of its own TLS and crypto libraries.\n\nIf you need to have this software first in your PATH run:\n  echo \u0026#39;export PATH=\u0026#34;/usr/local/opt/openssl/bin:$PATH\u0026#34;\u0026#39; \u0026gt;\u0026gt; ~/.bash_profile\n\nFor compilers to find this software you may need to set:\n    LDFLAGS:  -L/usr/local/opt/openssl/lib\n    CPPFLAGS: -I/usr/local/opt/openssl/include\n\n==\u0026gt; Summary\n🍺  /usr/local/Cellar/openssl/1.0.2l: 1,709 files, 12.3MB\n==\u0026gt; Installing python\n==\u0026gt; Downloading https://homebrew.bintray.com/bottles/python-2.7.14.high_sierra.bottle.tar.gz\n######################################################################## 100.0%\n==\u0026gt; Pouring python-2.7.14.high_sierra.bottle.tar.gz\n==\u0026gt; /usr/local/Cellar/python/2.7.14/bin/python2 -s setup.py --no-user-cfg install --force --verbose --single-v\n==\u0026gt; /usr/local/Cellar/python/2.7.14/bin/python2 -s setup.py --no-user-cfg install --force --verbose --single-v\n==\u0026gt; /usr/local/Cellar/python/2.7.14/bin/python2 -s setup.py --no-user-cfg install --force --verbose --single-v\n==\u0026gt; Caveats\nThis formula installs a python2 executable to /usr/local/bin.\nIf you wish to have this formula\u0026#39;s python executable in your PATH then add\nthe following to ~/.bash_profile:\n  export PATH=\u0026#34;/usr/local/opt/python/libexec/bin:$PATH\u0026#34;\n\nPip and setuptools have been installed. To update them\n  pip2 install --upgrade pip setuptools\n\nYou can install Python packages with\n  pip2 install \u0026lt;package\u0026gt;\n\nThey will install into the site-package directory\n  /usr/local/lib/python2.7/site-packages\n\nSee: https://docs.brew.sh/Homebrew-and-Python.html\n==\u0026gt; Summary\n🍺  /usr/local/Cellar/python/2.7.14: 3,517 files, 48.4MB\n\u003c/code\u003e\u003c/pre\u003e","title":"brew install python"},{"content":"정규식으로 http 분석 def processHTTP(data): str_method = \u0026quot;\u0026quot; str_uri = \u0026quot;\u0026quot; 정규표현식을 통해 넘어온 데이터에서 METHOD, URI, HTTP 버전 정보등으로 구분함 h = re.search(\u0026quot;(?P\u0026lt;method\u0026gt;(^GET|^POST|^PUT|^DELETE)) (?P\u0026lt;uri\u0026gt;.+) (?P\u0026lt;version\u0026gt;.+)\u0026quot;, data) if not h: return \u0026quot;Error\u0026quot; # 정규표현식에 해당하는 데이터가 없는 경우 Error 를 리턴해줌 # method 로 정의된 부준은 str_method 에 저장 if h.group(\u0026quot;method\u0026quot;): str_method = h.group(\u0026quot;method\u0026quot;) # URI 데이터는 str_uri 에 저장 if h.group(\u0026quot;uri\u0026quot;): str_uri = h.group(\u0026quot;uri\u0026quot;) return str_method,str_uri # method 와 uri 를 리턴해 줌 출처 : http://www.packetinside.com/2010/11/scapy-로-패킷-핸들링하는-프로그램-만들기-세번째.html?showComment=1423994884595\n","date":"2017-10-01T09:36:35+09:00","permalink":"https://cychong47.github.io/post/2017/parsing-http-header-with-scary/","summary":"\u003ch3 id=\"정규식으로-http-분석\"\u003e정규식으로 http 분석\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003edef processHTTP(data):\n\n    str_method = \u0026quot;\u0026quot;\n    str_uri = \u0026quot;\u0026quot;\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"정규표현식을-통해-넘어온-데이터에서-method-uri-http-버전-정보등으로-구분함\"\u003e정규표현식을 통해 넘어온 데이터에서 METHOD, URI, HTTP 버전 정보등으로 구분함\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eh = re.search(\u0026quot;(?P\u0026lt;method\u0026gt;(^GET|^POST|^PUT|^DELETE)) (?P\u0026lt;uri\u0026gt;.+) (?P\u0026lt;version\u0026gt;.+)\u0026quot;, data)\nif not h: return \u0026quot;Error\u0026quot;    # 정규표현식에 해당하는 데이터가 없는 경우 Error 를 리턴해줌\n\n# method 로 정의된 부준은 str_method 에 저장\nif h.group(\u0026quot;method\u0026quot;): str_method = h.group(\u0026quot;method\u0026quot;)\n# URI 데이터는 str_uri 에 저장\nif h.group(\u0026quot;uri\u0026quot;): str_uri = h.group(\u0026quot;uri\u0026quot;)\n\nreturn str_method,str_uri   # method 와 uri 를 리턴해 줌\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e출처 : \u003ca href=\"http://www.packetinside.com/2010/11/scapy-\"\u003ehttp://www.packetinside.com/2010/11/scapy-\u003c/a\u003e로-패킷-핸들링하는-프로그램-만들기-세번째.html?showComment=1423994884595\u003c/p\u003e","title":"Parsing http header with scary"},{"content":"Maglev Google( https://research.google.com/pubs/pub44824.html ) Used in Google Cloud since 2008 Scalable load balancer Consistent hashing Connection Tracking Scale-out model backed by router\u0026rsquo;s ECMP Bypass kernel space for performance. Support connection persistence Network Architecture DNS - Routers - Maglevs - Service EndPoints. One service is served by one or more VIPs DNS returns VIP considering geolocation and load of location One VIP is served by multiple Maglevs Router use ECMP to select one Maglev One VIP is mapped to multiple Service EndPoints Maglev select Service EndPoint by seletion algorithm and connection tracking table Maglev use GRE to send incoming packet to Service EndPoint or another Maglev Send to IP fragment to another special Maglev servers Use only 3-tuple for IP fragment Each Service EndPoint use Direct Server Return(DSR) Maglev Controller Responsible for VIP announcement with BGP Check health status of forwarder If forwarder is not headthy, withdraw all VIP announcements Forwarder Each VIP has one or multiple backend pools(BP) BP contain physical IP address of the Service EndPoint Each BP has specific health checking methods - depends on the service requirement(just reachability or more) Config Manager parse and update configuration of forwarder\u0026rsquo;s behavior based on the Config Objects Sharding Sharding of Maglev enables service isolation - new service or QoS Backend Selection Consistent Hashing distribute loads Record selection in LOCAL connection tracking table Connection tracking table is not shared with another Maglev Does not guarantee consistency on Maglev or Service EndPoint Changes(add/delete) For different traffic type TCP SYN : select Backend and record it in connection tracking table TCP non-SYN : lookup connection tracking table 5-tuple : (maybe) lookup connection tracking table and select backend if not found Consistent Hashing If Maglev is added or removed, router select different Maglev for the exsiting session - ECMP is changed If one Maglev\u0026rsquo;s local connection tracking table is overflowed, it will lose previous selection To resolve this issues, Synchronize local connection tracking table between Maglevs -\u0026gt; overhead, overhead, overhead Consistent hashing for minimize disruption in member changes Maglev hashing - load balancing and minimal disruption on member changes reference Maglev: A Fast and Reliable Software Network Load Balancer Consistent Hashing The Simple Magic of Consistent Hashing ","date":"2017-10-01T08:34:30+09:00","permalink":"https://cychong47.github.io/post/2017/googles-load-balancer/","summary":"\u003ch1 id=\"maglev\"\u003eMaglev\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eGoogle( \u003ca href=\"https://research.google.com/pubs/pub44824.html\"\u003ehttps://research.google.com/pubs/pub44824.html\u003c/a\u003e )\u003c/li\u003e\n\u003cli\u003eUsed in Google Cloud since 2008\u003c/li\u003e\n\u003cli\u003eScalable load balancer\n\u003cul\u003e\n\u003cli\u003eConsistent hashing\u003c/li\u003e\n\u003cli\u003eConnection Tracking\u003c/li\u003e\n\u003cli\u003eScale-out model backed by router\u0026rsquo;s ECMP\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eBypass kernel space for performance.\u003c/li\u003e\n\u003cli\u003eSupport connection persistence\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"network-architecture\"\u003eNetwork Architecture\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eDNS - Routers - Maglevs - Service EndPoints.\u003c/li\u003e\n\u003cli\u003eOne service is served by one or more VIPs\n\u003cul\u003e\n\u003cli\u003eDNS returns VIP considering geolocation and load of location\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eOne VIP is served by multiple Maglevs\n\u003cul\u003e\n\u003cli\u003eRouter use ECMP to select one Maglev\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eOne VIP is mapped to multiple Service EndPoints\n\u003cul\u003e\n\u003cli\u003eMaglev select Service EndPoint by seletion algorithm and connection tracking table\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eMaglev use GRE to send incoming packet to Service EndPoint or another Maglev\n\u003cul\u003e\n\u003cli\u003eSend to IP fragment to another special Maglev servers\u003c/li\u003e\n\u003cli\u003eUse only 3-tuple for IP fragment\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eEach Service EndPoint use Direct Server Return(DSR)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"maglev-1\"\u003eMaglev\u003c/h1\u003e\n\u003ch2 id=\"controller\"\u003eController\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eResponsible for VIP announcement with BGP\u003c/li\u003e\n\u003cli\u003eCheck health status of forwarder\u003c/li\u003e\n\u003cli\u003eIf forwarder is not headthy, withdraw all VIP announcements\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"forwarder\"\u003eForwarder\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eEach VIP has one or multiple backend pools(BP)\u003c/li\u003e\n\u003cli\u003eBP contain physical IP address of the Service EndPoint\u003c/li\u003e\n\u003cli\u003eEach BP has specific health checking methods - depends on the service requirement(just reachability or more)\u003c/li\u003e\n\u003cli\u003eConfig Manager parse and update configuration of forwarder\u0026rsquo;s behavior based on the \u003cstrong\u003eConfig Objects\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eSharding\n\u003cul\u003e\n\u003cli\u003eSharding of Maglev enables service isolation - new service or QoS\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"backend-selection\"\u003eBackend Selection\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eConsistent Hashing distribute loads\u003c/li\u003e\n\u003cli\u003eRecord selection in \u003cstrong\u003eLOCAL connection tracking table\u003c/strong\u003e\n\u003cul\u003e\n\u003cli\u003eConnection tracking table is \u003cstrong\u003enot shared\u003c/strong\u003e with another Maglev\u003c/li\u003e\n\u003cli\u003eDoes not guarantee consistency on Maglev or Service EndPoint Changes(add/delete)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eFor different traffic type\n\u003cul\u003e\n\u003cli\u003eTCP SYN : select Backend and record it in connection tracking table\u003c/li\u003e\n\u003cli\u003eTCP non-SYN : lookup connection tracking table\u003c/li\u003e\n\u003cli\u003e5-tuple : (maybe) lookup connection tracking table and select backend if not found\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"consistent-hashing\"\u003eConsistent Hashing\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eIf Maglev is added or removed, router select different Maglev for the exsiting session - ECMP is changed\u003c/li\u003e\n\u003cli\u003eIf one Maglev\u0026rsquo;s local connection tracking table is overflowed, it will lose previous selection\u003c/li\u003e\n\u003cli\u003eTo resolve this issues,\n\u003cul\u003e\n\u003cli\u003eSynchronize local connection tracking table between Maglevs -\u0026gt; overhead, overhead, overhead\u003c/li\u003e\n\u003cli\u003eConsistent hashing for minimize disruption in member changes\u003c/li\u003e\n\u003cli\u003eMaglev hashing - load balancing and minimal disruption on member changes\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"reference\"\u003ereference\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://blog.acolyer.org/2016/03/21/maglev-a-fast-and-reliable-software-network-load-balancer/\"\u003eMaglev: A Fast and Reliable Software Network Load Balancer\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://blog.carlosgaldino.com/consistent-hashing.html\"\u003eConsistent Hashing\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://dzone.com/articles/simple-magic-consistent\"\u003eThe Simple Magic of Consistent Hashing\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Google's Load Balancer"},{"content":"ZTE Pharos Lab Pharos : OPNFV를 시험하는 worldwide lab 외부에서 접속하는 것이 필요하므로 ssh를 열어줄 수는 없어서 openVPN을 제공하고, 망을 분리하는 등의 이슈 해결을 위해 노력한 듯\nhttps://www.opnfv.org/developers/pharos Pharos는 시험 환경을 구축해서 community에 공개해서 사용할 수 있는 환경을 제공하는 듯 Provide developers with substantial resources for early testing within realistic NFV environments via an open, consistent, repeatable test domain\nWhy donate Pharos environment NFV 환경에 사용할 HW를 직접 제조하는 업체들에게는 제품 호환성에 대한 시험을 유도할 수 있는 장점을 가짐.\nhttps://www.opnfv.org/news-faq/blog/2015/10/view-board-opnfv-one-year-part-1\nThese are member- donated and operated labs that are available for testing of OPNFV software releases, the testing of OPNFV releases with third-party VNFs and other related systems. This has resulted in a global community that is engaged in the business of establishing interoperability, integration and standardization across the NFV solution space, in an open and transparent manner\nFuncTest https://wiki.opnfv.org/display/fds/FDS+Testing#FDSTesting-vPing https://wiki.opnfv.org/display/functest/Opnfv+Functional+Testing#OpnfvFunctionalTesting-VNF vPing SSH vPing userdata ODL suite - Robot framework, ODL functional testing\nhttps://git.opnfv.org/cgit/functest git clone git://git.opnfv.org/functest\n/Users/cychong/Work/functest/functest/opnfv_tests/OpenStack/vPing\nssh 접속에 paramiko module을 사용함.\nDoctor Project Project leader from NEC\nDemo : Openstack and OPNFV - Keeping your mobile phone calls connected\nhttps://www.youtube.com/watch?v=Dvh8q5m9Ahk\nDeveopment Tools On boarding - specially Jira for agile\nhttps://wiki.opnfv.org/display/DEV/Developer+On-boarding\nvPing example logger.info(\u0026quot;Trying to establish SSH connection to %s...\u0026quot; % floatip) username = 'cirros' password = 'cubswin:)' ssh = paramiko.SSHClient() ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) timeout = 50 nolease = False got_ip = False discover_count = 0 cidr_first_octet = PRIVATE_SUBNET_CIDR.split('.')[0] while timeout \u0026gt; 0: try: ssh.connect(floatip, username=username, password=password, timeout=2) logger.debug(\u0026quot;SSH connection established to %s.\u0026quot; % floatip) break except: logger.debug(\u0026quot;Waiting for %s...\u0026quot; % floatip) time.sleep(6) timeout -= 1 console_log = vm.get_console_output() paramiko example http://docs.paramiko.org/en/2.0/api/hostkeys.html\n\u0026gt;\u0026gt;\u0026gt; import paramiko \u0026gt;\u0026gt;\u0026gt; ssh = paramiko.SSHClient() \u0026gt;\u0026gt;\u0026gt; ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy()) \u0026gt;\u0026gt;\u0026gt; ssh.connect(\u0026#34;127.0.0.1\u0026#34;, username=\u0026#34;cychong\u0026#34;, password=\u0026#34;FIXME\u0026#34;, timeout=2) Check what if key is not matched\nVisualization grafana http://testresults.opnfv.org/grafana/login\nhttp://grafana.org\nKibana based https://opnfv.biterg.io/\nNot a single vendor dominate contribution which was true for the OpenStack(Rockspace)\nEricsson, Huawei, RedHat are on tops.\n","date":"2017-10-01T08:28:34+09:00","permalink":"https://cychong47.github.io/post/2017/opnfv-asia-meeting/","summary":"\u003ch2 id=\"zte-pharos-lab\"\u003eZTE Pharos Lab\u003c/h2\u003e\n\u003cp\u003ePharos : OPNFV를 시험하는 worldwide lab\n외부에서 접속하는 것이 필요하므로 ssh를 열어줄 수는 없어서 openVPN을 제공하고, 망을 분리하는 등의 이슈 해결을 위해 노력한 듯\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.opnfv.org/developers/pharos\"\u003ehttps://www.opnfv.org/developers/pharos\u003c/a\u003e\nPharos는 시험 환경을 구축해서 community에 공개해서 사용할 수 있는 환경을 제공하는 듯\nProvide developers with substantial resources for early testing within realistic NFV environments via an open, consistent, repeatable test domain\u003c/p\u003e\n\u003ch3 id=\"why-donate-pharos-environment\"\u003eWhy donate Pharos environment\u003c/h3\u003e\n\u003cp\u003eNFV 환경에 사용할 HW를 직접 제조하는 업체들에게는 제품 호환성에 대한 시험을 유도할 수 있는 장점을 가짐.\u003c/p\u003e","title":"OPNFV Asia Meeting"},{"content":"VES project VNF Event Stream Project\nDemo vHello VES Demo in OpenStack Barcelona 2016 VES ONAP demo from OPNFV Summit 2017 From VF Event Streaming (VES) Project Proposal Alok Gupta 13 Jun, 2016 OPNFV VES.pptx VNF Event Stream Prpoposal OPNFV projects that potentially benefit from the VES project\nFault Management ([Doctor] (https://wiki.opnfv.org/display/doctor)) *** Virtualized Infrastructure Deployment Policies (Copper) High Availability for OPNFV (Availability) Data Collection for Failure Prediction (Prediction) *** Audit (Inspector) Fault localization (RCA, Pinpoint ) *** Service Function Chaining (sfc) Moon Security Management OpenStack projects that potentially benefit from the VES project\nMonasca: a monitoring-agent plugin for VES can provide a new/converged source for Monasca events Vitrage: similar to Monasca can provide new data for the Graph DB of Vitrage Congress: Congress data source drivers can integrate additional data from Monasca, Vitrage, or directly VNF Event Streaming:Onboarding Telemetry Policies Alok Gupta, Bryan Sullivan(AT\u0026amp;T) June 15, 2017 VES Project overview ONAP and VES project ONAP is now the upstream home of VES and maintained in ONAP(where???)\nFiles used in demo https://wiki.opnfv.org/display/ves/VES+Home\nmonitor.py : Collector and event processor on VDU4 evel_demo.c : VES agent sample code on VDU1 and VDU2 ves_data_model.json : VES data schema in JSON vHello_VES.sh : seems that deleted or rename to other ves_plugin.py : Python-based collectd client ","date":"2017-09-25T15:44:11+09:00","permalink":"https://cychong47.github.io/post/2017/ves-to-opnfv/","summary":"\u003ch1 id=\"ves-project\"\u003eVES project\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://wiki.opnfv.org/display/ves/VES+Home\"\u003eVNF Event Stream Project\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"demo\"\u003eDemo\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://wiki.opnfv.org/display/ves/vHello_VES+Demo\"\u003evHello VES Demo in OpenStack Barcelona 2016\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=Zoxcj4mwUwU\"\u003eVES ONAP demo from OPNFV Summit 2017\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"from-vf-event-streaming-ves-project-proposal\"\u003eFrom VF Event Streaming (VES) Project Proposal\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eAlok Gupta 13 Jun, 2016\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://wiki.opnfv.org/download/attachments/6819329/OPNVF%20VES.pptx?version=4\u0026amp;modificationDate=1466395653000\u0026amp;api=v2\"\u003eOPNFV VES.pptx\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://wiki.opnfv.org/display/PROJ/VNF+Event+Stream\"\u003eVNF Event Stream\u003c/a\u003e Prpoposal\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOPNFV projects that potentially benefit from the VES project\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eFault Management ([Doctor] (\u003ca href=\"https://wiki.opnfv.org/display/doctor\"\u003ehttps://wiki.opnfv.org/display/doctor\u003c/a\u003e)) ***\u003c/li\u003e\n\u003cli\u003eVirtualized Infrastructure Deployment Policies (\u003ca href=\"https://wiki.opnfv.org/display/copper\"\u003eCopper\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eHigh Availability for OPNFV (\u003ca href=\"https://wiki.opnfv.org/display/availability\"\u003eAvailability\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eData Collection for Failure Prediction (\u003ca href=\"https://wiki.opnfv.org/display/prediction\"\u003ePrediction\u003c/a\u003e) ***\u003c/li\u003e\n\u003cli\u003eAudit (\u003ca href=\"https://wiki.opnfv.org/display/inspector\"\u003eInspector\u003c/a\u003e)\u003c/li\u003e\n\u003cli\u003eFault localization (RCA, \u003ca href=\"https://wiki.opnfv.org/display/pinpoint/\"\u003ePinpoint\u003c/a\u003e ) ***\u003c/li\u003e\n\u003cli\u003eService Function Chaining (sfc)\u003c/li\u003e\n\u003cli\u003eMoon Security Management \u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eOpenStack projects that potentially benefit from the VES project\u003c/p\u003e","title":"Integrating VES to OPNFV"},{"content":"Summary The VES can be supported with the help of Kafka broker with the collectd in OPNFV Barometer project which is aim to collect telemetrics from the NFVI.\nBarometer Project The purpose of this project is providing metrics can be used to decide quality of NFVI. For this, the followings are reported\nNIC statistics Resources such as CPU, Memory, load, cache, themals, fan speeds, voltages and machine check exceptions. This means the output of this project will be used in the host itself as well as inside of VM.\nThe original project name was \u0026ldquo;Software Fastpath Service Quality Metrics\u0026rdquo;.\nCollectd Barometer project uses collectd open source project(https://wiki.opnfv.org/display/fastpath/Collectd+101) It was already provide a lot of statistics can be collected from the system(usually unix systme)\nInput and output plugins To support diverse of data and interface, collectd has input and output plugin. The input plugins fed the data to the collectd and output plugins export the data to other system.\nThe supported plugins are listed in here.\nReference Collectd 101 Collectd advantages, disadvantages and a few asides Barometer and Collectd Barometer develops several plugins for collectd.\ndpdkstat plugin: A read plugin that retrieves stats from the DPDK extended NIC stats API. dpdkevents plugin: A read plugin that retrieves DPDK link status and DPDK forwarding cores liveliness status (DPDK Keep Alive). gnocchi plugin: A write plugin that pushes the retrieved stats to Gnocchi. It’s capable of pushing any stats read through collectd to Gnocchi, not just the DPDK stats. aodh plugin: A notification plugin that pushes events to Aodh, and creates/updates alarms appropriately. hugepages plugin: A read plugin that retrieves the number of available and free hugepages on a platform as well as what is available in terms of hugepages per socket. Open vSwitch events Plugin: A read plugin that retrieves events from OVS. Open vSwitch stats Plugin: A read plugin that retrieves flow and interface stats from OVS. mcelog plugin: A read plugin that uses mcelog client protocol to check for memory Machine Check Exceptions and sends the stats for reported exceptions. PMU plugin: A read plugin that provides performance counters data on Intel CPUs using Linux perf interface. RDT plugin: A read plugin that provides the last level cache utilization and memory bandwidth utilization. virt: A read plugin that uses virtualization API libvirt to gather statistics about virtualized guests on a system directly from the hypervisor, without a need to install collectd instance on the guest. SNMP Agent: A write plugin that will act as a AgentX subagent that receives and handles queries from SNMP master agent and returns the data collected by read plugins. The SNMP Agent plugin handles requests only for OIDs specified in configuration file. To handle SNMP queries the plugin gets data from collectd and translates requested values from collectd’s internal format to SNMP format. Supports SNMP: get, getnext and walk requests. VES Plugin for collectd https://wiki.opnfv.org/display/fastpath/VES+plugin+updates\n1st design - Implemented as Collectd Output plugin The VES collectd plugin as output plugin of collectd VES plugin get the data from the collectd and export to VES collector in VES format VES schema change requires VES collectd plugin updated Collectd requries MIT license while OPNFV prefer Apache license 2nd design - Use Kafka broker VES Application(not collectd plugin anymore) get the data from the Kafka broker and convert the data based on the YAML configuration(collectd stats to VES events)\nReference [Apache Kafka] 1. 소개및 아키텍처 정리\n","date":"2017-09-25T15:05:40+09:00","permalink":"https://cychong47.github.io/post/2017/opnfv-barometer/","summary":"\u003ch1 id=\"summary\"\u003eSummary\u003c/h1\u003e\n\u003cp\u003eThe VES can be supported with the help of Kafka broker with the collectd in OPNFV Barometer project which is aim to collect telemetrics from the NFVI.\u003c/p\u003e\n\u003ch1 id=\"barometer-project\"\u003eBarometer Project\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"https://wiki.opnfv.org/display/fastpath/Barometer+Home\"\u003eThe purpose of this project\u003c/a\u003e is providing metrics can be used to decide quality of NFVI. For this, the followings are reported\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eNIC statistics\u003c/li\u003e\n\u003cli\u003eResources such as CPU, Memory, load, cache, themals, fan speeds, voltages and machine check exceptions.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eThis means the output of this project will be used in the host itself as well as inside of VM.\u003c/p\u003e","title":"OPNFV Barometer and VES"},{"content":"From https://www.youtube.com/watch?v=rYRiH3HZFN4\u0026amp;t=3s\nPresented in OpenStack Summit 2017 Boston\nContainer will be used for workload processing after 2019 VNF is differ from Enterprise IT worklaod(4:19)\nVNF is not a simple VM Maintain a state Complex network configuration Sophisticated Storage Connectivity HA is important 2018-2019 vendor and open source project especially openstack should do something to meet the requirements.\nEven it takes some time for container to replace VM for workload perspective, running the Openstack service as a container is possible today.\nWhat AT\u0026amp;T expect from the container Better CI/CD means deploy Openstack more quickly with the help of container.\nCombining OpenStack and Container 2nd option is what AT\u0026amp;T is highly interested. Magnum integrates containers and VMs\nOpenstack is another apps which can be contolled with orchestrator such k8s(right figure)\nOpenstack Helm1\nContainer Sandwidth\nRuns Openstack services inside of the container and k8s governs them Several options Explains option 2, running VM inside of the container(container runs on bare-metal)\nBenefits of Openstack services inside of container Modular scaling of specific OpenStack service such as more authentication can be supported with more keystone containers deployment.\nHitless/In-place upgrade means enabling upgrade of Openstack version without removing or rebooting VMs.\nQ\u0026amp;A Not clear for me. Why running Openstack service inside of the container has more security with a little performance penalty?\nWhat makes NFV go slowly toward container?\nWhy K8s is chosen rather than the alternatives?\nPresentation The goal of OpenStack-Helm is to enable deployment, maintenance, and upgrading of loosely coupled OpenStack services and their dependencies individually or as part of complex environments. Information specific to OpenStack-Helm can be found below. http://openstack-helm.readthedocs.io/en/latest/\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2017-09-21T15:21:45+09:00","permalink":"https://cychong47.github.io/post/2017/summary-at-t-container-strategy/","summary":"\u003cp\u003eFrom \u003ca href=\"https://www.youtube.com/watch?v=rYRiH3HZFN4\u0026amp;t=3s\"\u003ehttps://www.youtube.com/watch?v=rYRiH3HZFN4\u0026amp;t=3s\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePresented in OpenStack Summit 2017 Boston\u003c/p\u003e\n\u003ch2 id=\"container-will-be-used-for-workload-processing-after-2019\"\u003eContainer will be used for workload processing after 2019\u003c/h2\u003e\n\u003cp\u003e\u003cimg src=\"/images/2017/09/Openstack-Summit-2017---ATT-Container-Strategy-03-1.png\" alt=\"Openstack-Summit-2017\u0026mdash;ATT-Container-Strategy-03-1\"\u003e\u003c/p\u003e\n\u003cp\u003eVNF is differ from Enterprise IT worklaod(4:19)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eVNF is not a simple VM\u003c/li\u003e\n\u003cli\u003eMaintain a state\u003c/li\u003e\n\u003cli\u003eComplex network configuration\u003c/li\u003e\n\u003cli\u003eSophisticated Storage Connectivity\u003c/li\u003e\n\u003cli\u003eHA is important\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e2018-2019 vendor and open source project especially openstack should do something to meet the requirements.\u003c/p\u003e\n\u003cp\u003eEven it takes some time for container to replace VM for workload perspective, running the Openstack service as a container is possible today.\u003c/p\u003e","title":"(Summary) AT\u0026T Container Strategy"},{"content":"September 12, 2017\nhttps://www.sdxcentral.com/articles/news/amdocs-brings-nfv-software-package-based-onap/2017/09/\nAmdocs announced its new NFV Powered by ONAP portfolio – a portfolio featuring modular capabilities that accelerate service design, virtualization and operating capabilities on demand.\nService providers using technologies developed in ONAP and its ecosystem of capabilities can provide enterprises the ability to design their own networks as part of a richer set of service features.\nfrom : https://www.amdocs.com/media-room/amdocs-nfv-powered-onap-worlds-first-software-and-services-portfolio-carriers-based-open\nAmdoc? Amdocs was initially involved with AT\u0026amp;T’s home-grown ECOMP platform as an integrator.(2016/07)\nPowered by ONAP Commercial versoins of ONAP modules which are contributed by Amdocs Amdocs Service Design and Create module : automate service design Amdocs Active Inventory module : a unified live view of services Amdocs Orchestration module : Cloud-based hosted development environment to simplify ONAP distribution Deployed locally or in the public cloud. Packaged NFV use cases to speed introduction of virtual services like SD-WAN From Amdocs NFV powered by ONAP slidesahre\nAmdocs’ NFV Powered by ONAP software will be available later this year as well\nCommericialized ONAP? By offering a commercially hardened approach to the lifecycle management of virtual services, building on Open Network Automation Platform (ONAP) , Amdocs wants to capitalize on the years of software development work its done with AT\u0026amp;T\nfrom : Amdocs Claims ONAP First-Mover Status\n\u0026ldquo;a more hardened version of ONAP within the construct of a kind of a larger service lifecycle management portfolio,\u0026rdquo;\nAnn Hatchell - VP of Open Network Marketing at ONAP\nBesides AT\u0026amp;T, Amdocs is also working with other service providers within ONAP. Hatchell mentioned Bell Canada and Orange, but she wouldn’t confirm them as customers of its NFV Powered by ONAP software.\nAmdocs NFV Partner Ecosystem For the services, Amdocs has created a partner ecosystem of vendors that provide more than 80 VNFs.\nAvoid vendor lock-in\nhttp://www.amdocsnfvpartners.com/partners.html\nvCPE vEPC - Affirmed, Connectem vIMS - Metaswitch, Sonus, Tango networks, Tropo(CISCO). vRAN - Altiostar, Asocsa Probes and Assurance - Accedian, Exfo, \u0026hellip; NFV infrastructure - Cloudify, HP, Juniper, Mirantis, Openstack, Redhat, Ubuntu, Vmware, WindRver SDN - CISCO, ECI, HP, Juniper, nuage networks, vmware. Hardware - CISCO, Dell, ECI, EMC2, Hitachi, HP, IBM, Intel, Mellanox Benefits of Amdocs Open Network Partner Program Enable rapid VNF onboarding and fast TTM\nReduce hybrid (physical and virtual) complexity\nDrive holistic NFV service lifecycle management\nFoster innovation in NFV use cases\n​\nAmdocs https://www.amdocs.com https://www.amdocs.com/open-network/nfv-powered-by-onap AMDOCS NFV POWERED BY ONAP – THE WORLD’S FIRST SOFTWARE AND SERVICES PORTFOLIO FOR CARRIERS BASED ON OPEN SOURCE Amdocs looks to ease carriers\u0026rsquo; NFV migration with ONAP-based services portfolio ONAP insider(pdf) ","date":"2017-09-20T15:30:44+09:00","permalink":"https://cychong47.github.io/post/2017/new-amdocs-brings-an-nfv-software-package-based-on-onap/","summary":"\u003cp\u003eSeptember 12, 2017\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.sdxcentral.com/articles/news/amdocs-brings-nfv-software-package-based-onap/2017/09/\"\u003ehttps://www.sdxcentral.com/articles/news/amdocs-brings-nfv-software-package-based-onap/2017/09/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eAmdocs announced its new \u003cstrong\u003eNFV Powered by ONAP portfolio\u003c/strong\u003e  \u003cstrong\u003e–\u003c/strong\u003e a portfolio featuring modular capabilities that accelerate service design, virtualization and operating capabilities on demand.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eService providers using technologies developed in ONAP and its ecosystem of capabilities can provide enterprises the ability to design their own networks as part of a richer set of service features.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003efrom : \u003ca href=\"https://www.amdocs.com/media-room/amdocs-nfv-powered-onap-worlds-first-software-and-services-portfolio-carriers-based-open\"\u003ehttps://www.amdocs.com/media-room/amdocs-nfv-powered-onap-worlds-first-software-and-services-portfolio-carriers-based-open\u003c/a\u003e\u003c/p\u003e\n\u003ch4 id=\"amdoc\"\u003eAmdoc?\u003c/h4\u003e\n\u003cp\u003e\u003ca href=\"https://www.sdxcentral.com/articles/news/amdocs-will-integrator-att-ecomp-platform/2016/07/\"\u003eAmdocs was initially involved\u003c/a\u003e with AT\u0026amp;T’s home-grown ECOMP platform as an integrator.(2016/07)\u003c/p\u003e","title":"(News) Amdocs Brings an NFV Software Package Based on ONAP"},{"content":"Cloud Native Computing Foundation(http://cncf.io)에 포함된 Container monitoring tool.\n집 맥미니에서 돌리고 있는 3개 container들을 관리하는데 사용할 수 있나 싶어(실은 관리할 것도 없지만 그냥 재미로 container monitor 기능을 보고 싶어서) 설치 해 봤다\nInstall cncf.io의 많은 툴이 그렇지만 golang으로 작성되어 있어 golang부터 설치했다\nbrew install go OSX에서 brew는 사용할 때마다 감탄을 금치 못하게 한다. 물론 우분투에도 apt가 있지만 apt보다 brew가 훨씬 편한 것 같다.\n그 다음에는 그냥 docker hub에 있는 prometheus docker 가져다 설치\ncychong:~/Dropbox/Documents/my_docker_repo/prometheus cychong$ docker run -p 9090:9090 -v ~/Dropbox/Apps/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus Unable to find image \u0026#39;prom/prometheus:latest\u0026#39; locally latest: Pulling from prom/prometheus 4b0bc1c4050b: Pull complete a3ed95caeb02: Pull complete d6ab6c75ce17: Pull complete 96eeb64debe6: Pull complete 1e7ee99aa461: Pull complete 8d3b35efed41: Pull complete be179630d433: Pull complete 63e70970c133: Pull complete 83449160ff0d: Pull complete Digest: sha256:4f6d3a525f030e598016be765283c6455c3c830997a5c916b27a5d727be718e1 Status: Downloaded newer image for prom/prometheus:latest time=\u0026#34;2017-09-18T12:46:39Z\u0026#34; level=info msg=\u0026#34;Starting prometheus (version=1.7.1, branch=master, revision=3afb3fffa3a29c3de865e1172fb740442e9d0133)\u0026#34; source=\u0026#34;main.go:88\u0026#34; time=\u0026#34;2017-09-18T12:46:39Z\u0026#34; level=info msg=\u0026#34;Build context (go=go1.8.3, user=root@0aa1b7fc430d, date=20170612-11:44:05)\u0026#34; source=\u0026#34;main.go:89\u0026#34; time=\u0026#34;2017-09-18T12:46:39Z\u0026#34; level=info msg=\u0026#34;Host details (Linux 4.9.41-moby #1 SMP Tue Aug 29 22:02:41 UTC 2017 x86_64 2bbd50a83799 (none))\u0026#34; source=\u0026#34;main.go:90\u0026#34; time=\u0026#34;2017-09-18T12:46:39Z\u0026#34; level=info msg=\u0026#34;Loading configuration file /etc/prometheus/prometheus.yml\u0026#34; source=\u0026#34;main.go:252\u0026#34; time=\u0026#34;2017-09-18T12:46:39Z\u0026#34; level=info msg=\u0026#34;Loading series map and head chunks...\u0026#34; source=\u0026#34;storage.go:428\u0026#34; time=\u0026#34;2017-09-18T12:46:39Z\u0026#34; level=info msg=\u0026#34;0 series loaded.\u0026#34; source=\u0026#34;storage.go:439\u0026#34; time=\u0026#34;2017-09-18T12:46:39Z\u0026#34; level=info msg=\u0026#34;Starting target manager...\u0026#34; source=\u0026#34;targetmanager.go:63\u0026#34; time=\u0026#34;2017-09-18T12:46:39Z\u0026#34; level=info msg=\u0026#34;Listening on :9090\u0026#34; source=\u0026#34;web.go:259\u0026#34; 실행시키는데 yaml 형태의 설정 파일이 필요하다고 해서 기본 값을 구해서 prometheus.yml파일에 저장했다. 이전에 ghost나 wordpress container 실행할 때 했던 것처럼 설정 파일은 ~/Dropbox/Apps/prometheus 디렉토리에 두고 docker 실행할 때 volume으로 연결했다\nhttps://prometheus.io/docs/introduction/install/ 에 설명된 대로 docker run!!!\ndocker run -p 9090:9090 -v ~/Dropbox/Apps/prometheus/prometheus.yml:/etc/prometheus/prometheus.yml prom/prometheus 특별한 문제 없이 실행된다. 웹 브라우저를 이용해 container들이 실행되고 있는 맥미니2011 서버에 접속하면 아주 심플한(이라고 쓰고 썰렁한 이라고 읽는다) 화면이 뜬다. http://192.168.1.200:9090\n그 다음부터는 그냥 맨붕.\nHow to monitor other containers Prometheus는 감시 당할 container에 prometheus를 위한 exporter를 실행해야 하는 듯 한다. 해당 Exporter가 export 하는 URL 주소를 prometheus.yml파일의 targets 항목에 넣어야 prometheus server가 해당 URL에 접근해서 정보를 가져오는 형식이다. 그래서 prometheus.yml파일에 적힌 targets 각각에 대해 상태를 확인할 수 있는 dashboard 화면을 제공한다.\nprometheus가 설치된 서버에 targets 주소(나의 경우 http://192.168.1.200:9090/targets)에 접근하면\n오늘은 여기까지. 나중에 container에서 해당 정보를 export하려면 어떻게 해야 하는지 알아봐야겠다.\n추가) 역시나 정보를 제공할 노드에는 exporter가 필요하다. 아래에 공식 및 비공식(비공식 exporter가 훨씬 많다)\nhttps://prometheus.io/docs/instrumenting/exporters/\n그래서 모니터링할 대상이 늘어날수록 prometheus server가 pull해야 할 대상이 많아지고, 반드시 모니터링 당할 노드에 exporter가 설치되어 한다는 것도 실제 deploy할 때 장애물이 될 수 있을 듯 하다(http://hyunki1019.tistory.com/127) 다만 이 중 두 번째는 문제는 다양한 서비스에 대한 exporter가 개발되고, 해당 서비스 패키지에 빌트인 될 수 있다면 완화될 수 있을 듯. Agent 를 사용하는 monitoring 방식의 숙명이지만, 그 만큼 monitoring tool이 원하는 정보를 획득하기 용이하고, monitoring tool에 최적화된 방법으로 정보를 수집할 수 있는 장점이 있어 반드시 agent-less 방식의 monitoring이 낫다고 보기는 힘들 듯\nPrometheus and Grafana http://hyunki1019.tistory.com/128 참고 Prometheus가 열심히 모든 데이터를 Grafana를 이용해서 좀 더 보기 쉽게 보일 수 있다는. Grafana가 prometheus data를 data source로 지원하고 있어 가능한\nGrafana vs. Kibana Kibana는 주로 ELK라고 불리는 삼총사(ElasticSearch - LogStash - Kibana) 에서 visual을 담당하고 있는 프로젝트. Grafana 와 유사해 보이는데 현재 대세는 Kibana로 보이고(다른 두 친구가 워낙 유명하고, 삼총사의 케미가 좋아)\n두 개를 아주 간단하게 비교한 글은 여기에서(http://opennaru.tistory.com/126)\ngraphite, Elasticsearch, InfluxDB, Zabbix 등 여러 데이터 소스를 지원하며, 데이터 소스에서 데이터를 조회하여 그래프로 표현 Kibana는 Elasticsearch와 사용되며, Grafana는 Graphite or InfluxDB을 주로 백엔드로 사용 다양한 표현방법은 Kibana가 압도적으로 우세함 Grafana는 시계열 그래프만 지원 Reference 오픈소스 모니터링 시스템 Prometheus #1 오픈소스 모니터링 시스템 Prometheus #2 https://prometheus.io/docs/introduction/install/ https://prometheus.io/docs/introduction/getting_started/ ","date":"2017-09-18T13:59:00+09:00","permalink":"https://cychong47.github.io/post/2017/prometheus/","summary":"\u003cp\u003eCloud Native Computing Foundation(\u003ca href=\"http://cncf.io\"\u003ehttp://cncf.io\u003c/a\u003e)에 포함된 Container monitoring tool.\u003c/p\u003e\n\u003cp\u003e집 맥미니에서 돌리고 있는 3개 container들을 관리하는데 사용할 수 있나 싶어(실은 관리할 것도 없지만 그냥 재미로 container monitor 기능을 보고 싶어서) 설치 해 봤다\u003c/p\u003e\n\u003ch3 id=\"install\"\u003eInstall\u003c/h3\u003e\n\u003cp\u003ecncf.io의 많은 툴이 그렇지만 golang으로 작성되어 있어 golang부터 설치했다\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ebrew install go\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eOSX에서 brew는 사용할 때마다 감탄을 금치 못하게 한다. 물론 우분투에도 apt가 있지만 apt보다 brew가 훨씬 편한 것 같다.\u003c/p\u003e\n\u003cp\u003e그 다음에는 그냥 docker hub에 있는 prometheus docker 가져다 설치\u003c/p\u003e","title":"Prometheus"},{"content":"NGINX Releases Microservices Platform, OpenShift Ingress Controller, and Service Mesh Preview\nNGNIX also join for service mesh bandwagon?\nNGNIX Application Platform NGINX Plus, the commercial variant of the popular open source NGINX web server. NGINX Web Application Firewall (WAF) NGINX Unit, a new open source application server that can run PHP, Python and Go NGINX Controller, a centralised control plane for monitoring and management of NGINX Plus Additional release a Kubernetes Ingress Controller solution for load balancing on the Red Hat OpenShift Container Platform an implementation of NGINX as a service proxy for the Istio service mesh control plane. NGINX has also released nginmesh, an open source preview version of NGINX as a service proxy for Layer 7 load balancing and proxying within the Istio service mesh platform. It aims to provide key capabilities and integration with Istio when deployed as a sidecar container, and will facilitate communication between services in a \u0026ldquo;standard, reliable, and secure manner\u0026rdquo;. Additionally, NGINX will collaborate as part of the Istio community by joining the Istio networking special interest group.\nThe concept of a \u0026ldquo;service mesh\u0026rdquo; has risen in popularity recently, as it allows developers to implement loosely coupled microservices-based applications with an underlying mesh (or communication bus) to manage traffic flows between services, enforce access policies, and aggregate telemetry data. Istio is an open source service mesh project led by Google, IBM, Lyft and others, and aims to provide a control plane to the service proxies’ data plane. Currently Istio is tightly integrated into Kubernetes, but there are plans to also support platforms such as virtual machines, PaaS like Cloud Foundry, and potentially FaaS \u0026ldquo;serverless\u0026rdquo; offerings.\nBy default Istio uses the Envoy service proxy, which was created by Matt Klein and the team at Lyft, and has been in production use at Lyft for a number of years. NGINX appears to not be the only company to realise the potential benefits of providing (and owning) the service proxy component within a microservices mesh, as Buoyant are also in the process of modifying their JVM-based service proxy, Linkerd (which was spawned from the Twitter Finagle stack), for integration with Istio.\nistio는 기본적으로 envoy를 사용(c++로 구현) Linkerd는 JVM 기반 nginmesh(golang)으로 구현\nThe NGINX nginmesh Istio service proxy module - written in Golang rather than C as used for the NGINX web server itself - integrates with an open source NGINX running as a sidecar (shown in Figure 2), and claims to offers \u0026ldquo;a small footprint, high-performance proxy with advanced load balancing algorithms, caching, SSL termination, scriptability with Lua and nginScript, and various security features with granular access control.\u0026rdquo;\nReference nginmesh architecture, repo nginx blog universal data plane Introduction to Service Meshes What is a service mesh and why do I need one ","date":"2017-09-15T14:39:11+09:00","permalink":"https://cychong47.github.io/post/2017/ngnix-for-service-mesh/","summary":"\u003cp\u003e\u003ca href=\"https://www.infoq.com/news/2017/09/nginx-platform-service-mesh?utm_source=facebook\u0026amp;utm_medium=link\u0026amp;utm_campaign=calendar\"\u003eNGINX Releases Microservices Platform, OpenShift Ingress Controller, and Service Mesh Preview\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eNGNIX also join for service mesh bandwagon?\u003c/p\u003e\n\u003ch3 id=\"ngnix-application-platform\"\u003eNGNIX Application Platform\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eNGINX Plus, the commercial variant of the popular open source NGINX web server.\u003c/li\u003e\n\u003cli\u003eNGINX Web Application Firewall (WAF)\u003c/li\u003e\n\u003cli\u003eNGINX Unit, a new open source application server that can run PHP, Python and Go\u003c/li\u003e\n\u003cli\u003eNGINX Controller, a centralised control plane for monitoring and management of NGINX Plus\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"additional-release\"\u003eAdditional release\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ea Kubernetes Ingress Controller solution for load balancing on the Red Hat OpenShift Container Platform\u003c/li\u003e\n\u003cli\u003ean implementation of NGINX as a service proxy for the Istio service mesh control plane.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003eNGINX has also released nginmesh, an open source preview version of NGINX as a service proxy for Layer 7 load balancing and proxying within the Istio service mesh platform. It aims to provide key capabilities and integration with Istio when deployed as a sidecar container, and will facilitate communication between services in a \u0026ldquo;standard, reliable, and secure manner\u0026rdquo;. Additionally, NGINX will collaborate as part of the Istio community by joining the Istio networking special interest group.\u003c/p\u003e","title":"NGNIX for service mesh"},{"content":"Under construction!!\nError https://docs.docker.com/compose/wordpress/#define-the-project 에 있는 에제대로 docker-compose.yaml 파일을 만든 후 도전~~\n근데 실패\ncychong:~/work/my_wordpress cychong$ docker-compose up -d Pulling db (mysql:5.7)... Traceback (most recent call last): File \u0026#34;docker-compose\u0026#34;, line 3, in \u0026lt;module\u0026gt; File \u0026#34;compose/cli/main.py\u0026#34;, line 68, in main File \u0026#34;compose/cli/main.py\u0026#34;, line 118, in perform_command File \u0026#34;compose/cli/main.py\u0026#34;, line 928, in up File \u0026#34;compose/project.py\u0026#34;, line 427, in up File \u0026#34;compose/service.py\u0026#34;, line 311, in ensure_image_exists File \u0026#34;compose/service.py\u0026#34;, line 1016, in pull File \u0026#34;site-packages/docker/api/image.py\u0026#34;, line 358, in pull File \u0026#34;site-packages/docker/auth.py\u0026#34;, line 50, in get_config_header File \u0026#34;site-packages/docker/auth.py\u0026#34;, line 97, in resolve_authconfig File \u0026#34;site-packages/docker/auth.py\u0026#34;, line 142, in _resolve_authconfig_credstore docker.errors.DockerException: Credentials store error: StoreError(\u0026#39;Credentials store docker-credential-osxkeychain exited with \u0026#34;User interaction is not allowed.\u0026#34;.\u0026#39;,) Failed to execute script docker-compose 저 에러가 뭘까 하고 Googling을 해 보니 \u0026quot;Credentials store docker-credential-osxkeychain exited with \u0026quot;User interaction is not allowed\u0026quot; 이런 해결책이 나왔다.\nhttps://github.com/docker/docker-credential-helpers/issues/82\nIf I click on the docker icon in the menu bar -\u0026gt; preferences -\u0026gt; and I untick \u0026ldquo;Securely store docker logins in macOS keychain\u0026rdquo; this problem goes away.\n시키는 대로 docker 옵션 수정 후 다시 실행했더니 이제 에러는 발생하지 않는다.\nError is gone cychong:~/work/my_wordpress cychong$ docker-compose up -d Pulling db (mysql:5.7)... 5.7: Pulling from library/mysql ad74af05f5a2: Already exists 0639788facc8: Pull complete de70fa77eb2b: Pull complete 724179e94999: Pull complete 50c77fb16ba6: Pull complete d51f459239fb: Pull complete 937bbdd4305a: Pull complete 35369f9634e1: Pull complete f6016aab25f1: Pull complete 5f1901e920da: Pull complete fdf808213c5b: Pull complete Digest: sha256:96edf37370df96d2a4ee1715cc5c7820a0ec6286551a927981ed50f0273d9b43 Status: Downloaded newer image for mysql:5.7 Creating mywordpress_db_1 ... Creating mywordpress_db_1 ... done Creating mywordpress_wordpress_1 ... Creating mywordpress_wordpress_1 ... done 마지막에 mywordpress_db_1 이란 말이 맘에 안들지만 그래도 일단 웹브라우저에서 접속을 해보는데 안되네\u0026hellip;.\nBut still in error ","date":"2017-09-03T15:00:57+09:00","permalink":"https://cychong47.github.io/post/2017/wordpress-with-docker-compose-failing/","summary":"\u003cp\u003eUnder construction!!\u003c/p\u003e\n\u003ch3 id=\"error\"\u003eError\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"https://docs.docker.com/compose/wordpress/#define-the-project\"\u003ehttps://docs.docker.com/compose/wordpress/#define-the-project\u003c/a\u003e 에 있는 에제대로 docker-compose.yaml 파일을 만든 후 도전~~\u003c/p\u003e\n\u003cp\u003e근데 실패\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong:~/work/my_wordpress cychong$ docker-compose up -d\nPulling db (mysql:5.7)...\nTraceback (most recent call last):\n  File \u0026#34;docker-compose\u0026#34;, line 3, in \u0026lt;module\u0026gt;\n  File \u0026#34;compose/cli/main.py\u0026#34;, line 68, in main\n  File \u0026#34;compose/cli/main.py\u0026#34;, line 118, in perform_command\n  File \u0026#34;compose/cli/main.py\u0026#34;, line 928, in up\n  File \u0026#34;compose/project.py\u0026#34;, line 427, in up\n  File \u0026#34;compose/service.py\u0026#34;, line 311, in ensure_image_exists\n  File \u0026#34;compose/service.py\u0026#34;, line 1016, in pull\n  File \u0026#34;site-packages/docker/api/image.py\u0026#34;, line 358, in pull\n  File \u0026#34;site-packages/docker/auth.py\u0026#34;, line 50, in get_config_header\n  File \u0026#34;site-packages/docker/auth.py\u0026#34;, line 97, in resolve_authconfig\n  File \u0026#34;site-packages/docker/auth.py\u0026#34;, line 142, in _resolve_authconfig_credstore\ndocker.errors.DockerException: Credentials store error: StoreError(\u0026#39;Credentials store docker-credential-osxkeychain exited with \u0026#34;User interaction is not allowed.\u0026#34;.\u0026#39;,)\nFailed to execute script docker-compose\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e저 에러가 뭘까 하고 Googling을 해 보니 \u003ccode\u003e\u0026quot;Credentials store docker-credential-osxkeychain exited with \u0026quot;User interaction is not allowed\u0026quot;\u003c/code\u003e 이런 해결책이 나왔다.\u003c/p\u003e","title":"Wordpress with docker-compose"},{"content":"얼마전에 구성한 ghost container는 ghost가 1.x로 업데이트가 되면서 설정 정보의 위치가 변경되었는데 그걸 미처 몰라 블로그 주소가 기본값인 localhost로 설정되는 문제가 있었다. 기존 ghost container에 접근해서 확인해 보니 `/var/lib/ghost/config.production.json\u0026rsquo; 파일에 주소가 설정되어 있는 걸 보고 이 파일도 따로 지정해 주도록 변경했다. 그러면서 docker-compose를 한번 써 보기로\n일단 기존 ghost를 정리하고\ncychong:~ cychong$ docker stop ghost ghost cychong:~ cychong$ docker rm ghost ghost cychong:~ cychong$ docker rmi ghost Untagged: ghost:latest Untagged: ghost@sha256:a1f70641d35755395eb16827de4e67861e01bffe18bac8e54ab5c68cd170a2ea Deleted: sha256:e6ba3dd3c2491c6086d570fa9769a9f60d7c004129ff9ae7ff9fa0bad16a993b Deleted: sha256:c1ee9d43624bb4a1922c15d7a9175a80d1952cb71464d6d9d900fe21948227af Deleted: sha256:f8f95cdbafce4ecd226cdd690e6f909203a0f83d3507c53a71d4e59826ea881b Deleted: sha256:935d8847555992b702173b83b0d210f2728a24b5287467396dc8d5c68907691f Deleted: sha256:f4766b72a49d4cd2e897da0efcec94c33a0d24a95cb8426a790e1c45e6e39fae Deleted: sha256:0c0dbaebe17c6f585eb596e705ed5acba668097698a7780844c12597bb99b34a Deleted: sha256:c807796bea7a34c0b73eae853b728f2bbcd7a4fecc19d049455b322120f95ce7 Deleted: sha256:15f9f4e44e22d3287b6caf9555110383d3ff2e88ee9cc03823b1ba5a01b75eac Deleted: sha256:77809f11069f2abfb571cba07ee3d696ec32823df0f5d0587042ffdb27a80add Deleted: sha256:5d6bba18f7b25c9b93d3cc0d93a4cff54eb88b0ba22ed867633a21fc3ded5f57 하는 김에 최신 버전의 ghost받아오고\ncychong:~ cychong$ docker pull ghost Using default tag: latest latest: Pulling from library/ghost ad74af05f5a2: Already exists 2b032b8bbe8b: Pull complete ad85906adb69: Pull complete 3caae50f774b: Pull complete ef87a0ce8025: Pull complete fc62209fe861: Pull complete 8610d8088e2a: Pull complete c360787a43d4: Pull complete 5d4f585a7cb1: Pull complete e204e870e4fc: Pull complete Digest: sha256:6c1adf02635cf2a31479a436192068f60c3cc86242d21093f55783ab1d1dd107 Status: Downloaded newer image for ghost:latest docker history 명령을 보니 ghost 버전이 1.8.1로 바뀐 걸 알 수 있네.(좀 쉽게 알 수는 없을까?)\ncychong:~ cychong$ docker history ghost IMAGE CREATED CREATED BY SIZE COMMENT 2d71383c27b9 2 days ago /bin/sh -c #(nop) CMD [\u0026#34;node\u0026#34; \u0026#34;current/in... 0B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) EXPOSE 2368/tcp 0B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) ENTRYPOINT [\u0026#34;docker-ent... 0B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) COPY file:ef6da72f41bc8f... 646B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) VOLUME [/var/lib/ghost/... 0B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) WORKDIR /var/lib/ghost 0B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c set -ex; mkdir -p \u0026#34;$GHOST_INST... 289MB \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) ENV GHOST_CONTENT=/var/... 0B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) ENV GHOST_INSTALL=/var/... 0B \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c npm install -g \u0026#34;ghost-cli@$GHOS... 143MB \u0026lt;missing\u0026gt; 2 days ago /bin/sh -c #(nop) ENV GHOST_VERSION=1.8.1 0B \u0026lt;missing\u0026gt; 8 days ago /bin/sh -c #(nop) ENV GHOST_CLI_VERSION=1... 0B \u0026lt;missing\u0026gt; 8 days ago /bin/sh -c #(nop) ENV NODE_ENV=production 0B \u0026lt;missing\u0026gt; 8 days ago /bin/sh -c #(nop) ENV NPM_CONFIG_LOGLEVEL... 0B \u0026lt;missing\u0026gt; 8 days ago /bin/sh -c set -x \u0026amp;\u0026amp; wget -O /usr/local/b... 1.29MB \u0026lt;missing\u0026gt; 8 days ago /bin/sh -c #(nop) ENV GOSU_VERSION=1.10 0B \u0026lt;missing\u0026gt; 2 weeks ago /bin/sh -c #(nop) CMD [\u0026#34;node\u0026#34;] 0B \u0026lt;missing\u0026gt; 2 weeks ago /bin/sh -c set -ex \u0026amp;\u0026amp; for key in 6A0... 3.89MB \u0026lt;missing\u0026gt; 2 weeks ago /bin/sh -c #(nop) ENV YARN_VERSION=0.27.5 0B \u0026lt;missing\u0026gt; 2 weeks ago /bin/sh -c buildDeps=\u0026#39;xz-utils\u0026#39; \u0026amp;\u0026amp; ARC... 42.5MB \u0026lt;missing\u0026gt; 4 weeks ago /bin/sh -c #(nop) ENV NODE_VERSION=6.11.2 0B \u0026lt;missing\u0026gt; 5 weeks ago /bin/sh -c #(nop) ENV NPM_CONFIG_LOGLEVEL... 0B \u0026lt;missing\u0026gt; 5 weeks ago /bin/sh -c set -ex \u0026amp;\u0026amp; for key in 955... 131kB \u0026lt;missing\u0026gt; 5 weeks ago /bin/sh -c groupadd --gid 1000 node \u0026amp;\u0026amp; u... 335kB \u0026lt;missing\u0026gt; 5 weeks ago /bin/sh -c set -ex; if ! command -v gpg \u0026gt;... 0B \u0026lt;missing\u0026gt; 5 weeks ago /bin/sh -c apt-get update \u0026amp;\u0026amp; apt-get insta... 44.6MB \u0026lt;missing\u0026gt; 5 weeks ago /bin/sh -c #(nop) CMD [\u0026#34;bash\u0026#34;] 0B \u0026lt;missing\u0026gt; 5 weeks ago /bin/sh -c #(nop) ADD file:a023a99f7d01868... 123MB my-ghost/docker-compose.yaml\nversion: \u0026#39;3\u0026#39; services: ghost: container_name: ghost image: ghost:latest volumes: - /Users/cychong/Dropbox/Apps/ghost/content/:/var/lib/ghost/content - /Users/cychong/Dropbox/Apps/ghost/config.production.json:/var/lib/ghost/config.production.json ports: - \u0026#34;2368:2368\u0026#34; restart: always environment: - NODE_ENV=production volumes: db_data: go!\ncychong:~/work/my_ghost cychong$ docker-compose up -d Creating network \u0026#34;myghost_default\u0026#34; with the default driver Creating volume \u0026#34;myghost_db_data\u0026#34; with default driver Creating ghost ... Creating ghost ... done 어디 볼까?\ncychong:~/work/my_ghost cychong$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES dea965b550e6 ghost:latest \u0026#34;docker-entrypoint...\u0026#34; 17 seconds ago Up 16 seconds 0.0.0.0:2368-\u0026gt;2368/tcp ghost 잠시 후 웹브라우저로 확인해 보면 제대로 접속은 되는데 의도한 대로 주소가 localhost가 아니라 sosa0sa.com으로 되었는지는 이 글을 publish하면 알 수 있겠지.\n","date":"2017-09-03T01:26:28+09:00","permalink":"https://cychong47.github.io/post/2017/ghost-container-with-docker-compose/","summary":"\u003cp\u003e얼마전에 구성한 ghost container는 ghost가 1.x로 업데이트가 되면서 설정 정보의 위치가 변경되었는데 그걸 미처 몰라 블로그 주소가 기본값인 localhost로 설정되는 문제가 있었다.\n기존 ghost container에 접근해서 확인해 보니 `/var/lib/ghost/config.production.json\u0026rsquo; 파일에 주소가 설정되어 있는 걸 보고 이 파일도 따로 지정해 주도록 변경했다.\n그러면서 docker-compose를 한번 써 보기로\u003c/p\u003e\n\u003cp\u003e일단 기존 ghost를 정리하고\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong:~ cychong$ docker stop ghost\nghost\ncychong:~ cychong$ docker rm ghost\nghost\ncychong:~ cychong$ docker rmi ghost\nUntagged: ghost:latest\nUntagged: ghost@sha256:a1f70641d35755395eb16827de4e67861e01bffe18bac8e54ab5c68cd170a2ea\nDeleted: sha256:e6ba3dd3c2491c6086d570fa9769a9f60d7c004129ff9ae7ff9fa0bad16a993b\nDeleted: sha256:c1ee9d43624bb4a1922c15d7a9175a80d1952cb71464d6d9d900fe21948227af\nDeleted: sha256:f8f95cdbafce4ecd226cdd690e6f909203a0f83d3507c53a71d4e59826ea881b\nDeleted: sha256:935d8847555992b702173b83b0d210f2728a24b5287467396dc8d5c68907691f\nDeleted: sha256:f4766b72a49d4cd2e897da0efcec94c33a0d24a95cb8426a790e1c45e6e39fae\nDeleted: sha256:0c0dbaebe17c6f585eb596e705ed5acba668097698a7780844c12597bb99b34a\nDeleted: sha256:c807796bea7a34c0b73eae853b728f2bbcd7a4fecc19d049455b322120f95ce7\nDeleted: sha256:15f9f4e44e22d3287b6caf9555110383d3ff2e88ee9cc03823b1ba5a01b75eac\nDeleted: sha256:77809f11069f2abfb571cba07ee3d696ec32823df0f5d0587042ffdb27a80add\nDeleted: sha256:5d6bba18f7b25c9b93d3cc0d93a4cff54eb88b0ba22ed867633a21fc3ded5f57\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e하는 김에 최신 버전의 ghost받아오고\u003c/p\u003e","title":"ghost container with docker-compose"},{"content":"docker 버전이 업데이트되고, 몇 가지 변경사항이 있은 후 ghost, wordpress/mysql 조합의 container들이 접속이 되질 않는다. 한참을 두고 보다 ghost는 새 버전(1.x)이 나온 걸 계기로 새로 설치를 했는데(당연히 이전 설치에서 데이터를 container 내부가 아니라 local machine에 두도록 해서 데이터는 그대로 보존) wordpress는 그러질 못했다.\n이것 역시 참다참다 못해 https://docs.docker.com/compose/wordpress/#define-the-project 에 나와있는 docker swarm을 이용해서 복구해 보려고 삽을 들었다.\n위 페이지에 있는 대로 설정 파일을 만들고\nversion: \u0026#39;3\u0026#39; services: db: image: mysql:5.7 volumes: - /Users/cychong/Dropbox/Apps/wordpress/:/var/lib/mysql restart: always environment: MYSQL_ROOT_PASSWORD: xxx MYSQL_DATABASE: xxx MYSQL_USER: xxx MYSQL_PASSWORD: xxx wordpress: depends_on: - db image: wordpress:latest volumes: - /Users/cychong/Documents/wordpress/:/var/www/html - /Users/cychong/Documents/wordpress/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini ports: - \u0026#34;8000:80\u0026#34; restart: always environment: WORDPRESS_DB_HOST: db:3306 WORDPRESS_DB_USER: xxx WORDPRESS_DB_PASSWORD: xxx volumes: db_data: 문서에 있는 대로 docker compose 명령을 실행했는데\ncychong:~/work/my_wordpress cychong$ docker-compose up -d Creating network \u0026#34;mywordpress_default\u0026#34; with the default driver Creating volume \u0026#34;mywordpress_db_data\u0026#34; with default driver Pulling db (mysql:5.7)... Traceback (most recent call last): File \u0026#34;docker-compose\u0026#34;, line 3, in \u0026lt;module\u0026gt; File \u0026#34;compose/cli/main.py\u0026#34;, line 68, in main File \u0026#34;compose/cli/main.py\u0026#34;, line 118, in perform_command File \u0026#34;compose/cli/main.py\u0026#34;, line 928, in up File \u0026#34;compose/project.py\u0026#34;, line 427, in up File \u0026#34;compose/service.py\u0026#34;, line 311, in ensure_image_exists File \u0026#34;compose/service.py\u0026#34;, line 1016, in pull File \u0026#34;site-packages/docker/api/image.py\u0026#34;, line 358, in pull File \u0026#34;site-packages/docker/auth.py\u0026#34;, line 50, in get_config_header File \u0026#34;site-packages/docker/auth.py\u0026#34;, line 97, in resolve_authconfig File \u0026#34;site-packages/docker/auth.py\u0026#34;, line 142, in _resolve_authconfig_credstore docker.errors.DockerException: Credentials store error: StoreError(\u0026#39;Credentials store docker-credential-osxkeychain exited with \u0026#34;User interaction is not allowed.\u0026#34;.\u0026#39;,) Failed to execute script docker-compose 쩝.. 아직 갈길이 멀구나.\n","date":"2017-09-03T00:36:25+09:00","permalink":"https://cychong47.github.io/post/2017/try-to-restore-wordpress-docker/","summary":"\u003cp\u003edocker 버전이 업데이트되고, 몇 가지 변경사항이 있은 후 ghost, wordpress/mysql 조합의 container들이 접속이 되질 않는다.\n한참을 두고 보다 ghost는 새 버전(1.x)이 나온 걸 계기로 새로 설치를 했는데(당연히 이전 설치에서 데이터를 container 내부가 아니라 local machine에 두도록 해서 데이터는 그대로 보존) wordpress는 그러질 못했다.\u003c/p\u003e\n\u003cp\u003e이것 역시 참다참다 못해 \u003ca href=\"https://docs.docker.com/compose/wordpress/#define-the-project\"\u003ehttps://docs.docker.com/compose/wordpress/#define-the-project\u003c/a\u003e 에 나와있는 docker swarm을 이용해서 복구해 보려고 삽을 들었다.\u003c/p\u003e\n\u003cp\u003e위 페이지에 있는 대로 설정 파일을 만들고\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eversion: \u0026#39;3\u0026#39;\n\nservices:\n   db:\n     image: mysql:5.7\n     volumes:\n       - /Users/cychong/Dropbox/Apps/wordpress/:/var/lib/mysql\n     restart: always\n     environment:\n       MYSQL_ROOT_PASSWORD: xxx\n       MYSQL_DATABASE: xxx\n       MYSQL_USER: xxx\n       MYSQL_PASSWORD: xxx\n\n   wordpress:\n     depends_on:\n       - db\n     image: wordpress:latest\n     volumes:\n       - /Users/cychong/Documents/wordpress/:/var/www/html\n       - /Users/cychong/Documents/wordpress/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini\n     ports:\n       - \u0026#34;8000:80\u0026#34;\n     restart: always\n     environment:\n       WORDPRESS_DB_HOST: db:3306\n       WORDPRESS_DB_USER: xxx\n       WORDPRESS_DB_PASSWORD: xxx\nvolumes:\n    db_data:\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e문서에 있는 대로 docker compose 명령을 실행했는데\u003c/p\u003e","title":"Try to restore Wordpress container"},{"content":"난 반대로 기존 상용차업체들이 몇 년간 테슬라를 보면서도 고작(?) 전기차 라는 키워드에만 집중해서 분석한 듯한 모습이 더 실망스러운데. 여전히 테슬라를 전기동력을 이용한 차를 만드는 회사로 인지하는 건 아닌지.\n다른 분야와 마찬가지로 자동차부문에 SW라는 개념을 넣은 것도 전기차 못지 않은 혁신이라고 생각. 도대체 서비스센터 갈때마다 뭔 소프트웨어 업데이트를 했다고 하지만 사용자인 내가 느낄 수 있는 건 단 한번도 없었는데(이건 내 제한된 경험때문에 V사만 그런 것일지도 모르지만)\n한번 차를 팔면 땡(그나마 하드웨어에 대한 유지보수망)이라는 생각을 가지고 있는 회사와 끊임없이 SW를 통해 부가가치를 만들어 제공하려는 회사는 하늘과 땅 차이가 아닐까 싶다. 내가 테슬라를 산다면(일단 한숨부터 쉬고\u0026hellip; 가격이 ㅎㄷㄷ) 그건 전기차여서라기 보다는 SW를 통한 기능 혁신 때문일 듯\n별거없다면서못하는건뭔지 안하는거라고말하겠지\n페북에서 본 글\n이런 뉴스 보면, 또한번 자뻑에 빠지지 않을 수가 없는 것이다!!\nhttp://biz.chosun.com/…/html_…/2017/08/11/2017081102367.html\n며칠전 내가 남긴 페북 포스팅 :\n\u0026ldquo;나보다 백만배 더 똑똑한 사람들이 테슬라에 열광하여 돈 태우는 걸 보면서\u0026hellip; 그래도 나는 이해가 안 되더라\u0026hellip;\n아니, 무슨 전기차가 어마어마한 기술이라고\u0026hellip;. 전기차랑 하이브리드랑 비교해 보면 뭐가 더 어려운 기술이겠나?\n게다가 나는 모델 3에 대해 수십가지 의문을 품고 있었다. 여러 면에서 합리적으로 설명되지 않아서\u0026hellip;\n테슬라만 독보적으로 싸고 좋은 차를 만들 수 있다고?? 내 의문의 핵심은 이 질문이다. 그럴 리가 없다는 게 내 의심이고\u0026hellip;\u0026rdquo;\n몇년전에 테슬라가 자사의 특허를 전부 무상공개하겠다는 뉴스를 발표했을 때.. 그때 정말 IT 힙스터들의 영웅이 되었었는데\u0026hellip;\n상식적으로 생각해서 진짜로 가치있는 특허라면 그건 \u0026ldquo;미친놈\u0026quot;이거나 \u0026ldquo;연쇄배임마\u0026quot;가 되는 것이었다. 그것도 나는 매우 의심스러운 눈으로 보았었다.\n예전부터 해오던 아주 간단한 의심이다. 전기차보다 하이브리드가 더 만들기 어렵다. 테슬라는 하이브리드를 만들 능력이 없고, 하이브리드 자동차 브랜드는 전기차를 만들 능력이 있다.\n그럼 누가 이기겠는가??\n이 간단한 질문에 답이 나와야 테슬라에 대해서도 답이 나온다고 생각한다.\n뭔 솔라시티니, 뭐니 하는 건 됐고. 그건 돈만 있으면 다 하는 거고\u0026hellip;\n","date":"2017-08-22T22:11:57+09:00","permalink":"https://cychong47.github.io/post/2017/tesla-pyeomhae-daehan-nayi-saenggag/","summary":"\u003cp\u003e난 반대로 기존 상용차업체들이 몇 년간 테슬라를 보면서도 고작(?) 전기차 라는 키워드에만 집중해서 분석한 듯한 모습이 더 실망스러운데. 여전히 테슬라를 전기동력을 이용한 차를 만드는 회사로 인지하는 건 아닌지.\u003c/p\u003e\n\u003cp\u003e다른 분야와 마찬가지로 자동차부문에 SW라는 개념을 넣은 것도 전기차 못지 않은 혁신이라고 생각. 도대체 서비스센터 갈때마다 뭔 소프트웨어 업데이트를 했다고 하지만 사용자인 내가 느낄 수 있는 건 단 한번도 없었는데(이건 내 제한된 경험때문에 V사만 그런 것일지도 모르지만)\u003c/p\u003e\n\u003cp\u003e한번 차를 팔면 땡(그나마 하드웨어에 대한 유지보수망)이라는 생각을 가지고 있는 회사와 끊임없이 SW를 통해 부가가치를 만들어 제공하려는 회사는 하늘과 땅 차이가 아닐까 싶다. 내가 테슬라를 산다면(일단 한숨부터 쉬고\u0026hellip; 가격이 ㅎㄷㄷ) 그건 전기차여서라기 보다는 SW를 통한 기능 혁신 때문일 듯\u003c/p\u003e","title":"Tesla 폄하에 대한 나의 생각"},{"content":"brew cask install qlmarkdown brew cask install quicklook-json brew cask install qlprettypatch brew cask install quicklook-csv ","date":"2017-07-26T14:36:10+09:00","permalink":"https://cychong47.github.io/post/2017/useful-quicklooks/","summary":"\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ebrew cask install qlmarkdown\nbrew cask install quicklook-json\nbrew cask install qlprettypatch\nbrew cask install quicklook-csv\n\u003c/code\u003e\u003c/pre\u003e","title":"Useful quicklooks"},{"content":"\n","date":"2017-06-08T22:06:37+09:00","permalink":"https://cychong47.github.io/post/2017/naver-labs-12-commandments/","summary":"\u003cp\u003e\u003cimg src=\"/images/2017/06/10322716_312737782251024_4003636941493260411_n.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2017/06/10730858_312737868917682_2073320376500002461_n.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2017/06/10177447_312737902251012_2276001140975349740_n.jpg\" alt=\"\"\u003e\u003c/p\u003e","title":"Naver Labs 12 commandments"},{"content":"출처 : O\u0026rsquo;reilly radar\n현장에서 발생하는 문제 몇 번 겪어본 사람이면 대부분 동의할 문제긴 한데 structured log 사용이나 application metric 측정 등은 오래\nWrap errors Error handler wrapper function을 이용해서 error code(annotation 포함) 등을 잘 출력해서 분석이 쉽게 하자\nReport panics Panic을 내야 하는 경우에는 해당 사실을 어딘가 기록(하거나 전송해서 남기고) 패닉 처리하자.\nUse structured logs 일반 text보다는 덜 human-readable하지만 SW를 이용해서 분석하기 쉬운 structured log를 남기자. ELK를 이용해 로그 분석하기도 용이하다.\nGo stdlib이 제공하는 lib은 unstructured log만 지원하므로 logrus(http://github.com/Sirupsen/logrus)와 같은 3rd party package를 활용한다.\nimport log \u0026quot;github.com/Sirupsen/logrus\u0026quot; log.SetFormatter(\u0026amp;log.JSONFormatter{}) log.WithFields(log.Fields{}).Info(\u0026quot;Redirecting User\u0026quot;) Ship application metrics 프로그램의 성능이나 쓰임새를 알 수 있는 metric 측정 기능을 구현하자.\n얼마나 많은 request에 대해 error response를 주는지? 99퍼센트의 request에 대한 응답 시간은? Native go client library를 제공하는 metric system들\nDatadog Prometheus StatsD + Graphite Write more tests than you think you should. API등은 더 자세히 테스트하자 필요하면 핵심 함수에 대해서는 code coverage를 측정하자.\ngo test -cover\n","date":"2017-05-04T12:24:27+09:00","permalink":"https://cychong47.github.io/post/2017/how-to-ship-production-grade-go/","summary":"\u003cp\u003e출처 : \u003ca href=\"https://www.oreilly.com/ideas/how-to-ship-production-grade-go?utm_medium=social\u0026amp;utm_source=twitter.com\u0026amp;utm_campaign=saeu17\u0026amp;utm_content=live+training+joshi+jj\u0026amp;cmp=tw-prog-trainreg-article-saeu17_training_go_joshi_ormt_jj\"\u003eO\u0026rsquo;reilly radar\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e현장에서 발생하는 문제 몇 번 겪어본 사람이면 대부분 동의할 문제긴 한데 structured log 사용이나 application metric 측정 등은 오래\u003c/p\u003e\n\u003ch2 id=\"wrap-errors\"\u003eWrap errors\u003c/h2\u003e\n\u003cp\u003eError handler wrapper function을 이용해서 error code(annotation 포함) 등을 잘 출력해서 분석이 쉽게 하자\u003c/p\u003e\n\u003ch2 id=\"report-panics\"\u003eReport panics\u003c/h2\u003e\n\u003cp\u003ePanic을 내야 하는 경우에는 해당 사실을 어딘가 기록(하거나 전송해서 남기고) 패닉 처리하자.\u003c/p\u003e\n\u003ch2 id=\"use-structured-logs\"\u003eUse structured logs\u003c/h2\u003e\n\u003cp\u003e일반 text보다는 덜 human-readable하지만 SW를 이용해서 분석하기 쉬운 structured log를 남기자. ELK를 이용해 로그 분석하기도 용이하다.\u003cbr\u003e\nGo stdlib이 제공하는 \u003ccode\u003elib\u003c/code\u003e은 unstructured log만 지원하므로 \u003ccode\u003elogrus\u003c/code\u003e(\u003ca href=\"http://github.com/Sirupsen/logrus\"\u003ehttp://github.com/Sirupsen/logrus\u003c/a\u003e)와 같은 3rd party package를 활용한다.\u003c/p\u003e","title":"(요약) How to ship production-grade Go"},{"content":"Slack에서 제공하는 여러 가지 기능 중 하나로 \u0026ldquo;Do not disturb\u0026quot;가 있다. 아래는 그 기능을 설명한 블로그 글( Slack으로 막일을 줄여요 ~ 막일을 줄이기 위한 유용한 팁 2 )\nSlack 툴을 만든 회사 Slack에서의 문화를 따라 나온 기능이라고 하는데 직원들이 퇴근 후에도 회사 일에 연결되어 있다는 부담감을 없애주고 싶었단다.\n이 기능을 활용하면 사람들간에 저녁이나 주말에 나누고 싶은 정보가 있을 때, 각자의 설정에 따라 바로 알림을 받거나, 혹은 나중에 알 수도 있을 거다. 정보를 보내는 사람 관점에서는 보다 부담없이 나누고 싶은 이야기를 할 수 있지 않을까 싶은데.\n설정 화면을 보면 특정 채널에 대해서만 선별적으로 적용하는 것이 아니라 채널 전체에 대해서 적용되나 보다. 어떨까? Slack을 써보자고 하면 어떨까? 대부분 카톡을 쓰고 있어 귀찮아 할 것 같긴 한데. 거기에다 회사에서는 slack이 아닌 메신저나 M-chat을 써야 할텐니\n","date":"2017-04-16T05:51:11+09:00","permalink":"https://cychong47.github.io/post/2017/slack-do-not-disturb/","summary":"\u003cp\u003eSlack에서 제공하는 여러 가지 기능 중 하나로 \u0026ldquo;Do not disturb\u0026quot;가 있다.\n아래는 그 기능을 설명한 블로그 글( \u003ca href=\"http://www.popit.kr/slack-tip/\"\u003eSlack으로 막일을 줄여요 ~ 막일을 줄이기 위한 유용한 팁 2\u003c/a\u003e )\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2017/04/slack-do-not-disturb.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eSlack 툴을 만든 회사 Slack에서의 문화를 따라 나온 기능이라고 하는데 직원들이 퇴근 후에도 회사 일에 연결되어 있다는 부담감을 없애주고 싶었단다.\u003c/p\u003e\n\u003cp\u003e이 기능을 활용하면 사람들간에 저녁이나 주말에 나누고 싶은 정보가 있을 때, 각자의 설정에 따라 바로 알림을 받거나, 혹은 나중에 알 수도 있을 거다. 정보를 보내는 사람 관점에서는 보다 부담없이 나누고 싶은 이야기를 할 수 있지 않을까 싶은데.\u003c/p\u003e","title":"Slack이 기능 중 하나 - 방해금지"},{"content":"요즘 재밌게 보고 있는 JTBC 윤식당. 이서진을 포함한 몇 명의 연기자가 해외에 식당을 내고 운영한다. 그나마 얼굴이 덜 알려진 해외에서 요리를 남에게 파는 행위를 해봤을 것 같지 않은 사람들이 모여 식당을 운영하는 걸 잔잔(?)한 톤으로 보여준다.\n그런데 우연히 읽은 글에서 \u0026lsquo;윤식당\u0026rsquo;과 스타트업을 연결한 걸 봤다.\nhttp://madedesignbyme.com/archives/1387\n하지만 윤식당이란 타이틀처럼 식당장사를 하게되는데 그들은 이걸 처음 해보게 됩니다. 이들은 처음하는 식당을 어떻게하면 좋은 결과를 만들어 낼수 있는지 저녁을 먹으며 연구하고 그 다음날 아침, 전날의 피드백을 반영하기위해 식재료를 사러가는 것으로 그날의 하루를 시작합니다.\n그러고 보니 매일 저녁 그날 장사를 회고하고, 다음 날 장사를 대비하여 새로운 메뉴를 개발하거나 영업 시간 등을 협의하여 개선해 나간다.\n1호점을 유지할 수 없어 새로운 장소로 옮겨야 하는 상황에서도 새로운 상황에 맞게 유연(?)하게 대응해 간다. 그것도 하루만에 빠르게. 할 수 있는 모든 사람이 힘을 합쳐\n주방팀에서는 종종 나와서 직접 고객의 feedback을 확인한다. 고객이 먹는 모습을 보기도 하고, 음식에 만족하는지 직접 물어보기도 하고, 다 먹은 식판에서 어떤 재료가 남았는지(좋아하지 않는지), 혹시 양은 많은 지 등을 확인해서 반영한다.\n스타트업 혹은 Agile에서 이야기하는 기민함을 보여주는 프로그램인 듯. 나피디는 실은 IT인?\n","date":"2017-04-16T05:40:05+09:00","permalink":"https://cychong47.github.io/post/2017/younkitchen-agile/","summary":"\u003cp\u003e요즘 재밌게 보고 있는 JTBC 윤식당. 이서진을 포함한 몇 명의 연기자가 해외에 식당을 내고 운영한다. 그나마 얼굴이 덜 알려진 해외에서 요리를 남에게 파는 행위를 해봤을 것 같지 않은 사람들이 모여 식당을 운영하는 걸 잔잔(?)한 톤으로 보여준다.\u003c/p\u003e\n\u003cp\u003e그런데 우연히 읽은 글에서 \u0026lsquo;윤식당\u0026rsquo;과 스타트업을 연결한 걸 봤다.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://madedesignbyme.com/archives/1387\"\u003ehttp://madedesignbyme.com/archives/1387\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e하지만 윤식당이란 타이틀처럼 식당장사를 하게되는데 그들은 이걸 처음 해보게 됩니다. 이들은 처음하는 식당을 어떻게하면 좋은 결과를 만들어 낼수 있는지 저녁을 먹으며 연구하고 그 다음날 아침, 전날의 피드백을 반영하기위해 식재료를 사러가는 것으로 그날의 하루를 시작합니다.\u003c/p\u003e","title":"윤식당에서 배우는 agile"},{"content":"Slack에 개인 채널(?)을 만들었다. 이런 저런 내가 수집(?)하는 정보들을 한 군데서 모아서 히스토리를 만들면 어떨까 하는 생각에\n누구는 slack과 빌드 상황도 연동해서 사용한다고 하는데 그건 좀 공부가 필요해 보이고, 일단 제일 쉬워 보이는 ghost와 연동을 시도해 봤다.\nGhost의 admin 화면에서 Apps를 선택하면 이런 화면이 나온다.\n여기서 Slack항목의 Active를 선택하면 slack와 연동할 수 있는 URL을 입력하라고 나온다. 아래는 이미 연동이 된 상태로 처음 선택한 경우에는 URL 아래에 있는 \u0026ldquo;Set up a new incoming webhook here\u0026quot;의 here를 선택한다.\n\u0026lsquo;here\u0026rsquo;를 선택하면 나오는 화면에서 ghost와 연결할 slack channel을 선택하고 \u0026ldquo;Add incoming WebHooks integration\u0026quot;을 누르면 나오는 화면에서 URL을 복사해서 위의 ghost/apps/slack 화면에 입력하면 된다.\n그 다음부터 ghost에 새로운 글을 쓴 경우 다음과 같이 slack의 채널에 알림이 함께 올라온다. 위 화면을 보니 이상하게 글의 링크가 localhost로 나와 확인해보니 ghost의 config.js에 url: 'http://localhost:2368',와 같이 설정되어 있었다는\u0026hellip;\n이 부분을 고치고 다시 실행했으니 이제 이 글을 올리면 제대로 된 URL이 나올 듯\n추가) 예상대로 수정 후에 글이 제대로 나온다\n","date":"2017-04-12T15:37:39+09:00","permalink":"https://cychong47.github.io/post/2017/slack-ghost/","summary":"\u003cp\u003eSlack에 개인 채널(?)을 만들었다.\n이런 저런 내가 수집(?)하는 정보들을 한 군데서 모아서 히스토리를 만들면 어떨까 하는 생각에\u003c/p\u003e\n\u003cp\u003e누구는 slack과 빌드 상황도 연동해서 사용한다고 하는데 그건 좀 공부가 필요해 보이고, 일단 제일 쉬워 보이는 ghost와 연동을 시도해 봤다.\u003c/p\u003e\n\u003cp\u003eGhost의 admin 화면에서 Apps를 선택하면 이런 화면이 나온다.\u003c/p\u003e\n\u003cp\u003e\u003cimg src=\"/images/2017/04/ghost_apps_menu.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e여기서 Slack항목의 Active를 선택하면 slack와 연동할 수 있는 URL을 입력하라고 나온다. 아래는 이미 연동이 된 상태로 처음 선택한 경우에는 URL 아래에 있는 \u0026ldquo;Set up a new incoming webhook here\u0026quot;의 here를 선택한다.\u003c/p\u003e","title":"Slack + Ghost"},{"content":"From Ericsson \u0026ldquo;Fueling 5G with DevOps\u0026rdquo;\nMaintaining one track in software development, using feature flag-driven development, and establishing version-controlled repositories for application code and application and system configuration data enables teams to create a complete environment that is ready for consistent “build and deploy”.\nWhat is feature flag-driven development? 특정 feature에 대해 일부 고객(예를 들면 전체 고객 중 1%)에 대해서만 먼저 적용한 후 feedback에 따라 확대 적용할 지 rollback할 지를 결정하는 방식\n문제가 발생하여 기능을 Rollback을 해야 하는 경우라도 일부 고객에만 영향을 주므로 부담이 적다는\nWaterfall, Agile과의 비교. Agile의 경우도 deploy 시점에는 all-or-nothing 방식으로 적용하는 것이 아니냐는 생각인 듯.\nRelated readings FFDD에 대한 Reddit Feature branch와의 비교에 대한 의견 FFDD에 대한 Hacker News 사이트의 의견들 FFDD가 아닌 module flag-driven development(자체 용어)를 낫다는 의견(Management agrees which set of features is released in a group as a module) FFDD는 수 많은 if들로 코드가 복잡해 진다는 의견. 이를 위해 removal branch를 운영한다는 의견도 FFDD 관련 솔류션을 제공하는 LaunchDarkly에서 공유한 FFDD 관련 가이드 LaunchDarkly에서 운영하는 Hub for FFDD ","date":"2017-04-12T15:29:09+09:00","permalink":"https://cychong47.github.io/post/2017/feature-flag-driven-development/","summary":"\u003cp\u003eFrom Ericsson \u0026ldquo;Fueling 5G with DevOps\u0026rdquo;\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eMaintaining one track in software development, using \u003cstrong\u003efeature flag-driven development\u003c/strong\u003e, and establishing version-controlled repositories for application code and application and system configuration data enables teams to create a complete environment that is ready for consistent “build and deploy”.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"what-is-feature-flag-driven-development\"\u003eWhat is \u003ccode\u003efeature flag-driven development\u003c/code\u003e?\u003c/h2\u003e\n\u003cp\u003e특정 feature에 대해 일부 고객(예를 들면 전체 고객 중 1%)에 대해서만 먼저 적용한 후 feedback에 따라 확대 적용할 지 rollback할 지를 결정하는 방식\u003cbr\u003e\n문제가 발생하여 기능을 Rollback을 해야 하는 경우라도 일부 고객에만 영향을 주므로 부담이 적다는\u003cbr\u003e\n\u003cimg src=\"http://blog.launchdarkly.com/wp-content/uploads/2015/10/ld_overview2.png\" alt=\"\"\u003e\u003c/p\u003e","title":"Feature Flag Driven Development"},{"content":"Google Fellow Amin Vahdat,\n“Early on, we realized that the network we needed to support our services did not exist and could not be bought,”\nEspresso makes Google cloud faster, more available and cost effective by extending SDN to the public internet\nnetwork should be treated as a large-scale distributed system leveraging the same control infrastructure we developed for Google’s compute and storage systems Four pillars on Google\u0026rsquo;s SDN strategy Jupiter: Google employed SDN principles to build Jupiter, a data center interconnect capable of supporting more than 100,000 servers. As of 2013 it supports more than 1 Pb/s of total bandwidth to host its services. B4 WAN interconnect: Google constructed B4 to connect its data centers to one another to replicate data in real-time between individual campuses. “It’s built on white boxes with our software controlling it,” said Vahdat at today’s session. “Our goal was to build a copy network. As it’s grown it’s become mission critical. B4 grows faster than our public network.” Andromeda: Google’s Andromeda is a network functions virtualization (NFV) stack that allows it to deliver the same capabilities available to its native applications all the way to containers and virtual machines running on the Google Cloud Platform. Espresso : Google\u0026rsquo;s peering edge architecture. Select the optimal internal server and route based on the real-time information Background For example, consider real-time voice search. Answering the question “What’s the latest news?” with Google Assistant requires a fast, low-latency connection from a user’s device to the edge of Google’s network, and from the edge of our network to one of our data centers. Once inside a data center, hundreds—or even thousands—of individual servers must consult vast amounts of data to score the mapping of an audio recording to possible phrases in one of many languages and dialects. The resulting phrase is then passed to another cluster to perform a web search, consulting a real-time index of internet content. The results are then gathered, scored and returned to the edge of Google’s network back to the end user.\nInnovation dynamically choose from where to serve individual users based on measurements of how end-to-end network connections are performing in real time. separate the logic and control of traffic management from the confines of individual router “boxes. Rather than relying on thousands of individual routers to manage and learn from packet streams, we push the functionality to a distributed system that extracts the aggregate information. Reference https://www.sdxcentral.com/articles/news/google-brings-sdn-public-internet/2017/04/\nhttps://blog.google/topics/google-cloud/making-google-cloud-faster-more-available-and-cost-effective-extending-sdn-public-internet-espresso/\n","date":"2017-04-12T00:32:57+09:00","permalink":"https://cychong47.github.io/post/2017/espresso-googles-peering-edge-architecture/","summary":"\u003cp\u003eGoogle Fellow Amin Vahdat,\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e“Early on, we realized that the network we needed to support our services did not exist and could not be bought,”\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"https://blog.google/topics/google-cloud/making-google-cloud-faster-more-available-and-cost-effective-extending-sdn-public-internet-espresso/\"\u003eEspresso makes Google cloud faster, more available and cost effective by extending SDN to the public internet\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003enetwork should be treated as a large-scale distributed system\u003c/li\u003e\n\u003cli\u003eleveraging the same control infrastructure we developed for Google’s compute and storage systems\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"https://storage.googleapis.com/gweb-uniblog-publish-prod/images/nespresso-2.width-566.png\" alt=\"nespresso-1\"\u003e\u003c/p\u003e\n\u003ch2 id=\"four-pillars-on-googles-sdn-strategy\"\u003eFour pillars on Google\u0026rsquo;s SDN strategy\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eJupiter\u003c/strong\u003e: Google employed SDN principles to build Jupiter, a data center interconnect capable of supporting more than 100,000 servers. As of 2013 it supports more than 1 Pb/s of total bandwidth to host its services.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eB4 WAN interconnect\u003c/strong\u003e: Google constructed B4 to connect its data centers to one another to replicate data in real-time between individual campuses. “It’s built on white boxes with our software controlling it,” said Vahdat at today’s session. “Our goal was to build a copy network. As it’s grown it’s become mission critical. B4 grows faster than our public network.”\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eAndromeda\u003c/strong\u003e: Google’s Andromeda is a \u003ca href=\"https://www.sdxcentral.com/nfv/\"\u003e\u003cstrong\u003enetwork functions virtualization (NFV)\u003c/strong\u003e\u003c/a\u003e stack that allows it to deliver the same capabilities available to its native applications all the way to \u003ca href=\"https://www.sdxcentral.com/cloud/containers/\"\u003econtainers\u003c/a\u003e and \u003ca href=\"https://www.sdxcentral.com/cloud/containers/definitions/what-is-a-linux-container/\"\u003evirtual machines\u003c/a\u003e running on the Google Cloud Platform.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eEspresso\u003c/strong\u003e : Google\u0026rsquo;s peering edge architecture. Select the optimal internal server and route based on the real-time information\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"background\"\u003eBackground\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eFor example, consider real-time voice search. Answering the question “What’s the latest news?” with \u003ca href=\"https://assistant.google.com/\"\u003eGoogle Assistant\u003c/a\u003e requires a fast, low-latency connection from a user’s device to the edge of Google’s network, and from the edge of our network to one of our data centers. Once inside a data center, hundreds—or even thousands—of individual servers must consult vast amounts of data to score the mapping of an audio recording to possible phrases in one of many languages and dialects. The resulting phrase is then passed to another cluster to perform a web search, consulting a real-time index of internet content. The results are then gathered, scored and returned to the edge of Google’s network back to the end user.\u003c/p\u003e","title":"Espresso - Google's peering edge architecture"},{"content":"","date":"2017-04-09T15:41:23+09:00","permalink":"https://cychong47.github.io/post/2017/why-message-queue-used-for-microservice/","summary":"","title":"Why message queue used for microservice?"},{"content":"Open source language for \u0026ldquo;Programming Protocol-independent Packet Processor\u0026rdquo;\nhttp://p4.org\nBarefoot network - Tofino - PISA(Protocol Independent Switch Architecture) switch Netronome - smart NIC 5G: flexibility or high performance? Both - Ericsson Research Blog POF/PIF and P4 initiatives all point in a direction where programmable packet processing will not depend on standardized OpenFlow action sets anymore\nPOF : Protocol Oblivious Forwarding PIF : Protocol Independent Forwarding\nOF-PI P4 in wikipedia p4 in ONRC Revolutionising networking technology from newelectronics P4: driving innovation in server-based networking (Jan 4 2017) Extern objects in P4:an ROHC Compression Case study ","date":"2017-04-09T08:58:50+09:00","permalink":"https://cychong47.github.io/post/2017/p4/","summary":"\u003cp\u003eOpen source language for \u0026ldquo;Programming Protocol-independent Packet Processor\u0026rdquo;\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://p4.org\"\u003ehttp://p4.org\u003c/a\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eBarefoot network - Tofino - PISA(Protocol Independent Switch Architecture) switch\u003c/li\u003e\n\u003cli\u003eNetronome - smart NIC\u003c/li\u003e\n\u003c/ul\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.ericsson.com/research-blog/5g/5g-flexibility-or-high-performance-both/\"\u003e5G: flexibility or high performance? Both - Ericsson Research Blog\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003ePOF/PIF and P4 initiatives all point in a direction where programmable packet processing will not depend on standardized OpenFlow action sets anymore\u003c/p\u003e\n\u003cp\u003ePOF : Protocol Oblivious Forwarding\nPIF : Protocol Independent Forwarding\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.opennetworking.org/protocol-independent-forwarding/174-certification\"\u003eOF-PI\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://en.wikipedia.org/wiki/P4_(programming_language)\"\u003eP4 in wikipedia\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://onrc.stanford.edu/p4.html\"\u003ep4 in ONRC\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.newelectronics.co.uk/electronics-technology/revolutionising-networking-technology/152737/\"\u003eRevolutionising networking technology from newelectronics\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.datacenterdynamics.com/content-tracks/core-edge/p4-driving-innovation-in-server-based-networking/97544.fullarticle\"\u003eP4: driving innovation in server-based networking (Jan 4 2017)\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.researchgate.net/publication/310595166_Extern_Objects_in_P4_an_ROHC_Compression_Case_Study\"\u003eExtern objects in P4:an ROHC Compression Case study\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"P4"},{"content":" They are going to have to make a choice here - do you want to be at the table or on the plate?\n먹을래 먹힐래?\n","date":"2017-04-06T00:40:05+09:00","permalink":"https://cychong47.github.io/post/2017/table-or-dish/","summary":"\u003cblockquote\u003e\n\u003cp\u003eThey are going to have to make a choice here - do you want to be at the table or on the plate?\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e먹을래 먹힐래?\u003c/p\u003e","title":"Table or dish"},{"content":"지금 집에 있는 두 대의 mac mini를 이용해서 각각 wordpress와 ghost를 돌리고 있다.\nwordpress의 경우 2013년부터 시작한 블로그를 운영하는데 사용하고 있는데, 웹호스팅 회사 몇 군데를 전전하다 몇 년 전부터 집에 있는 mac mini 2009에 MAMP를 이용해서 자체 서버를 이용하고 있었다.\nGhost는 내가 좋아하는 markdown을 기본으로 사용하는 블로그 툴을 찾다 만났는데 지금은 사라졌지만 초기 홈페이지에 있던 멋진 dashboard에 낚여 설치했다. Open source 답지 않고 느린 개발 속도가 이해되지는 않지만, 여전히 markdwon을 제대로 지원하는 흔치 않은 설치형 블로그 툴이라 아직 희망을 버리지 않고 사용하고 있다. 현재는 0.11.2 버전이 공식 stable 버전이고 올해 나올 걸로 예상되는 1.0의 alpha 버전이 개발중이다.\nGhost역시 mac mini 2009에 node.js를 설치해서 그냥(?) 사용하다, docker for mac이 나온 걸 보고 mac mini 2011로 옮겼다. Docker for mac이 mac mini 2009를 지원하지 않는 바람에 -_-;;;\n초반에는 official docker image가 없어 다른 사람이 패키징해 놓은 걸 사용하고, 블로그 글 역시 docker container 안에 저장하다 이번에 정비를 하면서 official ghost image를 사용하고, 블로그 글도 container 밖에 저장하는 방식으로 변경하기로 했다.\nghost $ docker run -d -p 2368:2368 -v ~/Dropbox/Apps/ghost:/var/lib/ghost ghost ghost의 데이터 파일이 저장되는 기본 위치인 /var/lib/ghost를 실제로는 ~/Dropbox/Apps/ghost위치로 지정하여 사용. 즉 docker를 실행할 때 ~/Dropbox/Apps/ghost 를 container에게 /var/lib/ghost로 인지하도록 하여 하여 container 내부에 ghost 블로그의 정보가 저장되지 않고 host 쪽에 저장되도록 했다. 이렇게 해야 행여 docker instance가 제대로 동작하지 않아도 데이터를 살릴 수 있다. 거기에 데이터 저장 위치를 아예 dropbox 위치로 지정해서 데이터가 자동으로 백업되도록 함.\n이제는 kitematic을 사용해서 동작 중. kitematic에서 제공하는 docker hub browsing 기능을 이용해서 ghost 최신 버전으로 업데이트해서 사용 중. Volume 외에 포트 값 등은 모두 기본값을 그대로 사용 중.\nwordpress wordpress는 좀 복잡하다. ghost도 실은 mysql을 사용하면 하나가 아닌 2개의 container를 연동해서 사용해야 하는데 실은 sqlite를 사용해서 간단한 것이라.\nwordpress는 ghost와 달리 다음과 같은 복잡성을 해결해야 한다.\nmysql과 wordpress의 2개 container를 연동해야 함 기존 MAMP(Mac/Apache/Mysql/PHP)를 통해 운영하던 기존 wordpress의 정보를 import해야 함 docker로 운영하는 mysql에 저장되는 블로그 정보를 mysql container내가 아닌 host 에 저장하도록 설정해야 함. wp-content에 저장하는 upload 파일 역시 wordpress container내가 아닌 외부에 저장하도록 해야 함 이 중 3번째는 mysql container의 volume 옵션을 사용하면 된다.\nwordpress의 파일들이 저장될 위치 /var/www/html위치도 host 머신의 `~/Documents/wordpress\u0026rsquo;를 사용하도록 지정했다.\n그리고 나서 RESTART를 선택하면 다음과 같이 wordpress가 실행된다. 왼쪽 console의 복잡한 내용은 모르겠지만, 오른쪽에 나오는 작은 화면을 보면 wordpress를 설치할 때 나오는 화면이 떴다는 것을 알 수 있다.\n그런데 이상하게 mysql에 연결이 안되어 결국 kitematic으로 wordpress를 실행하는 것은 포기하고 cli 명령을 이용해서 wordpress container를 새로 생성했다.\ncychong:~ cychong$ docker run --restart=always -e WORDPRESS_DB_PASSWORD=blog -d --name wordpress --link mysql:mysql -p 80:80 -v ~/Documents/wordpress:/var/www/html wordpress 3a0a8163171a54152a9281c2638b02046d0b99aaa018242d1b4c08a7511aa579 kitematic으로 설정한 경우 문제가 mysql에 연결이 안되는 것인데 서로 다른 container에서 동작하는 wordpress오 mysql을 연결시켜주는 것이 안되는 듯 한다. cli 명령에는 --link 옵션으로 mysql을 다른 container인 mysql에서 찾아오라고 명시적으로 지정하는 듯 한데 이와 관련된 설정을 kitematic에서 찾지 못했다. 일단 cli로 실행한 후에는 kitematic에서 실행한 것과 동일하게 container에 대한 정보를 볼 수 있는데 여기서도 특별히 mysql container와의 연결에 대한 내용을 찾지 못했다.\nwordpress 데이터 이전 이전 wordpress에서 tools / export 기능을 이용해서 post와 pages 등을 모두 export한 후 Wordpress docker에서 import를 하려는데 php에서 허용하는 upload file의 최대 크기가 2MB다. 이전 wordpress에서 export한 데이터 파일은 9.4MB인데\u0026hellip;\n이런 경우 이전에는 php.ini파일의 설정을 변경해서 파일 크기를 늘리는 방식으로 해결했는데 docker에서는 이 파일 정보가 없단다. 구글링을 해보니 docker 환경이라 해결방법이 다르다.\nhttps://github.com/docker-library/wordpress/issues/10\n위 글을 읽어보니 container image는 가능한 default와 동일하게 하고, 서로 다른 쓰임에 딸라 달라지는 부분은 가변부로 처리하게 한다는 것이 정책이라는 거다. base repository라면 당연하다는 생각이 들었다. 그래서 대부분의 사람들이 제안하는 방법 역시 dockerfile을 수정해서 docker를 생성할 때 아래 파일을 넣어주거나 하는 방법이거나 host에 필요한 파일을 만들어 놓고 그 파일을 container가 찾는 위치에 mount되도록 하는 방법이 주 였다.\n처음에는 이런 생각을 못하고 그냥 container 내 파일을 만들어 wordpress가 인식되기를 기대(?)했는데 일단 변경 사항이 반영되지도 않고(import 페이지를 화면에 보여줄 때 파일 크기 값을 읽어서 사용할 거라 기대했는데) 반영이 된다 하더라도 container를 종료했다 다시 실행하면 어차피 아래 파일이 사라지고 없을 거라는 생각이 들었다.\n# pwd /usr/local/etc/php/conf.d # cat \u0026gt; uploads.ini file_uploads = On memory_limit = 64M upload_max_filesize = 64M post_max_size = 64M max_execution_time = 600 문제는 이미 만들어진 docker container에 이런 파일 정보를 추가하는 것은 불가능하다는 점. 그러므로 다시 wordpress container를 새로 만들면서 위의 파일 정보도 함께 추가해야 한다.\n$ vi /Users/cychong/Documents/wordpress/php_uploads.ini file_uploads = On memory_limit = 64M upload_max_filesize = 64M post_max_size = 64M max_execution_time = 600 이제 추가한 파일을 포함해서 다시 docker instance를 생성(이전 wordpress instance를 제거하고)\ncychong:~ cychong$ docker run --restart=always -e WORDPRESS_DB_PASSWORD=blog -d --name wordpress --link mysql:mysql -p 80:80 -v ~/Documents/wordpress:/var/www/html -v ~/Documents/wordpress/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini wordpress container를 실행한 후 mount된 volume을 보면 다음과 같다.\n이제 다시 wordpress의 import 기능을 선택하면 파일 최대 크기가 2MB가 아니라 64MB로 변경되었음을 확인할 수 있다.\n이렇게 해서 기존 wordpress에서 export한 파일들을 무사히 import해 왔는데\u0026hellip;\n남은 문제 일단 지금까지 확인된 건\n기존 wordpress에서 wordpress의 첨부 파일 위치 정보가 모두 http://sosa0sa.com/wp/wp-content 이런 형식이었는데 이번에는 http://sosa0sa.com/wp-content로 되어 버렸네. 아마도 volume mapping하는 부분을 조정(?)하면 될지도 모르겠는데 아예 이번에 모두 정리하는 걸 고민해 봐야겠다. 어차피. URL이 저장된 정보가 xml파일이나 sql 파일 등에 있는 text라. 아니면 wordpress/settings에 있는 wordpress base url(?) 정보를 변경하면 될 지도 모르겠다.\n!!! 망했다. 혹시나 하고 위 마지막에 적은 내용을 적용했더니 wordpress자체가 접속이 안된다. wp-config.php파일 등에도 이 정보가 없던데. 그냥 아래 내용까지 고려해서 다시 해결할까? 아님 이참에 ghost로 확 이전?. 이건 ghost 1.0이 나오고 나서 생각해 보고 !!!\n이건 늘 wordpress를 설치할 때마다 겪는 문제인데\u0026hellip; markdown으로 작성한 글들을 보기 위해 jetpack을 설치하는데 jetpack을 설치하더라도 제대로 markdown 파일 형식이 렌더링 되지 않는다. 덕분에 문단 편집도 이상하게 보이고, 그림은 보이지도 않고. 일일이 글 하나 하나 마다 dashboard를 통해 한번 update를 해줘야 제대로 보이는데 이게 유일한 방법인지. 도저히 불가능한 방법이라\u0026hellip;. 해결책을 찾아봐야겠다. 벌써 새벽 1:40분이다. 이제 그만하고 자야겠다.\n2017/04/07 00:33 update). 간단(?)하게 wordpress container를 삭제하고 새로 설치했다. mysql은 그냥 mysql 정보가 저장되는 디렉토리의 파일을 삭제했다. (mysql container에게 /var/lib/mysql로 매핑한 디렉토리) DB내 저장된 블로그 글들에 지금과 다른 link를 가진 부분이 많이 있고, 위 1번 문제에서 언급한 망한 문제 관련된 내용이 mysql DB내 저장되어 있을 듯 해서 깔끔하게 초기화를 하려고 기존 파일들을 삭제했다.\nWordpress container를 만든 후 한 첫번째 작업은 Jetpack에서 markdown관련 내용을 켠 것이다. 이 작업은 Jetpack을 설치하면 생기는 admin의 Jetpack 메뉴가 아니라 plugins에 있는 Jetpack 의 setting 항목에서 지정했다. 그 다음 activate를 선택했다. 이 순서가 중요한 건지 모르겠다.\n그 다음 이전 wordpress에서 export한 xml 파일을 vi를 이용해서 http://sosa0sa.com/wp/를 http://sosa0sa.com/으로 일괄 변경한 후 다시 import했다. 일부 항목은 http://sosa0sa.com/wp/이 아니라 그냥 http://sosa0sa.com/wp로 되어 있는 경우도 있어 이 부분은 따로 찾아서 수정했다.\n그리고 나서 다시 웹페이지를 여니 짠. markdown으로 작성한 글도 제대로 보이고(그림도 제대로 보이고) 전반적으로 제대로 동작하는 듯 하다. 이제 이틀 밤에 걸쳐 진행한 wordpress 블로그의 docker로의 이전이 얼추 정리가 된 듯 하다.\n참고 mycontainer에 shell로 접속하려면\n$ docker exec -it \u0026lt;mycontainer\u0026gt; bash ","date":"2017-04-04T13:51:03+09:00","permalink":"https://cychong47.github.io/post/2017/move-to-docker/","summary":"\u003cp\u003e지금 집에 있는 두 대의 mac mini를 이용해서 각각 wordpress와 ghost를 돌리고 있다.\u003cbr\u003e\nwordpress의 경우 2013년부터 시작한 블로그를 운영하는데 사용하고 있는데, 웹호스팅 회사 몇 군데를 전전하다 몇 년 전부터 집에 있는 mac mini 2009에 \u003ca href=\"https://www.mamp.info/\"\u003eMAMP\u003c/a\u003e를 이용해서 자체 서버를 이용하고 있었다.\u003c/p\u003e\n\u003cp\u003eGhost는 내가 좋아하는 markdown을 기본으로 사용하는 블로그 툴을 찾다 만났는데 지금은 사라졌지만 초기 홈페이지에 있던 멋진 dashboard에 낚여 설치했다. Open source 답지 않고 느린 개발 속도가 이해되지는 않지만, 여전히 markdwon을 제대로 지원하는 흔치 않은 설치형 블로그 툴이라 아직 희망을 버리지 않고 사용하고 있다. 현재는 0.11.2 버전이 공식 stable 버전이고 올해 나올 걸로 예상되는  1.0의 alpha 버전이 개발중이다.\u003c/p\u003e","title":"Move to docker"},{"content":"만독 책을 느리게(집중해서) 읽기 아이에게 책 읽어주기 부모가 읽어야 아이도 읽는다 1단계. 책 선정 초등학생이면 어휘가 풍부한 국내 소설 오래 살아남은 책. 고전 문학 2단계. 반복해서 읽기 3단계. 파생독서 하기 저자의 다른 책 저자가 참고한 책 비슷한 주제의 책 4단계. 챕터별 요약하기 5단계. 챕터별로 생각 적어보기 책을 읽으면 추가 자료와, 자신의 생각을 곁들여 정리 6단계. 장문 쓰기 다독 고정형/성장형 생각 특히 힘든 시기에 영향을 줌 갑자기 어려워지는 중학교 시절 두뇌도 근육과 같다. 능력을 키울 수 있다. 당신이 할 수 있다고 생각하든, 할 수 없다고 생각하든 생각하는 대로 될 것이다. 나도 책을 많이 읽을 수 있다! 남독 다양하게 읽기 수용적/비판적/창의적 사고 수렴적 vs. 발산성 지능 수렴적 - 성실 발산성 - 창의. 변칙 위기때는 발산성 지능이 필요 관독 ‘Seeing is believing”? 시각은 뇌를 속인다 ‘본 것’이 아니라 ‘봤다고 생각’한 것 저자의 관점을 이해하기 특정 관점을 가지고 책을 보기 재독 좋은 부모 안정적인 기지 마련 기지를 거점삼아 세상을 마음껏 탐구하도록 격려 필독 쓰면서 읽기 메모 남기기 다시 읽을 때 나의 관점을 기억 망각 10분 호 망각 시작, 한 시간 뒤 50%, 하루 뒤 70%, 한달 뒤 80% 망각 글은 제기하고자 하는 주제의 근거를 제시하고 타당성 입증 좋은 자료가 성패를 가른다 짧게 써야 읽힌다 ","date":"2016-06-10T14:43:55+09:00","permalink":"https://cychong47.github.io/post/2016/how-to-read-2/","summary":"\u003ch2 id=\"만독\"\u003e만독\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e책을 느리게(집중해서) 읽기\u003c/li\u003e\n\u003cli\u003e아이에게 책 읽어주기\n\u003cul\u003e\n\u003cli\u003e부모가 읽어야 아이도 읽는다\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e1단계. 책 선정\n\u003cul\u003e\n\u003cli\u003e초등학생이면 어휘가 풍부한 국내 소설\u003c/li\u003e\n\u003cli\u003e오래 살아남은 책. 고전 문학\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e2단계. 반복해서 읽기\u003c/li\u003e\n\u003cli\u003e3단계. 파생독서 하기\n\u003cul\u003e\n\u003cli\u003e저자의 다른 책\u003c/li\u003e\n\u003cli\u003e저자가 참고한 책\u003c/li\u003e\n\u003cli\u003e비슷한 주제의 책\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e4단계. 챕터별 요약하기\u003c/li\u003e\n\u003cli\u003e5단계. 챕터별로 생각 적어보기\n\u003cul\u003e\n\u003cli\u003e책을 읽으면 추가 자료와, 자신의 생각을 곁들여 정리\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e6단계. 장문 쓰기\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"다독\"\u003e다독\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e고정형/성장형 생각\n\u003cul\u003e\n\u003cli\u003e특히 힘든 시기에 영향을 줌\u003c/li\u003e\n\u003cli\u003e갑자기 어려워지는 중학교 시절\u003c/li\u003e\n\u003cli\u003e두뇌도 근육과 같다. 능력을 키울 수 있다.\u003c/li\u003e\n\u003cli\u003e당신이 할 수 있다고 생각하든, 할 수 없다고 생각하든 생각하는 대로 될 것이다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e나도 책을 많이 읽을 수 있다!\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"남독\"\u003e남독\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e다양하게 읽기\u003c/li\u003e\n\u003cli\u003e수용적/비판적/창의적 사고\n\u003cul\u003e\n\u003cli\u003e수렴적 vs. 발산성 지능\u003c/li\u003e\n\u003cli\u003e수렴적 - 성실\u003c/li\u003e\n\u003cli\u003e발산성 - 창의. 변칙\u003c/li\u003e\n\u003cli\u003e위기때는 발산성 지능이 필요\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"관독\"\u003e관독\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e‘Seeing is believing”?\n\u003cul\u003e\n\u003cli\u003e시각은 뇌를 속인다\u003c/li\u003e\n\u003cli\u003e‘본 것’이 아니라 ‘봤다고 생각’한 것\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e저자의 관점을 이해하기\u003c/li\u003e\n\u003cli\u003e특정 관점을 가지고 책을 보기\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"재독\"\u003e재독\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e좋은 부모\n\u003cul\u003e\n\u003cli\u003e안정적인 기지 마련\u003c/li\u003e\n\u003cli\u003e기지를 거점삼아 세상을 마음껏 탐구하도록 격려\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"필독\"\u003e필독\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e쓰면서 읽기\n\u003cul\u003e\n\u003cli\u003e메모 남기기\u003c/li\u003e\n\u003cli\u003e다시 읽을 때 나의 관점을 기억\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e망각\n\u003cul\u003e\n\u003cli\u003e10분 호 망각 시작, 한 시간 뒤 50%, 하루 뒤 70%, 한달 뒤 80% 망각\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e글은 제기하고자 하는 주제의 근거를 제시하고 타당성 입증\n\u003cul\u003e\n\u003cli\u003e좋은 자료가 성패를 가른다\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e짧게 써야 읽힌다\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg src=\"/images/2016/06/how-to-read.png\" alt=\"\"\u003e\u003c/p\u003e","title":"(책) 어떻게 읽을 것인가 - 2"},{"content":" 고정형 - 지능은 변하지 않는다\n성장형 - 지능은 좋아질 수 있다\n생각을 바꾼다는 것이 쉬운 일은 아니지만 인식의 변화가 주는 효과는 크다\n중학교에서는 고정형 아이들의 성적이 급속히 떨어지고 지속적으로 하양곡선을 그림. 중학생이 되면 초등학교 과정과 질적으로 더 어려운 학과 공부에 직면하므로 실패와 좌절을 할 가능성이 더 많은데 고정형 학생들은 실패와 좌절에 더 큰 영향을 받기 때문\n힘든 상황에서 더 큰 영향을 준다.\n두뇌는 근육과 같이 운동을 통해 근육을 키우듯 두뇌 능력을 키울 수 있다. 필요한 건 시간과 노력이다.\n일단 믿어 보자.\n당신이 할 수 있다고 생각하든, 할 수 없다고 생각하든 생각하는 대로 될 것이다.\n명언\n다독을 하려면 성장형 사고방식을 갖다. 처음에는 힘들지만 뇌는 책 읽는 뇌로 변할 수 있다.\n\u0026ldquo;난 책하고 안 맞아\u0026quot;라는 생각이 들때 성장형 사고방식으로 한번 시도해 보자.\n내 편견을 자극하고 그럴듯 해 보이면 명저로 생각하기 쉽다.\n내가 미처 생각하지 못했던 걸 알려준다고 다 명저는 아니다.\n수용적 사고, 비판적 사고, 창의적 사고\n수렴성 지능과 발산성 지능.\n수렴적 사고는 위기가 없으며 일상적이고 반복적인 세계에서는 유용할지 모르지만, 예기치 못한 위기가 닥쳐오고 변칙적인 상황이 되면 오히려 역효과를 낼 수 있다. 새로운 상황에서는 새로운 생각, 곧 창의적인 생각이 필요하며, 실제로 급변하는 세상에서 최고의 부가가치를 내고 있는 것들은 모두 창의적 사고의 부산물을 통해서다.\n위기의 시절에는 좀 나내는 사람이 필요하다.\n책을 선정했으면 챕터별로 정리를 하되, 그냥 요약하지 말고 관련 주제를 담은 책이나 인터넷에서 자료를 토대로 자신의 견해를 덧붙여 완성된 글로 만들어라.\n내 생각을 곁들이고, 책에 없는 내용을 \u0026ldquo;찾아서\u0026rdquo; 함께 정리하면 더 오래 기억에 남는다.\nSeeing is believing. But sometimes not\n‘본다’는 것은 철저히 주관적 행위이다. 객관적 시선이란 허상이며, 우리에게는 오직 주관적 관점만이 있을 뿐이다.\n분명히 \u0026lsquo;본 것\u0026rsquo;이라고 다 사실은 아니다. \u0026lsquo;본 것\u0026rsquo;이라고 착각할 수도 있고, 맥락을 모른 체 본 것은 \u0026lsquo;주관적 판단\u0026rsquo;에 의해 \u0026lsquo;사실\u0026rsquo;과 다른 기억을 갖게 할 수 있다.\n‘생각의 탄생’에서는 ‘명백히 달라 보이는 두 개의 사물이 중요한 특질과 기능을 공유하고 있음을 깨닫는 일이야말로, 세계에서 가장 위대한 학문과 예술작품, 불후의 과학이론, 공학적 발명을 이루어내는 일의 중심에 놓여 있는 것이다’\n‘좋은 부모는 아이에게 안정적인 기지를 마련해 주고, 아이가 그 기지를 거점 삼아 마음껏 세상을 탐구할 수 있도록 격려한다\u0026rsquo;라고 말했다.\n부모의 의무\n고통의 경중보다 고통에 대한 대응이 행복과 불행을 갈라 놓는 가장 중요한 키워드임을 밝혀냈다. ‘성숙한 방어기제’를 갖고 있는 사람일수록 행복을 빼앗기지 않는다.\n상황보다 상황에 대한 대응이 그 \u0026lsquo;상황\u0026rsquo;으로 인한 결과를 만들어낸다.\n헤르만 에빙하우스.\n학습 후 10분 후부터 망각 시작 한 시간 뒤에는 50% 하루 뒤에는 70% 한달 뒤에는 80%를 망각 단순히 읽는 것이 아니라 열심히 학습을 하더라도 하루가 지나면 열에 일곱은 사라진다.\n잊는 게 자연스러운 거다. 자신의 기억력을 탓하지 말고 반복해서 읽거나 적어서 보완하자\n글은 자신이 제기하고자 하는 주제의 근거를 제시하고 그 타당성을 입증해 보이는 싸움이다. 이 싸움은 좋은 자료를 얼마나 많이 모으느냐에 성패가 좌우된다. 자료가 충분하면 그 안에 반드시 길이 있다. 자료를 찾다보면 새로운 생각이 떠오른다.\n논리 싸움. 근거는 곧 총알\n퓰리처. “무엇이든 짧게 써라. 그러면 읽힐 것이다”\n일단 짧아야 눈이 간다\n","date":"2016-06-10T14:00:20+09:00","permalink":"https://cychong47.github.io/post/2016/how-to-read/","summary":"\u003cblockquote\u003e\n\u003cp\u003e고정형 - 지능은 변하지 않는다\u003cbr\u003e\n성장형 - 지능은 좋아질 수 있다\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e생각을 바꾼다는 것이 쉬운 일은 아니지만 인식의 변화가 주는 효과는 크다\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e중학교에서는 고정형 아이들의 성적이 급속히 떨어지고 지속적으로 하양곡선을 그림. 중학생이 되면 초등학교 과정과 질적으로 더 어려운 학과 공부에 직면하므로 실패와 좌절을 할 가능성이 더 많은데 고정형 학생들은 실패와 좌절에 더 큰 영향을 받기 때문\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e힘든 상황에서 더 큰 영향을 준다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e두뇌는 근육과 같이 운동을 통해 근육을 키우듯 두뇌 능력을 키울 수 있다. 필요한 건 시간과 노력이다.\u003c/p\u003e","title":"(책) 어떻게 읽을 것인가"},{"content":" fossilize also -lise\n(usually passive) if people, ideas, systems etc fossilize or are fossilized, they never change or develop, even when there are good reasons why they should change\nMost couples, however fossilized their relationship, have some interests in common.\n간혹 팟캐스트에 공룡에 대한 이야기가 나온다. 공룡에 대한 연구가 상대적으로 오래되지 않고, 현존하지 않은 생명체에 대한 거라 발굴된 화석에 의존해서 복원해야 해서 그 복원 결과가 시간에 따라 달라진다고 한다. 새로운 증거나 보다 논리적인 설명이 나오면 그걸로 기존의 가설의 결과가 달라진다고. 예를 들면 티라노사우르스가 빠르게 달리는 것처럼 알려졌지만, 요즈음은 티라노사우르스는 뛰지 못했다는 게 정설이다. 몸무게 덕에 뛰었다간 무릎이 다 망가진다고.\n아무튼 오늘 들은 재밌는(실은 황당하고 어이없는) 이야기는 코드에 주석이 적다고 구박하고, 코드 제일 위에 있는 file comment에 수정 이력을 안 적었다고 구박한단다. 이미 화석화된 지식이다. 주석이 필요없게 코드를 작성하는게 가장 좋은 거고, 주석은 정말 필요한 부분에만 \u0026lsquo;왜\u0026rsquo;에 대해서 적으라는 것이 요즘 트렌드다(적어도 내가 이해하기엔. 내가 그렇게 못하더라도) 그리고 파일 수정 이력은 예전부터 쓰고 있는 소스 관리 시스템에 다 있는 정보라 쓸데없이 파일에 쓰는 건 권장하지 않는다. 코드 열었을 때 몇 장에 걸쳐서 구구절절 이력이 있다면.\n혹여 소스 관리 시스템에서 변경 이력을 찾기 어려워서 저런 말을 했을 거라고는 생각하지 않는다.\n개발자 뿐만 아니라 개발자랑 같이 일하는 관리자도 계속해서 공부해야 한다. 저런 엉뚱한 이야기를 안하려면\n","date":"2016-05-12T03:41:20+09:00","permalink":"https://cychong47.github.io/post/2016/fossilization/","summary":"\u003cblockquote\u003e\n\u003cp\u003efossilize also -lise\u003c/p\u003e\n\u003cp\u003e(usually passive) if people, ideas, systems etc fossilize or are fossilized, they never change or develop, even when there are good reasons why they should change\u003c/p\u003e\n\u003cp\u003e Most couples, however fossilized their relationship, have some interests in common.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e간혹 팟캐스트에 공룡에 대한 이야기가 나온다. 공룡에 대한 연구가 상대적으로 오래되지 않고, 현존하지 않은 생명체에 대한 거라 발굴된 화석에 의존해서 복원해야 해서 그 복원 결과가 시간에 따라 달라진다고 한다. 새로운 증거나 보다 논리적인 설명이 나오면 그걸로 기존의 가설의 결과가 달라진다고. 예를 들면 티라노사우르스가 빠르게 달리는 것처럼 알려졌지만, 요즈음은 티라노사우르스는 뛰지 못했다는 게 정설이다. 몸무게 덕에 뛰었다간 무릎이 다 망가진다고.\u003c/p\u003e","title":"fossilization"},{"content":"먼저 주변을 의심해 보자.\n상식적인 혹은 알려진 것과 다른 결과가 나왔다면 내가 한 시험 방법을 다시 한번 의심해 보자. 제발\n","date":"2016-05-11T10:01:53+09:00","permalink":"https://cychong47.github.io/post/2016/too-early-confident/","summary":"\u003cp\u003e먼저 주변을 의심해 보자.\u003c/p\u003e\n\u003cp\u003e상식적인 혹은 알려진 것과 다른 결과가 나왔다면 내가 한 시험 방법을 다시 한번 의심해 보자. 제발\u003c/p\u003e","title":"상식과 다른 결과를 보면"},{"content":"개발자의 품을 가벼이 여기는 조직에서 일 할때는 일정보다 일을 빨리하면 안된다. 기껏 한 일이 아무 소용없을 때가 많다.\n","date":"2016-05-11T09:59:23+09:00","permalink":"https://cychong47.github.io/post/2016/no-need-to-rush/","summary":"\u003cp\u003e개발자의 품을 가벼이 여기는 조직에서 일 할때는 일정보다 일을 빨리하면 안된다. 기껏 한 일이 아무 소용없을 때가 많다.\u003c/p\u003e","title":"빨리 해봐야 소용없다"},{"content":"theme을 수정해서 ghost blog 화면에서 글 본문이 다 나오도록 할 수 있다.\n대신 theme마다 조금씩 적용 방법이 다른데 기본적으로 변경해야 할 내용은 동일\ncasper theme casper는 index.hbs 파일에서 loop.hbs라는 별도 파일을 통해 본문을 보이게 하고 있다.\nindex.hbs\n21 {{! The main content area on the homepage }} 22 \u0026lt;main id=\u0026#34;content\u0026#34; class=\u0026#34;content\u0026#34; role=\u0026#34;main\u0026#34;\u0026gt; 23 24 {{! The tag below includes the post loop - partials/loop.hbs }} 25 {{\u0026gt; \u0026#34;loop\u0026#34;}} 26 27 \u0026lt;/main\u0026gt; 위 코드에서 가리키는 partials/loop.hbs 코드에서 exceprt인 부분을 찾아서 다음과 같이 변경한다. 아래에서 13라인부터 15라인이 원본으로 각 post의 일부만 보이게 하고, 더 읽으려면 \u0026gt;\u0026gt;등을 클릭하게 한다. 이 부분을 막고 post 전체를 표시하는 17라인에서 19라인까지의 내용을 추가한다.\npartials/loop.hbs\n12 \u0026lt;!-- 13 \u0026lt;section class=\u0026#34;post-excerpt\u0026#34;\u0026gt; 14 \u0026lt;p\u0026gt;{{excerpt words=\u0026#34;26\u0026#34;}} \u0026lt;a class=\u0026#34;read-more\u0026#34; href=\u0026#34;{{url}}\u0026#34;\u0026gt;\u0026amp;raquo;\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt; 15 \u0026lt;/section\u0026gt; 16 --\u0026gt; 17 \u0026lt;section class=\u0026#34;post-content\u0026#34;\u0026gt; 18 {{content}} 19 \u0026lt;/section\u0026gt; landyon theme 이건 별도의 loop.hbs없이 직접 index.hbs에서 처리하고 있어 보다 구조가 간단하다. 위 방법 역시 이 theme 파일을 분석(?)해서 알아냈다. Caspser theme에서와 동일하게 post-exceprt인 부분을 post-content class로 변경하면 동일하게 기본 화면에서 post 내용을 모두 볼 수 있다.\n참고로 post를 모두 보는 방법은 특정 post를 화면에 출력할 때 사용하는(것으로 추정되는) page.hbs파일의 내용을 통해 알아냈다.\n깔끔한 page.hbs\n{{!\u0026lt; default}} \u0026lt;article class=\u0026#34;{{post_class}}\u0026#34;\u0026gt; {{#post}} \u0026lt;h1 class=\u0026#34;post-title\u0026#34;\u0026gt;{{title}}\u0026lt;/h1\u0026gt; \u0026lt;section class=\u0026#34;post-content\u0026#34;\u0026gt; {{content}} \u0026lt;/section\u0026gt; {{/post}} \u0026lt;/article\u0026gt; ","date":"2016-05-09T15:23:57+09:00","permalink":"https://cychong47.github.io/post/2016/display-post-by-default-ghost/","summary":"\u003cp\u003etheme을 수정해서 ghost blog 화면에서 글 본문이 다 나오도록 할 수 있다.\u003c/p\u003e\n\u003cp\u003e대신 theme마다 조금씩 적용 방법이 다른데 기본적으로 변경해야 할 내용은 동일\u003c/p\u003e\n\u003ch1 id=\"casper-theme\"\u003ecasper theme\u003c/h1\u003e\n\u003cp\u003ecasper는 \u003ccode\u003eindex.hbs\u003c/code\u003e 파일에서 \u003ccode\u003eloop.hbs\u003c/code\u003e라는 별도 파일을 통해 본문을 보이게 하고 있다.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eindex.hbs\u003c/code\u003e\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e 21 {{! The main content area on the homepage }}\n 22 \u0026lt;main id=\u0026#34;content\u0026#34; class=\u0026#34;content\u0026#34; role=\u0026#34;main\u0026#34;\u0026gt;\n 23\n 24     {{! The tag below includes the post loop - partials/loop.hbs }}\n 25     {{\u0026gt; \u0026#34;loop\u0026#34;}}\n 26\n 27 \u0026lt;/main\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e위 코드에서 가리키는 partials/loop.hbs 코드에서 exceprt인 부분을 찾아서 다음과 같이 변경한다. 아래에서 13라인부터 15라인이 원본으로 각 post의 일부만 보이게 하고, 더 읽으려면 \u003ccode\u003e\u0026gt;\u0026gt;\u003c/code\u003e등을 클릭하게 한다. 이 부분을 막고 post 전체를 표시하는 17라인에서 19라인까지의 내용을 추가한다.\u003c/p\u003e","title":"Ghost 본문 다 보이기"},{"content":"set environment export RTE_ARCH=x86_64 export RTE_SDK=/home/cychong/Work/dpdk-2.1.0 export RTE_TARGET=x86_64-native-linuxapp-gcc export RTE_OUTPUT=$RTE_SDK/$RTE_TARGET run sudo ./build/ip_reassembly -c 0x1 -n 4 -m 1000M --no-huge --no-pci --no-hpet -- --display_pps 1 --tx_pps 10 ","date":"2016-05-01T15:35:28+09:00","permalink":"https://cychong47.github.io/post/2016/frag-reassembly-test/","summary":"\u003ch2 id=\"set-environment\"\u003eset environment\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eexport RTE_ARCH=x86_64\nexport RTE_SDK=/home/cychong/Work/dpdk-2.1.0\nexport RTE_TARGET=x86_64-native-linuxapp-gcc\nexport RTE_OUTPUT=$RTE_SDK/$RTE_TARGET\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"run\"\u003erun\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003esudo ./build/ip_reassembly -c 0x1 -n 4 -m 1000M  --no-huge --no-pci --no-hpet --  --display_pps 1 --tx_pps 10\n\u003c/code\u003e\u003c/pre\u003e","title":"Frag \u0026 Reassembly Test"},{"content":"2 다른 이들과 달리 멋지게 시작하라\n자신의 경력을 사업으로 봐야 한다. 자신의 정체성이나 경력은 조직에서 주어진 역할과 별개로 존재한다고 생각 팔수 있는 제품이나 서비스가 필요 그 가치가 정확히 뭔지, 그 가치가 다른 개발자가 제공하는 가치와 어떻게 다른지 설명할 수 있어야 한다 3 목표를 설정하고 미래에 대비하라\n목표를 설정. 목표를 정확히 이해 명확한 목표가 없으면 아무리 열심히 살아도 의미가 없다. 목표 없이 인생을 낭비하지 말라 큰 목표를 정하고 밟아갈 작은 목표를 설정 큰 목표는 방향을 제시할 정도만 되도 된다. 최종적으로이루고 싶은 꿈은? 큰 목표에 이르는 길목에 작은 목표들. 큰 목표에서 현재 상태까지 거꾸로 생각 매월, 혹은 매일 일정 분량을 읽고 학습하겠다는 더 작은 목표를 세운다 자신이 세운 목표를 주기적으로 살펴보고 필요할 때마다 조금씩 업데이트 4 소프트 스킬은 생각보다 중요하다\n하고 싶은 말을 전부 내뱉지 말고 응원의 말만 하는 법을 배워야 당신이 원하는 바를 상대에게 와 닿는 방식으로 표현 어떤 기능을 왜 특정 방식으로 구현했는지 설명하기 보다 어떤 이득이 있는 지 알려주라 다른 이들도 논리적으로 사고할 거라는 착각. 확고한 논리를 제시하면 상대방도 자신의 사고방식을 받아들일 거라는 착각 어떤 수를 쓰든 논쟁을 피하라. 논쟁에서 이기는 유일한 방법은 논쟁을 피하는 것 7 전문성을 갖춰라\n전문성이 높아질수록 잠재적 기회가 줄어드는 반면 기회를 잡을 확률은 올라간다 전문 분야 - 웹 개발 기술, 임베디드 시스템, 특정 OS, 모바일 개발, framework, SW system 9 승진하기\n기회 만들기. 아무도 원하지 않는 legacy application이나 코드 중 문제가 많은 모듈 자신의 문제 외에 다른 이들의 문제까지 함께 부딪쳐 해결하다보면 많은 것을 배우고, 팀의 해결사라는 평판을 얻을 수 있다. 업무 절차를 기록하고, 이러한 문서를 항상 최신 정보로 채워두는 역할 누구나 피하려 하지만 당신이 맡아서 더 수월하게 하거나 자동화할 수 있는 일 존재감 있게 일하기 주간 보고서로 자신의 업무를 홍보 팀이 다뤄야 하는 주제나 문제에 대해 발표 의견을 분명히 밝힐 것. 언제 어디서든 기회가 있을 때마다 눈에 띄도록 노력. 정기적으로 상사와 만날 것. 꼭 자주 만날 것 학습하기 - 리더십, 관리, 비즈니스 등의 분야도 공부. 배운 내용을 다른 이들과 공유 해결사 되기 어떤 문제든 해결책을 제시하는 사람, 또 해결책을 실행할 수 있는 사람이 돼라 10 전문가 되기\n전문가는 맡은 일과 경력을 진지하게 생각하는 사람 옳다고 생각하는 바를 실천하기 위해 손해를 감수하고 어려운 결정을 내릴 용기가 있는 사람 일을 맡겼을 때 제대로 완수할 것이라고 믿을 수 있는 사람 자신의 기술수준을 철저히 파악해두고 발전하고자 꾸준히 노력 답을 모를 때 스스럼없이 인정. 결국 해결책을 찾아내리라 믿을 수 있다 스스로 설정한 높은 작업 품질 수준을 한결같이 지킨다 약속을 어기지 않는다. 전문가가 되려면 좋은 습관부터 전문가다운 습관 사전 준비(회의 등) 매일 계획을 세워 시간을 효과적으로 관리하는 습관 그날 꼭 마쳐야 하는 일이 뭔지, 마칠 때까지 시간이 얼마나 될지 대략 예상 일관성이 있어야 다른 이들이 당신을 신뢰할 수 있다. 해야할 일을 가늠하고 우선 순위를 정한 뒤 업무에 착수 디테일까지 정해둔 품질 기준에 미치도록 노력. 적당히 만족하는 나쁜 습관은 버리도록 11 이렇게 독립하라\nSo Good they Can\u0026rsquo;t ignore you. Cal Newport. Act Big, Think Small. 실력이 열정을 이긴다. 24 강연, 강의 그리고 발표\n전문가인 척할 필요는 없다. 배운 내용을 공유한다는 마음으로 성의껏 임하라 27 학습 방법 익히기\n배우려면 바로 실행에 올기자.(뒤에 나오는 10단계 참고) 28 10단계 학습법\nhttp://simpleprogrammer.com/ss-10steps 1단계. 큰 그림을 보라 학습이 아니라, 배울 주제에 어떤 내용이 있는 지, 범위가 어느정도 인지 등 큰 그림을 보는 일에 주력 2단계. 범위를 정하라 1단계에서 모은 정보를 활용하여 배우고자 하는 영역을 적절한 크기로 선택 학습 목적을 생각하여 적정 학습 범위 설정 범위 설정이 어려우면 시간부터 제한. 시간내 할 수 있는 범위를 대상으로 설정 예) 사진 배우기 -\u0026gt; 인물 사진 촬영용 디지털 사진 기술 배우기 3단계. 성공을 정의하라 성공 기준을 명확히 정의 성공 기준은 달성할 목표에 따라 정해야 목표가 명확하면 목표에서 거슬러 오면서 목표에 이르는 길을 생각할 수 있다 간결하게 한 문장으로 정의 예) C# 기초를 배우겠다 -\u0026gt; C#의 주요 기능을 활용해서 간단한 응용 프로그램을 만들겠다 4단계. 자료를 찾아라 선택한 주제에 대해 최대한 다양한 자료를 찾는다 5단계. 학습 계획을 세워라 자료를 바탕으로 무엇을 어떤 순서로 배울 지 정리 책의 목차처럼 학습 순서를 정리 6단계. 자료를 선별하라 수집한 자료 중 목표 달성에 도움이 될 가치가 있는 자료만 선별 중복을 피해 목표 달성에 가장 도움이 되는 자료를 고른다. 자료의 품질도 검증 31 멘토 찾기\n누군가에게 도움을 구할 때는 자기가 아는 것이 정답이라는 생각을 버려야 32 멘토 되기\n해당 주제에 대한 자신의 생각을 정리하고 새로운 관점에서 바라볼 기회가 됨 멘토 역할을 하려면 \u0026lsquo;왜?\u0026lsquo;라는 질문과 씨름해야 한다. \u0026ldquo;왜?\u0026ldquo;라는 질문을 마주해야 지금까지 자신이 그 답ㅇ르 모르고 있었다는 사실을 깨닫는다. 다른 사람을 돕기 위해 답을 찾는 동안 해당 주제를 깊이 있게 이해할 수 있으며, 때로는 생각이 완전히 달라지기도 한다. 33 가르치기\n가르쳐본 경험이 있어야 전문가로 인정받음 다른 사람에게 무언가 가르치려면 해당 주제에 관한 어려운 문제를 정면으로 돌피해야 한다 단순히 아는 수준을 넘어 제대로 정확히 이해하는 수준까지 파헤쳐야 한다. 배운 내용은 금세 까먹어도 이해한 내용은 오래 간다. 가르칠 때는 겸손한 자세를 유지하되, 권위를 잃지 않고. 말에 확신과 자신감을 실어서 전달 당신이 즐겁게 배울 수 있게 도와준, 당신에게 가장 큰 영향을 끼친 선생님은 어떤 자질을 지니고 있었고, 어떤 방식으로 가르쳤는가? 35 지식의 빈틈 찾기\n평소 유난히 시간이 많이 드는 부분이나 반복적으로 자주 하는 작업을 살펴볼 것 더 찾아볼 필요가 있거나 명확히 이해가 되지 않는 사항을 한데 모아서 적어두고, 그 문제를 얼마나 자주 마주치는 지 기록 정확히 무엇을 배워야 할 지 알아내라. 집중할 영역을 최대한 구체적이고 명확하게 설정 36 집중이 중요하다\n생산적 != 효율적 생산적 : 많은 일을 하는 것 효율적 : 필요한 일을 하는 것 생산성에 가장 중요한 것은 집중 37 생산성 계획\nKanbanflow 38 Pomodoro\n뽀모도로/하루 목표 수립 및 수행 기록 대개 업무 예측에 대해 과장하는 착각 일을 더 해야 할 것 같은 죄책감. 하루에 해낼 수 있는 작업량을 모르고, 완료할 작업목표를 명확히 설정하지 않아서 39 할당 체계를 도입해 생산성을 높여라\n매주 일정한 수준만큼 꾸준히 진행 진행 정도도 명확하게 측정 비가 오나 눈이 오나 변함없이 할당량 완수 일관성이 있어 시간에 따른 진척도를 측정/기록할 수 있다. 실천이 가장 중요 달성 가능하고 유지 가능한 할당량 선택 할당량은 무조건 완료. 할당량을 실천하는 도중에는 결코 규칙을 중단하거나 바꾸지 않아야 함 느리지만 꾸준한 속도로 일하는 게 빠르지만 지속성이 없는 것보다 낫다 40 책임감을 가져라\n자기 자신에 대한 책임감 자제력은 스스로 동기를 부여할 수 있는 방법 자기 동기 부여의 핵심은 자기 책임감 41 멀티태스킹 규칙\n일괄 처리가 훨씬 더 생산적 생산성을 떨어뜨리지 않는 조합의 작업 선택 42 탈진 극복하기\n휴가에서 돌아와도 더 심한 탈진감. 내적 동기나 흥미에 대한 회복도 없고, 관성도 사라졌기 때문 시간이 지나면 처음 느꼈던 일에 대한 흥미는 떨어지는 것이 당연 해결책은 벽 너머의 일을 생각할 것 탈진이 오더라도 신경 쓰지 말고 고통을 견뎌야 한다. 벽을 넘어야 탈진을 \u0026lsquo;치유\u0026rsquo;할 수 있다. 고통을 견디는 것 이야말로 탈진을 극복하는 비결 벽을 넘기 위해서는 꾸준히 앞으로 나아가는 자신만의 규칙을 만들어야 함 43 낭비되는 시간 줄이기\n당장 TV를 꺼라 TV 프로그램은 뇌에서 문제 해결을 담당하는 부위를 축소하고 머릿 속에 온갖 것을 주입한다 TV를 많이 볼수록 자신의 생각과 행동에 대한 자기 지배력을 잃어가는 꼴 하루 중 SNS 활동에 사용할 시간을 정해두고 몰아서 할 것 회의로 시간을 낭비하지 않는 가장 좋은 방법은 회의에 참석하지 않는 것 회의는 시간을 덜 소비하는 메일이나 전화 같은 다른 수단으로는 도저히 다룰 수 없는 사안일 때만 사용 시간을 어디에 썼는지 정확하게 알 수 있다면 시간을 가장 많이 낭비하는 요인을 찾아서 없앨 수 있다. 44 반복 행위의 중요성\n자신의 삶과 목표 꿈을 위해 나아가기 위해 실제로 매일 노력하고 있는가? 매일 한 걸음씩 목표에 다가갈 반복 행위를 만든다면 결국 목표를 달성할 수 있지 않을까? 지금이 바로 행동에 옮길 때. 내일이나 다음 주는 없다. 지금이어야 한다. 좋은 반복 행위는 큰 목표를 정하는 것에서부터 시작 큰 목표를 정한 후 목표를 달성할 수 있는 단계를 생각 목표를 이룰 일정을 결정 반복 행위 일정. 예) TV보는 시간 30분 대신 글 읽기/쓰기 등 반복 행위가 내가 이룬 성공의 기반 매일 30분씩 규칙적으로 내 업무와 관련 있는 기술을 공부. \u0026lsquo;연구 시간\u0026rsquo; 45 코드 손질하듯 습관 개발하기\n\u0026lsquo;당신이 반복하는 일이 당신을 규정한다. 위대함은 하나의 행위가 아니라 습관에서 온다\u0026rsquo; 아리스토텔레스 습관 = (신호, 반복 행위 , 보상) 나쁜 습관을 인식하는 가장 좋은 방법은 늘 하는 일 중 죄책감이 느껴지는 것을 찾아보기. 그만두고 싶지만 지끔껏 미뤄왔던 습관 가장 어려운 것은 새 습관이 예전 습관을 밀어내고 자리잡을 때까지 충분히 오랜 기간 동안 노력 새로운 습관을 잘 만들려면 충분한 시간을 들여 반복 행위를 해야 함 Http://ejohn.org/blog/write-code-every-day 46 작업 분할하기\n일을 미루는 이유는 문제에 압도되기 때문 문제의 크기가 크다고 놀라느라 실제로 문제를 해결할 생각을 하지 못함 인간은 먼 미래를 보지 못하는 존재 -\u0026gt; 큰 작업을 받으면 심리적으로 압박을 받는 동시에 생산성도 떨어짐. 문제를 해결하려 하기보다 문제 자체를 생각하는데 시간을 더 많이 씀. 인간에게는 가장 편한 길을 택하려는 습성 큰 작업을 작은 작업으로 나눠야 하는 이유 작업은 클수록 정의하기 어려움 큰 작업은 측정하기도 어려움 작업이 작을 수록 쉬워짐 작업이 작을 수록 작업 완료 시간를 더 정확하게 예측할 수 있으며 작업을 정확하게 수행할 가능성도 큼. 작은 작업으로 나누다보면 자신이 해야 할 일에 대한 정보가 충분하지 않다는 사실을 깨닫게 됨. 큰 작업을 작게 나눌 때 중요한 과정 중 하나는 누락된 정보를 확인하는 것 작은 작업 하나하나에는 명확한 목표가 있어야 함 작게 나누면 고객이 원하는 것을 더 잘 설명할 수 있게 도와줄 수 있음 독립적으로 해결할 수 있는 작은 조각으로 나누어 작업 47 힘든 일을 피하지 마라\n가치 있는 것들은 모두 힘들게 일해서 얻은 결과물. 자신의 인생을 위해, 특히 소프트퉤어 개발자로서 경력을 다지기 위해 제대로 된 성과를 얻고 싶다면 자리를 지키고 앉아서 원하는 일이든 그렇지 않은 일이든 모두 해내는 법을 배워야 당신이 힘들다고 말하는 일은 거의 당신에게 득이 되는 일이며, 경력을 개척하거나 새로운 기회를 열 수 있는 일. 하지만 별 소득이 없는 일은 항상 굉장히 쉽게 느껴짐 정말 효율적으로 일하고 싶다면 똑똑하게 일하는 법과 열심히 일하는 법을 둘 다 배워라. 똑똑한 것만으로는 부족하다. 일정 수준의 영리함과 일정 수준의 끈기가 모두 필요 힘든 일을 피하는 이유는 지루하기 때문. 그러나 장기적으로 노력하고 인고의 시간을 보내며 꼭 필요한 지루한 일을 해낸 사람이 앞서간다. 큰 격차로 세상에 쉽게 얻을 수 있는 건 하나도 없다. 성공은 성공을 낳는다. 더 많이 성공할수록 다른 성공도 쉽게 얻을 수 있다. 올라야 하는 첫 번째 산이 길고 가파를 뿐이다 의지는 반드시 필요하다. 배운 것을 실천하여 효과를 보려면 기꺼이 힘든 일을 해낼 의지가 있어야 한다. 누구나 같은 문제로 싸우고 있다. 이제는 해야 할 일을 해야겠다고 결심하라. 목표를 이룰 방법은 하나밖에 없다고 깨달아야 한다. 자신의 모든 잠재력을 발휘할 수 있는 방법은 칼을 갈고, 이를 악물고, 일하러 가는 것이다. 48 뭐라도 하는 게 아무것도 하지 않는 것보다 낫다\n\u0026lsquo;배우는 게 있다면 실수는 더 이상 실수가 아니다. 아무것도 하지 않는다면 아무것도 배울 수 없다\u0026rsquo; 가장 악질적인 생산성 훼방꾼은 바로 아무런 행동도 하지 않는 것이다. 행동하지 않으면 엄청나게 많은 기회와 가능성을 놓친다. 내가 행동하지 않는 이유는 두렵기 때문이다. 가장 좋은 답을 찾지 못했거나 잘못된 선택을 할까 두려워서 아무것도 하지 않은 채 무조건 실패하는 선택을 한 적은 몇 번이나 되는가? 지금이야말로 행동에 옮길 때다 움직이는 차의 방향을 트는 것이 더 쉽다. 55 보너스. 나는 33세에 은퇴했다.\n투자할 줄 모른다면 은퇴라는 목표는 이룰 수 없다. 기회를 잡는 것만으로는 부족하다. 아무리 일생일대의 기회라 해도 자신이 잡은 기회에서 최선의 결과를 내지 못한다면 큰 의미가 없다. 69 추천 도서 목록\nHow to win friends and influence people 부정적인 지적은 전혀 도움이 되지 않으며 타인을 내가 원하는 대로 움직이려면 그들 스스로 원하게 해야 한다는 것을 깨달았다. 그외\n투자/금융 49 ~ 54 운동 56 ~ 64 영혼 ","date":"2016-04-19T10:25:08+09:00","permalink":"https://cychong47.github.io/post/2016/soft-skill/","summary":"\u003cp\u003e2 다른 이들과 달리 멋지게 시작하라\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e자신의 경력을 사업으로 봐야 한다.\u003c/li\u003e\n\u003cli\u003e자신의 정체성이나 경력은 조직에서 주어진 역할과 별개로 존재한다고 생각\u003c/li\u003e\n\u003cli\u003e팔수 있는 제품이나 서비스가 필요\u003c/li\u003e\n\u003cli\u003e그 가치가 정확히 뭔지, 그 가치가 다른 개발자가 제공하는 가치와 어떻게 다른지 설명할 수 있어야 한다\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e3 목표를 설정하고 미래에 대비하라\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e목표를 설정. 목표를 정확히 이해\n\u003cul\u003e\n\u003cli\u003e명확한 목표가 없으면 아무리 열심히 살아도 의미가 없다. 목표 없이 인생을 낭비하지 말라\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e큰 목표를 정하고 밟아갈 작은 목표를 설정\n\u003cul\u003e\n\u003cli\u003e큰 목표는 방향을 제시할 정도만 되도 된다.\u003c/li\u003e\n\u003cli\u003e최종적으로이루고 싶은 꿈은?\u003c/li\u003e\n\u003cli\u003e큰 목표에 이르는 길목에 작은 목표들. 큰 목표에서 현재 상태까지 거꾸로 생각\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e매월, 혹은 매일 일정 분량을 읽고 학습하겠다는 더 작은 목표를 세운다\u003c/li\u003e\n\u003cli\u003e자신이 세운 목표를 주기적으로 살펴보고 필요할 때마다 조금씩 업데이트\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e4 소프트 스킬은 생각보다 중요하다\u003c/p\u003e","title":"(책) 소프트 스킬"},{"content":"rte_ipv4_frag_reassemble_packet()\nip_frag_find() 기존에 존재하는 flow면 해당 flow를 저장한 entry 정보를(ip_frag_pkt *pkg) 신규 flow인 경우 해당 신규 flow를 저장할 신규 혹은 재사용된 entry를 return함 추가할 수 있는 통계 신규 flow? 기존 flow에 정상 추가 기존 flow에 비정상 추가(기존 flow가 timeouted) 이도 저도 아닌 상황(할당 실패) LRU entry free tbl-\u0026gt;max_entries tbl-\u0026gt;use_entries return 기존 존재하는 flow, 신규 할당한 flow entry 혹은 NULL 만일 NULL을 return하면 현재 수신한 mbuf를 death row에 추가한다. 불쌍한\u0026hellip; ip_frag_lookup() if matched entry is exist return flow entry return \u0026amp;stale if time-outed entry is exist if new entry return NULL return free for new empty entry return \u0026amp;stale if time-outed entry is exist ip_frag_key_cmp() return 0 if key matched if ip_frag_lookup() returns NULL if stale entry is not NULL, remove it with ip_frag_tbl_del() and save to free for reuse even if free is not NULL, check if tbl-\u0026gt;use_entries does not exceed tbl-\u0026gt;max_entries. If so, check if the LRU entry is timeouted, then free the LRU entry. Otherwise, fail to add new entry to the tbl tbl에서 할당하는 것고 max_entries, use_entries간의 차이점은?? If free is not NULL, add new flow to this free entry if ip_frag_lookup() returns non-NULL if timeouted, reuse it for the received flow tbl-\u0026gt;use_entries—; del_num++ ip_frag_process() rte_ip_frag_free_death_row() 주기적으로 호출해줘야 함 ","date":"2016-03-24T15:03:55+09:00","permalink":"https://cychong47.github.io/post/2016/dpdk-ipv4-reassembly/","summary":"\u003cp\u003e\u003ccode\u003erte_ipv4_frag_reassemble_packet()\u003c/code\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003eip_frag_find()\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003e기존에 존재하는 flow면 해당 flow를 저장한 entry 정보를(\u003ccode\u003eip_frag_pkt *pkg\u003c/code\u003e)\u003c/li\u003e\n\u003cli\u003e신규 flow인 경우 해당 신규 flow를 저장할 신규 혹은 재사용된 entry를 return함\u003c/li\u003e\n\u003cli\u003e추가할 수 있는 통계\n\u003cul\u003e\n\u003cli\u003e신규 flow?\u003c/li\u003e\n\u003cli\u003e기존 flow에 정상 추가\u003c/li\u003e\n\u003cli\u003e기존 flow에 비정상 추가(기존 flow가 timeouted)\u003c/li\u003e\n\u003cli\u003e이도 저도 아닌 상황(할당 실패)\u003c/li\u003e\n\u003cli\u003eLRU entry free\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etbl-\u0026gt;max_entries\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etbl-\u0026gt;use_entries\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ereturn\n\u003cul\u003e\n\u003cli\u003e기존 존재하는 flow, 신규 할당한 flow entry 혹은 NULL\u003c/li\u003e\n\u003cli\u003e만일 NULL을 return하면 현재 수신한 mbuf를 death row에 추가한다. 불쌍한\u0026hellip;\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eip_frag_lookup()\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003eif matched entry is exist\n\u003cul\u003e\n\u003cli\u003ereturn flow entry\u003c/li\u003e\n\u003cli\u003ereturn \u003ccode\u003e\u0026amp;stale\u003c/code\u003e if time-outed entry is exist\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eif new entry\n\u003cul\u003e\n\u003cli\u003ereturn NULL\u003c/li\u003e\n\u003cli\u003ereturn free for new empty entry\u003c/li\u003e\n\u003cli\u003ereturn \u003ccode\u003e\u0026amp;stale\u003c/code\u003e if time-outed entry is exist\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eip_frag_key_cmp()\u003c/code\u003e return 0 if key matched\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eif \u003ccode\u003eip_frag_lookup()\u003c/code\u003e returns NULL\n\u003cul\u003e\n\u003cli\u003eif stale entry is not NULL, remove it with \u003ccode\u003eip_frag_tbl_del()\u003c/code\u003e and save to free for reuse\u003c/li\u003e\n\u003cli\u003eeven if free is not NULL, check if \u003ccode\u003etbl-\u0026gt;use_entries\u003c/code\u003e does not exceed \u003ccode\u003etbl-\u0026gt;max_entries\u003c/code\u003e. If so, check if the LRU entry is timeouted, then free the LRU entry. Otherwise, fail to add new entry to the tbl\u003c/li\u003e\n\u003cli\u003etbl에서 할당하는 것고 \u003ccode\u003emax_entries\u003c/code\u003e, \u003ccode\u003euse_entries\u003c/code\u003e간의 차이점은??\u003c/li\u003e\n\u003cli\u003eIf free is not NULL, add new flow to this free entry\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eif \u003ccode\u003eip_frag_lookup()\u003c/code\u003e returns non-NULL\n\u003cul\u003e\n\u003cli\u003eif timeouted, reuse it for the received flow\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003etbl-\u0026gt;use_entries—; del_num++\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eip_frag_process()\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003erte_ip_frag_free_death_row()\u003c/code\u003e 주기적으로 호출해줘야 함\u003c/li\u003e\n\u003c/ul\u003e","title":"DPDK IPv4 reassembly"},{"content":" 코드에 신경쓰기 어떤 코드든 간에 수정한 후에는 이전 보다 나아져야 한다 기능이 추가된 것은 \u0026lsquo;나아진\u0026rsquo; 것이 아니다. 기능이 추가되고, 코드 수가 늘어나도 여전히 좋은 구조를 유지하는 것이 \u0026lsquo;나아진\u0026rsquo; 것이다. 정돈된 코드 유지하기 좋은 코드는 명백하며 일관성이 있다. 보기 좋은 코드는 의도를 드러낸다(예술) 코드를 읽을 사람은 지금 당장의 나 외에 몇 달 후의 나, 다른 동료 그리고 미래의 유지 보수 프로그래머다. 그들이 혼란을 덜 겪도록 코드를 작성해야 한다. 실은 다른 사람을 위해 코딩한다는 것을 인정해야 하고, 잊으면 안된다. 코딩 스타일 가이드를 정리한다. 코딩 스타일의 목적은 일관성이다. 불필요하게 반복되는 단어를 피한다. DataObject(?) 간결함보다 중요한 것은 명확함이다. 코드를 \u0026lsquo;정리정돈\u0026rsquo;해야 할 경우에는 기능 변경과 모양 변경을 동시에 진행하지 말라 프로젝트의 공통 관습이 존재한다면 따른다. 코드 작게 쓰기 소프트웨어를 개선하는 최고의 방법 가운데 하나는 바로 코드를 제거하는 것이다. 매일 같이 코드를 더 좋게 만들라. 중복 코드는 발견 즉시 제거한다. 더 많은 양의 코드가 더 좋은 SW를 의미하지는 않는다. 필요하지 않다면 코딩하지 말라. 적게 쓰고 그 대신 더 재미난 것을 찾으라. 코드 줄여 개선하기 C의 전처리기는 사용되지 않는 코드를 만들어 내는 역효과를 낼 수 있다. 함수의 return 값이 사용되지 않으면 void로 변경한다. 가능하면 죽은 코드를 제거한다. 죽은 코드를 발견했음에도 아무런 조치를 취하지 않는 것이야말로 실패의 징조다. 코드베이스의 망령 프로그래머로서 자질은 작성한 코드가 아닐 그것을 대하는 태도와 작성하는 방식에 의해 결정된다. 예전에 작성한 코드가 최신 라이브러리에 의해 대체할 수 있을 경우도 있다. 기존의 코드를 돌아보는 것은 자신을 위한 코드 리뷰이자, 가치있는 행동이다. 경로 탐색하기 코드를 작성하는 것이 읽는 것보다 쉽다.(하지만 숨겨진 의도를 파악하지 못하고 새로 작성하면 새로운 문제를 일으킨다. 실은 예전에 발생했던 문제를 부활시키는…) 코드 분석을 통해 알아낸 것이 있으면 프로젝트의 최상위 위치에 README파일을 만든다. 의도, 주의사항, 의존성, 빌드 방법 등 똥통에서 뒹굴기 goto 문이 남발되면 알고리즘 구조를 읽기 어렵다. 외부에 노출하는 API는 깔끔하고 합리적인가? 자료형을 잘 고르고, 변수 명이 적절한가? 코드의 레이아웃을 정돈하여 일관성 있게 작성했는가? 코드의 외관이 코드의 근본적인 품질을 보장하지는 않지만, 일관성 없고 지저분한 코드가 대개 구조도 부적절하고, 다루기 어려웠다(저자의 경험상) 특정 기능을 구현하는 코드 부분이 어디에 있는 지 쉽게 찾을 수 있는가? 보이스카웃 규칙을 따른다. 어떤 코드를 건드리건 이전보다 나아지도록 한다. 거대한 함수는 더 작으면서도 적절히 명명된 작은 함수들로 나눈다. 성능 최적화 측면에서 함수 호출이 갖는 penalty는 어떻게 할 것인지? 주기적으로 코드 일부라도 확인하고 그때마다 조금씩 나아지게 만든다. 수정으로 인해 기존 기능에 문제가 생기지 않음을 보장할 수 있는 모든 수단을 사용한다. 똥떵어리 수정을 별 의미없는 작업이라 치부하기보다는 더 나은 품질을 실현할 기회로 삼으라 수정하면서 자신의 태도도 확인하라. 어쩌면 당신은 원 저자보다 자신이 더 잘 알고 있다고 생각할 수도 있다. 과연 언제나 그럴까? 오류 무시하지 않기 반환 코드는 주로 정수 값으로 0은 성공, 그 외의 수는 오류를 의미 예상하지 못한 것을 예상하기 에러 코드는 절대로 무시하지 말라 버그 사냥하기 버그를 피할 수 있는 가장 좋은 충고는 믿기 힘들 정도로 \u0026lsquo;영리한(종종 복잡한 것과 동일시 되는)\u0026rsquo; 코드를 만들리 말라는 것이다. Martin Fowler, 미련한 프로그래머는 컴퓨터가 이해할 수 있는 코드를 만들고, 좋은 프로그래머는 사람이 이해할 수 있는 코드를 만든다. 단위 테스트에 시간을 투자 특정 코드가 test coverage에 포함되지 않으면 제대로 작동한다고 신뢰할 수 없다. 문제를 다른 사람에게 설명해 보라. Rubber Duck strategy 버그를 찾고 해결하려 할 때 마구잡이로 달려들어서는 안된다. 코드의 어느 부분에 더 많은 문제가 있는 지 메모해둔다. 핫스팟을 찾으면 집중적인 개선 노력을 기울일 수 잇다. 아이젠버그. \u0026lsquo;관찰자\u0026rsquo;가 있으면 양상이 달라질 수 있다는 \u0026lsquo;관리자 효과\u0026rsquo;라는 용어를 만든 Werner Heisenberg 테스트하기 위대한 소프트웨어를 제대로 만들려면 피드백을 받아야 한다. 가능하면 자주, 그리고 빨리 좋은 테스트 전략은 피드백 절차를 간소화하는 것 피드백 과정이 짧을 수록 설계 변경을 더 빠르게 반복할 수 있고, 코드에 대해 더 강하게 확신할 수 있다. 더 열심히 일하려 하기보다 더 영리하게 일하라 코드에 대한 확신은 곧 테스트 코드의 품질이 결정한다. 실패 경우를 유닛 테스트로 만들어 재발을 방지한다. 성능이 주요 요구사항이면, 코드의 성능을 모니터링하는 테스트도 수행한다. 나쁜 테스트는 짐이 된다. 자산이라기보다 채무다 나쁜 테스트는 코드에 약간만 수정을 가해도 처리하기 어렵고, 조밀하며 이해하기 힘들다 좋은 테스트의 조건 나쁜 테스트란 테스트 코드도 유지 보수한다. 프로그램 테스트를 통해 버그의 존재를 확인할 수는 있지만, 버그가 없음을 확신할 수는 없다. 복잡도 다루기 Blob(Binary Large Object)은 정확한 역할과 책임을 확실히 가져야 한다. 우리의 뇌는 문제를 계층으로 나누고 추상화하여 추론하는데 최적화되어 있다. 사용하지 않은 helper method는 제거한다. 순환 의존 관계는 가장 복잡한 관계다. 프로그래머들에게 리팩토링할 시간도 허락하지 않은 채, 시스템을 확장하고 확장하며 또 확장한다. 버려야할 prototype을 출시 시스템으로 둔갑시킨다. 두 개의 시스템에 대한 이야기 대도시 이야기 vs. 디자인 타운 소프트웨어는 건강하지 못한 회사 구조와 개발 절차로 인해 잘못 설계될 수 있다. 이해 불가. 소프트웨어 설계의 품질을 유지 보수하라. 나쁜 설계는 더 나쁜 설계를 불러온다. 응집도의 부족. 각각의 컴포넌트는 필요하지 않은 다양한 기능을 포함하고 있다. 개발팀의 작업자들 간의 관계가 얼마나 건강한지는 소프트웨어 설계의 품질에 직접적 영향을 끼친다. 부적절한 관계와 자만심은 잘못된 소프트웨어를 만든다. 훌륭한 소프트웨어 디자인은 모듈 간의 상호 작동에서 필요한 것들만 허용한다. 불필요한 결합. 좋은 설계는 상호 연결 구조나 컴포넌트 간 연결의 분량을 검토한다. 시스템의 개별 부분은 단독으로 작동할 수 있어야 한다. 밀착 결합은 테스트하기 어렵게 만든다. 코드 문제. 공통된 규칙이나 공통 라이브러리 사용, 공통된 관례에 대한 무신경 새로운 기능을 붙이기가 너무 어렵다 보니 사람들은 점점 더 자주 실수했고, 디자인 타운은 초기 설계를 작동하기에 알맞은 수준으로 결정. 최상위 수준의 디렉토리 구조, 명명 규칙, 일반적 코딩 관례에 덧붙인 코드 작성 방법, 유닛 테스트 프레임워크 선택과 기반 구조가 되는 내부 구조들. 시스템 구조에 대한 명확한 비전. 일관성. 모든 수준에서의 모든 결정을 전체 설계의 관점에서 수행 구조 확장. 그 어떤 것도 변하지 않은 것은 없다. 소프트웨어의 구조는 불변이 아니다. 필요하다면 변경하라. 변경 가능하게 만들려면 구조를 간결하게 유지해야 한다. 기술 부채에 대한 인정과 후속 개선 작업 훌륭한 자동화 테스트는 최소한의 위험만으로 근본적인 구조 변경을 수행할 수 있게 한다. 팀이 분열되어 있다면, 코드도 어색하게 엮인다. 코드 작성에 앞서 계획적으로 설계한다. 더도 말고 덜도 말고 알맞게 설계. 소프트웨어 개발이란 훌륭한 프로그래머의 주요 특징 중 하나는 작성한 소프트웨어와 그 작성법에 대해 진심으로 주의를 기울이는 것이다. 좋은 소프트웨어는 정확하고, 입증되고, 측정되고, 실험되며, 검증되어야 한다 -\u0026gt; 좋은 테스트 자신이 작성한 소프트웨어는 언제나 완전히 정확하고 완벽하게 정밀한가? 이를 증명하는 방법은 무엇인가? 어떻게 하면 현재와 미래에 명시화 할 수 있는가? 일련의 규칙과 특정 팀 문화를 기반으로 개발을 진행 효율적인 프로그래머가 되려면 집안일을 두려워해서는 안 된다. 제품의 최신 버전에 대해 멋진 설계를 하는 것은 대단한 일이지만, 제품을 출시하고 지저분한 코드에서 오류를 찾아 수정하는 지루한 작업을 해야 할 때도 종종 있다. 문제의 수정 방법을 찾으면 적절한 시점에 파괴적이지 않은 방식으로 수정해야 하낟. 청소부로서 다른 사람에게 즐겁지 않은 작업을 넘겨버리지 말고 책임을 져야 한다. 죽은 코드를 제거하고, 망가진 코드를 수정한다. 적절하지 않은 코드를 리팩토링하고 재구성하며, 코드를 줄이고 깔끔하게 만든다. 코드가 황폐한 상태에 빠지지 않도록 하기 위함이다. 규칙 가지고 놀기 때때로 못난 프로그래머들에게는 더 많은 규칙이 필요하다. 규칙은 새로운 팀원에게 줄 수 있을 만큼의 단순해야 한다. 단순히 방법론과 절차에 대한 것이 아닌 팀에서 좋은 플레이어가 되는 방법과 같은 코딩 문화를 설명하는 규칙이어야 한다. 좋은 코드를 작성하기 위한 세개의 규칙이란 간결하게 하라 머리를 쓰라 변하지 않는 것은 없다. 간결하게 하기 간결한 코드는 설계하는 데 많은 노력이 필요하다. 다만 간결한 코드가 곧 과도하게 단순한 코드를 의미하지는 않는다. 잘못되고 단세포적인 \u0026lsquo;단순함\u0026rsquo;이 아니라 가장 간결한 코드를 작성하기 위해 노력해야 간결한 설계는 빠르고 명확하게 묘사할 수 있고, 쉽게 이해할 수 있다 \u0026lsquo;간결한\u0026rsquo; 인터페이스 설계에서는 동적으로 할당한 객체를 받아 사용 후 사용자가 그 객체를 직접 삭제할 필요가 없다. 간결한 코드는 읽기 쉽고 이해하기 쉽다. 따라서 작업하기에도 쉽다. 명백한 방식으로 납득할 만한 코드를 작성하면, 코딩 스타일도 그렇게 된다. 그러면 유지 보수하는 프로그래머들이 고마워할 것이다. 오류를 수정하면서 간결함을 유지해야 한다. 증상 부위가 아닌 근본 원인에 대해 버그 수정을 적용하라 설계/구현을 위해 세운 가설이 있다면 코드에 명시한다. 유용할 것이라고 생각되는 대량의 코드를 작성하지 말라. 사용되지 않는 코드는 그저 잠일 뿐이다. 요구사항을 충족시키는 데 필요한 만큼의 코드만 작성하라. 코드를 적게 작성할 수로고 더 적은 버그가 만들어질 것이다. 머리 쓰기 일을 멈추고 생각하라. 바보 같은 코드를 작성하지 말라. 일단 작업을 멈추고 정신을 차린 뒤 대안이 있는 지 확인해보라. 가차없는 수정이 필요한 누더기 코드를 발견했을 때는 거기에 또 다른 누더기 코드를 덧씌우지 말라. 변하지 않는 것은 없다. 항상 시간이 해결해 준다고들 하지만, 실제로는 당신 스스로 변하게 만들어야 한다. 프로그래머는 두려움을 느끼고 코드를 깨뜨리지 않도록 하려다 보니, 코드를 단단히 얼어붙게 만든다. 이것이 바로 소프트웨어 사후 경직이다. 본래의 개발자가 프로젝트를 떠나고 오래된 중요한 코드를 완벽하게 이해하는 사람이 남지 않았을 때, 해당 코드가 사후 경직되는 경우가 종종 있다. 코드가 구속력을 가지면, 더 이상 소프트웨어를 개발한다고 볼 수 없으며 코드에 맞서 싸우는 형태가 된다. 코딩 시 두려움을 가지고 피하기만 한다면, 코더의 인생은 쉽게 만들어줄 지 몰라도, 설계는 썩어간다. 코드 성장에 도움이 되는 태도 수정하기 두려운 코드를 발견한다면 반드시 수정해야 한다. 리팩토링 또한 권장한다. 누구도 코드의 어떤 영역을 소유하고 있지 않다. 좋은 프로그래머는 변화를 기대한다. 변화야말로 소프트웨어 개발의 전부다. 모양과 의도를 드러내고, 간결함과 명확함, 일관성을 표방하는 코드. 코드 재사용 사례 코드가 하나의 프로젝트가 아닌 더 많은 용도로 사용될 지 의심스러운 상황에서 처음부터 다양하게 사용할 수 있도록 처리하는 것은 가치가 없는 일이다. 당장의 요구사항을 만족할 수 있는 가장 간단한 코드를 만드는 데에만 집중한다. 가능한 가장 적은 양의 소프트웨어를 만듦으로써, 버그를 양산하거나 향후 수년간 지원해야 하는 불필요한 API를 만들 위험을 줄일 수 있다. 한 곳이 아닌 여러 곳에서 사용되어야 한다면 공통 라이브러리 혹은 공통 코드 파일을 만든다. 가능하다면 기존에 존재하는 코드를 재사용한다. 효과적인 버전 관리 최상위 디렉토리에 도움이 되는 README 문서를 포함한다. 자주 조금씩 변경 사항을 체크인한다. 한 번에 두 가지 이상의 변경 사항을 다루는 체크인을 해서는 안 된다. 커밋 메시지는 코드와 같은 성격을 갖는다. 명확/간결/DRY. 변경한 파일을 나열할 필요는 없다. 개선하려면 변화해야 한다. 완벽하려면 자주 변화해야 한다. 골기퍼 있다고 골 안 들어가랴 QA와 개발을 별도의 단계이자 행위로 보고 다른 팀으로 나누어버리면, 경쟁심은 커지고 단절감은 심해진다. 신뢰감이 없어진다. 그러나 비개발 출신의 관리자는 부서간의 관계를 신뢰하지 못하고 별개의 부서로 만든다 품질 보장 업무는 개발자들과 테스터들이 긴밀히 연계될 때 비로소 효과적으로 수행될 수 있다. 팀 간의 의사소통이 건전하지 않으면 코드도 건전해지지 않는다. 개발자는 반드시 QA와 좋은 관계를 유지해야 하며, 우정과 동지애를 가져야 한다. 정확하고 신뢰할 만한 오류 보고서를 만든 뒤 구조화되고 규칙을 따르는 방식, 예를 들면 좋은 오류 추적 체계를 사용해 전달하는 것은 테스터의 의무이다. 오류 보고서를 개인적으로 받아들이지 말라. 개인적 모욕이 아니다!! 다툼이 있는 곳에는 언제나 관계를 해치는 결과와 더 긴밀히 만드는 결과로 구분 짓는 하나의 요소가 존재한다. 바로 \u0026lsquo;태도\u0026rsquo;이다. 폭포수 모델에 따라 테스트에 도달하기 전에 90%수준에 도달했다면, 프로젝트를 마감하기 위해 또 다른 90%수준의 노력이 필요함을 깨닫게 될 것이다. QA는 같은 팀의 일부임을 기억하라. 그들은 경쟁 집단이 아니다. 동결된 코드의 신기한 사례 코드 동결은 코드가 완전해졌다고 판단되는 시점으로 모든 기능이 구현되었을 뿐 아니라, 어처구니 없는 버그가 없는 때를 의미한다. \u0026lsquo;코드 동결\u0026rsquo;은 변경을 완전히 막는다기보다는 개발 작업에 대해 새로운 규칙을 적용한다는 의미 가깝다. 변경 사항이 아무리 가치 있다 해도 신중한 합의 후에 이루어져야 한다. 코드 동결 기간에는 기술적 부채가 발생할 수도 있다. 부채의 발생을 감시하고, 배포 이후에 곧바로 빚을 갚을 준비를 하라. 제발 저를 배포해주세요 배움을 사랑하며 살기 프로그래머에게는 배움, 즉 기량과 능력의 향상이 지속적으로 요구된다. 배움을 즐기는 것을 배우라 배울 때 재미있을 만한 것을 조사하는데 우선 시간을 들이라. 새로운 기술/기법/문제 영역에 대해 배우라. 사람들과 함께 일하는 것을 배우라. 사회학이나 경영학 책을 공부해보라. 소프트웨어 팀의 리더가 되는 것에 대해 읽어보라. 어떻게 배워야 할 지 배우라. 완전히 다른 것을 배우라. 새로운 외국어나 악기, 다른 과학 분야 미술 혹은 철학을 배우라. 나중에 버릴지언정 지금 배우고 있는 것을 기록하라 Knowledge Portfolio. 현재 업무 지식을 투자 포트폴리오로 간주해보라. 수집한 정보를 어떻게 관리해야 하고, 현재의 포트폴리오를 유지하기 위해 어떤 방식으로 신중하게 투자해야 하며, 포트폴리오를 강화하기 위해 새로운 투자를 어떻게 이끌어낼지를 밝혀낼 수 있다. 아인슈타인. 간단하게 설명할 수 없다면, 충분히 잘 이해하지 못했다는 증거이다. 배움에 있어 핵심적인 기술은 행동하는 것이다. 추상적으로만 알고 있던 것들을 구체적이고 실천적으로 알 수 있도록 하라. 뛰어들어 실행해보라. 테스트 기반 개발자 아무런 생각 없이 \u0026lsquo;성급하게 반응하는\u0026rsquo; 식의 접근 방법은 카우보이 코더에게나 찾아볼 수 있는 증상이다. 오랜 경력을 가진 코드라고 해도 누구나 전문적인 기술자가 되지 않는다. 관련 업계에서 보낸 시간만으로는 판단할 수 없다. 승진했다고 해서 당신이 처음 개발을 시작했을 때보다 더 좋은 프로그래머라는 의미는 아니다. 도전 즐기기 코딩 연습, 코딩 문제, 개인적인 프로젝트, 새로운 직업을 찾아본다. 작업 중인 진행 상황을 볼 수 있도록 하라. 무엇을 성취했는 지 확인할 수 있도록 소스 로그를 리뷰하라. 부진 피하기 자신의 능력 이상을 해낸 마지막 시점은 언제였는가? 안전지대는 유해한 영역이다. 편한 삶이란 곧 학습하지 않고, 진행하지 않으며, 더 이상의 발전이 없는 것을 의미한다. 안전지대에 있는 것은 정체되었다는 뜻이다. 안전지대는 퇴보로 가는 지름길이다. 타성에 젖어버리기란 쉬운 일이다. 스스로를 불편한 상황에 두어야 하고 많은 노력을 쏟아 부어야 한다. 위험하고 어려운 일이며 자신을 난처하게 만들 수도 있다. 의식적으로 자신의 기술에 투자하려 해야 한다. 그런 결정을 지속해야 한다. 힘든 일이라 생각하지 말라. 도전 안에서 즐거움을 느끼라. 다른 도구/프로그래밍 언어/OS/편집기를 사용해 본다. 키보드 단축키를 알아본다. 개인적인 프로젝트를 시작한다. 프로젝트의 새로운 부분을 담당하라. 한 가지 직업/역할에 너무 오래 머물거나 아무런 도전거리도 없는 같은 일만 반복하는 것은 위험하다. 자신만의 작은 코딩 제국의 왕이 되는 것이다. 참으로 안락한 상황이다. 좋은 프로그래머는 코드에 대한 접근 방식에서든 자신의 경력에 대한 접근 방식에서든 과감하다. 윤리적인 프로그래머 기술 부채를 추후 탐금하기 위해 작업 목록에 새로운 업무에 추가한다. 언어에 대한 사랑 좋은 프로그래머들은 다양한 언어와 방법론을 알고 있는 만큼 문제 해결의 범위가 넓다. 언어 고유의 방식과 관습에 돌입해야 한다. 의사소통은 말하는 것만큼이나 듣는 것도 중요하다. 프로그래머의 자세 \u0026lsquo;더 열심히\u0026rsquo;보다는 \u0026lsquo;더 현명하게\u0026rsquo; 기술적 통찰력만이 아닌 문제를 풀고 전투를 선택하는 방법에서 찾아볼 수 있다. 좋은 프로그래머는 일을 빠르게 끝낸다. 어떻게 하면 문제를 잘 해결할 수 있는 지 아는 것이다. 현명하게 재사용한다. 직접 만들기보다는 이미 있는 코드를 사용하고, 더 중요한 일에 시간을 투자하라. 다른 사람이 거들어줄 수 있거나 훨씬 빨리 완료할 수 있다면, 그의 작업 목록에 올려주는편이 훨신 나을 것이다. 모든 것을 테스트하지 않고 취약할 것으로 예상되는 지점들에 집중하라. 테스트의 전장을 잘 선택하라. 최선책을 골라내기 위해 심사숙고하느라 많은 시간을 소모하지 말라. 우선 순위 설정에 엄격하라. 중요하지 않은 사소한 것에 몰두하지 말라. 새로운 업무가 할당될 때는 지금 당장 필요한 일인지부터 확인한다. 초기부터 지나치게 많은 코드를 작성하는 행동은 위험하다. 하나를 끝내고 다른 것을 하라. 코드와 설계를 가능한 한 작고 간결하게 유지하라. 미래의 요구사항이 무엇일지 지금 정확히 예견할 수는 없다. 지금 당장은 나중에 코드를 고치기 쉽도록 하는 정도에서 만족하는 것이 더 쉽고 똑똑한 일이다. 언젠가 발생할 가능성이 있는 기능을 미리 만들어주는 것은 더 어렵고 어리석다. 어려운 일을 미뤄두지 말라. 코드 통합 등이 그 예이다. 많은 사람들이 고통을 줄이기 위해 일을 미뤄두고 있다. 반복 작업은 손수하는 것보다는 도구를 작성하고 해당 도구를 한 번만 실행하는 편이 더 빠를 수 있다. 건전한 프로젝트는 연속한 야근을 요구하지 않는다. 항상 업무 흐름을 가속화해줄 새로운 도구를 찾으라. 다만 새로운 도구를 찾는 일에 노예가 되지는 말자. 끝나야 끝나는 것 \u0026lsquo;완료 상태란 어떤 것인지, 그리고 \u0026lsquo;완료\u0026rsquo; 상태에 얼마나 가까운 지를 현실적으로 파악하는 것이다. 엄청난 업무를 할당받았다면, 일을 시작하기 전에 더 작고 이해할 만한 부분으로 일을 나누도록 하라. \u0026lsquo;완료\u0026rsquo; 상태를 정의해야 한다. \u0026lsquo;완료 상태\u0026rsquo;는 명확하고 구체적어야 한다. 구현해야 할 기능, 추가 혹은 확장해야 할 모든 API, 수정해야 할 특저 오류를 목록화한다. 모든 주요 관련자들이 성공 기준을 확인하도록 하라. 작동함을 증명하기 위해 코드로 작성된 테스트를 사용하라. 필요 이상으로 많은 작업을 수행하지 말라. \u0026lsquo;완료\u0026rsquo; 상태까지만 작업하라. 그런 뒤에는 중지하라. 교훈 얻기 다른 프로그래머에게 의무감을 가지라. 그들과 주기적으로 작업 경과를 확인하라. 사람의 힘 생각이 중요하다. 작업의 품질을 보증하기 위해 다른 프로그래머들에 대한 의무감을 가지면, 코드 품질을 환상적으로 높일 수 있다. 다른 사람이 코드를 읽고 품평하리라는 것을 알고 나면 좋은 코드를 짜고 싶은 마음이 더 커진다. 말하기 코드는 다른 사람과의 의사소통이다. 명백하고 애매호호함이 없어야만 다른 사람들이 코드를 유지 보수할 수 있다. 선언문 코드에 신경 쓰라 팀의 힘을 키우라 간결함을 유지하라 머리를 쓰라 그 무엇도 고정된 것은 없다. 꾸준히 배우라 (주체가 자신이든 팀이든 코드든 간에) 나아질 방향을 꾸준히 모색하라 언제나 가치를 전달하려 애쓰라. 길게 볼 수 있도록 해보라. 코드 찬가 Rober C. Martin 보이스카웃 규칙 리더 자신이 문제의 일부라면? 보통 소프트웨어 개발과 관련해 까다로운 부분은 기술적인 측면에 있지 않다. 결국 사람의 문제다. 나쁜 습관에 빠져들지 않도록 하라. 보통 소프트웨어 개발과 관련핸 까다로운 부분은 기술적인 측면에 있지 않다. 결국 사람의 문제다. 나쁜 습관에 빠져들지 않도록 하라. 코드에 신경 쓰지 않는 코더에게 둘러싸여 있다면, 자신만이라도 건전한 태도를 유지하라. 태도가 핵심이다. 좋은 프로그래머와 나쁜 프로그래머를 구분하는 요소는 바로 태도다. 태도는 기술적인 부분을 넘어선다. ","date":"2016-03-14T14:50:15+09:00","permalink":"https://cychong47.github.io/post/2016/becoming-a-better-programmer/","summary":"\u003col\u003e\n\u003cli\u003e코드에 신경쓰기\n\u003cul\u003e\n\u003cli\u003e어떤 코드든 간에 수정한 후에는 이전 보다 나아져야 한다\u003c/li\u003e\n\u003cli\u003e기능이 추가된 것은 \u0026lsquo;나아진\u0026rsquo; 것이 아니다. 기능이 추가되고, 코드 수가 늘어나도 여전히 좋은 구조를 유지하는 것이 \u0026lsquo;나아진\u0026rsquo; 것이다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e정돈된 코드 유지하기\n\u003cul\u003e\n\u003cli\u003e좋은 코드는 명백하며 일관성이 있다. 보기 좋은 코드는 의도를 드러낸다(예술)\u003c/li\u003e\n\u003cli\u003e코드를 읽을 사람은 지금 당장의 나 외에 몇 달 후의 나, 다른 동료 그리고 미래의 유지 보수 프로그래머다. 그들이 혼란을 덜 겪도록 코드를 작성해야 한다.\u003c/li\u003e\n\u003cli\u003e실은 다른 사람을 위해 코딩한다는 것을 인정해야 하고, 잊으면 안된다.\u003c/li\u003e\n\u003cli\u003e코딩 스타일 가이드를 정리한다.  코딩 스타일의 목적은 일관성이다.\u003c/li\u003e\n\u003cli\u003e불필요하게 반복되는 단어를 피한다. DataObject(?)\u003c/li\u003e\n\u003cli\u003e간결함보다 중요한 것은 명확함이다.\u003c/li\u003e\n\u003cli\u003e코드를 \u0026lsquo;정리정돈\u0026rsquo;해야 할 경우에는 기능 변경과 모양 변경을 동시에 진행하지 말라\u003c/li\u003e\n\u003cli\u003e프로젝트의 공통 관습이 존재한다면 따른다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e코드 작게 쓰기\n\u003cul\u003e\n\u003cli\u003e소프트웨어를 개선하는 최고의 방법 가운데 하나는 바로 코드를 제거하는 것이다.\u003c/li\u003e\n\u003cli\u003e매일 같이 코드를 더 좋게 만들라. 중복 코드는 발견 즉시 제거한다.\u003c/li\u003e\n\u003cli\u003e더 많은 양의 코드가 더 좋은 SW를 의미하지는 않는다. 필요하지 않다면 코딩하지 말라. 적게 쓰고 그 대신 더 재미난 것을 찾으라.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e코드 줄여 개선하기\n\u003cul\u003e\n\u003cli\u003eC의 전처리기는 사용되지 않는 코드를 만들어 내는 역효과를 낼 수 있다.\u003c/li\u003e\n\u003cli\u003e함수의 return 값이 사용되지 않으면 void로 변경한다.\u003c/li\u003e\n\u003cli\u003e가능하면 죽은 코드를 제거한다.\u003c/li\u003e\n\u003cli\u003e죽은 코드를 발견했음에도 아무런 조치를 취하지 않는 것이야말로 실패의 징조다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e코드베이스의 망령\n\u003cul\u003e\n\u003cli\u003e프로그래머로서 자질은 작성한 코드가 아닐 그것을 대하는 태도와 작성하는 방식에 의해 결정된다.\u003c/li\u003e\n\u003cli\u003e예전에 작성한 코드가 최신 라이브러리에 의해 대체할 수 있을 경우도 있다.\u003c/li\u003e\n\u003cli\u003e기존의 코드를 돌아보는 것은 자신을 위한 코드 리뷰이자, 가치있는 행동이다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e경로 탐색하기\n\u003cul\u003e\n\u003cli\u003e코드를 작성하는 것이 읽는 것보다 쉽다.(하지만 숨겨진 의도를 파악하지 못하고 새로 작성하면 새로운 문제를 일으킨다. 실은 예전에 발생했던 문제를 부활시키는…)\u003c/li\u003e\n\u003cli\u003e코드 분석을 통해 알아낸 것이 있으면 프로젝트의 최상위 위치에 README파일을 만든다. 의도, 주의사항, 의존성, 빌드 방법 등\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e똥통에서 뒹굴기\n\u003cul\u003e\n\u003cli\u003egoto 문이 남발되면 알고리즘 구조를 읽기 어렵다.\u003c/li\u003e\n\u003cli\u003e외부에 노출하는 API는 깔끔하고 합리적인가?\u003c/li\u003e\n\u003cli\u003e자료형을 잘 고르고, 변수 명이 적절한가?\u003c/li\u003e\n\u003cli\u003e코드의 레이아웃을 정돈하여 일관성 있게 작성했는가?\n\u003cul\u003e\n\u003cli\u003e코드의 외관이 코드의 근본적인 품질을 보장하지는 않지만, 일관성 없고 지저분한 코드가 대개 구조도 부적절하고, 다루기 어려웠다(저자의 경험상)\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e특정 기능을 구현하는 코드 부분이 어디에 있는 지 쉽게 찾을 수 있는가?\u003c/li\u003e\n\u003cli\u003e보이스카웃 규칙을 따른다. 어떤 코드를 건드리건 이전보다 나아지도록 한다.\u003c/li\u003e\n\u003cli\u003e거대한 함수는 더 작으면서도 적절히 명명된 작은 함수들로 나눈다.\n\u003cul\u003e\n\u003cli\u003e성능 최적화 측면에서 함수 호출이 갖는 penalty는 어떻게 할 것인지?\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e주기적으로 코드 일부라도 확인하고 그때마다 조금씩 나아지게 만든다.\u003c/li\u003e\n\u003cli\u003e수정으로 인해 기존 기능에 문제가 생기지 않음을 보장할 수 있는 모든 수단을 사용한다.\u003c/li\u003e\n\u003cli\u003e똥떵어리 수정을 별 의미없는 작업이라 치부하기보다는 더 나은 품질을 실현할 기회로 삼으라\u003c/li\u003e\n\u003cli\u003e수정하면서 자신의 태도도 확인하라. 어쩌면 당신은 원 저자보다 자신이 더 잘 알고 있다고 생각할 수도 있다. 과연 언제나 그럴까?\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e오류 무시하지 않기\n\u003cul\u003e\n\u003cli\u003e반환 코드는 주로 정수 값으로 0은 성공, 그 외의 수는 오류를 의미\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e예상하지 못한 것을 예상하기\n\u003cul\u003e\n\u003cli\u003e에러 코드는 절대로 무시하지 말라\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e버그 사냥하기\n\u003cul\u003e\n\u003cli\u003e버그를 피할 수 있는 가장 좋은 충고는 믿기 힘들 정도로 \u0026lsquo;영리한(종종 복잡한 것과 동일시 되는)\u0026rsquo; 코드를 만들리 말라는 것이다.\u003c/li\u003e\n\u003cli\u003eMartin Fowler, 미련한 프로그래머는 컴퓨터가 이해할 수 있는 코드를 만들고, 좋은 프로그래머는 사람이 이해할 수 있는 코드를 만든다.\u003c/li\u003e\n\u003cli\u003e단위 테스트에 시간을 투자\u003c/li\u003e\n\u003cli\u003e특정 코드가 test coverage에 포함되지 않으면 제대로 작동한다고 신뢰할 수 없다.\u003c/li\u003e\n\u003cli\u003e문제를 다른 사람에게 설명해 보라. Rubber Duck strategy\u003c/li\u003e\n\u003cli\u003e버그를 찾고 해결하려 할 때 마구잡이로 달려들어서는 안된다.\u003c/li\u003e\n\u003cli\u003e코드의 어느 부분에 더 많은 문제가 있는 지 메모해둔다. 핫스팟을 찾으면 집중적인 개선 노력을 기울일 수 잇다.\u003c/li\u003e\n\u003cli\u003e아이젠버그. \u0026lsquo;관찰자\u0026rsquo;가 있으면 양상이 달라질 수 있다는 \u0026lsquo;관리자 효과\u0026rsquo;라는 용어를 만든 Werner Heisenberg\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e테스트하기\n\u003cul\u003e\n\u003cli\u003e위대한 소프트웨어를 제대로 만들려면 피드백을 받아야 한다. 가능하면 자주, 그리고 빨리\u003c/li\u003e\n\u003cli\u003e좋은 테스트 전략은 피드백 절차를 간소화하는 것\u003c/li\u003e\n\u003cli\u003e피드백 과정이 짧을 수록 설계 변경을 더 빠르게 반복할 수 있고, 코드에 대해 더 강하게 확신할 수 있다.\u003c/li\u003e\n\u003cli\u003e더 열심히 일하려 하기보다 더 영리하게 일하라\u003c/li\u003e\n\u003cli\u003e코드에 대한 확신은 곧 테스트 코드의 품질이 결정한다.\u003c/li\u003e\n\u003cli\u003e실패 경우를 유닛 테스트로 만들어 재발을 방지한다.\u003c/li\u003e\n\u003cli\u003e성능이 주요 요구사항이면, 코드의 성능을 모니터링하는 테스트도 수행한다.\u003c/li\u003e\n\u003cli\u003e나쁜 테스트는 짐이 된다. 자산이라기보다 채무다\u003c/li\u003e\n\u003cli\u003e나쁜 테스트는 코드에 약간만 수정을 가해도 처리하기 어렵고, 조밀하며 이해하기 힘들다\u003c/li\u003e\n\u003cli\u003e좋은 테스트의 조건\u003c/li\u003e\n\u003cli\u003e나쁜 테스트란\u003c/li\u003e\n\u003cli\u003e테스트 코드도 유지 보수한다.\u003c/li\u003e\n\u003cli\u003e프로그램 테스트를 통해 버그의 존재를 확인할 수는 있지만, 버그가 없음을 확신할 수는 없다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e복잡도 다루기\n\u003cul\u003e\n\u003cli\u003eBlob(Binary Large Object)은 정확한 역할과 책임을 확실히 가져야 한다.\u003c/li\u003e\n\u003cli\u003e우리의 뇌는 문제를 계층으로 나누고 추상화하여 추론하는데 최적화되어 있다.\u003c/li\u003e\n\u003cli\u003e사용하지 않은 helper method는 제거한다.\u003c/li\u003e\n\u003cli\u003e순환 의존 관계는 가장 복잡한 관계다.\u003c/li\u003e\n\u003cli\u003e프로그래머들에게 리팩토링할 시간도 허락하지 않은 채, 시스템을 확장하고 확장하며 또 확장한다. 버려야할 prototype을 출시 시스템으로 둔갑시킨다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e두 개의 시스템에 대한 이야기\n\u003cul\u003e\n\u003cli\u003e대도시 이야기 vs. 디자인 타운\u003c/li\u003e\n\u003cli\u003e소프트웨어는 건강하지 못한 회사 구조와 개발 절차로 인해 잘못 설계될 수 있다.\u003c/li\u003e\n\u003cli\u003e이해 불가. 소프트웨어 설계의 품질을 유지 보수하라. 나쁜 설계는 더 나쁜 설계를 불러온다.\u003c/li\u003e\n\u003cli\u003e응집도의 부족. 각각의 컴포넌트는 필요하지 않은 다양한 기능을 포함하고 있다.\n\u003cul\u003e\n\u003cli\u003e개발팀의 작업자들 간의 관계가 얼마나 건강한지는 소프트웨어 설계의 품질에 직접적 영향을 끼친다. 부적절한 관계와 자만심은 잘못된 소프트웨어를 만든다.\u003c/li\u003e\n\u003cli\u003e훌륭한 소프트웨어 디자인은 모듈 간의 상호 작동에서 필요한 것들만 허용한다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e불필요한 결합. 좋은 설계는 상호 연결 구조나 컴포넌트 간 연결의 분량을 검토한다. 시스템의 개별 부분은 단독으로 작동할 수 있어야 한다. 밀착 결합은 테스트하기 어렵게 만든다.\n\u003cul\u003e\n\u003cli\u003e코드 문제. 공통된 규칙이나 공통 라이브러리 사용, 공통된 관례에 대한 무신경\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e새로운 기능을 붙이기가 너무 어렵다 보니 사람들은 점점 더 자주 실수했고,\u003c/li\u003e\n\u003cli\u003e디자인 타운은 초기 설계를 작동하기에 알맞은 수준으로 결정. 최상위 수준의 디렉토리 구조, 명명 규칙, 일반적 코딩 관례에 덧붙인 코드 작성 방법, 유닛 테스트 프레임워크 선택과 기반 구조가 되는 내부 구조들.\u003c/li\u003e\n\u003cli\u003e시스템 구조에 대한 명확한 비전.\u003c/li\u003e\n\u003cli\u003e일관성. 모든 수준에서의 모든 결정을 전체 설계의 관점에서 수행\u003c/li\u003e\n\u003cli\u003e구조 확장. 그 어떤 것도 변하지 않은 것은 없다. 소프트웨어의 구조는 불변이 아니다. 필요하다면 변경하라. 변경 가능하게 만들려면 구조를 간결하게 유지해야 한다.\u003c/li\u003e\n\u003cli\u003e기술 부채에 대한 인정과 후속 개선 작업\u003c/li\u003e\n\u003cli\u003e훌륭한 자동화 테스트는 최소한의 위험만으로 근본적인 구조 변경을 수행할 수 있게 한다.\u003c/li\u003e\n\u003cli\u003e팀이 분열되어 있다면, 코드도 어색하게 엮인다.\u003c/li\u003e\n\u003cli\u003e코드 작성에 앞서 계획적으로 설계한다. 더도 말고 덜도 말고 알맞게 설계.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e소프트웨어 개발이란\n\u003cul\u003e\n\u003cli\u003e훌륭한 프로그래머의 주요 특징 중 하나는 작성한 소프트웨어와 그 작성법에 대해 진심으로 주의를 기울이는 것이다.\u003c/li\u003e\n\u003cli\u003e좋은 소프트웨어는 정확하고, 입증되고, 측정되고, 실험되며, 검증되어야 한다 -\u0026gt; 좋은 테스트\u003c/li\u003e\n\u003cli\u003e자신이 작성한 소프트웨어는 언제나 완전히 정확하고 완벽하게 정밀한가? 이를 증명하는 방법은 무엇인가? 어떻게 하면 현재와 미래에 명시화 할 수 있는가?\u003c/li\u003e\n\u003cli\u003e일련의 규칙과 특정 팀 문화를 기반으로 개발을 진행\u003c/li\u003e\n\u003cli\u003e효율적인 프로그래머가 되려면 집안일을 두려워해서는 안 된다. 제품의 최신 버전에 대해 멋진 설계를 하는 것은 대단한 일이지만, 제품을 출시하고 지저분한 코드에서 오류를 찾아 수정하는 지루한 작업을 해야 할 때도 종종 있다.\u003c/li\u003e\n\u003cli\u003e문제의 수정 방법을 찾으면 적절한 시점에 파괴적이지 않은 방식으로 수정해야 하낟. 청소부로서 다른 사람에게 즐겁지 않은 작업을 넘겨버리지 말고 책임을 져야 한다.\u003c/li\u003e\n\u003cli\u003e죽은 코드를 제거하고, 망가진 코드를 수정한다. 적절하지 않은 코드를 리팩토링하고 재구성하며, 코드를 줄이고 깔끔하게 만든다. 코드가 황폐한 상태에 빠지지 않도록 하기 위함이다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e규칙 가지고 놀기\n\u003cul\u003e\n\u003cli\u003e때때로 못난 프로그래머들에게는 더 많은 규칙이 필요하다.\u003c/li\u003e\n\u003cli\u003e규칙은 새로운 팀원에게 줄 수 있을 만큼의 단순해야 한다. 단순히 방법론과 절차에 대한 것이 아닌 팀에서 좋은 플레이어가 되는 방법과 같은 코딩 문화를 설명하는 규칙이어야 한다.\u003c/li\u003e\n\u003cli\u003e좋은 코드를 작성하기 위한 세개의 규칙이란\n\u003cul\u003e\n\u003cli\u003e간결하게 하라\u003c/li\u003e\n\u003cli\u003e머리를 쓰라\u003c/li\u003e\n\u003cli\u003e변하지 않는 것은 없다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e간결하게 하기\n\u003cul\u003e\n\u003cli\u003e간결한 코드는 설계하는 데 많은 노력이 필요하다. 다만 간결한 코드가 곧 과도하게 단순한 코드를 의미하지는 않는다.\u003c/li\u003e\n\u003cli\u003e잘못되고 단세포적인 \u0026lsquo;단순함\u0026rsquo;이 아니라 가장 간결한 코드를 작성하기 위해 노력해야\u003c/li\u003e\n\u003cli\u003e간결한 설계는 빠르고 명확하게 묘사할 수 있고, 쉽게 이해할 수 있다\u003c/li\u003e\n\u003cli\u003e\u0026lsquo;간결한\u0026rsquo; 인터페이스 설계에서는 동적으로 할당한 객체를 받아 사용 후 사용자가 그 객체를 직접 삭제할 필요가 없다.\u003c/li\u003e\n\u003cli\u003e간결한 코드는 읽기 쉽고 이해하기 쉽다. 따라서 작업하기에도 쉽다.\u003c/li\u003e\n\u003cli\u003e명백한 방식으로 납득할 만한 코드를 작성하면, 코딩 스타일도 그렇게 된다. 그러면 유지 보수하는 프로그래머들이 고마워할 것이다.\u003c/li\u003e\n\u003cli\u003e오류를 수정하면서 간결함을 유지해야 한다. 증상 부위가 아닌 근본 원인에 대해 버그 수정을 적용하라\u003c/li\u003e\n\u003cli\u003e설계/구현을 위해 세운 가설이 있다면 코드에 명시한다.\u003c/li\u003e\n\u003cli\u003e유용할 것이라고 생각되는 대량의 코드를 작성하지 말라. 사용되지 않는 코드는 그저 잠일 뿐이다. 요구사항을 충족시키는 데 필요한 만큼의 코드만 작성하라. 코드를 적게 작성할 수로고 더 적은 버그가 만들어질 것이다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e머리 쓰기\n\u003cul\u003e\n\u003cli\u003e일을 멈추고 생각하라. 바보 같은 코드를 작성하지 말라.\u003c/li\u003e\n\u003cli\u003e일단 작업을 멈추고 정신을 차린 뒤 대안이 있는 지 확인해보라.\u003c/li\u003e\n\u003cli\u003e가차없는 수정이 필요한 누더기 코드를 발견했을 때는 거기에 또 다른 누더기 코드를 덧씌우지 말라.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e변하지 않는 것은 없다.\n\u003cul\u003e\n\u003cli\u003e항상 시간이 해결해 준다고들 하지만, 실제로는 당신 스스로 변하게 만들어야 한다.\u003c/li\u003e\n\u003cli\u003e프로그래머는 두려움을 느끼고 코드를 깨뜨리지 않도록 하려다 보니, 코드를 단단히 얼어붙게 만든다. 이것이 바로 소프트웨어 사후 경직이다.\u003c/li\u003e\n\u003cli\u003e본래의 개발자가 프로젝트를 떠나고 오래된 중요한 코드를 완벽하게 이해하는 사람이 남지 않았을 때, 해당 코드가 사후 경직되는 경우가 종종 있다.\u003c/li\u003e\n\u003cli\u003e코드가 구속력을 가지면, 더 이상 소프트웨어를 개발한다고 볼 수 없으며 코드에 맞서 싸우는 형태가 된다.\u003c/li\u003e\n\u003cli\u003e코딩 시 두려움을 가지고 피하기만 한다면, 코더의 인생은 쉽게 만들어줄 지 몰라도, 설계는 썩어간다.\u003c/li\u003e\n\u003cli\u003e코드 성장에 도움이 되는 태도\n\u003cul\u003e\n\u003cli\u003e수정하기 두려운 코드를 발견한다면 반드시 수정해야 한다.\u003c/li\u003e\n\u003cli\u003e리팩토링 또한 권장한다.\u003c/li\u003e\n\u003cli\u003e누구도 코드의 어떤 영역을 소유하고 있지 않다.\u003c/li\u003e\n\u003cli\u003e좋은 프로그래머는 변화를 기대한다. 변화야말로 소프트웨어 개발의 전부다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e모양과 의도를 드러내고, 간결함과 명확함, 일관성을 표방하는 코드.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e코드 재사용 사례\n\u003cul\u003e\n\u003cli\u003e코드가 하나의 프로젝트가 아닌 더 많은 용도로 사용될 지 의심스러운 상황에서 처음부터 다양하게 사용할 수 있도록 처리하는 것은 가치가 없는 일이다.\u003c/li\u003e\n\u003cli\u003e당장의 요구사항을 만족할 수 있는 가장 간단한 코드를 만드는 데에만 집중한다.\u003c/li\u003e\n\u003cli\u003e가능한 가장 적은 양의 소프트웨어를 만듦으로써, 버그를 양산하거나 향후 수년간 지원해야 하는 불필요한 API를 만들 위험을 줄일 수 있다.\u003c/li\u003e\n\u003cli\u003e한 곳이 아닌 여러 곳에서 사용되어야 한다면 공통 라이브러리 혹은 공통 코드 파일을 만든다.\u003c/li\u003e\n\u003cli\u003e가능하다면 기존에 존재하는 코드를 재사용한다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e효과적인 버전 관리\n\u003cul\u003e\n\u003cli\u003e최상위 디렉토리에 도움이 되는 README 문서를 포함한다.\u003c/li\u003e\n\u003cli\u003e자주 조금씩 변경 사항을 체크인한다.\u003c/li\u003e\n\u003cli\u003e한 번에 두 가지 이상의 변경 사항을 다루는 체크인을 해서는 안 된다.\u003c/li\u003e\n\u003cli\u003e커밋 메시지는 코드와 같은 성격을 갖는다. 명확/간결/DRY. 변경한 파일을 나열할 필요는 없다.\u003c/li\u003e\n\u003cli\u003e개선하려면 변화해야 한다. 완벽하려면 자주 변화해야 한다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e골기퍼 있다고 골 안 들어가랴\n\u003cul\u003e\n\u003cli\u003eQA와 개발을 별도의 단계이자 행위로 보고 다른 팀으로 나누어버리면, 경쟁심은 커지고 단절감은 심해진다. 신뢰감이 없어진다. 그러나 비개발 출신의 관리자는 부서간의 관계를 신뢰하지 못하고 별개의 부서로 만든다\u003c/li\u003e\n\u003cli\u003e품질 보장 업무는 개발자들과 테스터들이 긴밀히 연계될 때 비로소 효과적으로 수행될 수 있다.\u003c/li\u003e\n\u003cli\u003e팀 간의 의사소통이 건전하지 않으면 코드도 건전해지지 않는다.\u003c/li\u003e\n\u003cli\u003e개발자는 반드시 QA와 좋은 관계를 유지해야 하며, 우정과 동지애를 가져야 한다.\u003c/li\u003e\n\u003cli\u003e정확하고 신뢰할 만한 오류 보고서를 만든 뒤 구조화되고 규칙을 따르는 방식, 예를 들면 좋은 오류 추적 체계를 사용해 전달하는 것은 테스터의 의무이다.\u003c/li\u003e\n\u003cli\u003e오류 보고서를 개인적으로 받아들이지 말라. 개인적 모욕이 아니다!!\u003c/li\u003e\n\u003cli\u003e다툼이 있는 곳에는 언제나 관계를 해치는 결과와 더 긴밀히 만드는 결과로 구분 짓는 하나의 요소가 존재한다. 바로 \u0026lsquo;태도\u0026rsquo;이다.\u003c/li\u003e\n\u003cli\u003e폭포수 모델에 따라 테스트에 도달하기 전에 90%수준에 도달했다면, 프로젝트를 마감하기 위해 또 다른 90%수준의 노력이 필요함을 깨닫게 될 것이다.\u003c/li\u003e\n\u003cli\u003eQA는 같은 팀의 일부임을 기억하라. 그들은 경쟁 집단이 아니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e동결된 코드의 신기한 사례\n\u003cul\u003e\n\u003cli\u003e코드 동결은 코드가 완전해졌다고 판단되는 시점으로 모든 기능이 구현되었을 뿐 아니라, 어처구니 없는 버그가 없는 때를 의미한다.\u003c/li\u003e\n\u003cli\u003e\u0026lsquo;코드 동결\u0026rsquo;은 변경을 완전히 막는다기보다는 개발 작업에 대해 새로운 규칙을 적용한다는 의미 가깝다. 변경 사항이 아무리 가치 있다 해도 신중한 합의 후에 이루어져야 한다.\u003c/li\u003e\n\u003cli\u003e코드 동결 기간에는 기술적 부채가 발생할 수도 있다. 부채의 발생을 감시하고, 배포 이후에 곧바로 빚을 갚을 준비를 하라.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e제발 저를 배포해주세요\u003c/li\u003e\n\u003cli\u003e배움을 사랑하며 살기\n\u003cul\u003e\n\u003cli\u003e프로그래머에게는 배움, 즉 기량과 능력의 향상이 지속적으로 요구된다.\u003c/li\u003e\n\u003cli\u003e배움을 즐기는 것을 배우라\u003c/li\u003e\n\u003cli\u003e배울 때 재미있을 만한 것을 조사하는데 우선 시간을 들이라.\u003c/li\u003e\n\u003cli\u003e새로운 기술/기법/문제 영역에 대해 배우라.\u003c/li\u003e\n\u003cli\u003e사람들과 함께 일하는 것을 배우라. 사회학이나 경영학 책을 공부해보라. 소프트웨어 팀의 리더가 되는 것에 대해 읽어보라.\u003c/li\u003e\n\u003cli\u003e어떻게 배워야 할 지 배우라.\u003c/li\u003e\n\u003cli\u003e완전히 다른 것을 배우라. 새로운 외국어나 악기, 다른 과학 분야 미술 혹은 철학을 배우라.\u003c/li\u003e\n\u003cli\u003e나중에 버릴지언정 지금 배우고 있는 것을 기록하라\u003c/li\u003e\n\u003cli\u003eKnowledge Portfolio. 현재 업무 지식을 투자 포트폴리오로 간주해보라. 수집한 정보를 어떻게 관리해야 하고, 현재의 포트폴리오를 유지하기 위해 어떤 방식으로 신중하게 투자해야 하며, 포트폴리오를 강화하기 위해 새로운 투자를 어떻게 이끌어낼지를 밝혀낼 수 있다.\u003c/li\u003e\n\u003cli\u003e아인슈타인. 간단하게 설명할 수 없다면, 충분히 잘 이해하지 못했다는 증거이다.\u003c/li\u003e\n\u003cli\u003e배움에 있어 핵심적인 기술은 행동하는 것이다.\u003c/li\u003e\n\u003cli\u003e추상적으로만 알고 있던 것들을 구체적이고 실천적으로 알 수 있도록 하라. 뛰어들어 실행해보라.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e테스트 기반 개발자\n\u003cul\u003e\n\u003cli\u003e아무런 생각 없이 \u0026lsquo;성급하게 반응하는\u0026rsquo; 식의 접근 방법은 카우보이 코더에게나 찾아볼 수 있는 증상이다.\u003c/li\u003e\n\u003cli\u003e오랜 경력을 가진 코드라고 해도 누구나 전문적인 기술자가 되지 않는다. 관련 업계에서 보낸 시간만으로는 판단할 수 없다.\u003c/li\u003e\n\u003cli\u003e승진했다고 해서 당신이 처음 개발을 시작했을 때보다 더 좋은 프로그래머라는 의미는 아니다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e도전 즐기기\n\u003cul\u003e\n\u003cli\u003e코딩 연습, 코딩 문제, 개인적인 프로젝트, 새로운 직업을 찾아본다.\u003c/li\u003e\n\u003cli\u003e작업 중인 진행 상황을 볼 수 있도록 하라. 무엇을 성취했는 지 확인할 수 있도록 소스 로그를 리뷰하라.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e부진 피하기\n\u003cul\u003e\n\u003cli\u003e자신의 능력 이상을 해낸 마지막 시점은 언제였는가?\u003c/li\u003e\n\u003cli\u003e안전지대는 유해한 영역이다. 편한 삶이란 곧 학습하지 않고, 진행하지 않으며, 더 이상의 발전이 없는 것을 의미한다. 안전지대에 있는 것은 정체되었다는 뜻이다.  안전지대는 퇴보로 가는 지름길이다.\u003c/li\u003e\n\u003cli\u003e타성에 젖어버리기란 쉬운 일이다.\u003c/li\u003e\n\u003cli\u003e스스로를 불편한 상황에 두어야 하고 많은 노력을 쏟아 부어야 한다. 위험하고 어려운 일이며 자신을 난처하게 만들 수도 있다.\u003c/li\u003e\n\u003cli\u003e의식적으로 자신의 기술에 투자하려 해야 한다. 그런 결정을 지속해야 한다. 힘든 일이라 생각하지 말라. 도전 안에서 즐거움을 느끼라.\u003c/li\u003e\n\u003cli\u003e다른 도구/프로그래밍 언어/OS/편집기를 사용해 본다.\u003c/li\u003e\n\u003cli\u003e키보드 단축키를 알아본다.\u003c/li\u003e\n\u003cli\u003e개인적인 프로젝트를 시작한다.\u003c/li\u003e\n\u003cli\u003e프로젝트의 새로운 부분을 담당하라.\u003c/li\u003e\n\u003cli\u003e한 가지 직업/역할에 너무 오래 머물거나 아무런 도전거리도 없는 같은 일만 반복하는 것은 위험하다. 자신만의 작은 코딩 제국의 왕이 되는 것이다. 참으로 안락한 상황이다.\u003c/li\u003e\n\u003cli\u003e좋은 프로그래머는 코드에 대한 접근 방식에서든 자신의 경력에 대한 접근 방식에서든 과감하다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e윤리적인 프로그래머\n\u003cul\u003e\n\u003cli\u003e기술 부채를 추후 탐금하기 위해 작업 목록에 새로운 업무에 추가한다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e언어에 대한 사랑\n\u003cul\u003e\n\u003cli\u003e좋은 프로그래머들은 다양한 언어와 방법론을 알고 있는 만큼 문제 해결의 범위가 넓다.\u003c/li\u003e\n\u003cli\u003e언어 고유의 방식과 관습에 돌입해야 한다.\u003c/li\u003e\n\u003cli\u003e의사소통은 말하는 것만큼이나 듣는 것도 중요하다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e프로그래머의 자세\u003c/li\u003e\n\u003cli\u003e\u0026lsquo;더 열심히\u0026rsquo;보다는 \u0026lsquo;더 현명하게\u0026rsquo;\n\u003cul\u003e\n\u003cli\u003e기술적 통찰력만이 아닌 문제를 풀고 전투를 선택하는 방법에서 찾아볼 수 있다.\u003c/li\u003e\n\u003cli\u003e좋은 프로그래머는 일을 빠르게 끝낸다. 어떻게 하면 문제를 잘 해결할 수 있는 지 아는 것이다.\u003c/li\u003e\n\u003cli\u003e현명하게 재사용한다. 직접 만들기보다는 이미 있는 코드를 사용하고, 더 중요한 일에 시간을 투자하라.\u003c/li\u003e\n\u003cli\u003e다른 사람이 거들어줄 수 있거나 훨씬 빨리 완료할 수 있다면, 그의 작업 목록에 올려주는편이 훨신 나을 것이다.\u003c/li\u003e\n\u003cli\u003e모든 것을 테스트하지 않고 취약할 것으로 예상되는 지점들에 집중하라. 테스트의 전장을 잘 선택하라.\u003c/li\u003e\n\u003cli\u003e최선책을 골라내기 위해 심사숙고하느라 많은 시간을 소모하지 말라.\u003c/li\u003e\n\u003cli\u003e우선 순위 설정에 엄격하라. 중요하지 않은 사소한 것에 몰두하지 말라.\u003c/li\u003e\n\u003cli\u003e새로운 업무가 할당될 때는 지금 당장 필요한 일인지부터 확인한다. 초기부터 지나치게 많은 코드를 작성하는 행동은 위험하다.\u003c/li\u003e\n\u003cli\u003e하나를 끝내고 다른 것을 하라.\u003c/li\u003e\n\u003cli\u003e코드와 설계를 가능한 한 작고 간결하게 유지하라.\u003c/li\u003e\n\u003cli\u003e미래의 요구사항이 무엇일지 지금 정확히 예견할 수는 없다. 지금 당장은 나중에 코드를 고치기 쉽도록 하는 정도에서 만족하는 것이 더 쉽고 똑똑한 일이다. 언젠가 발생할 가능성이 있는 기능을 미리 만들어주는 것은 더 어렵고 어리석다.\u003c/li\u003e\n\u003cli\u003e어려운 일을 미뤄두지 말라. 코드 통합 등이 그 예이다. 많은 사람들이 고통을 줄이기 위해 일을 미뤄두고 있다.\u003c/li\u003e\n\u003cli\u003e반복 작업은 손수하는 것보다는 도구를 작성하고 해당 도구를 한 번만 실행하는 편이 더 빠를 수 있다.\u003c/li\u003e\n\u003cli\u003e건전한 프로젝트는 연속한 야근을 요구하지 않는다.\u003c/li\u003e\n\u003cli\u003e항상 업무 흐름을 가속화해줄 새로운 도구를 찾으라. 다만 새로운 도구를 찾는 일에 노예가 되지는 말자.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e끝나야 끝나는 것\n\u003cul\u003e\n\u003cli\u003e\u0026lsquo;완료 상태란 어떤 것인지, 그리고 \u0026lsquo;완료\u0026rsquo; 상태에 얼마나 가까운 지를 현실적으로 파악하는 것이다.\u003c/li\u003e\n\u003cli\u003e엄청난 업무를 할당받았다면, 일을 시작하기 전에 더 작고 이해할 만한 부분으로 일을 나누도록 하라.\u003c/li\u003e\n\u003cli\u003e\u0026lsquo;완료\u0026rsquo; 상태를 정의해야 한다.\u003c/li\u003e\n\u003cli\u003e\u0026lsquo;완료 상태\u0026rsquo;는 명확하고 구체적어야 한다. 구현해야 할 기능, 추가 혹은 확장해야 할 모든 API, 수정해야 할 특저 오류를 목록화한다. 모든 주요 관련자들이 성공 기준을 확인하도록 하라. 작동함을 증명하기 위해 코드로 작성된 테스트를 사용하라.\u003c/li\u003e\n\u003cli\u003e필요 이상으로 많은 작업을 수행하지 말라. \u0026lsquo;완료\u0026rsquo; 상태까지만 작업하라. 그런 뒤에는 중지하라.\u003c/li\u003e\n\u003cli\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e교훈 얻기\n\u003cul\u003e\n\u003cli\u003e다른 프로그래머에게 의무감을 가지라. 그들과 주기적으로 작업 경과를 확인하라.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e사람의 힘\u003c/li\u003e\n\u003cli\u003e생각이 중요하다.\n\u003cul\u003e\n\u003cli\u003e작업의 품질을 보증하기 위해 다른 프로그래머들에 대한 의무감을 가지면, 코드 품질을 환상적으로 높일 수 있다.\u003c/li\u003e\n\u003cli\u003e다른 사람이 코드를 읽고 품평하리라는 것을 알고 나면 좋은 코드를 짜고 싶은 마음이 더 커진다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e말하기\n\u003cul\u003e\n\u003cli\u003e코드는 다른 사람과의 의사소통이다. 명백하고 애매호호함이 없어야만 다른 사람들이 코드를 유지 보수할 수 있다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e선언문\n\u003cul\u003e\n\u003cli\u003e코드에 신경 쓰라\u003c/li\u003e\n\u003cli\u003e팀의 힘을 키우라\u003c/li\u003e\n\u003cli\u003e간결함을 유지하라\u003c/li\u003e\n\u003cli\u003e머리를 쓰라\u003c/li\u003e\n\u003cli\u003e그 무엇도 고정된 것은 없다.\u003c/li\u003e\n\u003cli\u003e꾸준히 배우라\u003c/li\u003e\n\u003cli\u003e(주체가 자신이든 팀이든 코드든 간에) 나아질 방향을 꾸준히 모색하라\u003c/li\u003e\n\u003cli\u003e언제나 가치를 전달하려 애쓰라. 길게 볼 수 있도록 해보라.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e코드 찬가\n\u003cul\u003e\n\u003cli\u003eRober C. Martin 보이스카웃 규칙\u003c/li\u003e\n\u003cli\u003e리더 자신이 문제의 일부라면?\u003c/li\u003e\n\u003cli\u003e보통 소프트웨어 개발과 관련해 까다로운 부분은 기술적인 측면에 있지 않다. 결국 사람의 문제다.\u003c/li\u003e\n\u003cli\u003e나쁜 습관에 빠져들지 않도록 하라.\u003c/li\u003e\n\u003cli\u003e보통 소프트웨어 개발과 관련핸 까다로운 부분은 기술적인 측면에 있지 않다. 결국 사람의 문제다.\u003c/li\u003e\n\u003cli\u003e나쁜 습관에 빠져들지 않도록 하라.\u003c/li\u003e\n\u003cli\u003e코드에 신경 쓰지 않는 코더에게 둘러싸여 있다면, 자신만이라도 건전한 태도를 유지하라.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e태도가 핵심이다.\n\u003cul\u003e\n\u003cli\u003e좋은 프로그래머와 나쁜 프로그래머를 구분하는 요소는 바로 태도다.\u003c/li\u003e\n\u003cli\u003e태도는 기술적인 부분을 넘어선다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ol\u003e","title":"(책) Becoming a better Programmer"},{"content":"l2_len, l3_len, l4_len 등을 사용하는 라이브러리가 존재함\nreassembly Tx checksum offload Reassembly rte_ipv6_frag_reassemble_packet(), rte_ipv4_frag_reassemble_packet() Incoming mbuf should have its l2_len and l3_len fields setup correctly.\nL4 checksum HW offloading To use hardware L4 checksum offload, the user needs to\nfill l2_len and l3_len in mbuf set the flags PKT_TX_TCP_CKSUM, PKT_TX_SCTP_CKSUM or PKT_TX_UDP_CKSUM set the flag PKT_TX_IPV4 or PKT_TX_IPV6 calculate the pseudo header checksum and set it in the L4 header (only for TCP or UDP). See rte_ipv4_phdr_cksum() and rte_ipv6_phdr_cksum(). For SCTP, set the crc field to 0. L3 checksum HW offloading set the flag PKT_TX_IPV4 (IP checksum은 IPv4에만 존재) set the IP checksum field in the packet to 0 fill the mbuf offload information: l2_len, l3_len PKT_TX_IP_CKSUM IP checksum offloading example from prog_guide/mbuf_lib.rst\nThis is supported on hardware advertising DEV_TX_OFFLOAD_IPV4_CKSUM.\nmb-\u0026gt;l2_len = len(out_eth) mb-\u0026gt;l3_len = len(out_ip) mb-\u0026gt;ol_flags |= PKT_TX_IPV4 | PKT_TX_IP_CSUM set out_ip checksum to 0 in the packet IP, UDP checksum offloading\nThis is supported on hardware advertising DEV_TX_OFFLOAD_IPV4_CKSUM and DEV_TX_OFFLOAD_UDP_CKSUM.\nmb-\u0026gt;l2_len = len(out_eth) mb-\u0026gt;l3_len = len(out_ip) mb-\u0026gt;ol_flags |= PKT_TX_IPV4 | PKT_TX_IP_CSUM | PKT_TX_UDP_CKSUM set out_ip checksum to 0 in the packet set out_udp checksum to pseudo header using rte_ipv4_phdr_cksum() Outer IP, inner IP and inner TCP checksum offloading\nThis is supported on hardware advertising DEV_TX_OFFLOAD_IPV4_CKSUM, DEV_TX_OFFLOAD_UDP_CKSUM and DEV_TX_OFFLOAD_OUTER_IPV4_CKSUM.\nmb-\u0026gt;outer_l2_len = len(out_eth) mb-\u0026gt;outer_l3_len = len(out_ip) mb-\u0026gt;l2_len = len(out_udp + vxlan + in_eth) mb-\u0026gt;l3_len = len(in_ip) mb-\u0026gt;ol_flags |= PKT_TX_OUTER_IPV4 | PKT_TX_OUTER_IP_CKSUM | \\ PKT_TX_IP_CKSUM | PKT_TX_TCP_CKSUM; set out_ip checksum to 0 in the packet set in_ip checksum to 0 in the packet set in_tcp checksum to pseudo header using rte_ipv4_phdr_cksum() ","date":"2016-03-06T08:22:24+09:00","permalink":"https://cychong47.github.io/post/2016/header-length-in-mbuf/","summary":"\u003cp\u003e\u003ccode\u003el2_len\u003c/code\u003e, \u003ccode\u003el3_len\u003c/code\u003e, \u003ccode\u003el4_len\u003c/code\u003e 등을 사용하는 라이브러리가 존재함\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003ereassembly\u003c/li\u003e\n\u003cli\u003eTx checksum offload\u003c/li\u003e\n\u003c/ol\u003e\n\u003ch3 id=\"reassembly\"\u003eReassembly\u003c/h3\u003e\n\u003cp\u003e\u003ccode\u003erte_ipv6_frag_reassemble_packet()\u003c/code\u003e, \u003ccode\u003erte_ipv4_frag_reassemble_packet()\u003c/code\u003e\nIncoming mbuf should have its \u003ccode\u003el2_len\u003c/code\u003e and \u003ccode\u003el3_len\u003c/code\u003e fields setup correctly.\u003c/p\u003e\n\u003ch3 id=\"l4-checksum-hw-offloading\"\u003eL4 checksum HW offloading\u003c/h3\u003e\n\u003cp\u003eTo use hardware L4 checksum offload, the user needs to\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003efill \u003ccode\u003el2_len\u003c/code\u003e and \u003ccode\u003el3_len\u003c/code\u003e in mbuf\u003c/li\u003e\n\u003cli\u003eset the flags \u003ccode\u003ePKT_TX_TCP_CKSUM\u003c/code\u003e, \u003ccode\u003ePKT_TX_SCTP_CKSUM\u003c/code\u003e or \u003ccode\u003ePKT_TX_UDP_CKSUM\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003eset the flag \u003ccode\u003ePKT_TX_IPV4\u003c/code\u003e or \u003ccode\u003ePKT_TX_IPV6\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003ecalculate the pseudo header checksum and set it in the L4 header (only for TCP or UDP). See \u003ccode\u003erte_ipv4_phdr_cksum()\u003c/code\u003e and \u003ccode\u003erte_ipv6_phdr_cksum()\u003c/code\u003e. For SCTP, set the crc field to 0.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"l3-checksum-hw-offloading\"\u003eL3 checksum HW offloading\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eset the flag \u003ccode\u003ePKT_TX_IPV4\u003c/code\u003e (IP checksum은 IPv4에만 존재)\u003c/li\u003e\n\u003cli\u003eset the IP checksum field in the packet to 0\u003c/li\u003e\n\u003cli\u003efill the mbuf offload information: \u003ccode\u003el2_len\u003c/code\u003e, \u003ccode\u003el3_len\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003ePKT_TX_IP_CKSUM\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"ip-checksum-offloading\"\u003eIP checksum offloading\u003c/h3\u003e\n\u003cp\u003eexample from \u003ccode\u003eprog_guide/mbuf_lib.rst\u003c/code\u003e\u003c/p\u003e","title":"DPDK new mbuf 사용 주의사항"},{"content":"DPDK to KNI RX KNI는 rx_q로부터 mbuf를 수신한 후 data_len 크기의 skb를 할당하여 데이터를 복사한 후 netif_rx를 호출한다. 그러므로 mbuf는 KNI kernel module까지만 사용되고, 커널 networking stack에서는 사용되지는 않는다.\nkni_net.c의 kni_net_rx_normal() 함수가 DPDK application으로부터 mbuf를 받아 커널에 전달하는 함수인데 실제 함수는 batch processing을 위해 한번에 여러 개의 패킷을 rx_q로부터 읽어 처리하도록 구현되어 있다.\n아래는 하나의 패킷에 대해 수행되는 코드를 간략화 한 것이다(예외 처리 부분도 제외)\nnum_rx = kni_fifo_get(kni-\u0026gt;rx_q, (void **)va, num_rx); kva = (void *)va[i] - kni-\u0026gt;mbuf_va + kni-\u0026gt;mbuf_kva; len = kva-\u0026gt;data_len; data_kva = kva-\u0026gt;buf_addr + kva-\u0026gt;data_off - kni-\u0026gt;mbuf_va + kni-\u0026gt;mbuf_kva; skb = dev_alloc_skb(len + 2); /* Align IP on 16B boundary */ skb_reserve(skb, 2); memcpy(skb_put(skb, len), data_kva, len); skb-\u0026gt;dev = dev; skb-\u0026gt;protocol = eth_type_trans(skb, dev); skb-\u0026gt;ip_summed = CHECKSUM_UNNECESSARY; /* Call netif interface */ netif_rx(skb); /* Update statistics */ kni-\u0026gt;stats.rx_bytes += len; kni-\u0026gt;stats.rx_packets++; /* Burst enqueue mbufs into free_q */ ret = kni_fifo_put(kni-\u0026gt;free_q, (void **)va, num_rx); In case DPDK application restarted\n만일 DPPK application이 비정상적으로 종료되어 다시 실행하는 경우 버퍼를 초기화 과정에서 문제가 발생할 수 있다.\n1. DPDK -\u0026gt; KNI rx_q나 free_q에는 이전 DPDK application에서 KNI에 전달했던 mbuf정보이다. 해당 버퍼 영역은 더 이상 유효하지 않고, rx_q, free_q 조차도 유효하지 않다. 그러므로 새로 실행된 DPDK application이 rx_q, free_q에 접근하여 queue에 존재하는 버퍼를 처리하는 것 조차 문제될 수 있다(확실한가???)\n2. KNI -\u0026gt; DPDK tx_q나 alloc_q 역시 rx_q, free_q 와 동일한 이슈를 갖는다. Tx를 위해 사용할 mbuf를 미리 할당해 놓은 alloc_q에 존재하는 mbuf는 이전 DPDK application이 할당한 것이고, tx_q 에 존재하는 mbuf 역시 동일하다.\nstruct rte_kni_mbuf는 DPDK와 KNI kernel module간 통신할 때 사용되는 구조체로 rte_mbuf 중 KNI에게 필요한 정보만 모은 것이다.\n/* * The kernel image of the rte_mbuf struct, with only the relevant fields. * Padding is necessary to assure the offsets of these fields */ struct rte_kni_mbuf { void *buf_addr __attribute__((__aligned__(RTE_CACHE_LINE_SIZE))); char pad0[10]; uint16_t data_off; /**\u0026lt; Start address of data in segment buffer. */ char pad1[4]; uint64_t ol_flags; /**\u0026lt; Offload features. */ char pad2[4]; uint32_t pkt_len; /**\u0026lt; Total pkt len: sum of all segment data_len. */ uint16_t data_len; /**\u0026lt; Amount of data in segment buffer. */ /* fields on second cache line */ char pad3[8] __attribute__((__aligned__(RTE_CACHE_LINE_SIZE))); void *pool; void *next; }; ","date":"2016-03-06T08:17:58+09:00","permalink":"https://cychong47.github.io/post/2016/how_kni_free_mbuf/","summary":"\u003ch1 id=\"dpdk-to-kni-rx\"\u003eDPDK to KNI RX\u003c/h1\u003e\n\u003cp\u003eKNI는 \u003ccode\u003erx_q\u003c/code\u003e로부터 mbuf를 수신한 후 \u003ccode\u003edata_len\u003c/code\u003e 크기의 skb를 할당하여 데이터를 복사한 후 \u003ccode\u003enetif_rx\u003c/code\u003e를 호출한다.\n그러므로 mbuf는 KNI kernel module까지만 사용되고, 커널 networking stack에서는 사용되지는 않는다.\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003ekni_net.c\u003c/code\u003e의 \u003ccode\u003ekni_net_rx_normal()\u003c/code\u003e 함수가 DPDK application으로부터 mbuf를 받아 커널에 전달하는 함수인데 실제 함수는 batch processing을 위해 한번에 여러 개의 패킷을 \u003ccode\u003erx_q\u003c/code\u003e로부터 읽어 처리하도록 구현되어 있다.\u003c/p\u003e\n\u003cp\u003e아래는 하나의 패킷에 대해 수행되는 코드를 간략화 한 것이다(예외 처리 부분도 제외)\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003enum_rx = kni_fifo_get(kni-\u0026gt;rx_q, (void **)va, num_rx);\n\nkva = (void *)va[i] - kni-\u0026gt;mbuf_va + kni-\u0026gt;mbuf_kva;\nlen = kva-\u0026gt;data_len;\ndata_kva = kva-\u0026gt;buf_addr + kva-\u0026gt;data_off - kni-\u0026gt;mbuf_va + kni-\u0026gt;mbuf_kva;\n\nskb = dev_alloc_skb(len + 2);\n\n/* Align IP on 16B boundary */\nskb_reserve(skb, 2);\nmemcpy(skb_put(skb, len), data_kva, len);\nskb-\u0026gt;dev = dev;\nskb-\u0026gt;protocol = eth_type_trans(skb, dev);\nskb-\u0026gt;ip_summed = CHECKSUM_UNNECESSARY;\n\n/* Call netif interface */\nnetif_rx(skb);\n\n/* Update statistics */\nkni-\u0026gt;stats.rx_bytes += len;\nkni-\u0026gt;stats.rx_packets++;\n\n/* Burst enqueue mbufs into free_q */\nret = kni_fifo_put(kni-\u0026gt;free_q, (void **)va, num_rx);\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003eIn case DPDK application restarted\u003c/p\u003e","title":"KNI가 buffer를 free 하는 방법"},{"content":"Without Suppressing Scapy IPv6 warning cychong@ubuntu:~$ python Python 2.7.6 (default, Jun 22 2015, 17:58:13) [GCC 4.8.2] on linux2 Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; from scapy.all import * WARNING: No route found for IPv6 destination :: (no default route?) \u0026gt;\u0026gt;\u0026gt; Suppress scapy IPv6 warning cychong@ubuntu:~$ python Python 2.7.6 (default, Jun 22 2015, 17:58:13) [GCC 4.8.2] on linux2 Type \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information. \u0026gt;\u0026gt;\u0026gt; import logging \u0026gt;\u0026gt;\u0026gt; logging.getLogger(\u0026#34;scapy.runtime\u0026#34;).setLevel(logging.ERROR) \u0026gt;\u0026gt;\u0026gt; from scapy.all import * \u0026gt;\u0026gt;\u0026gt; ","date":"2016-03-03T14:50:24+09:00","permalink":"https://cychong47.github.io/post/2016/scapy-suppress-scapy-warning-message/","summary":"\u003ch1 id=\"without-suppressing-scapy-ipv6-warning\"\u003eWithout Suppressing Scapy IPv6 warning\u003c/h1\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@ubuntu:~$ python\nPython 2.7.6 (default, Jun 22 2015, 17:58:13)\n[GCC 4.8.2] on linux2\nType \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information.\n\u0026gt;\u0026gt;\u0026gt; from scapy.all import *\nWARNING: No route found for IPv6 destination :: (no default route?)\n\u0026gt;\u0026gt;\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e\u003ch1 id=\"suppress-scapy-ipv6-warning\"\u003eSuppress scapy IPv6 warning\u003c/h1\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003ecychong@ubuntu:~$ python\nPython 2.7.6 (default, Jun 22 2015, 17:58:13)\n[GCC 4.8.2] on linux2\nType \u0026#34;help\u0026#34;, \u0026#34;copyright\u0026#34;, \u0026#34;credits\u0026#34; or \u0026#34;license\u0026#34; for more information.\n\u0026gt;\u0026gt;\u0026gt; import logging\n\u0026gt;\u0026gt;\u0026gt; logging.getLogger(\u0026#34;scapy.runtime\u0026#34;).setLevel(logging.ERROR)\n\u0026gt;\u0026gt;\u0026gt; from scapy.all import *\n\u0026gt;\u0026gt;\u0026gt;\n\u003c/code\u003e\u003c/pre\u003e","title":"(Scapy) Suppress Scapy warning message"},{"content":"import modules $ python \u0026gt;\u0026gt;\u0026gt; from scapy.all import * \u0026gt;\u0026gt;\u0026gt; from scapy.layers.ipsec import * build plaintext packet \u0026gt;\u0026gt;\u0026gt; p = IP(src=\u0026#39;1.1.1.1\u0026#39;, dst=\u0026#39;2.2.2.2\u0026#39;) / TCP(sport=45012, dport=80) / Raw(\u0026#39;testdata\u0026#39;) \u0026gt;\u0026gt;\u0026gt; p = IP(str(p)) setup SA \u0026gt;\u0026gt;\u0026gt; sa = SecurityAssociation(ESP, spi=0xdeadbeef, crypt_algo=\u0026#39;AES-CBC\u0026#39;,crypt_key=\u0026#39;sixteenbytes key\u0026#39;) Encrypt w/o IV \u0026gt;\u0026gt;\u0026gt; e = sa.encrypt(p, 5) \u0026gt;\u0026gt;\u0026gt; e \u0026lt;IP version=4L ihl=5L tos=0x0 len=76 id=1 flags= frag=0L ttl=64 proto=esp chksum=0x747a src=1.1.1.1 dst=2.2.2.2 |\u0026lt;ESP spi=0xdeadbeef seq=5 data=\u0026#39;uD\\x7fdj19\\xe7\\xc4\\xff8\\x10\\xcdQ\\xf0\\xa6\\x1e!\\x84\\xc3\u0026gt;!\\x18\\xa6\\xf6\\xb8\\x93\\xc6it\\x9a\\xfc\\x1c\\xee\\xe5C\\xcd\\xf0\\x7fD\\xca\\x8d\\xadKh\\xa8\\xe5x\u0026#39; |\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; e.show() ###[ IP ]### version = 4L ihl = 5L tos = 0x0 len = 76 id = 1 flags = frag = 0L ttl = 64 proto = esp chksum = 0x747a src = 1.1.1.1 dst = 2.2.2.2 \\options \\ ###[ ESP ]### spi = 0xdeadbeef seq = 5 data = \u0026#39;uD\\x7fdj19\\xe7\\xc4\\xff8\\x10\\xcdQ\\xf0\\xa6\\x1e!\\x84\\xc3\u0026gt;!\\x18\\xa6\\xf6\\xb8\\x93\\xc6it\\x9a\\xfc\\x1c\\xee\\xe5C\\xcd\\xf0\\x7fD\\xca\\x8d\\xadKh\\xa8\\xe5x\u0026#39; Encrypt w/ IV \u0026gt;\u0026gt;\u0026gt; e = sa.encrypt(p, 5, \u0026#34;1234567890123456\u0026#34;) \u0026gt;\u0026gt;\u0026gt; e \u0026lt;IP version=4L ihl=5L tos=0x0 len=76 id=1 flags= frag=0L ttl=64 proto=esp chksum=0x747a src=1.1.1.1 dst=2.2.2.2 |\u0026lt;ESP spi=0xdeadbeef seq=5 data=\u0026#39;1234567890123456\\xa4\\x0b\\xebZ\\xa7\\xc8\\xb6\\x95\\xfb\\x13\\x07\\xc5TD\\xa2\\xe7DP\\xfcP\\xa5y\\xc4\\x06W\\xe8\\xf5\\xf0\\x86\\xe1\\x0c\\xfd\u0026#39; |\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; e.show() ###[ IP ]### version = 4L ihl = 5L tos = 0x0 len = 76 id = 1 flags = frag = 0L ttl = 64 proto = esp chksum = 0x747a src = 1.1.1.1 dst = 2.2.2.2 \\options \\ ###[ ESP ]### spi = 0xdeadbeef seq = 5 data = \u0026#39;1234567890123456\\xa4\\x0b\\xebZ\\xa7\\xc8\\xb6\\x95\\xfb\\x13\\x07\\xc5TD\\xa2\\xe7DP\\xfcP\\xa5y\\xc4\\x06W\\xe8\\xf5\\xf0\\x86\\xe1\\x0c\\xfd\u0026#39; data 의 시작 부분에 IV값 \u0026lsquo;1234567890123456\u0026rsquo;이 있음을 알 수 있다. ESP는 SPI(4B), SEQ(4B), IV(16B) , Encrypted Data 형태로 구성된다.\n만일 IV값의 길이가 틀리면 다음와 같이 에러 출력\n\u0026gt;\u0026gt;\u0026gt; e = sa.encrypt(p, 5, \u0026#34;1234567890\u0026#34;) Traceback (most recent call last): File \u0026#34;\u0026lt;stdin\u0026gt;\u0026#34;, line 1, in \u0026lt;module\u0026gt; File \u0026#34;ipsec.py\u0026#34;, line 903, in encrypt return self._encrypt_esp(pkt, seq_num=seq_num, iv=iv) File \u0026#34;ipsec.py\u0026#34;, line 787, in _encrypt_esp raise TypeError(\u0026#39;iv length must be %s\u0026#39; % self.crypt_algo.iv_size) TypeError: iv length must be 16 SecurityAssocaition 옵션 1. tunnel_header Tunnel mode를 사용하려면 tunnel_header 인자로 outer IP header instance를 넘긴다.\n\u0026gt;\u0026gt;\u0026gt; outer_ip = IP(src=\u0026#39;10.10.10.10\u0026#39;, dst=\u0026#39;20.20.20.20\u0026#39;) \u0026gt;\u0026gt;\u0026gt; sa = SecurityAssociation(ESP, spi=0xdeadbeef, crypt_algo=\u0026#39;AES-CBC\u0026#39;,crypt_key=\u0026#39;sixteenbytes key\u0026#39;, tunnel_header=outer_ip) \u0026gt;\u0026gt;\u0026gt; e = sa.encrypt(p, 5, \u0026#34;1234567890123456\u0026#34;) \u0026gt;\u0026gt;\u0026gt; e \u0026lt;IP version=4L ihl=5L tos=0x0 len=108 id=1 flags= frag=0L ttl=64 proto=esp chksum=0x3e24 src=10.10.10.10 dst=20.20.20.20 |\u0026lt;ESP spi=0xdeadbeef seq=5 data=\u0026#39;1234567890123456`\\xc6\\xa9\\xe9Q\\x97-\\xd6\\xe5\\x07\\xb3\\x85\\xfb\\xc9\\xeaz\\x07~\\xfe\\x14\\xd1\\x19\\xd8F\\x8cS\\x10[\\x8f\\xfe\\x93_ut\\xef1\\xc0\\xc4|\\xdb\\xccH\\xea\\xf8\\xd2\\xd0jj\\xeeD\\x88\\x80\\xc5}U\\xb5_x)\\xaal/,\\x96\u0026#39; |\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; e.show() ###[ IP ]### version = 4L ihl = 5L tos = 0x0 len = 108 id = 1 flags = frag = 0L ttl = 64 proto = esp chksum = 0x3e24 src = 10.10.10.10 dst = 20.20.20.20 \\options \\ ###[ ESP ]### spi = 0xdeadbeef seq = 5 data = \u0026#39;1234567890123456`\\xc6\\xa9\\xe9Q\\x97-\\xd6\\xe5\\x07\\xb3\\x85\\xfb\\xc9\\xeaz\\x07~\\xfe\\x14\\xd1\\x19\\xd8F\\x8cS\\x10[\\x8f\\xfe\\x93_ut\\xef1\\xc0\\xc4|\\xdb\\xccH\\xea\\xf8\\xd2\\xd0jj\\xeeD\\x88\\x80\\xc5}U\\xb5_x)\\xaal/,\\x96\u0026#39; Tunnel mode를 사용하지 않은 경우와 별반 차이가 없어 보이지만, IP의 total length값이 기존 76바이에서 108바이트로 변경되었고, ESP data값도 달라졌다. Tunnel mode의 경우 ESP data에 원본 패킷 전체가 포함되는 반면 Transport mode이 경우 L4 layer이상만 포함되므로 값이 달라진다. IP total length의 경우 32바이트가 차이나는데 20 + 12 ???? FIMXE\n2. nat_t_header NAT traversal을 위해는 UDP encapsulation을 이용하는데 이 역시 SA 를 생성할 때 지정할 수 있다. IP total length의 경우 추가된 8byte의 UDP header가 고려되어 108byte에서 116byte로 커졌다.\n\u0026gt;\u0026gt;\u0026gt; nat_t_udp = UDP(dport=4500) \u0026gt;\u0026gt;\u0026gt; sa = SecurityAssociation(ESP, spi=0xdeadbeef, crypt_algo=\u0026#39;AES-CBC\u0026#39;,crypt_key=\u0026#39;sixteenbytes key\u0026#39;, tunnel_header=outer_ip, nat_t_header=nat_t_udp) \u0026gt;\u0026gt;\u0026gt; e = sa.encrypt(p, 5, \u0026#34;1234567890123456\u0026#34;) \u0026gt;\u0026gt;\u0026gt; e \u0026lt;IP version=4L ihl=5L tos=0x0 len=116 id=1 flags= frag=0L ttl=64 proto=udp chksum=0x3e3d src=10.10.10.10 dst=20.20.20.20 options=[] |\u0026lt;UDP sport=domain dport=ipsec_nat_t len=8 chksum=0x0 |\u0026lt;ESP spi=0xdeadbeef seq=5 data=\u0026#39;1234567890123456`\\xc6\\xa9\\xe9Q\\x97-\\xd6\\xe5\\x07\\xb3\\x85\\xfb\\xc9\\xeaz\\x07~\\xfe\\x14\\xd1\\x19\\xd8F\\x8cS\\x10[\\x8f\\xfe\\x93_ut\\xef1\\xc0\\xc4|\\xdb\\xccH\\xea\\xf8\\xd2\\xd0jj\\xeeD\\x88\\x80\\xc5}U\\xb5_x)\\xaal/,\\x96\u0026#39; |\u0026gt;\u0026gt;\u0026gt; \u0026gt;\u0026gt;\u0026gt; e.show() ###[ IP ]### version = 4L ihl = 5L tos = 0x0 len = 116 id = 1 flags = frag = 0L ttl = 64 proto = udp chksum = 0x3e3d src = 10.10.10.10 dst = 20.20.20.20 \\options \\ ###[ UDP ]### sport = domain dport = ipsec_nat_t len = 8 chksum = 0x0 ###[ ESP ]### spi = 0xdeadbeef seq = 5 data = \u0026#39;1234567890123456`\\xc6\\xa9\\xe9Q\\x97-\\xd6\\xe5\\x07\\xb3\\x85\\xfb\\xc9\\xeaz\\x07~\\xfe\\x14\\xd1\\x19\\xd8F\\x8cS\\x10[\\x8f\\xfe\\x93_ut\\xef1\\xc0\\xc4|\\xdb\\xccH\\xea\\xf8\\xd2\\xd0jj\\xeeD\\x88\\x80\\xc5}U\\xb5_x)\\xaal/,\\x96\u0026#39; ","date":"2016-02-14T14:59:42+09:00","permalink":"https://cychong47.github.io/post/2016/how-to-use-snapy-for-ipsec/","summary":"\u003ch2 id=\"import-modules\"\u003eimport modules\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e$ python\n\u0026gt;\u0026gt;\u0026gt; from scapy.all import *\n\u0026gt;\u0026gt;\u0026gt; from scapy.layers.ipsec import *\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"build-plaintext-packet\"\u003ebuild plaintext packet\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e\u0026gt;\u0026gt;\u0026gt; p = IP(src=\u0026#39;1.1.1.1\u0026#39;, dst=\u0026#39;2.2.2.2\u0026#39;) / TCP(sport=45012, dport=80) / Raw(\u0026#39;testdata\u0026#39;) \n\u0026gt;\u0026gt;\u0026gt; p = IP(str(p))\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"setup-sa\"\u003esetup SA\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e\u0026gt;\u0026gt;\u0026gt; sa = SecurityAssociation(ESP, spi=0xdeadbeef, crypt_algo=\u0026#39;AES-CBC\u0026#39;,crypt_key=\u0026#39;sixteenbytes key\u0026#39;)\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"encrypt-wo-iv\"\u003eEncrypt w/o IV\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e\u0026gt;\u0026gt;\u0026gt; e = sa.encrypt(p, 5)\n\u0026gt;\u0026gt;\u0026gt; e\n\u0026lt;IP  version=4L ihl=5L tos=0x0 len=76 id=1 flags= frag=0L ttl=64 proto=esp chksum=0x747a src=1.1.1.1 dst=2.2.2.2 |\u0026lt;ESP  spi=0xdeadbeef seq=5 data=\u0026#39;uD\\x7fdj19\\xe7\\xc4\\xff8\\x10\\xcdQ\\xf0\\xa6\\x1e!\\x84\\xc3\u0026gt;!\\x18\\xa6\\xf6\\xb8\\x93\\xc6it\\x9a\\xfc\\x1c\\xee\\xe5C\\xcd\\xf0\\x7fD\\xca\\x8d\\xadKh\\xa8\\xe5x\u0026#39; |\u0026gt;\u0026gt;\n\u0026gt;\u0026gt;\u0026gt; e.show()\n###[ IP ]###\n  version   = 4L\n  ihl       = 5L\n  tos       = 0x0\n  len       = 76\n  id        = 1\n  flags     = \n  frag      = 0L\n  ttl       = 64\n  proto     = esp\n  chksum    = 0x747a\n  src       = 1.1.1.1\n  dst       = 2.2.2.2\n  \\options   \\\n###[ ESP ]###\n     spi       = 0xdeadbeef\n     seq       = 5\n     data      = \u0026#39;uD\\x7fdj19\\xe7\\xc4\\xff8\\x10\\xcdQ\\xf0\\xa6\\x1e!\\x84\\xc3\u0026gt;!\\x18\\xa6\\xf6\\xb8\\x93\\xc6it\\x9a\\xfc\\x1c\\xee\\xe5C\\xcd\\xf0\\x7fD\\xca\\x8d\\xadKh\\xa8\\xe5x\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003ch2 id=\"encrypt-w-iv\"\u003eEncrypt w/ IV\u003c/h2\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e\u0026gt;\u0026gt;\u0026gt; e = sa.encrypt(p, 5, \u0026#34;1234567890123456\u0026#34;)\n\u0026gt;\u0026gt;\u0026gt; e\n\u0026lt;IP  version=4L ihl=5L tos=0x0 len=76 id=1 flags= frag=0L ttl=64 proto=esp chksum=0x747a src=1.1.1.1 dst=2.2.2.2 |\u0026lt;ESP  spi=0xdeadbeef seq=5 data=\u0026#39;1234567890123456\\xa4\\x0b\\xebZ\\xa7\\xc8\\xb6\\x95\\xfb\\x13\\x07\\xc5TD\\xa2\\xe7DP\\xfcP\\xa5y\\xc4\\x06W\\xe8\\xf5\\xf0\\x86\\xe1\\x0c\\xfd\u0026#39; |\u0026gt;\u0026gt;\n\u0026gt;\u0026gt;\u0026gt; e.show()\n###[ IP ]###\n  version   = 4L\n  ihl       = 5L\n  tos       = 0x0\n  len       = 76\n  id        = 1\n  flags     = \n  frag      = 0L\n  ttl       = 64\n  proto     = esp\n  chksum    = 0x747a\n  src       = 1.1.1.1\n  dst       = 2.2.2.2\n  \\options   \\\n###[ ESP ]###\n     spi       = 0xdeadbeef\n     seq       = 5\n     data      = \u0026#39;1234567890123456\\xa4\\x0b\\xebZ\\xa7\\xc8\\xb6\\x95\\xfb\\x13\\x07\\xc5TD\\xa2\\xe7DP\\xfcP\\xa5y\\xc4\\x06W\\xe8\\xf5\\xf0\\x86\\xe1\\x0c\\xfd\u0026#39;\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003edata 의 시작 부분에  IV값 \u0026lsquo;1234567890123456\u0026rsquo;이 있음을 알 수 있다.\nESP는 SPI(4B), SEQ(4B), IV(16B) , Encrypted Data 형태로 구성된다.\u003c/p\u003e","title":"how to build IPsec packet with scapy"},{"content":"다음과 같이 scapy를 이용해서 fragment를 쉽게 만들 수 있다.\nfrom scapy.all import * dip=\u0026#34;10.0.0.1\u0026#34; payload=\u0026#34; \u0026#34;*1000 packet=IP(dst=dip)/UDP(dport=0x1234)/payload frag_list=fragment(packet,fragsize=500) counter=1 for fragment in frag_list: print \u0026#34;Packet no%d\u0026#34; %counter print fragment.show() counter+=1 send(fragment) frag_list에서 counter 변수를 확인해서 전송하지 않으면 간단하게 fragment가 수신되지 않은 경우에 시험할 수 있음.\n필요하면 frag_list의 순서를 뒤집는 것도 가능하고, 각 fragment의 offset값을 조정하거나 패킷 크기를 변경하면 다른 비정상 경우도 쉽게 시험할 수 있다.\nscapy interactive tutorial\n","date":"2016-02-14T13:57:41+09:00","permalink":"https://cychong47.github.io/post/2016/fragment-missing-test-with-scapy/","summary":"\u003cp\u003e다음과 같이 scapy를 이용해서 fragment를 쉽게 만들 수 있다.\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003efrom scapy.all import *\n\ndip=\u0026#34;10.0.0.1\u0026#34;\npayload=\u0026#34; \u0026#34;*1000\n\npacket=IP(dst=dip)/UDP(dport=0x1234)/payload\n \nfrag_list=fragment(packet,fragsize=500)\n \ncounter=1\nfor fragment in frag_list:\n  print \u0026#34;Packet no%d\u0026#34; %counter\n  print \n\n  fragment.show()\n  counter+=1\n  send(fragment)\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003efrag_list에서 counter 변수를 확인해서 전송하지 않으면 간단하게 fragment가 수신되지 않은 경우에 시험할 수 있음.\u003c/p\u003e\n\u003cp\u003e필요하면 frag_list의 순서를 뒤집는 것도 가능하고, 각 fragment의 offset값을 조정하거나 패킷 크기를 변경하면 다른 비정상 경우도 쉽게 시험할 수 있다.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://www.secdev.org/projects/scapy/doc/usage.html#interactive-tutorial\"\u003escapy interactive tutorial\u003c/a\u003e\u003c/p\u003e","title":"fragment missing test with scapy"},{"content":"Vagrant\nfd.io의 개발 환경 구성하는 문서를 보니 vagrant를 사용한다. 그런데 또 virtualbox니 vmware 이야기를 한다. 이전에도 vagrant라는 단어를 들어본적이 있었는데 이번 기회에 좀 알아보기로\nWhy Vagrant를 보면 다음과 같이 설명하고 있다.\nVagrant provides easy to configure, reproducible, and portable work environments built on top of industry-standard technology and controlled by a single consistent workflow to help maximize the productivity and flexibility of you and your team.\nTo achieve its magic, Vagrant stands on the shoulders of giants. Machines are provisioned on top of VirtualBox, VMware, AWS, or any other provider. Then, industry-standard provisioning tools such as shell scripts, Chef, or Puppet, can be used to automatically install and configure software on the machine.\nChef, Puppet 역시 다른 글에서 본 적은 있지만 구체적으로 뭔지는 모른다. 하지만 대충(?) 이해하기에는 VirtualBox, vmware, AWS용 이미지 등을 만드는데 필요한 설정 내용을 기술하는 방법으로 보인다. 그래서 지원하는 몇 가지 양식에 맞게 필요한 요구사항을 기술하면 vagrant가 VM용 이미지를 만들어 준다는 것으로 보인다.\nVPP 빌드를 생각해 보면 다음과 같다.\nVirtualBox 혹은 vmware 설치 vagrant up 명령 실행. 아마도 지정한 VAGRANT PROVIDER(VirtualBox 혹은 wmware)에 맞는 VM 이미지를 생성 VM 실행 흠. 그런데 vagrant up 명령을 내\n","date":"2016-02-14T07:52:01+09:00","permalink":"https://cychong47.github.io/post/2016/vagrant/","summary":"\u003cp\u003eVagrant\u003c/p\u003e\n\u003cp\u003efd.io의 개발 환경 구성하는 문서를 보니 vagrant를 사용한다. 그런데 또 virtualbox니 vmware 이야기를 한다.\n이전에도 vagrant라는 단어를 들어본적이 있었는데 이번 기회에 좀 알아보기로\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.vagrantup.com/docs/why-vagrant/\"\u003eWhy Vagrant\u003c/a\u003e를 보면 다음과 같이 설명하고 있다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eVagrant provides easy to configure, reproducible, and portable work environments built on top of industry-standard technology and controlled by a single consistent workflow to help maximize the productivity and flexibility of you and your team.\u003c/p\u003e\n\u003cp\u003eTo achieve its magic, Vagrant stands on the shoulders of giants. Machines are provisioned on top of VirtualBox, VMware, AWS, or any other provider. Then, industry-standard provisioning tools such as shell scripts, Chef, or Puppet, can be used to automatically install and configure software on the machine.\u003c/p\u003e","title":"Vagrant"},{"content":"├── build-data │ ├── packages │ └── platforms ├── build-root │ ├── deb │ │ └── debian │ │ └── source │ ├── emacs-lisp │ ├── packages │ ├── rpm │ ├── scripts │ └── vagrant ├── dpdk │ ├── dkms │ ├── dpdk-2.1.0_patches │ └── dpdk-2.2.0_patches ├── g2 ├── gmod │ └── gmod ├── perftool ├── sample-plugin │ └── sample ├── svm ├── test │ ├── resources │ │ ├── libraries │ │ │ ├── bash │ │ │ ├── python │ │ │ └── robot │ │ │ └── vat │ │ └── templates │ │ └── vat │ └── tests │ └── suites │ ├── bridge_domain │ └── vhost_user_dummy ├── vlib │ ├── example │ └── vlib │ └── unix ├── vlib-api │ ├── vlibapi │ ├── vlibmemory │ └── vlibsocket ├── vnet │ ├── etc │ │ └── scripts │ │ ├── dhcp │ │ ├── ludd-cluster-1 │ │ ├── ludd-cluster-3 │ │ ├── mpls-o-ethernet │ │ ├── mpls-o-gre │ │ ├── sr │ │ └── virl │ └── vnet │ ├── cdp │ ├── classify │ ├── devices │ │ ├── dpdk │ │ ├── ssvm │ │ └── virtio │ ├── dhcp │ ├── dhcpv6 │ ├── ethernet │ ├── flow │ ├── gre │ ├── hdlc │ ├── ip │ ├── ipsec │ ├── l2 │ ├── l2tp │ ├── lawful-intercept │ ├── lisp-gpe │ ├── llc │ ├── map │ │ └── examples │ ├── mcast │ ├── mpls-gre │ ├── nsh-gre │ ├── nsh-vxlan-gpe │ ├── osi │ ├── pg │ ├── plugin │ ├── policer │ ├── ppp │ ├── snap │ ├── sr │ ├── srp │ ├── unix │ ├── vcgn │ └── vxlan ├── vpp │ ├── api │ ├── app │ ├── conf │ ├── oam │ ├── stats │ └── vnet ├── vpp-api-test │ ├── scripts │ └── vat ├── vpp-japi │ ├── japi │ │ ├── org │ │ │ └── openvpp │ │ │ └── vppjapi │ │ └── test │ └── m4 ├── vppapigen └── vppinfra ├── config ├── tools └── vppinfra ","date":"2016-02-13T05:51:52+09:00","permalink":"https://cychong47.github.io/post/2016/fd-io-tree/","summary":"\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e├── build-data\n│   ├── packages\n│   └── platforms\n├── build-root\n│   ├── deb\n│   │   └── debian\n│   │       └── source\n│   ├── emacs-lisp\n│   ├── packages\n│   ├── rpm\n│   ├── scripts\n│   └── vagrant\n├── dpdk\n│   ├── dkms\n│   ├── dpdk-2.1.0_patches\n│   └── dpdk-2.2.0_patches\n├── g2\n├── gmod\n│   └── gmod\n├── perftool\n├── sample-plugin\n│   └── sample\n├── svm\n├── test\n│   ├── resources\n│   │   ├── libraries\n│   │   │   ├── bash\n│   │   │   ├── python\n│   │   │   └── robot\n│   │   │       └── vat\n│   │   └── templates\n│   │       └── vat\n│   └── tests\n│       └── suites\n│           ├── bridge_domain\n│           └── vhost_user_dummy\n├── vlib\n│   ├── example\n│   └── vlib\n│       └── unix\n├── vlib-api\n│   ├── vlibapi\n│   ├── vlibmemory\n│   └── vlibsocket\n├── vnet\n│   ├── etc\n│   │   └── scripts\n│   │       ├── dhcp\n│   │       ├── ludd-cluster-1\n│   │       ├── ludd-cluster-3\n│   │       ├── mpls-o-ethernet\n│   │       ├── mpls-o-gre\n│   │       ├── sr\n│   │       └── virl\n│   └── vnet\n│       ├── cdp\n│       ├── classify\n│       ├── devices\n│       │   ├── dpdk\n│       │   ├── ssvm\n│       │   └── virtio\n│       ├── dhcp\n│       ├── dhcpv6\n│       ├── ethernet\n│       ├── flow\n│       ├── gre\n│       ├── hdlc\n│       ├── ip\n│       ├── ipsec\n│       ├── l2\n│       ├── l2tp\n│       ├── lawful-intercept\n│       ├── lisp-gpe\n│       ├── llc\n│       ├── map\n│       │   └── examples\n│       ├── mcast\n│       ├── mpls-gre\n│       ├── nsh-gre\n│       ├── nsh-vxlan-gpe\n│       ├── osi\n│       ├── pg\n│       ├── plugin\n│       ├── policer\n│       ├── ppp\n│       ├── snap\n│       ├── sr\n│       ├── srp\n│       ├── unix\n│       ├── vcgn\n│       └── vxlan\n├── vpp\n│   ├── api\n│   ├── app\n│   ├── conf\n│   ├── oam\n│   ├── stats\n│   └── vnet\n├── vpp-api-test\n│   ├── scripts\n│   └── vat\n├── vpp-japi\n│   ├── japi\n│   │   ├── org\n│   │   │   └── openvpp\n│   │   │       └── vppjapi\n│   │   └── test\n│   └── m4\n├── vppapigen\n└── vppinfra\n    ├── config\n    ├── tools\n    └── vppinfra\n\u003c/code\u003e\u003c/pre\u003e","title":"fd.io"},{"content":"2016년 2월 11일 공개된 CISCO 주도의 프로젝트. 무려 2002년부터 개발한 것으로 현재 버전은 3번째 revision이라고 한다.\n간만에 dpdk.org mailing list에 들어갔다 가장 최근에 올라온 글 제목이 눈에 띄었다.\n[dpdk-dev] [dpdk-announce] new project using DPDK - FD.io Vincent JARDIN\n\u0026ldquo;new project\u0026rdquo;?\n그래서 내용을 봤더니 이게 다 였다는\nA new project using DPDK is available, http://FD.io said FiDo You can clone it from: http://gerrit.fd.io/ Best regards, Vincent 그래도 첫 번째 링크를 따라가 보니 화려하다. CISCO, Ericsson, Intel이 platinum member네. 어딜가나 있는 여러 회사 이름도 보이고. Cavium도 있네. ODP를 밀고 있는데 잘 안되나? 물론 내용을 보면 조금 다르긴 하지만.\n거기에 6wind도 있다. 역시 직접적인 경쟁회사라고 볼 수도 있을 텐데. E, H사가 보이는데 N사는 아직 없다. OFP에 집중하려는 걸까\n코드는 github에 올려있어 확인해 봐야겠지만, https://fd.io/technology 에 설명된 내용을 잠깐 보면 이런 특징을 갖는다고 한다.\nVector Packet Processing Rather than processing the first packet through the whole graph, and then the second packet through the whole graph, VPP instead processes the entire vector of packets through a graph node before moving on to the next graph node. ... Picking up each tool in order for each piece of lumber is going to be much slower. 예전 Network Processor와 달리 Instruction Cache의 영향을 많이 받는 General Purpose Processor를 목적으로 한 SW라 instruction cache miss에 대한 고민을 많이 한 듯 하다.\n기능 들은 graph node라고 표현했는데 일반적인 모듈 형태와 동일한 것으로 이해되고\nConfiguration 설정관련해서는 다양한 방법을 제공한다. 이를 윟 HoneyComb Agent라는 것을 두는데 NetConf/Yang, REST 등의 인터페이스를 제공한다.\nExternal App과의 연동도 가능한데 C혹은 Java library를 지원한다고 한다. 이 부분도 좀 구체적으로 봐야 할 듯 한데.\n재밌는 프로젝트로 보인다. 기존에 하고 있는 일과 많이 겹치는 게 사실이라는 것이 이슈지만\u0026hellip;\n성능 관련 내용은 lightreading 기사(2015년 10월) Validating Cisco\u0026rsquo;s NFV Infrastructure Pt. 1 를 참고. Part 2도 참고\nbuild 빌드하려면 VM과 valgrid환경이 필요하다고 하는데.\nSetting Up Your Dev Environment\nmailing list vpp-dev, mail archive irc 2/11일 당일 기사 The Linux Foundation Forms Open Source Effort to Advance IO Services\nfounding members 6WIND, Brocade, Cavium, Cisco, Comcast, Ericsson, Huawei, Inocybe Technologies, Intel Corporation, Mesosphere, Metaswitch Networks (Project Calico), PLUMgrid and Red Hat The design of FD.io is hardware, kernel, and deployment (bare metal, VM, container) agnostic. providing an out-of-the-box vSwitch/vRouter VPP is production code currently running in products available on the market today. VPP runs in user space on multiple architectures, including x86, ARM, and Power, and is deployed on various platforms including servers and embedded devices. Continuous Performance Lab (CPL). The CPL provides an open source, fully automated testing infrastructure framework for continuous verification of code functionality and performance. Code breakage and performance degradation is flagged before patch review, conserving project resources and increasing code quality. ","date":"2016-02-13T01:29:43+09:00","permalink":"https://cychong47.github.io/post/2016/fd-io/","summary":"\u003cp\u003e2016년 2월 11일 공개된 CISCO 주도의 프로젝트.\n무려 2002년부터 개발한 것으로 현재 버전은 3번째 revision이라고 한다.\u003cbr\u003e\n간만에 dpdk.org mailing list에 들어갔다 가장 최근에 올라온 글 제목이 눈에 띄었다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e[dpdk-dev] [dpdk-announce] new project using DPDK - FD.io   Vincent JARDIN\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u0026ldquo;new project\u0026rdquo;?\u003c/p\u003e\n\u003cp\u003e그래서 내용을 봤더니 이게 다 였다는\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eA new project using DPDK is available,\n   http://FD.io\nsaid\n   FiDo\n\nYou can clone it from:\n   http://gerrit.fd.io/\n\nBest regards,\n   Vincent\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e그래도 첫 번째 링크를 따라가 보니 화려하다. CISCO, Ericsson, Intel이 platinum member네. 어딜가나 있는 여러 회사 이름도 보이고. Cavium도 있네. ODP를 밀고 있는데 잘 안되나? 물론 내용을 보면 조금 다르긴 하지만.\u003cbr\u003e\n거기에 6wind도 있다. 역시 직접적인 경쟁회사라고 볼 수도 있을 텐데. E, H사가 보이는데 N사는 아직 없다. OFP에 집중하려는 걸까\u003c/p\u003e","title":"fd.io"},{"content":" 왜 공부해야 하는가\n사회의 변화속도는 우리의 변화속도를 압도하기 때문입니다.\n\u0026lt;누가 내 치즈를 옮겼을까\u0026gt;에 잘 묘사되어 있지요.\n따라잡지 않으면 뒤쳐지기 때문에 우리는 늘 공부해야 합니다.\nhttps://brunch.co.kr/@choihs0228/4\n","date":"2016-02-10T04:23:12+09:00","permalink":"https://cychong47.github.io/post/2016/why_have_to_keep_studying/","summary":"\u003cblockquote\u003e\n\u003cp\u003e왜 공부해야 하는가\u003cbr\u003e\n사회의 변화속도는 우리의 변화속도를 압도하기 때문입니다.\u003cbr\u003e\n\u0026lt;누가 내 치즈를 옮겼을까\u0026gt;에 잘 묘사되어 있지요.\u003cbr\u003e\n따라잡지 않으면 뒤쳐지기 때문에 우리는 늘 공부해야 합니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u003ca href=\"https://brunch.co.kr/@choihs0228/4\"\u003ehttps://brunch.co.kr/@choihs0228/4\u003c/a\u003e\u003c/p\u003e","title":"왜 공부해야 하는가에 대한 간단하지만 명확한 답"},{"content":"constructor attribute http://phoxis.org/2011/04/27/c-language-constructors-and-destructors-with-gcc/\nconstructor attribute을 가진 함수는 main 함수를 실행하기 전에 호출한다.\n예제 (출처)\n#include \u0026lt;stdio.h\u0026gt; void begin (void) __attribute__((constructor)); void end (void) __attribute__((destructor)); int main (void) { printf (\u0026#34;\\nInside main ()\u0026#34;); } void begin (void) { printf (\u0026#34;\\nIn begin ()\u0026#34;); } void end (void) { printf (\u0026#34;\\nIn end ()\\n\u0026#34;); } 실행하면\nIn begin () Inside main () In end () DPDK DPDK의 경우 device driver들을 모두 constructor attirbute을 사용해서 main 함수 전에 호출되록 한다.\nPMD_REGISTER_DRIVER(pmd_igb_drv); PMD_REGISTER_DRIVER(pmd_igbvf_drv); PMD_REGISTER_DRIVER(em_pmd_drv); Physical device 외에 virtual device들도 동일하게 등록한다.\nPMD_REGISTER_DRIVER(cryptodev_aesni_mb_pmd_drv); PMD_REGISTER_DRIVER(pmd_qat_drv); PMD_REGISTER_DRIVER()는 lib/librte_eal/common/include/rte_dev.h에 다음과 같이 정의되어 있다.\n#define PMD_REGISTER_DRIVER(d)\\ void devinitfn_ ##d(void);\\ void __attribute__((constructor, used)) devinitfn_ ##d(void)\\ {\\ rte_eal_driver_register(\u0026amp;d);\\ } rte_eal_deriver_register()는 lib/librte_eal/common/eal_common_dev.c에서 static 변수로 정의된 rte_driver_list[]에 함수 인자로 넘겨진 driver를 등록한다.\n인자는 다음 struct 형태로 정의된다.\n/** * A structure describing a device driver. */ struct rte_driver { TAILQ_ENTRY(rte_driver) next; /**\u0026lt; Next in list. */ enum pmd_type type; /**\u0026lt; PMD Driver type */ const char *name; /**\u0026lt; Driver name. */ rte_dev_init_t *init; /**\u0026lt; Device init. function. */ rte_dev_uninit_t *uninit; /**\u0026lt; Device uninit. function. */ }; 등록된 디바이스들은 rte_eal_init() 초기화 과정에서 호출되는 함수 rte_eal_dev_init()에서 각 디바이스의 초기화 함수가 호출된다.\nint rte_eal_dev_init(void) { /* call the init function for each virtual device */ TAILQ_FOREACH(devargs, \u0026amp;devargs_list, next) { if (devargs-\u0026gt;type != RTE_DEVTYPE_VIRTUAL) continue; if (rte_eal_vdev_init(devargs-\u0026gt;virt.drv_name, devargs-\u0026gt;args)) { ... } /* Once the vdevs are initalized, start calling all the pdev drivers */ TAILQ_FOREACH(driver, \u0026amp;dev_driver_list, next) { if (driver-\u0026gt;type != PMD_PDEV) continue; /* PDEV drivers don\u0026#39;t get passed any parameters */ driver-\u0026gt;init(NULL, NULL); } QAT device static struct rte_driver pmd_qat_drv = { .type = PMD_PDEV, .init = rte_qat_pmd_init, }; QAT PMD 초기화 rte_qat_pmd_init() rte_cryptodev_pmd_driver_register() rte_cryptodev_init() \u0026amp; rte_eal_pci_register() AESNI_MB device static struct rte_driver cryptodev_aesni_mb_pmd_drv = { .name = CRYPTODEV_NAME_AESNI_MB_PMD, .type = PMD_VDEV, .init = cryptodev_aesni_mb_init, .uninit = cryptodev_aesni_mb_uninit }; AESNI_MB 초기화 cryptodev_aesni_mb_init() cryptodev_aesni_mb_create() CPU가 AES 연산을 지원하는 지 확인 CPU가 AVX2/AVX/SSE4_1 중 최소 한 가지를 지원하는 지 확인 rte_cryptodev_pmd_virtual_dev_init()를 이용해 PMD device로 등록 e1000 static int rte_em_pmd_init(const char *name __rte_unused, const char *params __rte_unused) { rte_eth_driver_register(\u0026amp;rte_em_pmd); return 0; } struct rte_driver em_pmd_drv = { .type = PMD_PDEV, .init = rte_em_pmd_init, }; Physical NIC은 rte_eth_driver_register()함수를 이용하여 rte_eth_dev에 등록된다. 이때 등록되는 디바이스 구조체는 다음과 같다.\nstatic struct eth_driver rte_em_pmd = { .pci_drv = { .name = \u0026#34;rte_em_pmd\u0026#34;, .id_table = pci_id_em_map, .drv_flags = RTE_PCI_DRV_NEED_MAPPING | RTE_PCI_DRV_INTR_LSC | RTE_PCI_DRV_DETACHABLE, }, .eth_dev_init = eth_em_dev_init, .eth_dev_uninit = eth_em_dev_uninit, .dev_private_size = sizeof(struct e1000_adapter), }; rte_eth 구조체에 등록하는 함수 rte_eth_driver_register()는 다음과 같이 구현되어 있어, PCI device list에 NIC을 등록한다. 등록된 PCI device들은 rte_eal_init() 과정에서 호출되는 PCI scan 과정을 통해 실제 NIC을 찾는 과정을 거친다.\n/** * Register an Ethernet [Poll Mode] driver. * * Function invoked by the initialization function of an Ethernet driver * to simultaneously register itself as a PCI driver and as an Ethernet * Poll Mode Driver. * Invokes the rte_eal_pci_register() function to register the *pci_drv* * structure embedded in the *eth_drv* structure, after having stored the * address of the rte_eth_dev_init() function in the *devinit* field of * the *pci_drv* structure. * During the PCI probing phase, the rte_eth_dev_init() function is * invoked for each PCI [Ethernet device] matching the embedded PCI * identifiers provided by the driver. */ void rte_eth_driver_register(struct eth_driver *eth_drv) { eth_drv-\u0026gt;pci_drv.devinit = rte_eth_dev_init; eth_drv-\u0026gt;pci_drv.devuninit = rte_eth_dev_uninit; rte_eal_pci_register(\u0026amp;eth_drv-\u0026gt;pci_drv); } ","date":"2016-02-09T14:54:21+09:00","permalink":"https://cychong47.github.io/post/2016/dpdk_nic_init/","summary":"\u003ch3 id=\"constructor-attribute\"\u003econstructor attribute\u003c/h3\u003e\n\u003cp\u003e\u003ca href=\"http://phoxis.org/2011/04/27/c-language-constructors-and-destructors-with-gcc/\"\u003ehttp://phoxis.org/2011/04/27/c-language-constructors-and-destructors-with-gcc/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003econstructor attribute을 가진 함수는 main 함수를 실행하기 전에 호출한다.\u003c/p\u003e\n\u003cp\u003e예제 (\u003ca href=\"http://phoxis.org/2011/04/27/c-language-constructors-and-destructors-with-gcc/\"\u003e출처\u003c/a\u003e)\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e#include \u0026lt;stdio.h\u0026gt;\n \nvoid begin (void) __attribute__((constructor));\nvoid end (void) __attribute__((destructor));\n \nint main (void)\n{\n  printf (\u0026#34;\\nInside main ()\u0026#34;);\n}\n \nvoid begin (void)\n{\n  printf (\u0026#34;\\nIn begin ()\u0026#34;);\n}\n \nvoid end (void)\n{\n  printf (\u0026#34;\\nIn end ()\\n\u0026#34;);\n}\n\u003c/code\u003e\u003c/pre\u003e\u003cp\u003e실행하면\u003c/p\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eIn begin ()\nInside main ()\nIn end ()\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"dpdk\"\u003eDPDK\u003c/h3\u003e\n\u003cp\u003eDPDK의 경우 device driver들을 모두 constructor attirbute을 사용해서 main 함수 전에 호출되록 한다.\u003c/p\u003e","title":"DPDK NIC 초기화"},{"content":"Introducing Python 을 판교어린이도서관에서 짧게 보고 적은 아이템들\npython3 based\nDecorator는 공부가 필요한 내용\nsys.path : module 검색 경로 __init__.py 파일이 있으면 그 디렉토리를 PKG로 간주함\ndefaultdic()\nCounters()\ndicionary는 key의 순서를 보장하지 않음. OrderedDict()로 사전을 정의하면 가능 deque = stack + queue pprint()는 print보다 깔끔하게 출력한다고.\n'\\uXXX' 유니코드\n%10.4s : 10칸의 공간. 문자열 중 4개만 출력\nstruct '\u0026gt;LL' : '\u0026gt;' Big endian, L : uint32_t\nlist comprehension : for loop보다 빠름. 어떻게 사용하는 지 구체적으로 좀 더 알아봐야 함.\nConfiguration pyyaml : load() 대신 safe_load() 사용 1단계 정보면 내장 configuration을 사용하는 것이 가장 편리함. ConfigParser()\n[A] B=C 접근할 때는 config = ConfigParser(filename)\nconfig[\u0026lsquo;A\u0026rsquo;][\u0026lsquo;B\u0026rsquo;]\nRedis Redis 서버. pip install redis redit.Redis() Request - Agent - Redis server - Checker\npip install requests\ngevent\nfab을 이용해 명령을 내린 후 PKG 정보를 알아낼 수 있음. cat XXX /pkg/.RegInfo endtime 파일 확인\nmodule dependency pip -r requirements.txt\ndebugging pylint\npyflakes\npep8\n","date":"2016-02-08T13:25:34+09:00","permalink":"https://cychong47.github.io/post/2016/introducing-python/","summary":"\u003cp\u003eIntroducing Python 을 판교어린이도서관에서 짧게 보고 적은 아이템들\u003c/p\u003e\n\u003cp\u003epython3 based\u003c/p\u003e\n\u003cp\u003eDecorator는 공부가 필요한 내용\u003c/p\u003e\n\u003cp\u003esys.path : module 검색 경로\n\u003ccode\u003e__init__.py\u003c/code\u003e 파일이 있으면 그 디렉토리를 PKG로 간주함\u003cbr\u003e\ndefaultdic()\u003cbr\u003e\nCounters()\u003cbr\u003e\ndicionary는 key의 순서를 보장하지 않음.  OrderedDict()로 사전을 정의하면 가능 \u003cbr\u003e\ndeque = stack + queue\npprint()는 print보다 깔끔하게 출력한다고.\u003cbr\u003e\n\u003ccode\u003e'\\uXXX'\u003c/code\u003e 유니코드\u003cbr\u003e\n\u003ccode\u003e%10.4s\u003c/code\u003e : 10칸의 공간. 문자열 중 4개만 출력\u003cbr\u003e\nstruct \u003ccode\u003e'\u0026gt;LL'\u003c/code\u003e : \u003ccode\u003e'\u0026gt;'\u003c/code\u003e Big endian, \u003ccode\u003eL\u003c/code\u003e : uint32_t\u003c/p\u003e\n\u003cp\u003elist comprehension : for loop보다 빠름. 어떻게 사용하는 지 구체적으로 좀 더 알아봐야 함.\u003c/p\u003e","title":"Introducing Python"},{"content":"SR-IOV and DPDK\nAccelerating the NFV Data Plane : SR-IOV and DPDK… in my own words 를 읽고 요약\nBefore HW assisted Virtualisation SR-IOV 전까지는 VMM이 패킷 송수신에 매번 개입해야 했음.\n1st interrupt from NIC to VMM 2nd interrupt from VMM to VM Intel VMDq Only one interrupt from NIC to VM as each VM has its own Rx queue.\nSR-IOV SR-IOV : Standard IO memory Memory Management Unit from Intel(VT-d) and AMD(IOV) Virtual Function - Limited, lightweight, PCIe resource and a dedicated Tx/Rx packet queue Interrupt 부담이 없다고 하는데 왜??? 마지막 결론에서는 SR-IOV를 사용하면 interrupt를 두 개 다 없앨 수 있다고 하는데 이 부분은 잘 이해가 안된다. HW 기반 SR-IOV and vSwitch SR-IOV는 VMM의 부담을 덜어주는 장점을 가지고 있지만, 반대로 vSwitch가 제공할 수 있는 네트웍 기능들 - portability, flexibility, QoS, complex traffic steering 등을 이용할 수 없게 되었다는. 문제는 이런 기능들이 NFV환경에서 필요하고(할 거고). vSwitch의 기능을 사용할 수 없으면 service chaining 같은 건 고민할 것도 없고, 위 기능들을 모두 각 VNF에서 구현해야 하는데. 물론 기존 PNF가 그랬던 것 처럼 못할 것도 없지만, 한 곳에 모아놓은 VNF사이에 구현해야 하는 공통 기능이면 가능하면 NFVI에서 구현할 수 있으면 좋겠지\nSR-IOV is good for stand-alone virtualised appliance or architecture where high-traffic VNFs, routers and L3 centric devices vSwitch is good for strict intra-host east-west demands\nHybrid architecture requires additional management complexities and rule out the possibility of a common, efficient and flexible SDN shot deployment infrastructure\nSR-IOV it isn’t currently possible to take advantage of overlay-based network virtualization, which is commonly used in large-scale virtualization environments.\nAccelerated vSwitch solutions do support overlay-based network virtualization, they are less efficient overall and they may also expose additional security risks through the use of shared memory that may be accessible from untrusted VMs on the same compute node.\nOVS/DPDK Megaflow : wildcard\nMicro flow : exact match based cache\nExcept 64B, SR-IOV and OVS/DPDK shows almost same performance against Bare-Metal (HP) http://www.slideshare.net/jstleger/dpdk-summit-2015-hp-al-sanders\nHowever, IMAX shows 50-60% is 64Byte\nhttp://www.metaswitch.com/the-switch/tackling-the-nfv-packet-performance-challenge\nTackling the NFV Packet Performance Challenge\nSR-IOV vs. virtue SRIOV is good for some cases in a VM but does not scale to many VMs or containers as NIC’s support for VF is limited in number and performance\nSRIOV is very god in the host user space to gain direct access to the devices.\nRight-now, virtue is the only solution we have today as a standard\n","date":"2016-02-07T23:40:26+09:00","permalink":"https://cychong47.github.io/post/2016/sriov-and-dpdk/","summary":"\u003cp\u003eSR-IOV and DPDK\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://www.metaswitch.com/the-switch/accelerating-the-nfv-data-plane\"\u003eAccelerating the NFV Data Plane : SR-IOV and DPDK… in my own words\u003c/a\u003e 를 읽고 요약\u003c/p\u003e\n\u003ch2 id=\"before-hw-assisted-virtualisation\"\u003eBefore HW assisted Virtualisation\u003c/h2\u003e\n\u003cp\u003eSR-IOV  전까지는 VMM이 패킷 송수신에 매번 개입해야 했음.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e1st interrupt from NIC to VMM\u003c/li\u003e\n\u003cli\u003e2nd interrupt from VMM to VM\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"intel-vmdq\"\u003eIntel VMDq\u003c/h2\u003e\n\u003cp\u003eOnly one interrupt from NIC to VM as each VM has its own Rx queue.\u003c/p\u003e\n\u003ch2 id=\"sr-iov\"\u003eSR-IOV\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eSR-IOV  : Standard IO memory Memory Management Unit from Intel(VT-d) and AMD(IOV)\u003c/li\u003e\n\u003cli\u003eVirtual Function - Limited, lightweight, PCIe resource and a dedicated Tx/Rx packet queue\u003c/li\u003e\n\u003cli\u003eInterrupt 부담이 없다고 하는데 왜??? 마지막 결론에서는 SR-IOV를 사용하면 interrupt를 두 개 다 없앨 수 있다고 하는데 이 부분은 잘 이해가 안된다.\nHW  기반\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"sr-iov-and-vswitch\"\u003eSR-IOV and vSwitch\u003c/h2\u003e\n\u003cp\u003eSR-IOV는 VMM의 부담을 덜어주는 장점을 가지고 있지만, 반대로 vSwitch가 제공할 수 있는 네트웍 기능들 - portability, flexibility, QoS, complex traffic steering 등을 이용할 수 없게 되었다는. 문제는 이런 기능들이 NFV환경에서 필요하고(할 거고). vSwitch의 기능을 사용할 수 없으면 service chaining 같은 건 고민할 것도 없고, 위 기능들을 모두 각 VNF에서 구현해야 하는데. 물론 기존 PNF가 그랬던 것 처럼 못할 것도 없지만, 한 곳에 모아놓은 VNF사이에 구현해야 하는 공통 기능이면 가능하면 NFVI에서 구현할 수 있으면 좋겠지\u003c/p\u003e","title":"SR-IOV and DPDK"},{"content":"pktmbuf_offload pool은 rte_pktmbuf_offload_pool_create()를 사용하여 생성 l2fwd_mbuf_ol_pool = rte_pktmbuf_offload_pool_create( \u0026#34;mbuf_offload_pool\u0026#34;, NB_MBUF, 128, 0, rte_socket_id()); 할당은 rte_pktmbuf_offload_alloc()를 이용. rte_pktmbuf_offload_alloc(l2fwd_mbuf_ol_pool, RTE_PKTMBUF_OL_CRYPTO); mbuf 마다 하나씩 할당해서 crypto 연산에 사용 crypto 연산에 필요한 추가 옵션 등을 설정함. /* Append space for digest to end of packet */ ol-\u0026gt;op.crypto.digest.data = (uint8_t *)rte_pktmbuf_append(m, cparams-\u0026gt;digest_length); ol-\u0026gt;op.crypto.digest.phys_addr = rte_pktmbuf_mtophys_offset(m, rte_pktmbuf_pkt_len(m) - cparams-\u0026gt;digest_length); ol-\u0026gt;op.crypto.digest.length = cparams-\u0026gt;digest_length; ol-\u0026gt;op.crypto.iv.data = cparams-\u0026gt;iv_key.data; ol-\u0026gt;op.crypto.iv.phys_addr = cparams-\u0026gt;iv_key.phys_addr; ol-\u0026gt;op.crypto.iv.length = cparams-\u0026gt;iv_key.length; ol-\u0026gt;op.crypto.data.to_cipher.offset = ipdata_offset; ol-\u0026gt;op.crypto.data.to_cipher.length = data_len; ol-\u0026gt;op.crypto.data.to_hash.offset = ipdata_offset; ol-\u0026gt;op.crypto.data.to_hash.length = data_len; l2fwd_simple_crypto_enqueue() crypto operation에 맞게 data align에 맞게 padding rte_crypto_op_attach_session() ol-\u0026gt;op에 crypto 연산에 필요한 정보를 설정 crypto 대상 위치, 길이 등 session 개념이 있는데 정확히 뭔지는 모르겠음… rte_crypto_op_attach_session() op-\u0026gt;session = sess; op-\u0026gt;type = RTE_CRYPTO_OP_WITH_SESSION; rte_pktmbuf_offload_attach() l2fwd_crypto_enqueue() l2fwd_crypto_send_burst() rte_cryptodev_enqueue_burst() struct rte_mbuf_offload /** * Generic packet mbuf offload * This is used to specify a offload operation to be performed on a rte_mbuf. * Multiple offload operations can be chained to the same mbuf, but only a * single offload operation of a particular type can be in the chain */ struct rte_mbuf_offload { struct rte_mbuf_offload *next; /**\u0026lt; next offload in chain */ struct rte_mbuf *m; /**\u0026lt; mbuf offload is attached to */ struct rte_mempool *mp; /**\u0026lt; mempool offload allocated from */ enum rte_mbuf_ol_op_type type; /**\u0026lt; offload type */ union { struct rte_crypto_op crypto; /**\u0026lt; Crypto operation */ } op; }; ","date":"2016-01-24T15:08:11+09:00","permalink":"https://cychong47.github.io/post/2016/dpdk-2-2-crypto-dev-api/","summary":"\u003ch3 id=\"pktmbuf_offload\"\u003epktmbuf_offload\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003epool은 \u003ccode\u003erte_pktmbuf_offload_pool_create()\u003c/code\u003e를 사용하여 생성\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003el2fwd_mbuf_ol_pool = rte_pktmbuf_offload_pool_create(\n            \u0026#34;mbuf_offload_pool\u0026#34;, NB_MBUF, 128, 0, rte_socket_id());\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e할당은 \u003ccode\u003erte_pktmbuf_offload_alloc()\u003c/code\u003e를 이용.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003erte_pktmbuf_offload_alloc(l2fwd_mbuf_ol_pool, RTE_PKTMBUF_OL_CRYPTO);\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003embuf 마다 하나씩 할당해서 crypto 연산에 사용\u003c/li\u003e\n\u003cli\u003ecrypto 연산에 필요한 추가 옵션 등을 설정함.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e/* Append space for digest to end of packet */\nol-\u0026gt;op.crypto.digest.data = (uint8_t *)rte_pktmbuf_append(m,\n\t\tcparams-\u0026gt;digest_length);\nol-\u0026gt;op.crypto.digest.phys_addr = rte_pktmbuf_mtophys_offset(m,\n\t\trte_pktmbuf_pkt_len(m) - cparams-\u0026gt;digest_length);\nol-\u0026gt;op.crypto.digest.length = cparams-\u0026gt;digest_length;\n\nol-\u0026gt;op.crypto.iv.data = cparams-\u0026gt;iv_key.data;\nol-\u0026gt;op.crypto.iv.phys_addr = cparams-\u0026gt;iv_key.phys_addr;\nol-\u0026gt;op.crypto.iv.length = cparams-\u0026gt;iv_key.length;\n\nol-\u0026gt;op.crypto.data.to_cipher.offset = ipdata_offset;\nol-\u0026gt;op.crypto.data.to_cipher.length = data_len;\n\nol-\u0026gt;op.crypto.data.to_hash.offset = ipdata_offset;\nol-\u0026gt;op.crypto.data.to_hash.length = data_len;\n\u003c/code\u003e\u003c/pre\u003e\u003ch3 id=\"l2fwd_simple_crypto_enqueue\"\u003e\u003ccode\u003el2fwd_simple_crypto_enqueue()\u003c/code\u003e\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003ecrypto operation에 맞게 data align에 맞게 padding\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003erte_crypto_op_attach_session()\u003c/code\u003e\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003eol-\u0026gt;op\u003c/code\u003e에 crypto 연산에 필요한 정보를 설정\n\u003cul\u003e\n\u003cli\u003ecrypto 대상 위치, 길이 등\u003c/li\u003e\n\u003cli\u003esession 개념이 있는데 정확히 뭔지는 모르겠음…\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ccode\u003erte_crypto_op_attach_session()\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003eop-\u0026gt;session = sess;\nop-\u0026gt;type = RTE_CRYPTO_OP_WITH_SESSION;\n\u003c/code\u003e\u003c/pre\u003e\u003cul\u003e\n\u003cli\u003e\u003ccode\u003erte_pktmbuf_offload_attach()\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"l2fwd_crypto_enqueue\"\u003e\u003ccode\u003el2fwd_crypto_enqueue()\u003c/code\u003e\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003el2fwd_crypto_send_burst()\u003c/code\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ccode\u003erte_cryptodev_enqueue_burst()\u003c/code\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"struct-rte_mbuf_offload\"\u003e\u003ccode\u003estruct rte_mbuf_offload\u003c/code\u003e\u003c/h3\u003e\n\u003cpre tabindex=\"0\"\u003e\u003ccode\u003e/**\n * Generic packet mbuf offload\n * This is used to specify a offload operation to be performed on a rte_mbuf.\n * Multiple offload operations can be chained to the same mbuf, but only a\n * single offload operation of a particular type can be in the chain\n */\nstruct rte_mbuf_offload {\n        struct rte_mbuf_offload *next;  /**\u0026lt; next offload in chain */\n        struct rte_mbuf *m;             /**\u0026lt; mbuf offload is attached to */\n        struct rte_mempool *mp;         /**\u0026lt; mempool offload allocated from */\n\n        enum rte_mbuf_ol_op_type type;  /**\u0026lt; offload type */\n        union {\n                struct rte_crypto_op crypto;    /**\u0026lt; Crypto operation */\n        } op;\n};\n\u003c/code\u003e\u003c/pre\u003e","title":"DPDK 2.2 crypto dev API"},{"content":"2016.02.10 기준\nDPDK-dump TRex - Realistic traffic generator\ngit-hub - trex-core, trex-doc, trex-profiles, trex-qt-gui Packet-journey git-hub FD.io Fast Data Path DPDK-nginx DPDK-pktgen DPDK-ODP TCP/IP stack for DPDK ","date":"2016-01-24T14:59:18+09:00","permalink":"https://cychong47.github.io/post/2016/dpdk_based_apps/","summary":"\u003cp\u003e2016.02.10 기준\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/marty90/DPDK-Dump\"\u003eDPDK-dump\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://trex-tgn.cisco.com\"\u003eTRex - Realistic traffic generator\u003c/a\u003e\u003cbr\u003e\n\u003ca href=\"https://github.com/cisco-system-traffic-generator\"\u003egit-hub\u003c/a\u003e - \u003ca href=\"https://github.com/cisco-system-traffic-generator/trex-core\"\u003etrex-core\u003c/a\u003e, \u003ca href=\"https://github.com/cisco-system-traffic-generator/trex-doc\"\u003etrex-doc\u003c/a\u003e, \u003ca href=\"https://github.com/cisco-system-traffic-generator/trex-profiles\"\u003etrex-profiles\u003c/a\u003e, \u003ca href=\"https://github.com/cisco-system-traffic-generator/trex-qt-gui\"\u003etrex-qt-gui\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.gandi.net/news/en/2015-12-16/6308-packet-journey_a_free_software_router_for_linux_based_on_dpdk/\"\u003ePacket-journey\u003c/a\u003e\n\u003ca href=\"https://github.com/Gandi/packet-journey\"\u003egit-hub\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://fd.io\"\u003eFD.io\u003c/a\u003e Fast Data Path\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/opendp/dpdk-nginx\"\u003eDPDK-nginx\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://dpdk.org/browse/apps/pktgen-dpdk/refs/\"\u003eDPDK-pktgen\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://github.com/opendp/dpdk-odp\"\u003eDPDK-ODP\u003c/a\u003e TCP/IP stack for DPDK\u003c/li\u003e\n\u003c/ol\u003e","title":"DPDK based applications"},{"content":"우연히 tumblr를 보니 2013년에 적었던 답답한 현실이 지금도 똑같다는 사실에 놀랐다. 들으려고 하는 사람은 없고, 쓸데없는 일에 시간을 보내는 건 지금도 전혀 바뀐게 없어 보인다.\n여전히 사용하라는 툴에서 제공하는 정보와 취합해 달라고 하는 정보가 다르다. 그럼 어떻게 하라는 건지? 툴을 고치던가, 툴의 정보를 원하는 정보로 바꾸는 기준을 제시해줘야 하는 거 아닌가? 내용은 관심없고, 그냥 결과만 달라고 하는. 자기가 그런 변환 작업을 한 적이 없으니 얼마나 귀찮은지 모르는 거다. 그리고 사람마다 다른 기준으로 정보를 취합해도 별 문제가 없다는 건 결국 별로 중요하지 않는 내용이라는 거다. 그런 걸 사람들이 못 느낄까? 다 안다. 결국 정보를 제공해야 하는 사람도 대충 대충 하게 된다. 악순환.\n정말 이젠 지겹다.\n","date":"2016-01-04T15:19:11+09:00","permalink":"https://cychong47.github.io/post/2016/two-years-back/","summary":"\u003cp\u003e우연히 tumblr를 보니 2013년에 적었던 답답한 현실이 지금도 똑같다는 사실에 놀랐다. 들으려고 하는 사람은 없고, 쓸데없는 일에 시간을 보내는 건 지금도 전혀 바뀐게 없어 보인다.\u003c/p\u003e\n\u003cp\u003e여전히 사용하라는 툴에서 제공하는 정보와 취합해 달라고 하는 정보가 다르다. 그럼 어떻게 하라는 건지? 툴을 고치던가, 툴의 정보를 원하는 정보로 바꾸는 기준을 제시해줘야 하는 거 아닌가?\n내용은 관심없고, 그냥 결과만 달라고 하는. 자기가 그런 변환 작업을 한 적이 없으니 얼마나 귀찮은지 모르는 거다. 그리고 사람마다 다른 기준으로 정보를 취합해도 별 문제가 없다는 건 결국 별로 중요하지 않는 내용이라는 거다. 그런 걸 사람들이 못 느낄까? 다 안다. 결국 정보를 제공해야 하는 사람도 대충 대충 하게 된다. 악순환.\u003c/p\u003e","title":"2년전에 느꼈던 답답함이 여전하네"},{"content":"일단 읽다가 중단. 다른 걸 먼저 봐야 할 것 같다. 공감하는 내용이 많지만 이 책을 본다고 내가 어쩔 수 있는 내용이 별로 없어서\u0026hellip;.\np78\n이렇게 투명하게 공개함으로써 얻을 수 있는 이득은 회사의 모든 직원이 현재 무슨 일이 어떻게 진행되고 있는 지 알게 된다는 것이다. 어쩌면 별것 아닌 것처럼 들릴 수도 있지만 전혀 그렇지 않다. 덩치가 큰 조직에서는 흔히 여러 하부 조직들이 쓸데없는 일을 하면서 자원을 낭비한다. 그러나 정보가 공유될 때 전 직원은 다른 부서나 팀의 목표가 제각기 다르다는 사실을 충분히 이해하고 내부의 소모적인 경쟁을 피한다.\np81\n투명성이 가져다주는 뜻하지 않은 이득 가운데 하나는 단지 자료를 공유하는 것만으로도 생산성이 향상된다는 점이다. 존스홉킨스 병원. 관상동맥 우회 수술의 사망률\np85\n직원의 목소리에 귀를 기울일 때 나타나는 긍정적인 효과는 이미 입증됐는데\u0026hellip;\n직원의 목소리를 이끌어내는 것은 정확한 판단과 조직에 효율성을 더하는 핵심 요인이라는 사실을 사람들은 오래전부터 알고 있었다. 직원의 목소리를 주제로 한 여러 연구조사는 직원의 목소리가 의사 결정의 질, 팀의 성과 그리고 회사의 성과에 긍정적인 효과를 발휘한다는 사실을 꾸준히 확산시켜준다.\n직원들이 가장 크게 좌절감을 느?낀 문제들은 사소하면서도 쉽게 고칠 수 있는 것들이었다.\n","date":"2016-01-04T14:03:21+09:00","permalink":"https://cychong47.github.io/post/2016/google-work-rules/","summary":"\u003cp\u003e일단 읽다가 중단. 다른 걸 먼저 봐야 할 것 같다. 공감하는 내용이 많지만 이 책을 본다고 내가 어쩔 수 있는 내용이 별로 없어서\u0026hellip;.\u003c/p\u003e\n\u003cp\u003ep78\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e이렇게 투명하게 공개함으로써 얻을 수 있는 이득은 회사의 모든 직원이 현재 무슨 일이 어떻게 진행되고 있는 지 알게 된다는 것이다. 어쩌면 별것 아닌 것처럼 들릴 수도 있지만 전혀 그렇지 않다. 덩치가 큰 조직에서는 흔히 여러 하부 조직들이 쓸데없는 일을 하면서 자원을 낭비한다. 그러나 정보가 공유될 때 전 직원은 다른 부서나 팀의 목표가 제각기 다르다는 사실을 충분히 이해하고 내부의 소모적인 경쟁을 피한다.\u003c/p\u003e","title":"(책) 구글의 아침은 자유가 시작된다."},{"content":"SCI 결과를 개선하기 위해 실질적으로 이뤄지는 노력이 안 보인다는 것. 노력한다해도 그건 관리자와 비관리자가 함께 노력해야 하는 일일텐데(관리자나 회사에 대한 불만이므로 그 불만 개선이 노력이 맞는 방향인지는 당연히 비관리지에게도 한께 논의되어야 한다) 그런 건 보기 어렵다.\n문제 제기는 니들이 하지만 문제 해결은 나만 할 수 있다고 착각은 버려야 한다. 직원들이 불만에 대해 공감도 못하는데 어떻게 그 불만을 해결하기 위해 노력할 수 있겠나. 아니 공감을 하지 못하면 이해하기 위해 혹은 설득하기 위해 함께 이야기해야 하는데 그런 노력은 대부분 알아서 하란다. 잘 될 턱이 있나.\n일년에 한 번 있는 피드백을 기다리겠다는 것 역시 불만을 제기하는 직원들이 지쳐서 포기하게 만들겠다는 게 아닌가 싶다. 직원들은 결과전에 진행상황만 봐도 자신의 이야기가 공감을 받았다고 생각하고 기뻐할 텐데 그런 점에 대한 고민은 없는 듯.\n구글의 아침은 자유가 시작된다 p218\n","date":"2016-01-02T02:44:51+09:00","permalink":"https://cychong47.github.io/post/2016/googlegeist_vs_sci/","summary":"\u003cp\u003eSCI 결과를 개선하기 위해 실질적으로 이뤄지는 노력이 안 보인다는 것. 노력한다해도 그건 관리자와 비관리자가 함께 노력해야 하는 일일텐데(관리자나 회사에 대한 불만이므로 그 불만 개선이 노력이 맞는 방향인지는 당연히 비관리지에게도 한께 논의되어야 한다) 그런 건 보기 어렵다.\u003c/p\u003e\n\u003cp\u003e문제 제기는 니들이 하지만 문제 해결은 나만 할 수 있다고 착각은 버려야 한다. 직원들이 불만에 대해 공감도 못하는데 어떻게 그 불만을 해결하기 위해 노력할 수 있겠나. 아니 공감을 하지 못하면 이해하기 위해 혹은 설득하기 위해 함께 이야기해야 하는데 그런 노력은 대부분 알아서 하란다. 잘 될 턱이 있나.\u003c/p\u003e","title":"Googlegeist vs. SCI"},{"content":"출처 : 왜 “애자일”, 특히 스크럼이 끔찍한가\n스크럼 팀에 실제 시니어 엔지니어의 역할은 없는데, 문제는 스크럼을 도입한 많은 회사에서 보통 전사적으로 시행한다는 것이다. 관리직으로 넘어가는 것 말고는, “스크럼 마스터”가 되어 이것을 말단에 도입하는 책임을 지는 선택지가 있다. 권한이 없는, 헛소리에 불과한 가짜 관리직 말이다. 스크럼 팀을 떠나서 해로운 마이크로매니지먼트를 받으면서 살지 않으려면 괴물 안으로 깊숙히 파고들어서 다른 사람에게 유해한 마이크로매니지먼트를 강요하는 수 밖에 없다. “애자일”과 스크럼이 나에게 말하는 것은 시니어 프로그래머는 반드시 필요하지 않다고 여겨지므로, 무시해도 좋으며, 마치 프로그래밍이란 35세 이전에 접어야 하는 유치한 것이라고 하는 것 같았다\n그렇게 볼 수도 있구나….\n출세지향적인 선동가 (“스크럼 마스터”) 에게는 우선 마을에 드래곤이 꼬이지 않게 하는 것보다 “드래곤 슬레이어”가 되는 것이 더 멋져 보일 것이다. 스크럼의 사업부 주도 엔지니어링에 대한 공격적인 주장의 문제점은, (“요구사항”이라 하는) 용을 꾀어내어 처치하는 것을 (“고객의 협력”이라는) 미덕으로 삼는 것이다. 처음부터 동굴에서 용을 꾀어내지 않는 편이 더 사려깊었을 것이지만.\n이건 애자일이 아니어도 흔히 적용되는 문제가 아닌가 싶다. 늘 문제가 생겨 요란스럽게(?) 문제를 해결하는 사람이 인정받지 문제가 발생하지 않도록 대비한 사람은 인정받기 어렵다. 전자는 문제를 해결했다는 눈에 보이는 성과가 있지만, 발생하지 않은 문제는 무형의 성과라 구분하기 어렵다.\n","date":"2016-01-01T15:25:13+09:00","permalink":"https://cychong47.github.io/post/2016/anti-agile/","summary":"\u003cp\u003e출처 : \u003ca href=\"http://wonnyz.tumblr.com/post/136256619316/%EC%99%9C-%EC%95%A0%EC%9E%90%EC%9D%BC-%ED%8A%B9%ED%9E%88-%EC%8A%A4%ED%81%AC%EB%9F%BC%EC%9D%B4-%EB%81%94%EC%B0%8D%ED%95%9C%EA%B0%80\"\u003e왜 “애자일”, 특히 스크럼이 끔찍한가\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e스크럼 팀에 실제 시니어 엔지니어의 역할은 없는데, 문제는 스크럼을 도입한 많은 회사에서 보통 전사적으로 시행한다는 것이다. 관리직으로 넘어가는 것 말고는, “스크럼 마스터”가 되어 이것을 말단에 도입하는 책임을 지는 선택지가 있다. 권한이 없는, 헛소리에 불과한 가짜 관리직 말이다. 스크럼 팀을 떠나서 해로운 마이크로매니지먼트를 받으면서 살지 않으려면 괴물 안으로 깊숙히 파고들어서 다른 사람에게 유해한 마이크로매니지먼트를 강요하는 수 밖에 없다. “애자일”과 스크럼이 나에게 말하는 것은 시니어 프로그래머는 반드시 필요하지 않다고 여겨지므로, 무시해도 좋으며, 마치 프로그래밍이란 35세 이전에 접어야 하는 유치한 것이라고 하는 것 같았다\u003c/p\u003e","title":"(글) 왜 “애자일”, 특히 스크럼이 끔찍한가."},{"content":"http://click.pocoo.org/5/\nC로 프로그램을 짤 때 사용할 표준 포맷도 이렇게 해야겠다.\n$ python hello.py --help Usage: hello.py [OPTIONS] Simple program that greets NAME for a total of COUNT times. Options: --count INTEGER Number of greetings. --name TEXT The person to greet. --help Show this message and exit. ","date":"2016-01-01T13:45:58+09:00","permalink":"https://cychong47.github.io/post/2016/click-python-module/","summary":"\u003cp\u003e\u003ca href=\"http://click.pocoo.org/5/\"\u003ehttp://click.pocoo.org/5/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eC로 프로그램을 짤 때 사용할 표준 포맷도 이렇게 해야겠다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e$ python hello.py --help\nUsage: hello.py [OPTIONS]\n\n  Simple program that greets NAME for a total of COUNT times.\n\nOptions:\n  --count INTEGER  Number of greetings.\n  --name TEXT      The person to greet.\n  --help           Show this message and exit.\n\u003c/code\u003e\u003c/pre\u003e","title":"click - python option 처리 모듈"},{"content":"Download dpdk-2.2.0.tar.gz Refer http://dpdk.org/download\nwget http://dpdk.org/browse/dpdk/snapshot/dpdk-2.2.0.tar.gz Download qat_mux Refer https://01.org/packet-processing/intel®-quickassist-technology-drivers-and-patches\nwget https://01.org/sites/default/files/page/qatmux.l.2.5.0-80.tgz Getting Started Guide 문서도 받아 둔다.\nwget https://01.org/sites/default/files/page/330750-004_qat_gsg.pdf Configure DPDK export RTE_SDK=/home/cychong/work/dpdk-2.2.0 export RTE_TARGET=x86_64-native-linuxapp-gcc make config T=$RTE_TARGET O=$RTE_TARGET make Configure QAT Ubuntu (14.04) 기준으로 몇 개 패키지를 설치해야 QAT를 빌드할 수 있는데 나름 기본적인 패키지들이라 그냥 설치해 놓으면 좋을 듯.\nsudo apt-get install zlib1g-dev sudo apt-get install libssl-dev 적당한 위치에 풀면 되는데 ~/work/qat에 압축을 푼 경우를 기준으로 정리\ncychong@ubuntu:~/work/qat$ ls LICENSE.GPL QAT1.5 QAT1.6 filelist installer.sh qatmux.l.2.5.0-80.tgz versionfile QAT HW에 따라사 1.5 혹은 1.6 버전을 사용해야 하는데 만일 이 두 개 버전을 모두 사용해야 하는 경우 qatmux.l.2.5.0-80.tgz도 빌드해야 한다고 한다.\nQAT1.5, QAT1.6아래에는 각각 다음과 같은 압축 파일이 있으므로 필요한 QAT 버전 밑에 있는 압축 파일을 풀어준다.\ncychong@ubuntu:~/tmp$ tree . |-- filelist |-- installer.sh |-- LICENSE.GPL |-- QAT1.5 | `-- QAT1.5.L.1.10.0-80.tar.gz |-- QAT1.6 | `-- QAT1.6.L.2.5.0-80.tar.gz |-- qatmux.l.2.5.0-80.tgz `-- versionfile 2 directories, 7 files Build QAT QAT Getting Started Guide를 보면 installer.sh을 이용해서 빌드할 수 있는데 이 스크립트는 빌드하는 머신에 QAT HW가 있는 경우에만 사용할 수 있다.\ncychong@ubuntu:~/work/qat$ sudo ./installer.sh [sudo] password for cychong: ========================================================= Welcome to Intel(R) QuickAssist Interactive Installer -v2 ========================================================= Please Select Option : ---------------------- 1 Build 2 Clean Build 3 Install 4 Uninstall 5 Show Accel Info 6 Change Configuration 7 Dependency List 0 Exit QAT Devices found: 0 QAT1.6 devices 0 QAT1.5 devices Configuration: Build Acceleration and Sample Code No Device detected And SR-IOV Disabled Exit and re-enter to set defaults 1 Driver mode auto selected. But no devices detected. Cannot build QAT HW가 없는 경우 cross compile 방식을 사용해야 하는데 QAT Getting Started Guide 3.6절을 참고해서 수동(?)으로 빌드하면 된다.\nexport ICP_ROOT=/home/cychong/work/qat/QAT1.6 cd quickassist\u2028export ICP_ENV_DIR=$ICP_ROOT/quickassist/build_system/build_files/env_files export ICP_BUILDSYSTEM_PATH=$ICP_ROOT/quickassist/build_system export ICP_BUILD_OUTPUT=$ICP_ROOT/build export ICP_TOOLS_TARGET=accelcomp export LD_LIBRARY_PATH=$ICP_ROOT/build 이제 빌드\n$ make ICP_ARCH_USER=x86_64 … Copying QAT-FW Binary Copying MMP Binary Copying Install Scripts Build Done 빌드 결과물은 ../build에\ncychong@ubuntu:~/work/qat/QAT1.6/build$ file * adf_ctl: ELF 64-bit LSB executable, x86-64, version 1 (SYSV), dynamically linked (uses shared libs), for GNU/Linux 2.6.24, BuildID[sha1]=e1b508cd4404dbeaf268d92271ef2ea894a143e7, not stripped dh895xcc_qa_dev0.conf: ASCII text icp_qa_al.ko: ELF 64-bit LSB relocatable, x86-64, version 1 (SYSV), BuildID[sha1]=5dffbaaac6514d161835bf7c9a4b086ff6a42b6b, not stripped libadf_proxy.a: current ar archive libicp_qa_al.a: current ar archive libicp_qa_al_s.so: ELF 64-bit LSB shared object, x86-64, version 1 (SYSV), dynamically linked, not stripped libosal.a: current ar archive mmp_firmware.bin: data mof_firmware.bin: data qat_service: Bourne-Again shell script, ASCII text executable Build DPDK_QAT example 이제 QAT 라이브러리가 준비되었으니 DPDK_QAT example 빌드\ncychong@ubuntu:~/work/dpdk-2.2.0/examples/dpdk_qat$ make LD dpdk_qat INSTALL-APP dpdk_qat INSTALL-MAP dpdk_qat.map QAT 라이브러리를 빌드하기 전에 example을 빌드하면 다음과 같이 에러 발생\ncychong@ubuntu:~/work/dpdk-2.2.0/examples/dpdk_qat$ make LD dpdk_qat /usr/bin/ld: cannot find /home/cychong/work/qat/QAT1.6/build/libicp_qa_al.a: No such file or directory /usr/bin/ld: cannot find -losal /usr/bin/ld: cannot find -ladf_proxy collect2: error: ld returned 1 exit status make[1]: *** [dpdk_qat] Error 1 make: *** [all] Error 2 ","date":"2016-01-01T10:57:39+09:00","permalink":"https://cychong47.github.io/post/2016/build_dpdk_qat/","summary":"\u003ch3 id=\"download-dpdk-220targz\"\u003eDownload dpdk-2.2.0.tar.gz\u003c/h3\u003e\n\u003cp\u003eRefer \u003ca href=\"http://dpdk.org/download\"\u003ehttp://dpdk.org/download\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ewget http://dpdk.org/browse/dpdk/snapshot/dpdk-2.2.0.tar.gz\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"download-qat_mux\"\u003eDownload qat_mux\u003c/h3\u003e\n\u003cp\u003eRefer \u003ca href=\"https://01.org/packet-processing/intel\"\u003ehttps://01.org/packet-processing/intel\u003c/a\u003e®-quickassist-technology-drivers-and-patches\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ewget https://01.org/sites/default/files/page/qatmux.l.2.5.0-80.tgz  \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003eGetting Started Guide 문서도 받아 둔다.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003ewget https://01.org/sites/default/files/page/330750-004_qat_gsg.pdf  \n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"configure-dpdk\"\u003eConfigure DPDK\u003c/h3\u003e\n\u003cpre\u003e\u003ccode\u003eexport RTE_SDK=/home/cychong/work/dpdk-2.2.0  \nexport RTE_TARGET=x86_64-native-linuxapp-gcc\nmake config T=$RTE_TARGET O=$RTE_TARGET\nmake  \n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"configure-qat\"\u003eConfigure QAT\u003c/h3\u003e\n\u003cp\u003eUbuntu (14.04) 기준으로 몇 개 패키지를 설치해야 QAT를 빌드할 수 있는데 나름 기본적인 패키지들이라 그냥 설치해 놓으면 좋을 듯.\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003esudo apt-get install zlib1g-dev\nsudo apt-get install libssl-dev\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e적당한 위치에 풀면 되는데 \u003ccode\u003e~/work/qat\u003c/code\u003e에 압축을 푼 경우를 기준으로 정리\u003c/p\u003e","title":"DPDK QAT example  빌드하기"},{"content":"Designing a RESTful API with Python and Flask\nRESTful API는 URI에 필요한 인자를 다 넘기는 형태라 사용자가 직접 주소를 입력하는 것이 아니라 다른 SW에서 해당 URI를 입력하는 형태로 사용하는 게 자연스러운 거네.\n","date":"2015-12-24T14:11:59+09:00","permalink":"https://cychong47.github.io/post/2015/designing-a-restful-api-with-python-and-flask/","summary":"\u003cp\u003e\u003ca href=\"http://blog.miguelgrinberg.com/post/designing-a-restful-api-with-python-and-flask\"\u003eDesigning a RESTful API with Python and Flask\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eRESTful API는 URI에 필요한 인자를 다 넘기는 형태라 사용자가 직접 주소를 입력하는 것이 아니라 다른 SW에서 해당 URI를 입력하는 형태로 사용하는 게 자연스러운 거네.\u003c/p\u003e","title":"Designing a RESTful API with Python and Flask"},{"content":"virtualenv 설치\nmini-2:~ cychong$ sudo easy_install pip mini-2:~ cychong$ sudo pip install virtualenv virtualenv로 project directory 생성\nmini-2:work cychong$ mkdir click mini-2:work cychong$ cd click/ mini-2:click cychong$ ls mini-2:click cychong$ virtualenv venv New python executable in venv/bin/python Installing setuptools, pip, wheel...done. mini-2:click cychong$ ls venv virtualenv 환경으로 들어가기\nmini-2:click cychong$ . venv/bin/activate 원하는 패키지 설치\n(venv)mini-2:click cychong$ pip install Click Collecting Click Downloading click-6.2-py2.py3-none-any.whl (70kB) 100% |████████████████████████████████| 73kB 270kB/s Installing collected packages: Click Successfully installed Click-6.2 ","date":"2015-12-21T14:59:29+09:00","permalink":"https://cychong47.github.io/post/2015/virtualenv/","summary":"\u003cp\u003evirtualenv 설치\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emini-2:~ cychong$ sudo easy_install pip\nmini-2:~ cychong$ sudo pip install virtualenv\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003evirtualenv로 project directory 생성\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emini-2:work cychong$ mkdir click\nmini-2:work cychong$ cd click/\nmini-2:click cychong$ ls\nmini-2:click cychong$ virtualenv venv\nNew python executable in venv/bin/python\nInstalling setuptools, pip, wheel...done.\nmini-2:click cychong$ ls\nvenv\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003evirtualenv 환경으로 들어가기\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003emini-2:click cychong$ . venv/bin/activate\n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003e원하는 패키지 설치\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003e(venv)mini-2:click cychong$ pip install Click\nCollecting Click\n  Downloading click-6.2-py2.py3-none-any.whl (70kB)\n    100% |████████████████████████████████| 73kB 270kB/s\nInstalling collected packages: Click\nSuccessfully installed Click-6.2\n\u003c/code\u003e\u003c/pre\u003e","title":"virtualenv 사용"},{"content":"\nfrom Google Work Rules\n2006년에 구글에 입사. 72년 생\n구글 임직원 나이 평균에 비하면 많지만, 그래도 비슷한 덩치의 국내 기업의 인사 담당자와 비교하면. 하긴 구글을 국내 (대)기업과 비교하는 것 자체가 의미없는 일이지만\n과연 현실은 그렇다해도 저런 생각을 가진 사람을 주변에서 볼 수 있을까?\n그러기에 현실은 너무 지난하다.\n","date":"2015-12-13T13:44:24+09:00","permalink":"https://cychong47.github.io/post/2015/culture/","summary":"\u003cp\u003e\u003cimg src=\"/images/2015/12/based_on_culture_from_workrules-net.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003efrom Google Work Rules\u003c/p\u003e\n\u003cp\u003e2006년에 구글에 입사.\n72년 생\u003c/p\u003e\n\u003cp\u003e구글 임직원 나이 평균에 비하면 많지만, 그래도 비슷한 덩치의 국내 기업의 인사 담당자와 비교하면. 하긴 구글을 국내 (대)기업과 비교하는 것 자체가 의미없는 일이지만\u003c/p\u003e\n\u003cp\u003e과연 현실은 그렇다해도 저런 생각을 가진 사람을 주변에서 볼 수 있을까?\u003c/p\u003e\n\u003cp\u003e그러기에 현실은 너무 지난하다.\u003c/p\u003e","title":"Culture should be setup first"},{"content":"Another Open source project.\nUser-land protocol stack. Incorporate with ODP\nTo use with DPDK, ODP and ODP-DPDK should be used.\nFrom the FAQ\nQ: Does the OFP IP stack mimic Linux stack config inside the fastpath, meaning does it intercept Linux ipconfig/ip commands and automatically create similar entities inside the fastpath stack? A: Yes. Uses Netlink to sync with ifconfig commands and also with routes. Q: Does the OFP IP stack have full IPv4/IPv6 fragmentation/re-assembly support? A: IPv4 only. Fragmentation and reassembly on IPv4. Q: Does the OFP IP stack have a replacement/equivalent of DPDK KNI (Kernel Network Interface) to allow forwarding packets between Linux/Fastpath? A: OFP uses a generic solution called TAP, not intended for performance. Fastpath can relay packets to Linux(slowpath). The use case to relay packets from Linux to Fastpath is not implemented. Linux will send packets straight to NIC/wire. ","date":"2015-12-11T14:40:23+09:00","permalink":"https://cychong47.github.io/post/2015/openfastpath/","summary":"\u003cp\u003eAnother Open source project.\u003c/p\u003e\n\u003cp\u003eUser-land protocol stack.\nIncorporate with ODP\u003cbr\u003e\nTo use with DPDK, ODP and ODP-DPDK should be used.\u003c/p\u003e\n\u003cp\u003eFrom the \u003ca href=\"http://www.openfastpath.org/index.php/faq/\"\u003eFAQ\u003c/a\u003e\u003c/p\u003e\n\u003cpre\u003e\u003ccode\u003eQ: Does the OFP IP stack mimic Linux stack config inside the fastpath, meaning does it intercept Linux ipconfig/ip commands and automatically create similar entities inside the fastpath stack?\n\nA: Yes. Uses Netlink to sync with ifconfig commands and also with routes.\nQ: Does the OFP IP stack have full IPv4/IPv6 fragmentation/re-assembly support?\nA: IPv4 only. Fragmentation and reassembly on IPv4.  \n\nQ: Does the OFP IP stack have a replacement/equivalent of DPDK KNI (Kernel Network Interface) to allow forwarding packets between Linux/Fastpath?\n\nA: OFP uses a generic solution called TAP, not intended for performance. Fastpath can relay packets to Linux(slowpath). The use case to relay packets from Linux to Fastpath is not implemented. Linux will send packets straight to NIC/wire.\n\u003c/code\u003e\u003c/pre\u003e","title":"OpenFastPath"},{"content":"Linux에서 사용하는 기본 page size는 4KB. 이 대신 2MB 혹은 1GB의 큰 크기를 hugepage라고 한다. Hugepage는 연속된 physical memory에 할당되어야 한다는 제약 조건이 있지만, 대신 swap out되지 않아 성능 개선 효과가 있다.\n아래 링크에서는 Oracle DB를 사용하는데 page swapping때문에 CPU 부하가 간헐적으로 크게 증가하는 현상을 hugepage를 사용해서 해결한 경우.\nPerformance tuning : hugepages in Linux Enabling huge pages for shared memory 기왕 hugepage를 사용한다면 shared memory도 hugepage에 할당하는 것이 유리할 듯.\n","date":"2015-12-11T14:30:56+09:00","permalink":"https://cychong47.github.io/post/2015/hugepage/","summary":"\u003cp\u003eLinux에서 사용하는 기본 page size는 4KB. 이 대신 2MB 혹은 1GB의 큰 크기를 hugepage라고 한다. Hugepage는 연속된 physical memory에 할당되어야 한다는 제약 조건이 있지만, 대신 swap out되지 않아 성능 개선 효과가 있다.\u003c/p\u003e\n\u003cp\u003e아래 링크에서는 Oracle DB를 사용하는데 page swapping때문에 CPU 부하가 간헐적으로 크게 증가하는 현상을 hugepage를 사용해서 해결한 경우.\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"http://www.pythian.com/blog/performance-tuning-hugepages-in-linux/\"\u003ePerformance tuning : hugepages in Linux\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.ibm.com/developerworks/community/wikis/home?lang=en#!/wiki/W51a7ffcf4dfd_4b40_9d82_446ebc23c550/page/Enabling+huge+pages+for+shared+memory\"\u003eEnabling huge pages for shared memory\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e기왕 hugepage를 사용한다면 shared memory도 hugepage에 할당하는 것이 유리할 듯.\u003c/p\u003e","title":"Hugepage"},{"content":"난 특히 멀티태스킹이 안된다.\n하나에도 제대로 집중하기 힘들다. 11월은 아무 쓸데없는 TF 2개에 참여하느라 제대로 일을 못했다. 정말\u0026hellip;\n","date":"2015-12-11T14:08:11+09:00","permalink":"https://cychong47.github.io/post/2015/single-tasking/","summary":"\u003cp\u003e난 특히 멀티태스킹이 안된다.\u003cbr\u003e\n하나에도 제대로 집중하기 힘들다.\n11월은 아무 쓸데없는 TF 2개에 참여하느라 제대로 일을 못했다. 정말\u0026hellip;\u003c/p\u003e","title":"Single tasking"},{"content":"Last login: Thu Dec 10 00:38:48 on ttys000 Chae-yongs-MacBook-Pro:~ cychong$ Chae-yongs-MacBook-Pro:~ cychong$ vi hard.txt Chae-yongs-MacBook-Pro:~ cychong$ ack \u0026ldquo;You have to\u0026rdquo; hard.txt | sort | uniq \u0026gt; a Chae-yongs-MacBook-Pro:~ cychong$ vi a Chae-yongs-MacBook-Pro:~ cychong$ ack \u0026ldquo;You have to\u0026rdquo; hard.txt | uniq \u0026gt; a Chae-yongs-MacBook-Pro:~ cychong$ vi a\nYou have to do the hard things. You have to make the call you’re afraid to make. You have to get up earlier than you want to get up. You have to give more than you get in return right away. You have to care more about others than they care about you. You have to fight when you are already injured, bloody, and sore. You have to feel unsure and insecure when playing it safe seems smarter. You have to lead when no one else is following you yet. You have to invest in yourself even though no one else is. You have to look like a fool while you’re looking for answers you don’t have. You have to grind out the details when it’s easier to shrug them off. You have to deliver results when making excuses is an option. You have to search for your own explanations even when you’re told to accept the “facts.” You have to make mistakes and look like an idiot. You have to try and fail and try again. You have to run faster even though you’re out of breath. You have to be kind to people who have been cruel to you. You have to meet deadlines that are unreasonable and deliver results that are unparalleled. You have to be accountable for your actions even when things go wrong. You have to keep moving towards where you want to be no matter what’s in front of you. 출처 : http://www.businessinsider.com/hard-things-you-need-to-do-to-be-successful-2015-12?amp 20 substitutions on 20 lines\n","date":"2015-12-10T14:58:06+09:00","permalink":"https://cychong47.github.io/post/2015/19-hard-things-you-need-to-do-to-be-successful/","summary":"\u003cp\u003eLast login: Thu Dec 10 00:38:48 on ttys000\nChae-yongs-MacBook-Pro:~ cychong$\nChae-yongs-MacBook-Pro:~ cychong$ vi hard.txt\nChae-yongs-MacBook-Pro:~ cychong$ ack \u0026ldquo;You have to\u0026rdquo; hard.txt | sort | uniq \u0026gt; a\nChae-yongs-MacBook-Pro:~ cychong$ vi a\nChae-yongs-MacBook-Pro:~ cychong$ ack \u0026ldquo;You have to\u0026rdquo; hard.txt | uniq \u0026gt; a\nChae-yongs-MacBook-Pro:~ cychong$ vi a\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eYou have to do the hard things.\u003c/li\u003e\n\u003cli\u003eYou have to make the call you’re afraid to make.\u003c/li\u003e\n\u003cli\u003eYou have to get up earlier than you want to get up.\u003c/li\u003e\n\u003cli\u003eYou have to give more than you get in return right away.\u003c/li\u003e\n\u003cli\u003eYou have to care more about others than they care about you.\u003c/li\u003e\n\u003cli\u003eYou have to fight when you are already injured, bloody, and sore.\u003c/li\u003e\n\u003cli\u003eYou have to feel unsure and insecure when playing it safe seems smarter.\u003c/li\u003e\n\u003cli\u003eYou have to lead when no one else is following you yet.\u003c/li\u003e\n\u003cli\u003eYou have to invest in yourself even though no one else is.\u003c/li\u003e\n\u003cli\u003eYou have to look like a fool while you’re looking for answers you don’t have.\u003c/li\u003e\n\u003cli\u003eYou have to grind out the details when it’s easier to shrug them off.\u003c/li\u003e\n\u003cli\u003eYou have to deliver results when making excuses is an option.\u003c/li\u003e\n\u003cli\u003eYou have to search for your own explanations even when you’re told to accept the “facts.”\u003c/li\u003e\n\u003cli\u003eYou have to make mistakes and look like an idiot.\u003c/li\u003e\n\u003cli\u003eYou have to try and fail and try again.\u003c/li\u003e\n\u003cli\u003eYou have to run faster even though you’re out of breath.\u003c/li\u003e\n\u003cli\u003eYou have to be kind to people who have been cruel to you.\u003c/li\u003e\n\u003cli\u003eYou have to meet deadlines that are unreasonable and deliver results that are unparalleled.\u003c/li\u003e\n\u003cli\u003eYou have to be accountable for your actions even when things go wrong.\u003c/li\u003e\n\u003cli\u003eYou have to keep moving towards where you want to be no matter what’s in front of you.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e출처 : \u003ca href=\"http://www.businessinsider.com/hard-things-you-need-to-do-to-be-successful-2015-12?amp\"\u003ehttp://www.businessinsider.com/hard-things-you-need-to-do-to-be-successful-2015-12?amp\u003c/a\u003e\n20 substitutions on 20 lines\u003c/p\u003e","title":"19 hard things you need to do to be successful"},{"content":"\n부정하기 어렵다. 하지만 코드가 늘어나는 것은 피할 수 없으니 불필요한 기능/코드는 삭제하는 노력을 끊임없이 해야 한다. 그렇지 않으면 technical debt만 늘어날 뿐이다. 개발할 때는 제대로 이해하고 만들어서 technical debt가 아니었더라도 시간이 지나 동작하지 않는 코드가 되면 불필요한 짐만 된다.\n","date":"2015-12-07T14:00:58+09:00","permalink":"https://cychong47.github.io/post/2015/errors_from_more_code/","summary":"\u003cp\u003e\u003cimg src=\"/images/2015/12/12313677_10153195940702321_1604212637607630351_n.jpg\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e부정하기 어렵다. 하지만 코드가 늘어나는 것은 피할 수 없으니 불필요한 기능/코드는 삭제하는 노력을 끊임없이 해야 한다. 그렇지 않으면 technical debt만 늘어날 뿐이다.  개발할 때는 제대로 이해하고 만들어서 technical debt가 아니었더라도 시간이 지나 동작하지 않는 코드가 되면 불필요한 짐만 된다.\u003c/p\u003e","title":"Code 량이 늘면 버그도 함께 들어나기 마련"},{"content":"누군가의 말을 빌리자면 품질 관리의 바이블(?)이라고 하는.\n내용면에서는 특별한 건 없지만, 그래도 국내에서는 SW를 잘한다고 하는 사람들이 많이 가는 회사이고, 누구못지 않게 SW 문화가 좋을 거라고 생각하는 회사라 어떤 고민을 하고 어떻게 SW 품질을 위해 노력하는 지 알 수 있게 해주는 유일한 책이다.\n외국의 많은 회사처럼 사내에 노하우 등을 많이 공유하는 좋은 모습을 보이고 있고, 실제 제공되는 서비스의 독점성이나 중립적이지 못한 언론 관련 내용은 맘에 들지 않지만 그래도 개발자 입장에서는 이렇게 현실적인 내용을 공유해주는게 감사할 따름\n2009년, 2010년에 있던 일이라 벌써 옛날 이야기이고, 지금도 그러는 지는 알 수 없다는 게 아쉬울 따름.\nSW의 생산성에 대해서도 참고할 만한 정의를 내리고 있다. 특별히 SW 생산성 보다는 품질 지표로 생산성을 보겠다는 생각에는 나도 동감. 관리하는 사람이 그렇게 보질 않아 문제지만.\nCoding Convention Code Review Code coverage Static Analysis Complexity analysis 5가지 면에서 어떤 도구를 사용해서 어떤 점을 측정하고, 개선하려고 노력하는 지, 그리고 목표 수준은 어떤 지 등을 설명하고 있다. 실제 각 항목 별로 100점 만점을 목표로 하는 것이 아니라 현실적인 수준과 NHN의 현재 수준을 실제로(2009년 정보지만) 보여주고 있어 참고할 만 하다.\n각 항목별 개발자들의 피드백을 보면 비슷하다(아니 5년 전 내용이니 5년 정도 뒤떨어졌다고 봐야 하나? 그렇지는 않을 듯)\n뭔가 변화를 주는 것이나, 의미없는(?) 수치화, 기존 코드의 수정에 대한 부담감. Test coverage 를 높이기 위해 들이는 노력에 대한 부담감, Online code review만으로 부족해 결국 offline code review를 하고 다시 online code review를 해야 하는 불합리성에 대한 고민 등은 내가(스스로 그리고 주변 사람들로부터) 보고 느낀 것과 크게 다르지 않다.\n적용 효과 순 적용 비용 순 책을 쓴 사람들은 품질관리하는 부서에 있는 사람들이다 보니 실제 저런 활동의 주체가 되어야 하는 개발자들의 의견은 피드백으로 기술된 내용으로 한정된다. 그래도 저 책에 기술된 내용과 크게 다르지 않을 것 같다. 그렇지 않으면 저 책을 쓴 사람들이 회사내에서 욕 먹을 각오를 했어야 하는데 그렇게까지 없는 내용을 쓰지는 않았을 테니.\n결국 개발 문화를 변화시키는 대는 개개인의 노력이 가장 중요하지만, 합리적인 접근을 통해 점진적인 변화를 유도해 가는 것이 가장 중요하다고 생각된다. 그렇지 않으면 실제 품질이 높아져 품질 지표가 올라가는 것이 아니라 품질 지표만 올라가는 현실과 동떨어진 숫자만 남게 될 수 있기 때문이다. 아울러 이런 활동을 할 때는 개발자들에게 의도부터 방법까지 충분한 설명을 통해 공감을 얻어야 하고, 개발자들이 필요한 정보를 충분히 받을 수 있도록 지원 체계를 만들어야 한다.\n지금처럼 주먹구구식으로 감시 항목만 늘어나는 한 숫자 뿐인 품질 수치만 좋아질 거다. 적어도 개발자들이 고통받는 혹은 들이는 노력에 비해 품질 향상은 아주 미비할 것이다. 누굴 위한 노력인지 정말 궁금할 뿐.\n","date":"2015-12-07T13:40:56+09:00","permalink":"https://cychong47.github.io/post/2015/nhn_sw_quality_control/","summary":"\u003cp\u003e누군가의 말을 빌리자면 품질 관리의 바이블(?)이라고 하는.\u003cbr\u003e\n내용면에서는 특별한 건 없지만, 그래도 국내에서는 SW를 잘한다고 하는 사람들이 많이 가는 회사이고, 누구못지 않게 SW 문화가 좋을 거라고 생각하는 회사라 어떤 고민을 하고 어떻게 SW 품질을 위해 노력하는 지 알 수 있게 해주는 유일한 책이다.\u003c/p\u003e\n\u003cp\u003e외국의 많은 회사처럼 사내에 노하우 등을 많이 공유하는 좋은 모습을 보이고 있고, 실제 제공되는 서비스의 독점성이나 중립적이지 못한 언론 관련 내용은 맘에 들지 않지만 그래도 개발자 입장에서는 이렇게 현실적인 내용을 공유해주는게 감사할 따름\u003c/p\u003e","title":"(책)  NHN은 이렇게 한다. 소프트웨어 품질 관리"},{"content":"출처 : Harvard Businee Review\n최소 52개 대형 회사가 기존 년 단위의 고과 평과 제도를 없앰. 이 중 33개 업체를 집중 분석하여 해당 업체에서 일어난 변화를 정리\nmanager-employee간 대화가 극적으로 증가. 33개 미국 기반의 업체 중 76%는 기존에 1년 단위의 역량 대화를 나눴으나, 이젠 68%가 최소 분기별 대화를 권장하고 있다고 함.\n관리 부담이 크게 줄어듬 33개 업체의 2/3에서 역량 평가를 위한 관리자의 문서 작성 요구가 공식적으로 줄어듬. 다른 30% 업체는 문서 작성을 아예 없앰.\nHBR에서 확인한 바로는 65,000이상의 고용인을 리뷰하기 위해 매년 2백만 시간이 필요했음. 실제 통상적인 고과 면담이 업무 역량을 높이는 데 도움이 되지 않는 것을 생각하면 이 시간은 낭비임.\n대화는 Goal, Growth 그리고 성장에 초점이 맞춰짐\n기존 고과 면담은 이미 지난 성과에 대한 평가가 주였으나, 새로운 체계에서는 목적을 세우고, 성장을 계획하고, 행동에 집중함.\n새로운 고과 관리 체계는 empower individuals, driver performance, support development, and crate a sense of purpose.\n성과와 관리는 비평가자들이 관리자들의 지원과 코치를 받고, 그들이 절차에 대해 더 많은 주도권을 가질 때 가장 효과적이라는 인식을 갖게 됨. 새로운 quality conversation은 관리자와 비평가자 모두 만족함\nNo single best practice\n회사마다 다른 상황이라 접근하는 방식 등은 다르다.\npay-for-performance 혹은 차등화된 연봉이 없어지지는 않는다. 기존과 유사하게 관리자들이 업적에 대한 기존보다 좋은 대화(better-quality conversations about performance)를 통해 우수 인력을 찾아내고, 그들의 판단에 따라 보상하라고 독려하고 있다.\nWell-designed change management is essential\n단번에 새로운 제대를 적용하면 안되고, 시간을 가지고 계획을 충분히 세운 후 적용해야 한다.\n","date":"2015-12-05T13:14:53+09:00","permalink":"https://cychong47.github.io/post/2015/what_happens_if_performance_rating_is_omitted/","summary":"\u003cp\u003e출처 : \u003ca href=\"https://hbr.org/2015/11/what-really-happens-when-companies-nix-performance-ratings\"\u003eHarvard Businee Review\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e최소 52개 대형 회사가 기존 년 단위의 고과 평과 제도를 없앰. 이 중 33개 업체를 집중 분석하여 해당 업체에서 일어난 변화를 정리\u003c/p\u003e\n\u003col\u003e\n\u003cli\u003e\n\u003cp\u003emanager-employee간 대화가 극적으로 증가.\n33개 미국 기반의 업체 중 76%는 기존에 1년 단위의 역량 대화를 나눴으나, 이젠 68%가 최소 분기별 대화를 권장하고 있다고 함.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e관리 부담이 크게 줄어듬\n33개 업체의 2/3에서 역량 평가를 위한 관리자의 문서 작성 요구가 공식적으로 줄어듬. 다른 30% 업체는 문서 작성을 아예 없앰.\u003cbr\u003e\nHBR에서 확인한 바로는 65,000이상의 고용인을 리뷰하기 위해 매년 2백만 시간이 필요했음. 실제 통상적인 고과 면담이 업무 역량을 높이는 데 도움이 되지 않는 것을 생각하면 이 시간은 낭비임.\u003c/p\u003e","title":"역량 평가를 없앤 회사에서 일어난 일"},{"content":"Neuron\nPython project 체계를 잡는데 도움이 될 듯 하다. 아래는 pylink를 이용해서 syntax 검사하는 script\nhttps://github.com/openstack/neutron/blob/master/tools/coding-checks.sh\n","date":"2015-11-25T11:36:43+09:00","permalink":"https://cychong47.github.io/post/2015/openstacki-pythoneuro-mandeuleojyeossdani/","summary":"\u003cp\u003e\u003ca href=\"https://github.com/openstack/neutron\"\u003eNeuron\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003ePython project 체계를 잡는데 도움이 될 듯 하다.\n아래는 pylink를 이용해서 syntax 검사하는 script\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/openstack/neutron/blob/master/tools/coding-checks.sh\"\u003ehttps://github.com/openstack/neutron/blob/master/tools/coding-checks.sh\u003c/a\u003e\u003c/p\u003e","title":"OpenStack이  Python으로 만들어졌다니"},{"content":"http://www.cisco.com/c/en/us/products/collateral/routers/cloud-services-router-1000v-series/datasheet-c78-733443.html\nHow many vCPUs are required for processing.\n","date":"2015-11-23T14:50:31+09:00","permalink":"https://cychong47.github.io/post/2015/cisco-cloud-services-router-1000v/","summary":"\u003cp\u003e\u003ca href=\"http://www.cisco.com/c/en/us/products/collateral/routers/cloud-services-router-1000v-series/datasheet-c78-733443.html\"\u003ehttp://www.cisco.com/c/en/us/products/collateral/routers/cloud-services-router-1000v-series/datasheet-c78-733443.html\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eHow many vCPUs are required for processing.\u003c/p\u003e","title":"Cisco Cloud Services Router 1000V"},{"content":"Data sheet (PDF)\nSome Cisco virtual network services that use the DPDK include Cisco Cloud Services Router (CSR) 1000V, Cisco Virtual Mobile Packet Core software, and Cisco IOS® XR 9000v virtual router. Supporte CISCO appliances Cisco Cloud Services Router (CSR) 1000V virtual router Cisco Virtual Adaptive Security Appliance (ASAv) Cisco Prime™ Data Center Network Manager (DCNM) Cisco Virtual Network Analysis Module (vNAM) Cisco Virtual Security Gateway (VSG) for Cisco Nexus® 1000V Switch deployments Cisco Virtual Supervisor Module (VSM) for Cisco Nexus 1000V Switch deployments 1U 2 CPU, each has 8 core Ivy Bridge(E5-2630 v3) REST API It uses REST API and NETCONF protocol for north-bound management and orchestration (MANO) tools. Network services could be abstracted to a pool of high-availability resources among several hosts. Cisco Systems and Intel Corporation NFV Partnership\nTechnical Reference Cisco Cloud Services Platform 2100 REST API Guide Cisco Cloud Services Platform 2100 Command Reference Guide Quick Start Guide - Must check Cisco Cloud Services Platform 2100 Hardware Installation Guide ","date":"2015-11-23T14:24:35+09:00","permalink":"https://cychong47.github.io/post/2015/cisco-cloud-service-platform-2100/","summary":"\u003cp\u003e\u003ca href=\"http://www.cisco.com/c/en/us/products/collateral/switches/cloud-services-platform-2100/datasheet-c78-735317.html\"\u003eData sheet\u003c/a\u003e (\u003ca href=\"http://www.cisco.com/c/en/us/products/collateral/switches/cloud-services-platform-2100/datasheet-c78-735317.pdf\"\u003ePDF\u003c/a\u003e)\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eSome Cisco virtual network services that use the DPDK include Cisco Cloud Services Router (CSR) 1000V, Cisco Virtual Mobile Packet Core software, and Cisco IOS® XR 9000v virtual router.\u003c/li\u003e\n\u003cli\u003eSupporte CISCO appliances\n\u003cul\u003e\n\u003cli\u003eCisco Cloud Services Router (CSR) 1000V virtual router\u003c/li\u003e\n\u003cli\u003eCisco Virtual Adaptive Security Appliance (ASAv)\u003c/li\u003e\n\u003cli\u003eCisco Prime™ Data Center Network Manager (DCNM)\u003c/li\u003e\n\u003cli\u003eCisco Virtual Network Analysis Module (vNAM)\u003c/li\u003e\n\u003cli\u003eCisco Virtual Security Gateway (VSG) for Cisco Nexus® 1000V Switch deployments\u003c/li\u003e\n\u003cli\u003eCisco Virtual Supervisor Module (VSM) for Cisco Nexus 1000V Switch deployments\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e1U\u003c/li\u003e\n\u003cli\u003e2 CPU, each has 8 core Ivy Bridge(E5-2630 v3)\u003c/li\u003e\n\u003cli\u003eREST API\u003c/li\u003e\n\u003cli\u003eIt uses REST API and NETCONF protocol for north-bound management and orchestration (MANO) tools.\u003c/li\u003e\n\u003cli\u003eNetwork services could be abstracted to a pool of high-availability resources among several hosts.\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003ca href=\"http://www.cisco.com/c/dam/en/us/solutions/collateral/service-provider/network-functions-virtualization-nfv/nfv-partnership.pdf\"\u003eCisco Systems and Intel Corporation NFV Partnership\u003c/a\u003e\u003c/p\u003e","title":"CISCO Cloud Service Platform 2100"},{"content":"철학의 부재. 중심의 부재. 대화의 부재\n제품을 만드는데 철학이 없다는 건 정말 큰 문제다. 누군가 대충 스케치만 그린 그림을 가지고 차를 만든다고 생각하면 끔찍하다. 각 부분 부분별로 , 기능 별로 어떻게 만들 것인지 고민없이 그냥 각 부서별로 자기가 맡은 걸 만든다면 그 차가 굴러가기만 해도 기적이지만, 제대로 굴러가는 커녕 일정 내 만들어질 리가 없다.\n처음부터 끝까지 혹은 적어도 그걸 만드는 사람들이 충분히 제품의 철학(성격 등)을 공감할 때까지 끊임없이 대화해서 그나마 비슷한 생각을 가진 후에야 각 기능별 부분별 설계가 이뤄져야 한다.\n하지만 대부분 기능에 대한, 제품의 성격에 대한 이야기는 하지않고 필요한 표준만 나열한다. 그리곤 알아서 하라고 한다. 거기까지가 스케치 하는 사람의 영역이라고.\n늘 하던 대로 기존 제품을 조금씩 개선하는 일이라면 이렇게 해도 큰 무리가 없을 것이다. 이미 경험적으로 제품의 성격을 알고 있으므로. 하지만 새로운 제품을 만드는 경우에는 달라야 한다. 그렇지 않으면 새로운 성격의 제품이 기존 제품과 똑같아진다.\n업무 영역간 일정부분의 겹치는 것으로는 부족하다. 제품 기획부터 개발 그리고 검증까지 제품의 성격을 확인하는 노력이 필요하다. 하지만 ‘과제’ 관리하는 사람들은 과제 진행이 목적이지 어떤 제품을 만들어야 하는 지에 대해서는 관심이 부족한 듯 하다. 관리되고 평가되는 건 오직 숫자로 표현되는 과제 진척도외 산출물 뿐이니.\n정말 제대로 \u0026lsquo;개발\u0026rsquo;을 하고 있는 걸까\n","date":"2015-11-22T14:35:23+09:00","permalink":"https://cychong47.github.io/post/2015/what_is_the_target_product/","summary":"\u003cp\u003e철학의 부재. 중심의 부재. 대화의 부재\u003c/p\u003e\n\u003cp\u003e제품을 만드는데 철학이 없다는 건 정말 큰 문제다. 누군가 대충 스케치만 그린 그림을 가지고 차를 만든다고 생각하면 끔찍하다. 각 부분 부분별로 , 기능 별로 어떻게 만들 것인지 고민없이 그냥 각 부서별로 자기가 맡은 걸 만든다면 그 차가 굴러가기만 해도 기적이지만, 제대로 굴러가는 커녕 일정 내 만들어질 리가 없다.\u003c/p\u003e\n\u003cp\u003e처음부터 끝까지 혹은 적어도 그걸 만드는 사람들이 충분히 제품의 철학(성격 등)을 공감할 때까지 끊임없이 대화해서 그나마 비슷한 생각을 가진 후에야 각 기능별 부분별 설계가 이뤄져야 한다.\u003c/p\u003e","title":"제대로 만들려면 제품의 성격부터 정의해야"},{"content":"잘못된(?) 진단은 잘못된 처방을 낳는다.\n모든 걸 개인의 잘못으로 돌리려는 의도는 의외로 단순. 잘못을 저지른 개인은 개선시키면 된다는 단순한 해법을 제시할 수 있으므로. 개인을 구박하거나 심지어는 그 조직에서 제외시키면 문제가 해결(?)되는 것처럼 보이니까.\n하지만 그 뒤에 숨어있는 실은 개인의 잘못으로 돌려진 관리의 문제, 시스템의 문제는 아무도 건드리지 않는다. 문제의 원인이 너무 커서, 문제의 원인이 너무 근본적이라, 문제의 원인이 권력자에게 있는 터라. 그렇게 문제는 반복된다. 비난의 대상이 되는 \u0026lsquo;개인\u0026rsquo;만 바뀔 뿐. 병든 조직은 서서히 그렇게 스러진다\u0026hellip;\n","date":"2015-11-19T22:22:07+09:00","permalink":"https://cychong47.github.io/post/2015/why_blame_personals/","summary":"\u003cp\u003e잘못된(?) 진단은 잘못된 처방을 낳는다.\u003c/p\u003e\n\u003cp\u003e모든 걸 개인의 잘못으로 돌리려는 의도는 의외로 단순. 잘못을 저지른 개인은 개선시키면 된다는 단순한 해법을 제시할 수 있으므로. 개인을 구박하거나 심지어는 그 조직에서 제외시키면 문제가 해결(?)되는 것처럼 보이니까.\u003c/p\u003e\n\u003cp\u003e하지만 그 뒤에 숨어있는 실은 개인의 잘못으로 돌려진 관리의 문제, 시스템의 문제는 아무도 건드리지 않는다. 문제의 원인이 너무 커서, 문제의 원인이 너무 근본적이라, 문제의 원인이 권력자에게 있는 터라.\n그렇게 문제는 반복된다. 비난의 대상이 되는 \u0026lsquo;개인\u0026rsquo;만 바뀔 뿐.\n병든 조직은 서서히 그렇게 스러진다\u0026hellip;\u003c/p\u003e","title":"개인의 잘못으로만 돌리는 이유"},{"content":"관리자들이 개발자들을 위해 한 일이 뭐가 있나?\n아무리 생각해도 잘 모르겠다.\n그럼 개발자를 위한 사람이나 제도는 없다는 건데\n그러면서 개발자가 잘 하기 기대하는 건 도둑놈 심보가 아닌가?\n자꾸만 벗어나길 원하는 \u0026lsquo;개발\u0026rsquo;업무를 만든 게 누구인지? 왜 그렇게 된 건지?\n이런 근본적인 질문에 대한 고민과 해결 없이 SW품질을 논한다는 건 어불성설이다.\n","date":"2015-11-18T14:43:51+09:00","permalink":"https://cychong47.github.io/post/2015/what_for_the_developer/","summary":"\u003cp\u003e관리자들이 개발자들을 위해 한 일이 뭐가 있나?\u003c/p\u003e\n\u003cp\u003e아무리 생각해도 잘 모르겠다.\u003c/p\u003e\n\u003cp\u003e그럼 개발자를 위한 사람이나 제도는 없다는 건데\u003c/p\u003e\n\u003cp\u003e그러면서 개발자가 잘 하기 기대하는 건 도둑놈 심보가 아닌가?\u003c/p\u003e\n\u003cp\u003e자꾸만 벗어나길 원하는 \u0026lsquo;개발\u0026rsquo;업무를 만든 게 누구인지? 왜 그렇게 된 건지?\u003c/p\u003e\n\u003cp\u003e이런 근본적인 질문에 대한 고민과 해결 없이 SW품질을 논한다는 건 어불성설이다.\u003c/p\u003e","title":"개발자를 위해 한 일이 뭐가 있지?"},{"content":"규제를 풀기 어려운 이유는 그 규제를 풀어도 문제가 없는 지 자신이 없기 때문이다. 증명하기 어려운 경우가 대부분. 하지만 머리를 맞대고 함께 이야기해봐야 한다. 정말 필요한 절차인지 고민해야 한다. 가능하면 절차는 줄이고 또 줄여야 한다고 생각.\n이런 고민조차 어려운 이유는 대부분 한 쪽이 들으려 하지 않기 때문. 기존에 하던 (불필요해보이는) 절차를 없애는 경우 발생할 수 있는 위험요소를 감수할 의지가 없으므로. 혹시 이렇게 생각하고 있는 건 아닌지\n그런 번거로운 절차는 내가 하는 게 아니라 니들이 하는 거니까\n곧 이 문제는 조직 문화가 변하기 힘든 것도 같은 이유라고 생각된다.\n","date":"2015-11-18T14:41:55+09:00","permalink":"https://cychong47.github.io/post/2015/gyujereul-pulgi-eoryeoun-iyuneun/","summary":"\u003cp\u003e규제를 풀기 어려운 이유는 그 규제를 풀어도 문제가 없는 지 자신이 없기 때문이다.  증명하기 어려운 경우가 대부분. 하지만 머리를 맞대고 함께 이야기해봐야 한다. 정말 필요한 절차인지 고민해야 한다. 가능하면 절차는 줄이고 또 줄여야 한다고 생각.\u003c/p\u003e\n\u003cp\u003e이런 고민조차 어려운 이유는 대부분 한 쪽이 들으려 하지 않기 때문. 기존에 하던 (불필요해보이는) 절차를 없애는 경우 발생할 수 있는 위험요소를 감수할 의지가 없으므로. 혹시 이렇게 생각하고 있는 건 아닌지\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e그런 번거로운 절차는 내가 하는 게 아니라 니들이 하는 거니까\u003c/p\u003e","title":"규제를 풀기 어려운 이유는"},{"content":"TAILQ_HEAD(ip_pkt_list, ip_frag_pkt); /**\u0026lt; @internal fragments tailq */ 자료 구조체 Fragment 관리용 table struct rte_ip_frag_tbl *frag_tbl; locking 없이 IP reassembly를 수행할 단위(통상 core)로 한 개씩 만든다. 즉 하나의 core가 여러 rx queue를 처리하더라도 하나의 frag_tbl만 가지면 된다.\n아래 rte_ip_frag_table_create()함수를 이용해서 생성한다.\nstruct rte_ip_frag_death_row death_row core별로 갖는 death_row. IP reassembly를 호출한 후 해당 함수내에서 free할 mbuf를 이 리스트에 담아줌.\nmain loop에서 reassembly작업 후 rte_ip_frag_free_death_row()함수를 호출해 reassembly에 실패한 mbuf를 free함\nIP_MAX_FRAG_NUM defines the maximum fragments of one reassembly. Defined same as RTE_LIBRTE_IP_FRAG_MAX_FRAG aka 4.\n주요 함수 rte_ipv4_frag_reassemble_packet 실제 reassembly를 수행하는 함수.\n첫번째 인자는 ip fragment들이 저장된 ip_frag_tbl의 pointer 두번째 인자는 death_row를 저장할 pointer. 세번째 인자는 현재 수신한 mbuf의 pointer 네번째 인자는 패킷이 수신한 timestamp. rdtsc_tsc()의 결과 다섯번째 인자는 pointer to ip header(struct ipv4_hdr *) rte_ipv6_frag_reassemble_packet() IPv6용 reassembly 함수. 함수의 인자는 rte_ipv4_frag_reassemble_packet()와 유사하지만, 마지막에 struct ipv6_extension_fragment *가 추가된다.\nrte_ipv4_frag_pkt_is_fragmented() Return 1 if packet is fragmented.\nrte_ipv6_frag_get_ipv6_fragment_header() IPv6 경우 위 함수를 통해 frag_hdr 위치를 돌려받는다. struct ipv6_extension_fragment * 단순히 IPv6 base header 바로 뒷 헤더만 확인함.(표준 확인 필요)\nrte_ip_frag_table_create() struct rte_ip_frag_tbl * rte_ip_frag_table_create( uint32_t bucket_num, uint32_t bucket_entries, uint32_t max_entries, uint64_t max_cycles, int socket_id); bucket_num : # of bucket(Flow 개수). Should be power of 2 bucket_entries : bucket당 개수(hash associativity) max_entries : # of flows to be stored in table. less or equal to max_flow_num * bucket_entries max_cycles : Maximum TTL in cycles for each fragmented packet. frag_cycles = (rte_get_tsc_hz() + MS_PER_S - 1) / MS_PER_S * max_flow_ttl; 예. 1ms에 해당하는 TSC value socket : 메모리를 할당할 socket ID. core와 함께 있는 socket 정보를 넣으면 됨. defined in lib/librte_ip_frag/rte_ip_frag.h\n/** fragmentation table */ struct rte_ip_frag_tbl { uint64_t max_cycles; /**\u0026lt; ttl for table entries. */ uint32_t entry_mask; /**\u0026lt; hash value mask. */ uint32_t max_entries; /**\u0026lt; max entries allowed. */ uint32_t use_entries; /**\u0026lt; entries in use. */ uint32_t bucket_entries; /**\u0026lt; hash assocaitivity. */ uint32_t nb_entries; /**\u0026lt; total size of the table. */ uint32_t nb_buckets; /**\u0026lt; num of associativity lines. */ struct ip_frag_pkt *last; /**\u0026lt; last used entry. */ struct ip_pkt_list lru; /**\u0026lt; LRU list for table entries. */ struct ip_frag_tbl_stat stat; /**\u0026lt; statistics counters. */ struct ip_frag_pkt pkt[0]; /**\u0026lt; hash table. */ }; rte_ip_frag_free_death_row() prefetch가 왜 필요한 지??(FIXME)\n/* * Free mbufs on a given death row. * * @param dr * Death row to free mbufs in. * @param prefetch * How many buffers to prefetch before freeing. */ void rte_ip_frag_free_death_row(struct rte_ip_frag_death_row *dr, uint32_t prefetch); 예) if death_row has 10 entries and prefetch is 5\n\u0026lt;\u0026lt; Step 1 \u0026gt;\u0026gt; prefetch 0 prefetch 1 prefetch 2 prefetch 3 prefetch 4 \u0026lt;\u0026lt; Step 2 \u0026gt;\u0026gt; prefetch 5 free 0 prefetch 6 free 1 prefetch 7 free 2 prefetch 8 free 3 prefetch 9 free 4 \u0026lt;\u0026lt; Step 3 \u0026gt;\u0026gt; free 5 free 6 free 7 free 8 free 9 동작 rte_ipv4_frag_reassemble_packet() 혹은 rte_ipv6_frag_reassemble_packet()는 reassembly에 성공한 경우 해당 struct mbuf *를 리터한다. 그러므로 해당 mbuf를 다음 작업에 처리하면 됨.\nstruct rte_ip_frag_death_row *dr = \u0026amp;qconf-\u0026gt;death_row; if (rte_ipv4_frag_pkt_is_fragmented(ip_hdr)) { struct rte_mbuf *mo; tbl = rxq-\u0026gt;frag_tbl; dr = \u0026amp;qconf-\u0026gt;death_row; /* prepare mbuf: setup l2_len/l3_len. */ m-\u0026gt;l2_len = sizeof(*eth_hdr); m-\u0026gt;l3_len = sizeof(*ip_hdr); /* process this fragment. */ mo = rte_ipv4_frag_reassemble_packet(tbl, dr, m, tms, ip_hdr); if (mo == NULL) /* no packet to send out. */ return; else /* mo를 이용해서 post processing */ } rte_ip_frag_free_death_row(dr, PREFETCH_OFFSET); IPv6 경우\nfrag_hdr = rte_ipv6_frag_get_ipv6_fragment_header(ip_hdr); if (frag_hdr != NULL) { struct rte_mbuf *mo; tbl = rxq-\u0026gt;frag_tbl; dr = \u0026amp;qconf-\u0026gt;death_row; /* prepare mbuf: setup l2_len/l3_len. */ m-\u0026gt;l2_len = sizeof(*eth_hdr); m-\u0026gt;l3_len = sizeof(*ip_hdr) + sizeof(*frag_hdr); mo = rte_ipv6_frag_reassemble_packet(tbl, dr, m, tms, ip_hdr, frag_hdr); if (mo == NULL) return; if (mo != m) { m = mo; eth_hdr = rte_pktmbuf_mtod(m, struct ether_hdr *); ip_hdr = (struct ipv6_hdr *)(eth_hdr + 1); } } rte_ip_frag_free_death_row(dr, PREFETCH_OFFSET); ","date":"2015-11-17T13:49:57+09:00","permalink":"https://cychong47.github.io/post/2015/dpdk-ip-reassembly-example/","summary":"\u003cpre\u003e\u003ccode\u003eTAILQ_HEAD(ip_pkt_list, ip_frag_pkt); /**\u0026lt; @internal fragments tailq */\n\u003c/code\u003e\u003c/pre\u003e\n\u003ch3 id=\"자료-구조체\"\u003e자료 구조체\u003c/h3\u003e\n\u003ch5 id=\"fragment-관리용-table\"\u003eFragment 관리용 table\u003c/h5\u003e\n\u003cpre\u003e\u003ccode\u003estruct rte_ip_frag_tbl *frag_tbl;  \n\u003c/code\u003e\u003c/pre\u003e\n\u003cp\u003elocking 없이 IP reassembly를 수행할 단위(통상 core)로 한 개씩 만든다. 즉 하나의 core가 여러 rx queue를 처리하더라도 하나의 \u003ccode\u003efrag_tbl\u003c/code\u003e만 가지면 된다.\u003cbr\u003e\n아래 \u003ccode\u003erte_ip_frag_table_create()\u003c/code\u003e함수를 이용해서 생성한다.\u003c/p\u003e\n\u003ch5 id=\"struct-rte_ip_frag_death_row-death_row\"\u003e\u003ccode\u003estruct rte_ip_frag_death_row death_row\u003c/code\u003e\u003c/h5\u003e\n\u003cp\u003ecore별로 갖는 death_row. IP reassembly를 호출한 후 해당 함수내에서 free할 mbuf를 이 리스트에 담아줌.\u003cbr\u003e\nmain loop에서 reassembly작업 후 \u003ccode\u003erte_ip_frag_free_death_row()\u003c/code\u003e함수를 호출해 reassembly에 실패한 mbuf를 free함\u003c/p\u003e\n\u003cp\u003e\u003ccode\u003eIP_MAX_FRAG_NUM\u003c/code\u003e defines the maximum fragments of one reassembly. Defined same as \u003ccode\u003eRTE_LIBRTE_IP_FRAG_MAX_FRAG\u003c/code\u003e aka 4.\u003c/p\u003e","title":"DPDK IP reassembly example"},{"content":" 자네는 Agile이 뭔지, Scrum Master가 어떤 일을 해야 하는 지 모르겠지만, 앞으로 자네를 \u0026lsquo;Scrum Master\u0026rsquo;라고 부르겠네.\n이제 우리는 Scrum Master를 가졌으니, Agile을 하는 걸쎄\n글쎄요\u0026hellip;\n저도 Agile을 잘 모르지만, 동의할 수가 없네요.\n국정교과서의 필요성에 대해 이야기하는 이상한 나라의 사람들 만큼이나 이해하기 어렵네요.\n","date":"2015-11-06T16:47:18+09:00","permalink":"https://cychong47.github.io/post/2015/do_you_know_agile/","summary":"\u003cblockquote\u003e\n\u003cp\u003e자네는 Agile이 뭔지, Scrum Master가 어떤 일을 해야 하는 지 모르겠지만, 앞으로 자네를 \u0026lsquo;Scrum Master\u0026rsquo;라고 부르겠네.\u003c/p\u003e\n\u003cp\u003e이제 우리는 Scrum Master를 가졌으니, Agile을 하는 걸쎄\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e글쎄요\u0026hellip;\u003c/p\u003e\n\u003cp\u003e저도 Agile을 잘 모르지만, 동의할 수가 없네요.\u003c/p\u003e\n\u003cp\u003e국정교과서의 필요성에 대해 이야기하는 이상한 나라의 사람들 만큼이나 이해하기 어렵네요.\u003c/p\u003e","title":"또 하나의 코미디"},{"content":"We can’t measure Programmer Productivity… or can we?\nLOC The more fundamental problem is that measuring productivity by lines (or Function Points or other derivatives) typed doesn’t make any sense. A lot of important work in software development, the most important work, involves thinking and learning – not typing.\nThe best programmers spend a lot of time understanding and solving hard problems, or helping other people understand and solve hard problems, instead of typing. They find ways to simplify code and eliminate duplication. And a lot of the code that they do write won’t count anyways, as they iterate through experiments and build prototypes and throw all of it away in order to get to an optimal solution.\nMoney Velocity But velocity (how much work, measured in story points or feature points or ideal days, that the team delivers in a period of time) is really a measure of predictability, not productivity. Velocity is intended to be used by a team to measure how much work they can take on, to calibrate their estimates and plan their work forward.\nOnce a team’s velocity has stabilized, you can measure changes in velocity within the team as a relative measure of productivity. If the team’s velocity is decelerating, it could be an indicator of problems in the team or the project or the system. Or you can use velocity to measure the impact of process improvements, to see if training or new tools or new practices actually make the team’s work measurably faster.\nOrganizations and managers who equate internal velocity with external productivity start to set targets for velocity, forgetting that what actually matters is working software in production. Treating velocity as productivity leads to unproductive team behaviors that optimize this metric at the expense of actual working software.\nThe down side of equating delivery speed with productivity? Optimizing for cycle time/speed of delivery by itself could lead to problems over the long term, because this incents people to think short term, and to cut corners and take on technical debt.\nBetter Software It’s easy to measure that you are writing good – or bad – software. Defect density. Defect escape rates (especially defects – including security vulnerabilities – that escape to production). Static analysis metrics on the code base, using tools like SonarQube.\nDevops As I pointed out in an earlier post this makes operational metrics more important than developer metrics. According to recent studies, success in achieving these goals lead to improvements in business success: not just productivity, but market share and profitability.\n그래서 결론은? Stop trying to measure individual developer productivity.\nIt’s a waste of time.\nEveryone knows who the top performers are. Point them in the right direction, and keep them happy.\nEveryone knows the people who are struggling. Get them the help that they need to succeed.\nEveryone knows who doesn\u0026rsquo;t fit in. Move them out.\nMeasuring and improving productivity at the team or (better) organization level will give you much more meaningful returns.\nWhen it comes to productivity:\nMeasure things that matter – things that will make a difference to the team or to the organization. Measures that are clear, important, and that aren\u0026rsquo;t easy to game. Use metrics for good, not for evil – to drive learning and improvement, not to compare output between teams or to rank people. ","date":"2015-11-01T15:02:04+09:00","permalink":"https://cychong47.github.io/post/2015/software-developeryi-saengsanseongeul-ceugjeonghal-su-isseulgga/","summary":"\u003cp\u003e\u003ca href=\"http://swreflections.blogspot.kr/2015/01/we-cant-measure-programmer-productivity.html?m=1\"\u003eWe can’t measure Programmer Productivity… or can we?\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"loc\"\u003eLOC\u003c/h2\u003e\n\u003cp\u003eThe more fundamental problem is that measuring productivity by lines (or Function Points or other derivatives) typed doesn’t make any sense. A lot of important work in software development, the most important work, involves thinking and learning – not typing.\u003c/p\u003e\n\u003cp\u003eThe best programmers spend a lot of time understanding and solving hard problems, or helping other people understand and solve hard problems, instead of typing. They find ways to simplify code and eliminate duplication. And a lot of the code that they do write won’t count anyways, as they iterate through experiments and build prototypes and throw all of it away in order to get to an optimal solution.\u003c/p\u003e","title":"Software developer의 생산성을 측정할 수 있을까?"},{"content":"예 ipsec on asf/se/\u0026hellip;\n불럭별 특징이 아니라 프로토콜별 호환성이나 주의사항에 대한 취합 필요\n보통 postmortem하면 그 블럭의 특징이라고 보는 경향이 강한데 그것과 무관하게 프로토콜 특성에 대한 내용은 블럭 설계와 별개로 모아놔야 하지 않을까?\nStackOverflow 처럼 분야별로\u0026hellip;\n","date":"2015-11-01T13:26:06+09:00","permalink":"https://cychong47.github.io/post/2015/bunyabyeol-nohau-gongyuga-pilyohande/","summary":"\u003cp\u003e예 ipsec on asf/se/\u0026hellip;\u003c/p\u003e\n\u003cp\u003e불럭별 특징이 아니라 프로토콜별 호환성이나 주의사항에 대한 취합 필요\u003c/p\u003e\n\u003cp\u003e보통 postmortem하면 그 블럭의 특징이라고 보는 경향이 강한데 그것과 무관하게 프로토콜 특성에 대한 내용은 블럭 설계와 별개로 모아놔야 하지 않을까?\u003c/p\u003e\n\u003cp\u003eStackOverflow 처럼 분야별로\u0026hellip;\u003c/p\u003e","title":"분야별 노하우 공유가 필요한데"},{"content":"VirtualBox supports emulated e1000 NIC for VM while VMware fusion does not. VMware Fusion\u0026rsquo;s VM setting does not support configuring of NIC HW type. The NIC HW is PCnet32 which is not supported by DPDK.\nHowever, we can change NIC HW type by editing VM configuration file directly.\nRefer : How to emulate 10 Gbps NIC in a VMware Fusion VM\nEdit vmx file to VMX file is in where vmware image located\nFor my case, this is where I can find\n~/Documents/Virtual Machines.localized/Ubuntu.vmwarevm/Ubuntu.vmx Note. VMX file is updated when VM is closed. Therefore, changes on this file while VM is running is overwritten by the VM\u0026rsquo;s current configuration. Be sure to quit VMware Fusion before changing this file.\nethernet3.present = \u0026quot;TRUE\u0026quot; ethernet3.connectionType = \u0026quot;custom\u0026quot; ethernet3.wakeOnPcktRcv = \u0026quot;FALSE\u0026quot; ethernet3.addressType = \u0026quot;static\u0026quot; ethernet3.vnet = \u0026quot;vmnet2\u0026quot; ethernet3.address = \u0026quot;00:50:56:2B:EC:A4\u0026quot; The reference guides to change the virtualDev string from e1000 to something else(10G for vmxnet3). However, I can not find ethernet3.virtualDev. So I just add it.\nethernet3.present = \u0026quot;TRUE\u0026quot; ethernet3.connectionType = \u0026quot;custom\u0026quot; ethernet3.wakeOnPcktRcv = \u0026quot;FALSE\u0026quot; ethernet3.addressType = \u0026quot;static\u0026quot; ethernet3.vnet = \u0026quot;vmnet2\u0026quot; ethernet3.address = \u0026quot;00:50:56:2B:EC:A4\u0026quot; ethernet3.virtualDev = \u0026quot;e1000\u0026quot; After starting VM, I can find VM has e1000 NIC for ethernet3.\nNow, eth3 is e1000 NIC.\n$ ethtool -i eth3 driver: e1000 version: 7.3.21-k8-NAPI firmware-version: bus-info: 0000:02:07.0 supports-statistics: yes supports-test: yes supports-eeprom-access: yes supports-register-dump: yes supports-priv-flags: no vmxnet3 for eth2 Once more, convert eth2 to vmxnet3\nethernet2.present = \u0026quot;TRUE\u0026quot; ethernet2.connectionType = \u0026quot;bridged\u0026quot; ethernet2.wakeOnPcktRcv = \u0026quot;FALSE\u0026quot; ethernet2.addressType = \u0026quot;generated\u0026quot; ethernet2.linkStatePropagation.enable = \u0026quot;TRUE\u0026quot; ethernet2.pciSlotNumber = \u0026quot;160\u0026quot; ethernet2.generatedAddress = \u0026quot;00:0c:29:52:14:e3\u0026quot; ethernet2.generatedAddressOffset = \u0026quot;20\u0026quot; ethernet2.virtualDev = \u0026quot;vmxnet3\u0026quot; And, it works too.\n$ ethtool -i eth2 driver: vmxnet3 version: 1.2.0.0-k-NAPI firmware-version: bus-info: 0000:03:00.0 supports-statistics: yes supports-test: no supports-eeprom-access: no supports-register-dump: yes supports-priv-flags: no Note. \u0026rsquo;e1000e\u0026rsquo; is also supported.\nethernet3.virtualDev = \u0026quot;e1000e\u0026quot; e1000 and e1000e are emulated device each for 1 Gbit Intel 82545EM card and 1 Gbit Intel 82574. e1000e is a newer one. Reference\n$ ethtool -i eth3 driver: e1000e Build DPDK The most easy way to build DPDK is using setup.sh\n$ source tools/setup.sh Option: 10 ================== Installing x86_64-native-linuxapp-gcc Configuration done == Build lib ... Build complete [x86_64-native-linuxapp-gcc] ------------------------------------------------------------------------------ RTE_TARGET exported as x86_64-native-linuxapp-gcc Three important environments.\nRTE_ARCH=x86_64 RTE_SDK=/home/cychong/dpdk-2.1.0 RTE_TARGET=x86_64-native-linuxapp-gcc ","date":"2015-10-20T14:19:05+09:00","permalink":"https://cychong47.github.io/post/2015/running-dpdk-on-vmware-fusion/","summary":"\u003cp\u003eVirtualBox supports emulated e1000 NIC for VM while VMware fusion does not. \u003cstrong\u003eVMware Fusion\u0026rsquo;s VM  setting does not support configuring of NIC HW type\u003c/strong\u003e. The NIC HW is PCnet32 which is not supported by DPDK.\u003c/p\u003e\n\u003cp\u003eHowever, we can change NIC HW type by editing VM configuration file directly.\u003c/p\u003e\n\u003cp\u003eRefer : \u003ca href=\"http://thesolutionsarchitect.net/how-to-emulate-10-gbps-nic-in-a-vmware-fusion-vm/\"\u003eHow to emulate 10 Gbps NIC in a VMware Fusion VM\u003c/a\u003e\u003c/p\u003e\n\u003ch5 id=\"edit-vmx-file-to\"\u003eEdit vmx file to\u003c/h5\u003e\n\u003cp\u003eVMX file is in where vmware image located\u003c/p\u003e","title":"Running DPDK on VMware Fusion"},{"content":"DPDK Userspace in Dublin 2015에서 발표\nStageful traffic generator\n특징 Generate traffic based on templates of real, captured flows No TCP/IP stack Up to 200Gbps with standard server hardware Low cost 1RU (C220M UCS-1RU) Cisco internal DPDK, ZMQ, Python libs Virtualization(vmxnet3/e1000) ~20Gbps per core Generate flow templates Support 1K templates Yaml based traffic profile GUI GUI which monitors real-time properties of TRex - min/max/average latency, jitter\nPython 연동 Code https://github.com/cisco-system-traffic-generator/trex-core\nManual http://trex-tgn.cisco.com/trex/doc/trex_manual.html\nWeb-site http://trex-tgn.cisco.com\nPresentation http://trex-tgn.cisco.com/trex/doc/trex_preso.html\n","date":"2015-10-12T13:11:14+09:00","permalink":"https://cychong47.github.io/post/2015/trex-dpdk-based-traffic-generator/","summary":"\u003cp\u003eDPDK Userspace in Dublin 2015에서 발표\u003c/p\u003e\n\u003cp\u003eStageful traffic generator\u003c/p\u003e\n\u003ch5 id=\"특징\"\u003e특징\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003eGenerate traffic based on templates of real, captured flows\u003c/li\u003e\n\u003cli\u003eNo TCP/IP stack\u003c/li\u003e\n\u003cli\u003eUp to 200Gbps with standard server hardware\u003c/li\u003e\n\u003cli\u003eLow cost 1RU (C220M UCS-1RU)\u003c/li\u003e\n\u003cli\u003eCisco internal\u003c/li\u003e\n\u003cli\u003eDPDK, ZMQ, Python libs\u003c/li\u003e\n\u003cli\u003eVirtualization(vmxnet3/e1000)\u003c/li\u003e\n\u003cli\u003e~20Gbps per core\u003c/li\u003e\n\u003cli\u003eGenerate flow templates\u003c/li\u003e\n\u003cli\u003eSupport 1K templates\u003c/li\u003e\n\u003cli\u003eYaml based traffic profile\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch5 id=\"gui\"\u003eGUI\u003c/h5\u003e\n\u003cp\u003eGUI which monitors real-time properties of TRex  - min/max/average latency, jitter\u003c/p\u003e\n\u003ch5 id=\"python-연동\"\u003ePython 연동\u003c/h5\u003e\n\u003cp\u003e\u003cimg src=\"/images/2015/10/TRex_realistic_traffic_generator.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003ch5 id=\"code\"\u003eCode\u003c/h5\u003e\n\u003cp\u003e\u003ca href=\"https://github.com/cisco-system-traffic-generator/trex-core\"\u003ehttps://github.com/cisco-system-traffic-generator/trex-core\u003c/a\u003e\u003c/p\u003e","title":"TRex - DPDK based traffic generator"},{"content":"From http://www.theeffectiveengineer.com/blog/what-makes-a-good-engineering-culture\n1. Optimize for iteration speed Continous deployment to support rapid validation High test coverage to reduce build and site breakages Fast unit tests to encourage people to run them Fast and incremental compiles and reloads to reduce development time Bill Walsh, 49ers to 3 Super bowls,\nCommit, Explode, Recover\nA team crippled with indecisiveness will just cause individual efforts to flounders\n2. Push relentlessly toward automation Consider operational burden per engineer\nratio of users to engineer radio of features to engineers Automating solutions and scripting repetitive tasks are important because they free up the engineers team to work on the actual product\nEasy\u0026rsquo;s motto of \u0026ldquo;Measure anything, measure everything\u0026rdquo; Automation must be driven by data and monitoring\n3. Build the right software abstractions MIT professor, Daniel Jackson\nPick the right one, and programming will flow naturally from design modules will have small and simple interface\nnew functionality will more likely fit in without extensive reorganization\nGoogle, Jeff Dean and Sanjay Ghemawat\nKeeping core abstractions simple and general\nreduces the need for custom solutions increases the team\u0026rsquo;s familiarity and expertise with the common abstraction common libraries get more robust monitoring gets more intelligent performance characteristics get better understood tests get more comprehensive 4. Develop a focus on high code quality with code reviews Technical debt easily accumulate from poorly written code\n5. Maintain a respectful work environment 6. Build shared ownership of code Free engineers from the sense that they\u0026rsquo;re stuck on certain projects and encourages them to work on a diversity of projects\nSwarm : The idea is that everyone on your team works on the same story at the same time\n7. Invest in automated testing Unit test coverage and some degrees of integrating test coverage is the only scalable way of managing a large codebase with a large group of people without constantly breaking the build or the product.\n8. Allot 20% time 9. Build a culture of learning and continuous improvement 10. Hire the best ","date":"2015-09-30T13:41:57+09:00","permalink":"https://cychong47.github.io/post/2015/what-makes-a-good-engineering-culture/","summary":"\u003cp\u003eFrom \u003ca href=\"http://www.theeffectiveengineer.com/blog/what-makes-a-good-engineering-culture\"\u003ehttp://www.theeffectiveengineer.com/blog/what-makes-a-good-engineering-culture\u003c/a\u003e\u003c/p\u003e\n\u003ch3 id=\"1-optimize-for-iteration-speed\"\u003e1. Optimize for iteration speed\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eContinous deployment to support rapid validation\u003c/li\u003e\n\u003cli\u003eHigh test coverage to reduce build and site breakages\u003c/li\u003e\n\u003cli\u003eFast unit tests to encourage people to run them\u003c/li\u003e\n\u003cli\u003eFast and incremental compiles and reloads to reduce development time\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eBill Walsh, 49ers to 3 Super bowls,\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eCommit, Explode, Recover\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eA team crippled with indecisiveness will just cause individual efforts to flounders\u003c/p\u003e\n\u003ch3 id=\"2-push-relentlessly-toward-automation\"\u003e2. Push relentlessly toward automation\u003c/h3\u003e\n\u003cp\u003eConsider operational burden per engineer\u003c/p\u003e","title":"What makes a good engineering culture?"},{"content":"부서간 협력이 잘 안되는 듯 하니 대책으로 \u0026lsquo;부서간 협력지수\u0026rsquo;를 수치화해서 평가하겠다. 그럼 협력이 잘 될까 궁금하네\n","date":"2015-09-20T01:31:36+09:00","permalink":"https://cychong47.github.io/post/2015/buseogan-hyeobryeogi-an-doeni-daecaegeuro/","summary":"\u003cp\u003e부서간 협력이 잘 안되는 듯 하니 대책으로 \u0026lsquo;부서간 협력지수\u0026rsquo;를 수치화해서 평가하겠다. 그럼 협력이 잘 될까 궁금하네\u003c/p\u003e","title":"부서간 협력이 안 되니 대책으로"},{"content":"HP, Intel, Cisco/Juniper, WindRiver 외에 Orchestrator 관련 회사도 다수 존재.\n개인적으로는 역시 Nokia가 가장 관심이 가는데\nTelco Cloud portfolio - virtualizing radio functions - LTE eNB L2/L3 processing, MME and GW functionality, Wi-Fi controllers and virtual RNCs and vBSCs Multi-layer architecture - pioneers the use of Ethernet fronthaul and any combination of distributed and centralized deployments Processing capacity is allocated from almost anywhere in the network, such as an adjacent cell or a centralized data center, to where it is needed most for coordination and capacity. The multi-layer approach supports distributed and centralized deployments, or a combination of both, using multiple fronthaul types, including Ethernet. Ready for the upcoming demands of 5G core and radio demands 출처 : Leading Lights 2015 Finalists: Most Innovative NFV Product Strategy (Vendor)\n","date":"2015-09-19T13:11:50+09:00","permalink":"https://cychong47.github.io/post/2015/leading-lights-2015-finalists-most-innovative-nfv-product-strategy-vendor/","summary":"\u003cp\u003eHP, Intel, Cisco/Juniper, WindRiver 외에 Orchestrator 관련 회사도 다수 존재.\u003c/p\u003e\n\u003cp\u003e개인적으로는 역시 Nokia가 가장 관심이 가는데\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTelco Cloud portfolio - virtualizing radio functions - \u003cstrong\u003eLTE eNB L2/L3 processing\u003c/strong\u003e, MME and GW functionality, Wi-Fi controllers and virtual RNCs and vBSCs\u003c/li\u003e\n\u003cli\u003eMulti-layer architecture - pioneers the use of Ethernet fronthaul and any combination of distributed and centralized deployments\u003c/li\u003e\n\u003cli\u003eProcessing capacity is allocated from almost anywhere in the network, such as an adjacent cell or a centralized data center, to where it is needed most for coordination and capacity.\u003c/li\u003e\n\u003cli\u003eThe multi-layer approach supports distributed and centralized deployments, or a combination of both, using multiple fronthaul types, including \u003cstrong\u003eEthernet\u003c/strong\u003e.\u003c/li\u003e\n\u003cli\u003eReady for the upcoming demands of \u003cstrong\u003e5G\u003c/strong\u003e core and radio demands\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e출처 : \u003ca href=\"http://www.lightreading.com/nfv/nfv-strategies/leading-lights-2015-finalists-most-innovative-nfv-product-strategy-(vendor)/d/d-id/716166\"\u003eLeading Lights 2015 Finalists: Most Innovative NFV Product Strategy (Vendor)\u003c/a\u003e\u003c/p\u003e","title":"Leading Lights 2015 Finalists - Most Innovative NFV Product Strategy (Vendor)"},{"content":"어딘가 보고 정리한 글인데 출처를 기억하지 못하겠다\u0026hellip;.\nSW 품질 개선 노력의 대상 SW 품질을 높이는데 Tool, System, People 그리고 Management중에 어떤 면을 개선하는 경우 효과가 높을까?\nTool : 2 배 System : 10배 People : 30배 Management : 60배 이상 그렇지만 대개의 관리자는 개선효과를 반대로 알고 있다.\n사람은 변화해야 할 때 변화한다(더 이상 저항하지 못할 때) 그러나 위기는 갑자기 오지 않는다. 다만 위기에 대한 인지를 갑자기 할 뿐이다.\n변화는 성능 저하를 유발한다. 그 성능 저하를 감수하고, 계속 변화해가야 변화가 주는 효과를 얻을 수 있다.\n고객 가치 중심 Agile은 가치가 높은 것을 가장 먼저 개발하여 SW의 가치를 초기부터 높이려고 노력한다. Action과 Result사이에 시간차가 크면 학습효과가 낮다. SW에서는 설계 내용이 Coding을 거쳐 Test하는 시점이 설계 시점과 멀면 멀 수록 학습효과가 낮아진다(잘못된 설계를 다른 기능 설계시에도 반영할 가능성이 높아진다) Agile에서는 설계/구현/Test의 간극을 줄여 학습효과를 높인다. 이를 위해 기능을 User story로 나누고, 1개 혹은 몇 개의 user story를 기준으로 빌드하여 User story를 추가해 나간다. 이때 user story는 사용자 입장에서의 사용 패턴이다. 하나의 Story는 여러개의 task로 나뉘어진다. Story가 사용자 측면의 기능이라면 task는 개발자 입장에서의 업무이다. 예) \u0026ldquo;xx 카드 승인 기능\u0026quot;이 story라면 해당 story를 구현하기 위해 필요한 기능들 \u0026ldquo;DB 설계\u0026rdquo;, \u0026ldquo;UI 구현\u0026quot;등등이 task다. Collaboration 한 사람이 1시간 동안 핵심적인 버그를 발견할 확률이 0.1이라고 하면, 총 7명이 있을 때 모든 사람이 버그를 발견할 확률은? 0.1^7 = 0.0000001 한 사람이라도 버그를 발견할 확률은? 1 - 0.9^7 = 0.53 예측 Task는 세분화할 수록 소요시간 예측력이 높아진다. 상벌은 개개인별이 아니라 팀단위로 이루어져야 효과가 높다. 동시에 팀웍 강화 노력도 필요. 개발자들은 절대시간으로 표현해야 하는 절대 시간 추정 능력은 떨어지지만, Story끼리의 상대적인 시간 소요를 비교할 때 필요한 상대 시간 추정 능력은 뛰어나다. ","date":"2015-09-13T05:23:38+09:00","permalink":"https://cychong47.github.io/post/2015/sw_quality/","summary":"\u003cp\u003e어딘가 보고 정리한 글인데 출처를 기억하지 못하겠다\u0026hellip;.\u003c/p\u003e\n\u003ch5 id=\"sw-품질-개선-노력의-대상\"\u003eSW 품질 개선 노력의 대상\u003c/h5\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003eSW 품질을 높이는데 Tool, System, People 그리고 Management중에 어떤 면을 개선하는 경우 효과가 높을까?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eTool : 2 배\u003c/li\u003e\n\u003cli\u003eSystem : 10배\u003c/li\u003e\n\u003cli\u003ePeople : 30배\u003c/li\u003e\n\u003cli\u003eManagement : 60배 이상\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e그렇지만 대개의 관리자는 개선효과를 반대로 알고 있다.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e사람은 변화해야 할 때 변화한다(더 이상 저항하지 못할 때) 그러나 위기는 갑자기 오지 않는다. 다만 위기에 대한 인지를 갑자기 할 뿐이다.\u003c/p\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e변화는 성능 저하를 유발한다. 그 성능 저하를 감수하고, 계속 변화해가야 변화가 주는 효과를 얻을 수 있다.\u003c/p\u003e","title":"SW 품질 강화 노력"},{"content":"경쟁을 부추켜서 조직의 성과를 얻으려는 관리자는 아무런 노력도 하지 않고 결과만 날로 먹으려는 것과 같다. 아무 고민없이 할 수 있는 제일 쉬운 방법이니까.\n조직원들에게 동기부여를 줄지, 조직의 협동심을 아떻게하면 높일 수 있을 지 고민할 필요가 없이 결과만 취하면 되니까. 그런 관리자는 조직에 해를 끼치는 존재다.\n할 수 있는 게 없는 건지,해도 안되는 건지. 여러가지 방법을 써도 안된다면 조직원과 함께 고민하면 안될까. 함께 속해 있는 \u0026lsquo;조직\u0026rsquo;의 성과를 위한 거니까\n@유정식의 \u0026lsquo;착각하는 CEO\u0026rsquo;를 읽는 중 프랑스/베트남/쥐 박멸/쥐 사육 부분을 읽고\n","date":"2015-09-12T10:28:31+09:00","permalink":"https://cychong47.github.io/post/2015/competetion_is_like_drug/","summary":"\u003cp\u003e경쟁을 부추켜서 조직의 성과를 얻으려는 관리자는 아무런 노력도 하지 않고 결과만 날로 먹으려는 것과 같다. 아무 고민없이 할 수 있는 제일 쉬운 방법이니까.\u003c/p\u003e\n\u003cp\u003e조직원들에게 동기부여를 줄지, 조직의 협동심을 아떻게하면 높일 수 있을 지 고민할 필요가 없이 결과만 취하면 되니까. 그런 관리자는 조직에 해를 끼치는 존재다.\u003c/p\u003e\n\u003cp\u003e할 수 있는 게 없는 건지,해도 안되는 건지. 여러가지 방법을 써도 안된다면 조직원과 함께 고민하면 안될까. 함께 속해 있는 \u0026lsquo;조직\u0026rsquo;의 성과를 위한 거니까\u003c/p\u003e\n\u003cp\u003e@유정식의 \u0026lsquo;착각하는 CEO\u0026rsquo;를 읽는 중 프랑스/베트남/쥐 박멸/쥐 사육 부분을 읽고\u003c/p\u003e","title":"경쟁을 통한 성과 추구는 마약과 같다"},{"content":"일단 책 제목부터 구박.\n\u0026ldquo;People Analytics: How social technology will transform business and what it tells us about the future of work\u0026quot;인데 이게 왜 저런 한글 제목이 된건지. 책 내용을 보면 짐작은 가지만, 책 제목만 봐서는 구글이 빅데이터를 이용해서 어떤 서비스를 만들어냈는지 라고 해석할 수 있지 않을까? 실제로는 구글등의 회사에서 빅데이터를 이용해 직원들 관리에 어떻게 활용했는지에 대한 내용이다. 그리고 실제 구글 이야기는 많이 나오지도 않는다.\n하지만 책 내용에는 저자가 강조하는 몇 가지 핵심 내용이 있다. 그리고 그 내용에 나도 동의한다. 그것도 쌍수를 듣고. 그리고 지금 우리 회사에서 가장 문제가 되는 취약점이 이게 아닌가 싶다. 더불어 지금의 위기를 해결해 나가는데 이런 점을 해결하면 위기 극복에 분명 큰 도움이 될 거라고 생각한다.\n직원의 생산성에 영향을 끼치는 가장 강력한 예측 변수가 바로 직원들 간의 대화라는 자료를 내놓았다.\n책에서 강조하는 핵심 내용은 조직을 구성하는 구성원들이 서로 정보를 공유하는 가장 효과적인 방법은 회의와 같은 공식적인 채널보다는 식수대 앞에서와 같이 편하게 만나 나누는 대화라는 점이다. 공식적인 대화 채널로는 진정으로 유의미한 정보를 자발적으로 공유하게 만들 수 없고, 위에서 시키는 내용만 형식적으로 전달하기 마련이다. 그럼 그 정보를 좀 더 의미있는 것으로 만들기 위해 윗 사람은 그 정보를 평가하고, 또 다른 지시를 내린다. 다시 그 지시를 받은 사람은 또 다른 숙제를 할 뿐 진정으로 다른 이에게 도움이 되는 정보는 좀처럼 공유되지 않는다.\n직원들간의 네트워크 방식은 회사 내에서 정보의 흐름과 업무 방식에 중대한 영향을 미친다.\n그리고 보니 회사에서 정보가 공유되는 방식은 거의 일방적이다. 늘 위에서 그 위로부터 받은 내용을 해석해서(혹은 해석도 하지 않고) 아래로 내려 보낸다. 이때 네트워크는 정보를 받는 사람과 주는 사람간에만 활발해진다. 정보를 받은 사람들 간의 네트워크는 별로 없다. 실은 그 사람들이 서로 받은 그리고 서로 알고 있는 정보를 공유해서 새로운 정보를 만들어 내야 함에도 불구하고\n기업들은 반드시 개발자들끼리 얼굴을 맞대고 의사소통을 많이 할 수 있는 분위기를 만들어야 한다. 우리 연구 결과가 분명히 보여주듯이, 의사소통의 불일치를 좁히는 데 디지털 의사소통 수단에만 의존할 수 없기 때문이다.\n여기서 말하는 디지털 의사 소통은 이메일을 말하는 듯 하다. 이메일은 일방적인 경우가 많다. 말로하면 서로의 오해를 쉽게 그리고 빠르게 풀 수 있는 경우도 여러 번의 이메일 교환이 필요한 경우도 있다.\n직원들의 소셜 네트워크가 얼마나 응집력이 높은지에 따라 생산성이 크게 달려졌기 때문이다. 직원들이 서로 대화를 많이 하면 할수록 직원들의 생산성이 더욱 높아졌다.\n과연 우리는 자발적으로 정보를 공유하고 있는지 의문이다. 그러다면 왜 정보를 공유하지 않는 걸까?\n직원들의 지식 공유가 바로 궁극적인 회사 생산력 향상의 원동력이다.\n왜 관리자들은 이런 지식 공유에 대해 강조하지 않을까? 단 한번도 지식/정보 공유에 대해 강조하거나, 분위기 조성을 위해 노력한 관리자를 본 적이 없다.\n그렇다면 어떻게 해야 할까? 정보를 공유할 수 있는 공간을 만들고, 내가 알게 된, 내가 정리한 정보를 계속해서 공유하고, 공유하는 모습을 보여줘야 한다. 솔선수범해야 다른 사람에게도 시킬 수 있다.\n기업에서 장기적으로 창의성이 계속해서 일어나려면, 다양한 분야의 직원들이 서로 교류를 해야 한다. 자신이 아는 사람만 사귀다 보면, 항상 같은 의견을 가진 직원들하고만 대화하기 마련이다. 그렇게 해서 노키아는 자신이 속한 휴대전화 시장에서 주요한 파괴적인 혁신이 일어났는지 몰랐다. 노키아는 그 폐쇄적인 조직 문화때문에 시장 장악력을 활용해서 스마트폰을 기업 전략의 핵심으로 올려놓는 혁신을 이루어내지 못했다.\n대형 프로젝트를 추진할 때 직원들은 흔히 큰 문제에만 집중하고 작은 문제는 방치하다가 나중에 문제가 커지는 사태를 맞는 경우가 많다. 형식에 얽매이지 않는 의사소통이 중요한 이유가 바로 여기에 있다. 이런 작은 문제는 공식적인 회의에서는 잘 드러나지 않는다. 그것은 모든 사람이 시간을 들여 귀 기울일 만큼 중요하지 않기 때문이다. 하지만 그런 사소한 문제는 직원들이 정수기 앞에서 잡담하기에 안성맞춤인 주제다. 직원들이 이렇게 사소한 문제를 두고 의사소통할 때, 앞으로 일어날 문제를 미연에 방지할 수 있다.\n메사추세츠 교통국의 문제 해결 방식은 작은 문제점들을 몇 년동안 방치하면서 그것이 갑자기 눈덩이처럼 불어나 큰 문제로 닥쳐왔다는 것이 문제였다. 이렇게 문제가 커졌을 때 이를 바로잡으려면 더 많은 비용이 들어간다.\n의존성 추척 도구는 거의 모든 주료 소프트웨어 개발 환경으로 통합되었고, 의존성 문제를 자동으로 검출하기 위한 수십가지 방법은 지난 수십 년 동안 컴퓨터 공학계의 화제가 되었다 최근에는 의사소통의 중요성이 이런 단계까지 이르렀다. 연구자와 산업계 종사자들은 공식적인 보고 도구만으로는 의존성 문제를 해결할 수 없다는 사실을 깨달았다. 개발자들 사이의 상호작용(의사소통)이 있어야 의존성 문제를 적절히 해소할 수 있다고 판단한 것이다. 연구자와 개발자들은 심지어 상호작용의 문제점을 지칭하는 전문용어까지 만들어냈다.\n소프트웨어 개발 과정에서 의존성 문제는 의사소통으로 제대로 해결되거나 그렇지 않으면 도중에 실패한다.\n프로젝트와 관련된 팀들이 자신의 의존성 문제를 언급할 수 있는 문제를 조성하는 것이 프로젝트의 성공의 관건이다.\n개발자들끼리 대화하는 데 추가로 시간을 5퍼센트 더 쓸 것인지 아니면 오류를 수정하는 데 시간을 30퍼센트 더 쓸 것인지, 둘 중에 어떤 선택을 해야 할 지는 분명해 보인다.\n기업들은 반드시 개발자들끼리 얼굴을 맞대고 의사소통을 많이 할 수 있는 분위기를 만들어야 한다. 우리 연구 결과가 분명히 보여주듯이, 의사소통의 불일치를 좁히는 데 디지털 의사소통 수단에만 의존할 수 없기 때문이다.\n","date":"2015-09-07T14:51:35+09:00","permalink":"https://cychong47.github.io/post/2015/caeg-gugeuleun-bigdeiteoreul-eoddeohge-hwalyonghaessneunga/","summary":"\u003cp\u003e일단 책 제목부터 구박.\u003c/p\u003e\n\u003cp\u003e\u0026ldquo;People Analytics: How social technology will transform business and what it tells us about  the future of work\u0026quot;인데 이게 왜 저런 한글 제목이 된건지. 책 내용을 보면 짐작은 가지만, 책 제목만 봐서는 구글이 빅데이터를 이용해서 어떤 서비스를 만들어냈는지 라고 해석할 수 있지 않을까? 실제로는 구글등의 회사에서 빅데이터를 이용해 직원들 관리에 어떻게 활용했는지에 대한 내용이다. 그리고 실제 구글 이야기는 많이 나오지도 않는다.\u003c/p\u003e\n\u003cp\u003e하지만 책 내용에는 저자가 강조하는 몇 가지 핵심 내용이 있다. 그리고 그 내용에 나도 동의한다. 그것도 쌍수를 듣고. 그리고 지금 우리 회사에서 가장 문제가 되는 취약점이 이게 아닌가 싶다. 더불어 지금의 위기를 해결해 나가는데 이런 점을 해결하면 위기 극복에 분명 큰 도움이 될 거라고 생각한다.\u003c/p\u003e","title":"(책) 구글은 빅데이터를 어떻게 활용했는가"},{"content":"Link : http://www.bloter.net/archives/233978\n스포카는 측정 가능한 업무 시스템을 위해 깃허브, 슬랙, 지라 같은 협업 도구를 이용했다. 직원들은 협업 도구들로 기록을 철저히 하면서 업무상황을 공유하고 있다. 기록 내용은 아주 자세한 내용을 담는다. 예를 들어 ‘○○에게 e메일을 보냈다’, ‘A에게 답변을 받았다’, ‘개발을 위한 자료 조사 중’ 같은 식이다. 이 내용은 직원별로 볼 수 있다. e메일 내용이 어떤 것이었는지, 자료 조사는 어떤 것을 했는지도 상세히 기록되고 있다.\n김재석 CTO는 “처음에는 기록을 습관화하는 데 시간이 조금 더 걸렸다”라며 “기록을 편하게 할 수 있도록 기존 협업도구를 스포카 환경에 맞게 재개발하기도 했다”라고 설명했다. 예를 들어 스포카는 채팅도구에 일본어 번역기를 붙여 일본어와 한국어를 모르는 직원들이 서로 정보를 공유할 수 있게 돕고 있다.\n기록의 습관화. 중요하다. 어떤 일을 한 후에 기록하지 않으면 시간이 지나면 그 일을 한 사람조차 \u0026ldquo;어떤 일\u0026quot;이 있었는지, 그 일의 \u0026ldquo;이유\u0026quot;가 뭐 였는지, 그 \u0026ldquo;결과\u0026quot;가 어땠는 지 기억조차 남지 않는다. 하물며 그 담당자가 다른 업무를 하거나, 연락이 안되는 상황이라면 어떻게 할 건지.\n리모트를 도입하며 스포카엔 보고 문화가 없어졌다. 정보가 모든 팀원을 상대로 투명하게 공유되기 때문이다. 김재석 CTO는 “의도하지 않았지만 해외 진출하는 과정에서 좋은 효과를 보고 있다”라며 “해외 지사 혹은 본사에서 나눴던 이야기가 차별 없이 많은 사람에게 공유되고 있다”라고 설명했다.\n정말 좋은 결과. 단순히 어떤 일이 있었는지를 보고하는 시간만큼 시간 낭비가 없다. 여러 사람이 함께 하는 만큼 그 시간은 보도 생산적인 일에 투자해야 한다. 함께 논의할 필요가 있거나, 함께 고민해야 할 일에 대해 시간을 투자해야지, 각자 필요한 정보를 보고 혼자서 할 수 있는 것을 굳이 여러 사람이 모인 자리에서 말로 설명할 필요는 없다.\n","date":"2015-07-28T12:26:14+09:00","permalink":"https://cychong47.github.io/post/2015/peom-seupoka-seongjang-baegyeong-rimoteuwa-beulrogeu-munhwa-deogbunijyo/","summary":"\u003cp\u003eLink : \u003ca href=\"http://www.bloter.net/archives/233978\"\u003ehttp://www.bloter.net/archives/233978\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e스포카는 측정 가능한 업무 시스템을 위해 깃허브, 슬랙, 지라 같은 협업 도구를 이용했다. 직원들은 협업 도구들로 기록을 철저히 하면서 업무상황을 공유하고 있다. 기록 내용은 아주 자세한 내용을 담는다. 예를 들어 ‘○○에게 e메일을 보냈다’, ‘A에게 답변을 받았다’, ‘개발을 위한 자료 조사 중’ 같은 식이다. 이 내용은 직원별로 볼 수 있다. e메일 내용이 어떤 것이었는지, 자료 조사는 어떤 것을 했는지도 상세히 기록되고 있다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e김재석 CTO는 “처음에는 기록을 습관화하는 데 시간이 조금 더 걸렸다”라며 “기록을 편하게 할 수 있도록 기존 협업도구를 스포카 환경에 맞게 재개발하기도 했다”라고 설명했다. 예를 들어 스포카는 채팅도구에 일본어 번역기를 붙여 일본어와 한국어를 모르는 직원들이 서로 정보를 공유할 수 있게 돕고 있다.\u003c/p\u003e","title":"(펌) 스포카, \"성장 배경? '리모트'와 '블로그 문화' 덕분이죠\""},{"content":"from NASA/JPL(Jet Propulsion Laboratory)\nThe result is that most existing guidelines contain well over a hundred rules, sometimes with questionable justification. Some rules especially those that try to stipulate the use of white-space in programs, may have been introduced by personal preference; others are meants to prevent very specific and unlikely types of error from eariler coding efforts within the same organization.\n효율적인 가이드라인이 되려면, rule의 개수는 적어야 하고, 쉽게 이해되고, 기억될 수 있을 만큼 명확해야 한다.\n규칙은 기계적으로 검사할 수 있을 만큼 구체적이어야 한다.\nRule 1 모든 코드는 매우 간단한 control flow를 가져야 한다. goto, setjmp, longjmp 그리고 직간접의 recursion은 사용하지 않는다.\n향상된 code clarity\nRule 2 All loops must have a fixed upper-bound Rule 3 Do not use dynamic memory allocation after initialization Memory allocator and garbage collectors often have unpredictable behavior that can significantly impact performance.\nRule 4 No function should be longer than what can be printed on a single sheet of paper 60 lines of code per function\nRule 5 The assertion density of the code should average to a minimum of two assertions per function Assertions must always be side-effect free and should be defined as Boolean tests. When an assertion fails, an explict recovery action must be taken(returning error condition to the caller of the function)\nRule 6. Data object must be declared at the smallest possible level of scope Prefer local and static rather than Global\nThe rule discourages the re-use of variables for multiple, incompatible purposes, which can complicated fault diagnosis.\nRule 7. The return value of non-void functions must be checked by each calling function, and the validity of parameters must be checked inside each function Rule 8. The use of preporcessor must be limited to the inclusion of header files and simple macro definitions. Token pasting, variable argument lists, and recursive macro calls are not allowed.\nThe use of conditional compilation directives is often also dubious, but cannot always be avoided. This means that there should rarely be justification for more than one or two conditional compilation directives even in large software development efforts, beyond the standard boilderplate that avoids multiple inclusion of the same header file.\n(boilerplate : Boilerplate (spaceflight), non-functional craft, system, or payload which is used to test various configurations and basic size, load, and handling characteristics)\nThe c preprocessor is a powerful obfuscation tool that can destroy code clarity and befubble many text based checkers.\n10 conditional compilation directives, there could be up to 2^10 possible versions of the code\nRule 9. The use of pointers should be restricted. Specifically, no more one level of dereference is allowed. Function pointers are not permitted. Rule 10. All code must be compiled, from the fist day of development, with all compiler warnings enabled at the compiler\u0026rsquo;s most pedantic settings. There simply is no excuse for any software development effort not to make use of this readily available technology. It should be considered routine practices, even for non-critical code development. Many devlopers have been caught in the assumption that a warning was surely invalid, only to realize much later that the message was in fact valid for less obvious reasons.\nRule 1~2 gurantees the creation of a clear and trasnparent control flow structure that is easier to build, test and anazyze\n","date":"2015-07-27T22:50:35+09:00","permalink":"https://cychong47.github.io/post/2015/the-power-of-ten-rules-for-developing-safety-critical-code/","summary":"\u003cp\u003efrom NASA/JPL(Jet Propulsion Laboratory)\u003c/p\u003e\n\u003cp\u003eThe result is that most existing guidelines contain well over a hundred rules, sometimes with questionable justification. Some rules especially those that try to stipulate the use of white-space in programs, may have been introduced by personal preference; others are meants to prevent very specific and unlikely types of error from eariler coding efforts within the same organization.\u003c/p\u003e\n\u003cp\u003e효율적인 가이드라인이 되려면, rule의 개수는 적어야 하고, 쉽게 이해되고, 기억될 수 있을 만큼 명확해야 한다.\u003cbr\u003e\n규칙은 기계적으로 검사할 수 있을 만큼 구체적이어야 한다.\u003c/p\u003e","title":"The Power of Ten-Rules for Developing Safety Critical Code"},{"content":"p81 전문가라서 승진했더니 전문적인 일에서는 점점 더 멀어지고, 해보지 않은 일을 끊임없이 떠안기는 게 현대 기업의 문화다. 이 과정에서 효율이 떨어지기라도 한다면 기업은 \u0026lsquo;너는 쓸모없다\u0026rsquo;며 직원을 내친다.\n중요한 것은 일을 제대로 해내는 능력을 갖춘 사람이다. 누구나 똑같은 말을 한다. 하지만 대기업은 최고의 능력을 갖춘 사람을 구하지 않는다. 조직 논리에 순적응할 수 있는 사람을 찾을 뿐이다. 따라서 결과적으로 대기업은 최고가 될 수 없다.\n그래서 Steve Jobs가 Apple은 여전히 작은 venture들의 모임이라고 한 건가? 그러게 되길 원하고\np83 \u0026lsquo;초전문화(Hyper Specialization)\u0026rsquo;\n초전문화로 얼마나 품질이 개선될 지 가늠하려면, 지금 자신이 스스로의 전문성과 상관없는, 따라서 잘하지도 못하는 일에 개인적으로 얼마나 많은 시간을 쏟고 있는 지 생각해보라.\np156 세상 모든 일이 그렇듯, 나이를 먹어서 뭔가 할 수 없는 사람은 젊은 시절에도 아무것도 할 수 없을 뿐이었다.\n","date":"2015-07-04T15:21:38+09:00","permalink":"https://cychong47.github.io/post/2015/caeg-big-seumol/","summary":"\u003ch3 id=\"p81\"\u003ep81\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e전문가라서 승진했더니 전문적인 일에서는 점점 더 멀어지고, 해보지 않은 일을 끊임없이 떠안기는 게 현대 기업의 문화다. 이 과정에서 효율이 떨어지기라도 한다면 기업은 \u0026lsquo;너는 쓸모없다\u0026rsquo;며 직원을 내친다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cblockquote\u003e\n\u003cp\u003e중요한 것은 일을 제대로 해내는 능력을 갖춘 사람이다. 누구나 똑같은 말을 한다. 하지만 대기업은 최고의 능력을 갖춘 사람을 구하지 않는다. 조직 논리에 순적응할 수 있는 사람을 찾을 뿐이다. 따라서 결과적으로 대기업은 최고가 될 수 없다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e그래서 Steve Jobs가 Apple은 여전히 작은 venture들의 모임이라고 한 건가? 그러게 되길 원하고\u003c/p\u003e","title":"(책) 빅 스몰"},{"content":"\n출처 : 관리의 기본 (Fundamental of management) #2 - 관리자/리더에게 필요한 역량\n가장 중요한 것은 Communication 역량으로, 팀내 또는 팀간의 조율을 위해서는 반드시 필요한 능력이라고 생각한다. 두말할 필요가 없는 부분인데, 효과적인 커뮤니케이션 스킬을 가지기 위해서는 상호 존중이 바탕이 되어야 한다. 존중의 바탕이 없이는 명령이되고, 명령은 팀을 Push하는 모델을 만들지, 팀이 스스로 높은 성과를 낼 수 있도록 Pull (당기는 형태)의 리더쉽을 만들어내기는 어렵다.\n관리자로써 전체적인 계획을 만들고 이를 실행하려면, 팀원들을 코칭할 필요가 있다. 이것이 Coaching skill이고.\n팀 셋업이나 팀관리에 대한 스킬, 프로젝트 관리 능력들도 당연히 중요한 스킬이 된다.\n컴퓨터 스킬이 들어 있는데, 단순히 MS 오피스와 같은 컴퓨터 스킬만을 이야기 하는 것이 아니라, 근래에 들어서 협업 관리 툴이 많이 보급 되고 있다. Slack과 같은 메신져나 JIRA와 같은 이슈 트랙킹 도구, 드롭박스나 구글과 같은 문서 협업도구들은 이러한 능력을 가지고 있으냐 마느냐, 그리고 이를 얼마나 효과적으로 팀에 도입할 수 있느냐 여부에 따라서도 팀의 성과에 많은 영향을 준다.\n다음으로, 주목할만한 것이 Writing Skill (쓰기의 기술)이다. 전적으로 공감하는 부분인데, 문서를 작성하고 이메일을 작성할때 효과적인 문서화는 효과적인 커뮤니케이션을 불러오고 팀을 효율적으로 일할 수 있게 해준다. 많은 관리자, 아니 비단 관리자뿐만 아니라 많은 사람들이 문서화 또는 쓰기 기술에 약해서 의사 전달이 잘못되서 효율성이 떨어지는 경우가 많다.\n마지막으로 주목할 부분은 Resource management skill로, 리소스란 사람, 돈 등 가용할 수 있는 자원을 모두 리소스라고 한다. 결국 관리란, 이 리소스를 효과적인 시점에 효율적으로 투여 하는 것인데, 이 리소스에 대한 개념이 없으면 팀의 역량을 엉뚱한곳으로 투여되서, 팀의 역량이 낭비되는 결과를 초래한다.\n가장 중요한 것이 communication skill임에도 불구하여, 여전히 조직에서 발생하는 문제점(버그) 수를 줄이는 것이 가장 중요하다고 생각하는 듯 하다. 실은 그렇게 그렇게 행동하길 원하는 분위기라서 그런 지도 모르지만, 그건 핑계인 듯 하고, 원래 그런 쪽에 대해서는 별 관심이 없어 보인다. 그러니 시간이 갈수록 조직이 이렇게 되지\u0026hellip;.\n","date":"2015-07-04T13:56:36+09:00","permalink":"https://cychong47.github.io/post/2015/gwanrija-deuldo-gongbu-jom-habsida/","summary":"\u003cp\u003e\u003cimg src=\"/images/2015/07/2569BC445582D18F35DDF5.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e출처 : \u003ca href=\"http://bcho.tistory.com/1034\"\u003e관리의 기본 (Fundamental of management) #2 - 관리자/리더에게 필요한 역량\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e가장 중요한 것은 Communication 역량으로, 팀내 또는 팀간의 조율을 위해서는 반드시 필요한 능력이라고 생각한다. 두말할 필요가 없는 부분인데, 효과적인 커뮤니케이션 스킬을 가지기 위해서는 상호 존중이 바탕이 되어야 한다. 존중의 바탕이 없이는 명령이되고, 명령은 팀을 Push하는 모델을 만들지, 팀이 스스로 높은 성과를 낼 수 있도록 Pull (당기는 형태)의 리더쉽을 만들어내기는 어렵다.\u003c/p\u003e\n\u003cp\u003e관리자로써 전체적인 계획을 만들고 이를 실행하려면, 팀원들을 코칭할 필요가 있다. 이것이 Coaching skill이고.\u003c/p\u003e","title":"관리자 들도 공부 좀 합시다"},{"content":"그냥 누구나 생각하는 바람직한 방법과 목표 그리고 절차를 따라야 한다는 게 고작 결론인가? 그런 누구나 할 수 있는 이야기잖아. 저런 이야기를 돈을 내고 들어야 한다는 건가? 이해가 안된다.\n현재 불편한, 잘못된, 쓸데없는 일을 하게 만드는 절차를 감당해야 하는 사람들에게 솔직한 의견을 구하는 것이 더 나은 방법 아닐까?\n아무리 다른 곳의 일하는 체계나 조직을 분석해도 소용없다. 그 비교자료에는 없는 내용이 핵심이니까. 조직을 운영하는 사람들의 능력과 그 조직을 구성하는 사람들의 능력. 그리고 생각들. 그건 아무리 해도 표현할 수가 없다. 알 수도 없다. 그런데 그게 핵심이다. 아무리 좋은 툴을 갖다 줘도, 아무리 선진 일처리 방식을 가져와도 사람을 빼놓고 일해서는 소용없다.\n급한 일정에 문제가 생겨 지연이 발생했을 때 함께 지연을 최소화할 방안을 찾는 게 아니라 왜 그런 지연이 발생했는지, 누구 잘못인지를 찾으라고 하는게 올바른 management인지는 모르겠다. 그게 그렇게 중요한가? 다시 실수를 안하기 위해 필요한 일인것은 알지만, 그건 추후에 회고하면서 하면 안되는 걸까?\n","date":"2015-06-24T15:20:57+09:00","permalink":"https://cychong47.github.io/post/2015/yeolsimhi-bigyohan-gyeolroni-gojag-geugeonga/","summary":"\u003cp\u003e그냥 누구나 생각하는 바람직한 방법과 목표 그리고 절차를 따라야 한다는 게 고작 결론인가? 그런 누구나 할 수 있는 이야기잖아. 저런 이야기를 돈을 내고 들어야 한다는 건가? 이해가 안된다.\u003c/p\u003e\n\u003cp\u003e현재 불편한, 잘못된, 쓸데없는 일을 하게 만드는 절차를 감당해야 하는 사람들에게 솔직한 의견을 구하는 것이 더 나은 방법 아닐까?\u003c/p\u003e\n\u003cp\u003e아무리 다른 곳의 일하는 체계나 조직을 분석해도 소용없다. 그 비교자료에는 없는 내용이 핵심이니까. 조직을 운영하는 사람들의 능력과 그 조직을 구성하는 사람들의 능력. 그리고 생각들. 그건 아무리 해도 표현할 수가 없다. 알 수도 없다. 그런데 그게 핵심이다. 아무리 좋은 툴을 갖다 줘도, 아무리 선진 일처리 방식을 가져와도 사람을 빼놓고 일해서는 소용없다.\u003c/p\u003e","title":"열심히 비교한 결론이 고작 그건가?"},{"content":"출처 : http://m.news.naver.com/read.nhn?mode=LSD\u0026amp;sid1=001\u0026amp;oid=008\u0026amp;aid=0003492855\n4.어려운 문제에 무턱대고 덤비지 마라\n어렵고 힘든 문제에 부딪히면 지레 겁을 먹기 쉽다. 아니면 무대포로 앞뒤 재지 않고 그냥 밀어붙인다. 그러나 구글과 페북에서 근무하며 얻은 지혜는 어렵고 덩치 큰 문제를 만나면 작게 쪼개서 각 부분별로 해결책을 찾는다는 것이다. 이렇게 부분별로 찾아진 해결책이 모아지면 원래의 덩치 큰 어려운 문제는 자연스럽게 풀리게 된다.\n문제가 어려우면 어려울 수록 잘게 쪼개자. 잘게 쪼갠 문제를 해결하다 보면 전체 문제가 풀릴 수도 있다. 하지만 동시에 문제의 전체적인 모습을 보는 것도 게을리하면 안된다. 모순같지만 세상사 모든 게 그렇다. 절대적으로 맞는 말은 없다.\n7.피드백을 사람에 겨냥하지 마라\n상대방이 해 준 피드백은 당신의 발전에 도움이 된다. 그런데 피드백을 할 때 사람이 아닌 이슈에 초점을 맞춰야 한다. 틀린 점을 끄집어내기 보다는 어떻게 하면 개선할 수 있는지에 초점을 맞추자. 이런 방식의 피드백은 긴장감을 누그러뜨릴 뿐만 아니라 더욱 효과적이고 긍정적인 결과를 낳게 된다.\n피드백은 사람이 아니라, Thing을 향해야 한다. 좋은 의도라 해도 사람에 대한 비난은 결국 나쁜 결과를 만든다. 사람에 대한 언급이 아무리 가벼워도 듣는 사람은 그렇게 듣지 못한다.\n8.현재의 순간에서 도망치려 하지 마라 경쟁이 심한 직장에서 근무하다 보면 겁먹을 일도 많고 스트레스 받는 일도 많다. 그래서 현재의 순간을 즐기지 못하고 도망치려 하기 쉽다. 하지만 그럴수록 현재의 상황을 받아들이며 사는 습관을 길러야 한다. 현재의 순간을 피하지 말고 소중히 여기자\n도망치지 말자. 더 이상 무슨 말이 필요하겠나. 특히 나에게 필요한 거.\n","date":"2015-06-21T08:24:05+09:00","permalink":"https://cychong47.github.io/post/2015/divide-conquer/","summary":"\u003cp\u003e출처 : \u003ca href=\"http://m.news.naver.com/read.nhn?mode=LSD\u0026amp;sid1=001\u0026amp;oid=008\u0026amp;aid=0003492855\"\u003ehttp://m.news.naver.com/read.nhn?mode=LSD\u0026amp;sid1=001\u0026amp;oid=008\u0026amp;aid=0003492855\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e4.어려운 문제에 무턱대고 덤비지 마라\u003cbr\u003e\n어렵고 힘든 문제에 부딪히면 지레 겁을 먹기 쉽다. 아니면 무대포로 앞뒤 재지 않고 그냥 밀어붙인다. 그러나 구글과 페북에서 근무하며 얻은 지혜는 어렵고 덩치 큰 문제를 만나면 작게 쪼개서 각 부분별로 해결책을 찾는다는 것이다. 이렇게 부분별로 찾아진 해결책이 모아지면 원래의 덩치 큰 어려운 문제는 자연스럽게 풀리게 된다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e문제가 어려우면 어려울 수록 잘게 쪼개자. 잘게 쪼갠 문제를 해결하다 보면 전체 문제가 풀릴 수도 있다. 하지만 동시에 문제의 전체적인 모습을 보는 것도 게을리하면 안된다. 모순같지만 세상사 모든 게 그렇다. 절대적으로 맞는 말은 없다.\u003c/p\u003e","title":"Divide \u0026 Conquer"},{"content":"(예를 들어) 분명 물리적으로 10개월이 필요한 일이 있다. 일정이 급하다고 6개월내 해 내라고 한다. 열심히 하지만 결국 6개월 기한은 넘어가고 겨우겨우 (담당자들이 개고생해서) 8개월 혹은 9개월내 일을 마친다.\n그리곤 말한다. (6개월을 요구했던 이들은) 처음에 6개월을 여구했으니까 8개월내 해낸거라고. 처음부터 10개월을 이야기했으면 못했을 거라고.\n하지만 경험상 저런 경우 8개월내 끝나기 보다 12개월이 걸리는 경우가 많다. 무리한 일정은 부실한 설계와 엉성한 구현을 만들어내고 버그로 인한 재작업을 유도한다. 이때 책임은 누가 져야 할까?\n","date":"2015-06-18T00:00:45+09:00","permalink":"https://cychong47.github.io/post/2015/magamhyogwareul-norineun-geonga/","summary":"\u003cp\u003e(예를 들어) 분명 물리적으로 10개월이 필요한 일이 있다. 일정이 급하다고 6개월내 해 내라고 한다. 열심히 하지만 결국 6개월 기한은 넘어가고 겨우겨우 (담당자들이 개고생해서) 8개월 혹은 9개월내 일을 마친다.\u003c/p\u003e\n\u003cp\u003e그리곤 말한다. (6개월을 요구했던 이들은) 처음에 6개월을 여구했으니까 8개월내 해낸거라고. 처음부터 10개월을 이야기했으면 못했을 거라고.\u003c/p\u003e\n\u003cp\u003e하지만 경험상 저런 경우 8개월내 끝나기 보다 12개월이 걸리는 경우가 많다. 무리한 일정은 부실한 설계와 엉성한 구현을 만들어내고 버그로 인한 재작업을 유도한다. 이때 책임은 누가 져야 할까?\u003c/p\u003e","title":"의도된 마감효과?"},{"content":"스스로 잘한다고 공공연하게 말하는 친구의 말은 믿을 수가 없다. 자기가 잘하는 단 하나만 생각해서 잘한다고 말하지만, 그게 SW 개발자가 가져야 할 모든 건 아닌데. 그것도 깨닫지 못하는 걸 보면 잘한다고 자만하는 건 스스로의 착각.\n남들의 인정을 받는 지 의문.\n혹은 남들이 자신과 함께 일하고 싶어 하는 지 한번이라도 생각해 봤으면.\n또 저런 친구들의 착각은 남들이 자기랑 함께 일하기 싫어하는 이유를 자신이 너무 잘나서 라고 생각한다는\u0026hellip;\n","date":"2015-05-28T14:14:28+09:00","permalink":"https://cychong47.github.io/post/2015/cagga/","summary":"\u003cp\u003e스스로 잘한다고 공공연하게 말하는 친구의 말은 믿을 수가 없다. 자기가 잘하는 단 하나만 생각해서 잘한다고 말하지만, 그게 SW 개발자가 가져야 할 모든 건 아닌데. 그것도 깨닫지 못하는 걸 보면 잘한다고 자만하는 건 스스로의 착각.\u003c/p\u003e\n\u003cp\u003e남들의 인정을 받는 지 의문.\u003c/p\u003e\n\u003cp\u003e혹은 남들이 자신과 함께 일하고 싶어 하는 지 한번이라도 생각해 봤으면.\u003c/p\u003e\n\u003cp\u003e또 저런 친구들의 착각은 남들이 자기랑 함께 일하기 싫어하는 이유를 자신이 너무 잘나서 라고 생각한다는\u0026hellip;\u003c/p\u003e","title":"착각과 자만"},{"content":" 대부분의 개발자는 현업에서 선배 개발자들이 작성한 코드를 유지보수하면서 코드 작성 방법을 배우게 됩니다. 회사에 따라 다르긴 하겠지만, 이렇게 접한 대부분의 코드는 겨우 겨우 동작만 하지, 코드의 가독성이나 유지보수를 거의 생각하지 않고 작성된 코드일 확률이 높습니다. 이런 코드를 읽고, 어떻게든 돌아가게 수정하는 훈련만 하다 보면 애시당초 코드를 잘 짠다는 게 무엇인지 알기가 어렵게 됩니다.\n출처 : http://wp.me/p66O1q-3j\n평소 내가 가진 생각과 비슷하다. 코드는 작성하는 게 1이면 읽는 게 9라고 한다. 그 만큼 기계가 아닌 사람이 읽는 것의 대상이 되는 경우가 많으므로 읽는 작업에 도움이 되도록 coding style의 정리가 반드시 필요하다고 생각한다. 하지만 이걸 무시하는 경우가 너무 많다는.\n부서 내부 혹은 블록 내부 조차 coding style이 없는 상황이라 외부에 일을 맡기는 경우 받아온 코드는 기존 coding style(이라고 할 것도 없지만 그래도)과 또 다른 style이라, 이런 코드들이 누적되면 그야말로 누더기가 된다. 논리와 계산이 혼재된 것 뿐만 아니라 coding style이 혼재된 코드 역시 읽기에 쉽지 않다.\n","date":"2015-05-25T12:44:28+09:00","permalink":"https://cychong47.github.io/post/2015/coding-styleyi-jungyoseong/","summary":"\u003cblockquote\u003e\n\u003cp\u003e대부분의 개발자는 현업에서 선배 개발자들이 작성한 코드를 유지보수하면서 코드 작성 방법을 배우게 됩니다. 회사에 따라 다르긴 하겠지만, 이렇게 접한 대부분의 코드는 겨우 겨우 동작만 하지, 코드의 가독성이나 유지보수를 거의 생각하지 않고 작성된 코드일 확률이 높습니다. 이런 코드를 읽고, 어떻게든 돌아가게 수정하는 훈련만 하다 보면 애시당초 코드를 잘 짠다는 게 무엇인지 알기가 어렵게 됩니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e출처 : \u003ca href=\"http://wp.me/p66O1q-3j\"\u003ehttp://wp.me/p66O1q-3j\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003e평소 내가 가진 생각과 비슷하다. 코드는 작성하는 게 1이면 읽는 게 9라고 한다. 그 만큼 기계가 아닌 사람이 읽는 것의 대상이 되는 경우가 많으므로 읽는 작업에 도움이 되도록 coding style의 정리가 반드시 필요하다고 생각한다. 하지만 이걸 무시하는 경우가 너무 많다는.\u003c/p\u003e","title":"Coding Style의 중요성"},{"content":"출처 : DPDK mailing list\nCoding Style Description This document specifies the preferred style for source files in the DPDK source tree. It is based on the Linux Kernel coding guidelines and the FreeBSD 7.2 Kernel Developer\u0026rsquo;s Manual (see man style(9)), but was heavily modified for the needs of the DPDK.\nGeneral Guidelines The rules and guidelines given in this document cannot cover every situation, so the following general guidelines should be used as a fallback:\nThe code style should be consistent within each individual file. In the case of creating new files, the style should be consistent within each file in a given directory or module. The primary reason for coding standards is to increase code readability and comprehensibility, therefore always use whatever option will make the code easiest to read. Line length is recommended to be not more than 80 characters, including comments. [Tab stop size should be assumed to be 8-characters wide].\nnote\nThe above is recommendation, and not a hard limit. However, it is expected that the recommendations should be followed in all but the rarest situations.\nC Comment Style Usual Comments These comments should be used in normal cases. To document a public API, a doxygen-like format must be used: refer to Doxygen Documentation.\n/* * VERY important single-line comments look like this. */ /* Most single-line comments look like this. */ /* * Multi-line comments look like this. Make them real sentences. Fill * them so they look like real paragraphs. */ License Header Each file should begin with a special comment containing the appropriate copyright and license for the file. Generally this is the BSD License, except for code for Linux Kernel modules. After any copyright header, a blank line should be left before any other contents, e.g. include statements in a C file.\nC Preprocessor Directives Header Includes In DPDK sources, the include files should be ordered as following:\nlibc includes (system includes first) DPDK EAL includes DPDK misc libraries includes application-specific includes Include files from the local application directory are included using quotes, while includes from other paths are included using angle brackets: \u0026ldquo;\u0026lt;\u0026gt;\u0026rdquo;.\nExample:\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;rte_eal.h\u0026gt; #include \u0026lt;rte_ring.h\u0026gt; #include \u0026lt;rte_mempool.h\u0026gt; #include \u0026#34;application.h\u0026#34; Header File Guards Headers should be protected against multiple inclusion with the usual:\n#ifndef _FILE_H_ #define _FILE_H_ /* Code */ #endif /* _FILE_H_ */ Macros Do not #define or declare names except with the standard DPDK prefix: RTE_. This is to ensure there are no collisions with definitions in the application itself.\nThe names of \u0026ldquo;unsafe\u0026rdquo; macros (ones that have side effects), and the names of macros for manifest constants, are all in uppercase.\nThe expansions of expression-like macros are either a single token or have outer parentheses. If a macro is an inline expansion of a function, the function name is all in lowercase and the macro has the same name all in uppercase. If the macro encapsulates a compound statement, enclose it in a do-while loop, so that it can be used safely in if statements. Any final statement-terminating semicolon should be supplied by the macro invocation rather than the macro, to make parsing easier for pretty-printers and editors.\nFor example:\n#define MACRO(x, y) do { \\ variable = (x) + (y); \\ (y) += 2; \\ } while(0) note\nWherever possible, enums and inline functions should be preferred to macros, since they provide additional degrees of type-safety and can allow compilers to emit extra warnings about unsafe code.\nConditional Compilation When code is conditionally compiled using #ifdef or #if, a comment may be added following the matching #endif or #else to permit the reader to easily discern where conditionally compiled code regions end. This comment should be used only for (subjectively) long regions, regions greater than 20 lines, or where a series of nested #ifdef\u0026rsquo;s may be confusing to the reader. Exceptions may be made for cases where code is conditionally not compiled for the purposes of lint(1), or other tools, even though the uncompiled region may be small. The comment should be separated from the #endif or #else by a single space. For short conditionally compiled regions, a closing comment should not be used. The comment for #endif should match the expression used in the corresponding #if or #ifdef. The comment for #else and #elif should match the inverse of the expression(s) used in the preceding #if and/or #elif statements. In the comments, the subexpression defined(FOO) is abbreviated as \u0026ldquo;FOO\u0026rdquo;. For the purposes of comments, #ifndef FOO is treated as #if !defined(FOO).\n#ifdef KTRACE #include \u0026lt;sys/ktrace.h\u0026gt; #endif #ifdef COMPAT_43 /* A large region here, or other conditional code. */ #else /* !COMPAT_43 */ /* Or here. */ #endif /* COMPAT_43 */ #ifndef COMPAT_43 /* Yet another large region here, or other conditional code. */ #else /* COMPAT_43 */ /* Or here. */ #endif /* !COMPAT_43 */ note\nConditional compilation should be used only when absolutely necessary, as it increases the number of target binaries that need to be built and tested.\nC Types Integers For fixed/minimum-size integer values, the project uses the form uintXX_t (from stdint.h) instead of older BSD-style integer identifiers of the form u_intXX_t.\nEnumerations Enumeration values are all uppercase. enum enumtype { ONE, TWO } et; Enum types should be used in preference to macros #defining a set of (sequential) values. Enum types should be prefixed with rte_ and the elements by a suitable prefix [generally starting RTE_\u0026lt;enum\u0026gt;_ - where \u0026lt;enum\u0026gt; is a shortname for the enum type] to avoid namespace collisions. Bitfields The developer should group bitfields that are included in the same integer, as follows:\nstruct grehdr { uint16_t rec:3, srr:1, seq:1, key:1, routing:1, csum:1, version:3, reserved:4, ack:1; /* ... */ } Variable Declarations In declarations, do not put any whitespace between asterisks and adjacent tokens, except for tokens that are identifiers related to types. (These identifiers are the names of basic types, type qualifiers, and typedef-names other than the one being declared.) Separate these identifiers from asterisks using a single space.\nFor example:\nint *x; /* no space after asterisk */ int * const x; /* space after asterisk when using a type qualifier */ All externally-visible variables should have an rte_ prefix in the name to avoid namespace collisions. Do not use uppercase letters - either in the form of ALL_UPPERCASE, or CamelCase - in variable names. Lower-case letters and underscores only. Structure Declarations In general, when declaring variables in new structures, declare them sorted by use, then by size (largest to smallest), and then in alphabetical order. Sorting by use means that commonly used variables are used together and that the structure layout makes logical sense. Ordering by size then ensures that as little padding is added to the structure as possible. For existing structures, additions to structures should be added to the end so for backward compatibility reasons. Each structure element gets its own line. Try to make the structure readable by aligning the member names using spaces as shown below. Names following extremely long types, which therefore cannot be easily aligned with the rest, should be separated by a single space. struct foo { struct foo *next; /* List of active foo. */ struct mumble amumble; /* Comment for mumble. */ int bar; /* Try to align the comments. */ struct verylongtypename *baz; /* Won\u0026#39;t fit with other members */ }; Major structures should be declared at the top of the file in which they are used, or in separate header files if they are used in multiple source files. Use of the structures should be by separate variable declarations and those declarations must be extern if they are declared in a header file. Externally visible structure definitions should have the structure name prefixed by rte_ to avoid namespace collisions. Queues Use queue(3) macros rather than rolling your own lists, whenever possible. Thus, the previous example would be better written:\n#include \u0026lt;sys/queue.h\u0026gt; struct foo { LIST_ENTRY(foo) link; /* Use queue macros for foo lists. */ struct mumble amumble; /* Comment for mumble. */ int bar; /* Try to align the comments. */ struct verylongtypename *baz; /* Won\u0026#39;t fit with other members */ }; LIST_HEAD(, foo) foohead; /* Head of global foo list. */ DPDK also provides an optimized way to store elements in lockless rings. This should be used in all data-path code, when there are several consumer and/or producers to avoid locking for concurrent access.\nTypedefs Avoid using typedefs for structure types.\nFor example, use:\nstruct my_struct_type { /* ... */ }; struct my_struct_type my_var; rather than:\ntypedef struct my_struct_type { /* ... */ } my_struct_type; my_struct_type my_var Typedefs are problematic because they do not properly hide their underlying type; for example, you need to know if the typedef is the structure itself, as shown above, or a pointer to the structure. In addition, they must be declared exactly once, whereas an incomplete structure type can be mentioned as many times as necessary. Typedefs are difficult to use in stand-alone header files. The header that defines the typedef must be included before the header that uses it, or by the header that uses it (which causes namespace pollution), or there must be a back-door mechanism for obtaining the typedef.\nNote that #defines used instead of typedefs also are problematic (since they do not propagate the pointer type correctly due to direct text replacement). For example, #define pint int * does not work as expected, while typedef int *pint does work. As stated when discussing macros, typedefs should be preferred to macros in cases like this.\nWhen convention requires a typedef; make its name match the struct tag. Avoid typedefs ending in _t, except as specified in Standard C or by POSIX.\nnote\nIt is recommended to use typedefs to define function pointer types, for reasons of code readability. This is especially true when the function type is used as a parameter to another function.\nFor example:\n/** * Definition of a remote launch function. */ typedef int (lcore_function_t)(void *); /* launch a function of lcore_function_t type */ int rte_eal_remote_launch(lcore_function_t *f, void *arg, unsigned slave_id); C Indentation General Indentation is a hard tab, that is, a tab character, not a sequence of spaces, note\nGlobal whitespace rule in DPDK, use tabs for indentation, spaces for alignment.\nDo not put any spaces before a tab for indentation. If you have to wrap a long statement, put the operator at the end of the line, and indent again. For control statements (if, while, etc.), continuation it is recommended that the next line be indented by two tabs, rather than one, to prevent confusion as to whether the second line of the control statement forms part of the statement body or not. Alternatively, the line continuation may use additional spaces to line up to an appropriately point on the preceding line, for example, to align to an opening brace. note\nAs with all style guidelines, code should match style already in use in an existing file.\nwhile (really_long_variable_name_1 == really_long_variable_name_2 \u0026amp;\u0026amp; var3 == var4){ /* confusing to read as */ x = y + z; /* control stmt body lines up with second line of */ a = b + c; /* control statement itself if single indent used */ } if (really_long_variable_name_1 == really_long_variable_name_2 \u0026amp;\u0026amp; var3 == var4){ /* two tabs used */ x = y + z; /* statement body no longer lines up */ a = b + c; } z = a + really + long + statement + that + needs + two + lines + gets + indented + on + the + second + and + subsequent + lines; Do not add whitespace at the end of a line. Do not add whitespace or a blank line at the end of a file. Control Statements and Loops Include a space after keywords (if, while, for, return, switch). Do not use braces ({ and }) for control statements with zero or just a single statement, unless that statement is more than a single line in which case the braces are permitted. for (p = buf; *p != \u0026#39;\\0\u0026#39;; ++p) ; /* nothing */ for (;;) stmt; for (;;) { z = a + really + long + statement + that + needs + two + lines + gets + indented + on + the + second + and + subsequent + lines; } for (;;) { if (cond) stmt; } if (val != NULL) val = realloc(val, newsize); Parts of a for loop may be left empty. for (; cnt \u0026lt; 15; cnt++) { stmt1; stmt2; } Closing and opening braces go on the same line as the else keyword. Braces that are not necessary should be left out. if (test) stmt; else if (bar) { stmt; stmt; } else stmt; Function Calls Do not use spaces after function names. Commas should have a space after them. No spaces after ( or [ or preceding the ] or ) characters. error = function(a1, a2); if (error != 0) exit(error); Operators Unary operators do not require spaces, binary operators do. Do not use parentheses unless they are required for precedence or unless the statement is confusing without them. However, remember that other people may be more easily confused than you. Exit Exits should be 0 on success, or 1 on failure.\nexit(0); /* * Avoid obvious comments such as * \u0026#34;Exit 0 on success.\u0026#34; */ }\nLocal Variables Variables should be declared at the start of a block of code rather than in the middle. The exception to this is when the variable is const in which case the declaration must be at the point of first use/assignment. When declaring variables in functions, multiple variables per line are OK. However, if multiple declarations would cause the line to exceed a reasonable line length, begin a new set of declarations on the next line rather than using a line continuation. Be careful to not obfuscate the code by initializing variables in the declarations, only the last variable on a line should be initialized. If multiple variables are to be initialised when defined, put one per line. Do not use function calls in initializers, except for const variables. int i = 0, j = 0, k = 0; /* bad, too many initializer */ char a = 0; /* OK, one variable per line with initializer */ char b = 0; float x, y = 0.0; /* OK, only last variable has initializer */ Casts and sizeof Casts and sizeof statements are not followed by a space. Always write sizeof statements with parenthesis. The redundant parenthesis rules do not apply to sizeof(var) instances. C Function Definition, Declaration and Use Prototypes It is recommended (and generally required by the compiler) that all non-static functions are prototyped somewhere. Functions local to one source module should be declared static, and should not be prototyped unless absolutely necessary. Functions used from other parts of code (external API) must be prototyped in the relevant include file. Function prototypes should be listed in a logical order, preferably alphabetical unless there is a compelling reason to use a different ordering. Functions that are used locally in more than one module go into a separate header file, for example, \u0026ldquo;extern.h\u0026rdquo;. Do not use the __P macro. Functions that are part of an external API should be documented using Doxygen-like comments above declarations. See the Doxgen documentation topic for details. Functions that are part of the external API must have an rte_ prefix on the function name. Do not use uppercase letters - either in the form of ALL_UPPERCASE, or CamelCase - in function names. Lower-case letters and underscores only. When prototyping functions, associate names with parameter types, for example: void function1(int fd); /* good */ void function2(int); /* bad */ Short function prototypes should be contained on a single line. Longer prototypes, e.g. those with many parameters, can be split across multiple lines. The second and subsequent lines should be further indented as for line statement continuations as described in the previous section. static char *function1(int _arg, const char *_arg2, struct foo *_arg3, struct bar *_arg4, struct baz *_arg5); static void usage(void); note\nUnlike function definitions, the function prototypes do not need to place the function return type on a separate line.\nDefinitions The function type should be on a line by itself preceding the function. The opening brace of the function body should be on a line by itself. static char * function(int a1, int a2, float fl, int a4) { Do not declare functions inside other functions. ANSI C states that such declarations have file scope regardless of the nesting of the declaration. Hiding file declarations in what appears to be a local scope is undesirable and will elicit complaints from a good compiler. Old-style (K\u0026amp;R) function declaration should not be used, use ANSI function declarations instead as shown below. Long argument lists should be wrapped as described above in the function prototypes section. /* * All major routines should have a comment briefly describing what * they do. The comment before the \u0026#34;main\u0026#34; routine should describe * what the program does. */ int main(int argc, char *argv[]) { char *ep; long num; int ch; C Statement Style and Conventions NULL Pointers NULL is the preferred null pointer constant. Use NULL instead of (type *)0 or (type *)NULL, except where the compiler does not know the destination type e.g. for variadic args to a function. Test pointers against NULL, for example, use: if (p == NULL) /* Good, compare pointer to NULL */ if (!p) /* Bad, using ! on pointer */ Do not use ! for tests unless it is a boolean, for example, use: if (*p == \u0026#39;\\0\u0026#39;) /* check character against (char)0 */ Return Value Functions which create objects, or allocate memory, should return pointer types, and NULL on error. The error type should be indicated may setting the variable rte_errno appropriately. Functions which work on bursts of packets, such as RX-like or TX-like functions, should return the number of packets handled. Other functions returning int should generally behave like system calls: returning 0 on success and -1 on error, setting rte_errno to indicate the specific type of error. Where already standard in a given library, the alternative error approach may be used where the negative value is not -1 but is instead -errno if relevant, for example, -EINVAL. Note, however, to allow consistency across functions returning integer or pointer types, the previous approach is preferred for any new libraries. For functions where no error is possible, the function type should be void not int. Routines returning void * should not have their return values cast to any pointer type. (Typecasting can prevent the compiler from warning about missing prototypes as any implicit definition of a function returns int - which, unlike void * needs a typecast to assign to a pointer variable.) note\nThe above rule about not typecasting void * applies to malloc, as well as to DPDK functions.\nValues in return statements should not be enclosed in parentheses. Logging and Errors In the DPDK environment, use the logging interface provided:\n#define RTE_LOGTYPE_TESTAPP1 RTE_LOGTYPE_USER1 #define RTE_LOGTYPE_TESTAPP2 RTE_LOGTYPE_USER2 /* enable these logs type */ rte_set_log_type(RTE_LOGTYPE_TESTAPP1, 1); rte_set_log_type(RTE_LOGTYPE_TESTAPP2, 1); /* log in debug level */ rte_set_log_level(RTE_LOG_DEBUG); RTE_LOG(DEBUG, TESTAPP1, \u0026#34;this is is a debug level message\\n\u0026#34;); RTE_LOG(INFO, TESTAPP1, \u0026#34;this is is a info level message\\n\u0026#34;); RTE_LOG(WARNING, TESTAPP1, \u0026#34;this is is a warning level message\\n\u0026#34;); /* log in info level */ rte_set_log_level(RTE_LOG_INFO); RTE_LOG(DEBUG, TESTAPP2, \u0026#34;debug level message (not displayed)\\n\u0026#34;); Branch Prediction When a test is done in a critical zone (called often or in a data path) the code made use the likely() and unlikely() macros to indicate the expected, or preferred fast path. They are expanded as a compiler builtin and allow the developer to indicate if the branch is likely to be taken or not. Example: #include \u0026lt;rte_branch_prediction.h\u0026gt; if (likely(x \u0026gt; 1)) do_stuff(); note\nThe use of likely() and unlikely() should only be done in performance critical paths, and only when there is a clearly preferred path, or a measured performance increase gained from doing so. These macros should be avoided in non-performance-critical code.\nStatic Variables and Functions All functions and variables that are local to a file must be declared as static because it can often help the compiler to do some optimizations (such as, inlining the code). Functions that should be inlined should to be declared as static inline and can be defined in a .c or a .h file. note\nStatic functions defined in a header file must be declared as static inline in order to prevent compiler warnings about the function being unused.\nConst Attribute The const attribute should be used as often as possible when a variable is read-only.\nInline ASM in C code The asm and volatile keywords do not have underscores. The AT\u0026amp;T syntax should be used. Input and output operands should be named to avoid confusion, as shown in the following example:\nasm volatile(\u0026#34;outb %[val], %[port]\u0026#34; : : [port] \u0026#34;dN\u0026#34; (port), [val] \u0026#34;a\u0026#34; (val)); Control Statements Forever loops are done with for statements, not while statements. Elements in a switch statement that cascade should have a FALLTHROUGH comment. For example: switch (ch) { /* Indent the switch. */ case \u0026#39;a\u0026#39;: /* Don\u0026#39;t indent the case. */ aflag = 1; /* Indent case body one tab. */ /* FALLTHROUGH */ case \u0026#39;b\u0026#39;: bflag = 1; break; case \u0026#39;?\u0026#39;: default: usage(); /* NOTREACHED */ } Environment or Architecture-specific Sources In DPDK and DPDK applications, some code is specific to an architecture (i686, x86_64) or to an executive environment (bsdapp or linuxapp) and so on. As far as is possible, all such instances of architecture or env-specific code should be provided via standard APIs in the EAL.\nBy convention, a file is common if it is not located in a directory indicating that it is specific. For instance, a file located in a subdir of \u0026ldquo;x86_64\u0026rdquo; directory is specific to this architecture. A file located in a subdir of \u0026ldquo;linuxapp\u0026rdquo; is specific to this execution environment.\nnote\nCode in DPDK libraries and applications should be generic. The correct location for architecture or executive environment specific code is in the EAL.\nWhen absolutely necessary, there are several ways to handle specific code:\nUse a #ifdef with the CONFIG option in the C code. This can be done when the differences are small and they can be embedded in the same C file: Use the CONFIG option in the Makefile. This is done when the differences are more significant. In this case, the code is split into two separate files that are architecture or environment specific. This should only apply inside the EAL library. Per Architecture Sources The following config options can be used:\nCONFIG_RTE_ARCH is a string that contains the name of the architecture. CONFIG_RTE_ARCH_I686, CONFIG_RTE_ARCH_X86_64, CONFIG_RTE_ARCH_X86_64_32 or CONFIG_RTE_ARCH_PPC_64 are defined only if we are building for those architectures. Per Execution Environment Sources The following config options can be used:\nCONFIG_RTE_EXEC_ENV is a string that contains the name of the executive environment. CONFIG_RTE_EXEC_ENV_BSDAPP or CONFIG_RTE_EXEC_ENV_LINUXAPP are defined only if we are building for this execution environment. Doxygen Documentation The API documentation is automatically generated in the DPDK framework. That is why all files that are part of the public API must be documented using Doxygen syntax.\nThe public API comprises functions of DPDK that can be used by an external application that will use the SDK. Only the Doxygen syntax described in the coding rules (this document) should be used in the code. All the Doxygen features are described in the Doxygen manual online.\nDocumenting a Function All public functions must be documented. The documentation is placed in the header file, above the declaration of the function. The definition of the function may be documented, but using standard comments (not in doxygen format). The following is an example of function documentation:\n/** * Summary here; one sentence on one line (should not exceed 80 chars). * * A more detailed description goes here. * * A blank line forms a paragraph. There should be no trailing white-space * anywhere. * * @param first * \u0026#34;@param\u0026#34; is a Doxygen directive to describe a function parameter. Like * some other directives, it takes a term/summary on the same line and a * description (this text) indented by 2 spaces on the next line. All * descriptive text should wrap at 80 chars, without going over. * Newlines are NOT supported within directives; if a newline would be * before this text, it would be appended to the general description above. * @param second * There should be no newline between multiple directives (of the same * type). * * @return * \u0026#34;@return\u0026#34; is a different Doxygen directive to describe the return value * of a function, if there is any. */ int rte_foo(int first, int second) Documenting Files Each public file may start with a comment describing what the file does. For example:\n/** * @file * This file describes the coding rules of RTE. * * It contains the coding rules of C code, ASM code, reStructured * Text documentation, and of course how to use doxygen to document * public API. */ Documenting Constants and Variables Examples:\n/** * The definition of a funny TRUE. */ #define TRUE 0 #define TRUE 1 /**\u0026lt; another way to document a macro */ /** * Frequency of the HPET counter in Hz * * @see rte_eal_hpet_init() */ extern uint64_t eal_hpet_resolution_hz; Documenting Structures Public structures should also be documented. The /**\u0026lt; sequence can be used to documented the fields of the structure, as shown in the following example:\n/** * Structure describing a memzone, which is a contiguous portions of * physical memory identified by a name. */ struct rte_memzone { #define MEMZONE_NAMESIZE 32 char name[MEMZONE_NAMESIZE]; /**\u0026lt; name of the memory zone */ phys_addr_t phys_addr; /**\u0026lt; start physical address */ void *addr; /**\u0026lt; start virtual address */ uint64_t len; /**\u0026lt; len of the memzone */ int socket_id; /**\u0026lt; NUMA socket id */ }; See Also Sections The @see keyword can be used to highlight a link to an existing function, file, or URL. This directive should be placed on one line, without anything else, at the bottom of the documentation header.\n/** * (documentation of function, file, ...) * * @see rte_foo() * @see eal_memzone.c */ ","date":"2015-05-21T14:51:37+09:00","permalink":"https://cychong47.github.io/post/2015/dpdk-coding-style/","summary":"\u003cp\u003e출처 : \u003ca href=\"http://dpdk.org/ml/archives/dev/2015-May/017666.html\"\u003eDPDK mailing list\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"coding-style\"\u003eCoding Style\u003c/h1\u003e\n\u003ch2 id=\"description\"\u003eDescription\u003c/h2\u003e\n\u003cp\u003eThis document specifies the preferred style for source files in the DPDK\nsource tree. It is based on the Linux Kernel coding guidelines and the\nFreeBSD 7.2 Kernel Developer\u0026rsquo;s Manual (see man style(9)), but was\nheavily modified for the needs of the DPDK.\u003c/p\u003e\n\u003ch2 id=\"general-guidelines\"\u003eGeneral Guidelines\u003c/h2\u003e\n\u003cp\u003eThe rules and guidelines given in this document cannot cover every\nsituation, so the following general guidelines should be used as a\nfallback:\u003c/p\u003e","title":"DPDK Coding style"},{"content":"\n출처 : Docker 무작정 따라하기\n참고 : 가장 빨리 배우는 Docker\n","date":"2015-05-20T14:18:04+09:00","permalink":"https://cychong47.github.io/post/2015/docker-for-dummies-jeongri/","summary":"\u003cp\u003e\u003cimg src=\"/images/2015/05/Docker_for_dummies.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e출처 : Docker 무작정 따라하기\u003c/p\u003e\n\u003cp\u003e참고 : \u003ca href=\"http://www.pyrasis.com/docker.html\"\u003e가장 빨리 배우는 Docker\u003c/a\u003e\u003c/p\u003e","title":"Docker for dummies 정리"},{"content":"p13 나는 사업을 하면서 수시로 수확체감의 법칙을 실감한다. 어떤 사업이든 일정 수준에 도달하면 노동이나 자본 등 생산 요소를 늘려도 결과물은 비례해서 증가하지 않는다.\n일과 성공 역시 마찬가지다. 들인 시관과 성과는 정비례하지 않는다. 6시간 일한다고 목표를 달성하지 못하는 것도 아니고 12시간 일한다고 두 배의 성과를 얻는 것도 아니다. 그런데도 여전히 많은 사람들이 50시간이 아니라 70시간을 일할 때 더 많은 일을 해낸다고 믿는다.\np15 우리가 12시간씩 일하며 인생은 원래 고달픈 거라고 스스로를 위로하는 동안 누군가는 획기적인 아이디어로 3시간 일하고 9시간 동안 여유를 즐긴다.\n인간은 주당 30시간에서 60시간 정도 일할 때 \u0026lsquo;최대의 행복감\u0026rsquo;을 느낀다고 한다. 일하는 시간이 적으면 자신의 존재 가치를 증명하고 자아실현을 할 충분한 기회를 갖지 못하고, 일하는 시간이 너무 길면 체력이 떨어지면서 삶에 대한 의욕도 사라진다. 잘 살기 위해 일을 하는 것인데 일하는데 모든 에너지를 다 써서 정작 좋아하는 것을 즐기지 못하게 되는 것이다.\np16 사람들은 인생에서 가장 중요한 게 무엇이냐는 질문을 받으면 가족, 친구, 건강이라고 주저 없이 말한다. 그러나 현실에서 선택하는 것은 그 세가지가 아니라 일이다. 씁쓸한 건 대부분의 사람들이 관계를 단절시키고 건강 악화를 초래하는 원인으로 가장 많이 꼽인 것이 바로 일이라는 사실이다.\np26 다른 사람들이 정의한 성공을 무작정 따라가는 것은 아무 의미가 없다. 사실 남들과 똑같은 방법으로는 성공할 수도 없다. 때로는 위험을 감수하고 나만의 길을 창조해야 만족감도 있고 행복도 느끼는 성공을 할 수 있다.\np45 최고가 아니라 유일함을 추구하라.\n1등은 시간이 지나면 잊여지지만 유일한 것은 시간이 갈수록 더 큰 의미를 갖는다.\n자기만의 특별함으로 잊히지 않는 존재가 되라.\np48 지나가던 사람들이 뒤돌아볼 정도로 튀는 옷을 입었던 적이 있는가? 남들과 다른 자신의 생각을 당당하게 말한 적은 언제인가? 성공하고 싶다면 다른 사람의 발자국 위에 발을 올리지 마라. 항상 자기만의 독특한 방식을 고민하라. 자신의 삶을 더 나은 것으로 만들기 위해서는 어떻게 하면 창조적인 결과물을 얻을 수 있는 가를 생각해야 한다.\np52 토니 세이 자포스 CEO. Collision \u0026amp; Co-learning \u0026amp; Connectedness\n마주치고, 서로 배우고, 연결되면 혁신이라는 기적은 저절로 일어난다.\n혼자 몰입하는 시간은 그 아이디어를 정리할 때 써도 충분하다.\n그러니 지금 하는 일에 효율성을 높이고 싶다면 자리에 앉아 일과 씨름하는 대신 나가서 사람들과 만나고 이야기를 주고받아라.\np56 \u0026lsquo;무엇을 해 볼 생각이 있다\u0026rsquo;는 말은 성공하는 데 필요한 요소 가운데 15 퍼센트 정도의 비중밖에 차지하지 않는다. 성공의 나머지 9599퍼센트는 실행에서 온다. 성공적으로 실행하기 위해서는 능숙하게 일을 처리하는 기술과 네트워크 구축 등 단기간 내에 습득할 수 없는 여러 요소들이 조화를 이뤄야 한다.\np70 좋은 시절은 나이 때문에 사라지는 것이 아니라 체념하기 때문에 사라진다. 각자 자신이 좋아하는 일을 해서 성공을 쟁취하기에 늦은 나이란 없음을 깨닫기를 바란다. 좋은 시절이란 지금 현재 시점이며, 어떤 일이든 시작하기에 가장 좋은 날은 바로 오늘이다.\np77 \u0026lsquo;뭐가 잘못됐을까\u0026rsquo; 걱정하며 애태우지 말고 \u0026lsquo;뭐가 잘됐을까\u0026rsquo;를 찾아 더 잘할 수 있는 방법을 고민하라.\n긍정적인 것이든 부정적인 것이든 삶은 스스로 에너지를 쏟고 주의를 기울이는 쪽으로 흘러간다.\np82 실제 사용자가 되 사람들과 이야기를 나누고 그들이 선택하는 것과 선택하지 않는 것을 주의 깊게 살펴라.\np92 확인해도 끝이 없는 일반적인 정보들의 흐름을 무작정 쫓아가 봤자 다른 사람들과 똑같은 것을 배우기 위해 시간을 썼을 뿐이다. 당신은 절대 그 어떤 이득도, 특별한 견문도, 세상에 도움이 될 만한 새로운 무언가를 얻지 못한다. 남들도 다 아는 것을 알기 위해 노력하는 것은 중요하지 않다. 우리가 해야 할 일은 다른 사람들과는 다른 무언가를 알기 위해 노력하는 것이다. 거기에서 기회가 발생하기 때문이다.\np93 티모시 페리스 \u0026lsquo;4시간\u0026rsquo; 을 읽을 더 이상 흘러가는 소식을 쫓지 않겠다는 결단을 내렸다.\n오히려 놀랍게도 뉴스를 끊고 몇 달이 지나자 소설에 대한 흥미가 생겨났다. 그리고 공부를 하고 싶다는 마음도 들었다.\n우리가 알려고 노력해야 하는 것들은 바로 이런 지식들이다. 순수한 호기심이 마음을 움직여서 얻은 지식이 당신을 남들과 다르게 만들어 줄 것이다. 그러니 평소 의무감 때문에 지켜보던 뉴스 채널을 던져 버리고 새롭고 사람들이 잘 모르는 지식을 찾아 나서라. 더 적은 시간으로 더 많은 것들을 달성할 수 있고 재미도 배가 할 것이다.\np96 전 직원이 같은 목표를 갖게 되자 기업 내에 목표지향적 환경이 만드러졌고 이를 바탕으로 자포스는 엄청난 능률과 더불어 행복까지 얻었다. 리더나 기업가들은 이따금씩 구성원들이 생각만큼 조직에 헌신하지 않는다고 불평한다. 그러면서 이를 바로잡기 위해 경영 관리를 더 철저하게 하고 더 엄격히 통제해야 한다고 결론을 내린다. 그러나 이것은 잘못된 판단이다. 근본저긴 원인은 리더나 기업가 자신에게 있다.\n한 조직의 리더로서 명확하게 흥미진진한 목표를 지닌 회사를 만들지 못했고, 회사의 계획에 진정으로 흥미를 느끼는 직원을 구하지 못했으며, 각각의 구성원들에게 공동체 속에서 자기 역할이 무엇인지 어떻게 공헌할 수 있는지를 확실히 말해 주지 않았기 때문이다. 다시 말해 직원들이 문제가 많은 게 아니라 스스로 준비 작업을 제대로 하지 않은 것에 대한 대가를 치르고 있는 것 뿐이다.\n이들에게 절실한 과제는 처음으로 돌아가 목표를 찾는 일이지, 조직이나 체계를 때려 고치는 일이 아니다.\n만약 당신이 아직 인생의 목표를 찾지 못했다면 이 책을 읽고 있는 지금 이 순간을 계기로 삼아 고민해 보길 바란다. 내 인생의 목표는 무엇인가. 목표도 없고 하고 싶은 일도 없다고 체념하지 말자. 즐겁게 했던 일을 따라가 보면 잘할 수 있는 일이 분명히 떠오를 것이다. 그 일이 직업으로 선택할 만한 것은 아닐지라도 신나게 뭔가에 열중했던 기억이 떠오른다면 목표를 세우는 데 큰 자극제가 된다.\n올해가 지나기 전에 1년 동안 달성할 목표를 세우고 뛰어들어라. 그러면 내년은 결코 나이만 한 살 더 먹은 덧없는 한 해가 되지 않을 것이다.\np101 도대체 왜 많은 기업들은 단순함을 따르지 않고 자꾸 옆길로 새는 것일까? 답은 간단하다. 똑독하게 보이려는 사람들이 노력이 일을 그토록 복잡하게 만드는 것이다.\np104 좋은 프로그램이란 원래의 목적을 가장 잘 구현할 수 있는 것이기 때문이다.\n그의 말처럼 시스템을 단순화할수록 일은 더 쉬워지고 효율은 올라간다. 그러니 그 무엇보다 먼저 간결함을 선택하라.\np116 스티브 코비 컨설팅\n\u0026lsquo;진실로 중요한 일에만 집중하라\u0026rsquo;. 학교에 다닐 때부터 모든 숙제를 빠짐없이 해내야 \u0026lsquo;참 잘했어요\u0026rsquo; 도장을 받을 수 있었던 우리에게 이것은 쉽지 않았다. 그보다는 긴긴 업무 목록을 작성하고 하나씩 지워 나가는 게 훨씬 안전하게 보였다. 그러나 이 훈련을 하면서 어떤 프로젝트를 하든 정말 중요한 일은 한 가지뿐이거나 많아야 세 가지에 불과하다는 사실을 발견했다.\n사람들은 습관적으로 엄청나게 중요한 일보다 업무 목록에 있는 작고 쉬운 일부터 먼저 처리하려고 한다.\np124 뼈 빠지게 일하면서도 성공을 거두지 못하는 그저 그런 리더와 별다른 희생을 치르지 않고도 어렵지 않게 놀라운 성과를 거두는 리더의 차이점은 무엇일까? 아마 적절한 인재를 고용하고 그들에게 동기와 영감을 부여하면서 올바른 문화를 조성하는 능력이 있느냐 없느냐의 차이일 것이다. 그러나 할 수 있는 대답이겠지만, 실제로 이 능력은 쉽게 얻을 수 있는 게 아니다.\np126 \u0026lsquo;서로 다른 업무를 하고 있는 사람들을 조화롭게 이어 주고 직원들에게 긍정적인 비전을 주는 것이 바로 리더죠. 직원들의 일에 사사건건 개입하고 생각을 떠보기 위해 소통을 하는 것이 아닙니다. 오히려 직원들이 지금 하고 있는 일을 믿고 있고 그들의 능력을 인정하고 있다는 사실을 알리기 위해 대화를 합니다. 그리고 도움이 필요한 타이밍에 도움을 주기 위해서이기도 하고요. 일을 진행하는데 있어서 리더가 방해물이 되어서는 안 됩니다\u0026rsquo;\np128 사람들은 자신의 말을 들어주는 사람에게 마음을 연다. 듣는다는 행동에는 당신을 존중하고 배려한다는 메시지가 담겨 있기 때문이다. 반면 비판과 평가를 받으면 마음의 문을 꽁꽁 닫아걸거나 논쟁을 벌인다. 서로 한 팀이 되지 않으면 어려움을 극복하는 일은 실패할 수 밖에 없다.\n리더란 자신의 성공이 아니라 평범한 다른 사람들이 뛰어난 성공을 거둘 수 있도록 돕기 위해 존재하는 것이다. 그러니 더 나은 미래를 만들고 싶다면 상대의 말에 비판과 평가보다는 경청을 하는 사람이 되라. 나와 DNA부터 다른 상대방의 관점을 진심으로 이해하고 그들의 마음을 움직이기 위해서는 먼저 귀를 기울여 들어야 한다는 사실을 잊지 말길 바란다.\np134 \u0026lsquo;회사가 아주 작았을 때부터 매일 그날 끝내야 하거나 진행해야 하는 업무 목록을 기록해 오고 있습니다. 그 일들을 다 마치고 사무실을 나서면 오늘 하루 열심히 일했고, 내 역할을 잘 해냈다는 생각이 듭니다.\np140 지칠 때까지 일하지 마라. 못한 일은 다음 날 다시 만회할 수 있지만 한번 말라붙은 열정을 복구하는 데는 몇 달 몇 년이 걸릴 수도 있다.\np155 하루 24시간을 8:8:8로 나누어 일을 하는데 8시간, 잠을 자는데 8시간 그리고 나머지 8시간을 자신이 진짜 하고 싶은 일을 하는 시간으로 삼았다.\np170 SAS\n\u0026ldquo;부모로서 아이가 아플 때 병원에 데려가고, 아이가 학교에서 하는 첫 연극이나 축구 경기를 보러 가는 일은 꼭 해야 하지 않을까요? 이런 것들을 포기하고 사무실에 앉아 일을 한다고 해서 대단한 제품이 개발될 거라고 생각하지 않습니다. 그래서 회사를 처음 세울 때부터 \u0026lsquo;일과 삶의 균형\u0026rsquo;을 1순위로 고려했습니다. \u0026quot;\np173 사람들은 일과 삶의 균형이라고 하면 자기 자신을 먼저 생각한다. 하지만 자신의 인생을 즐기며 일도 잘하기 위해서는 팀 전체가 그렇게 되어야 한다. 그러니까 일을 잘한다고 또는 자기가 리더라고 혼자만 여유를 가져서는 안 된다는 말이다.\n직원 모두가 즐겁고 신나게 일하고 출근하게 회사, 그리고 그 경험을 다른 팀원들과 나눌 수 있는 회사에서는 그렇지 않은 회사에 비해 특별한 유대감이 생겨나고 서로를 훨씬 더 많이 배려하는 문화가 형성된다. 함께 일하는 동료들에게 배려를 베풀면 베풀수록 자신 또한 더욱 큰 힘을 얻고 서로를 위해 더 열심히 일하게 되며, 팀을 위한 충성심이 높아질수록 또는 팀원 간에 의리가 넘칠수록 능률은 더 오른다.\np180 할아버지는 월요일을 실험일로 정했다. 그리고 어떻게 시간을 효율적으로 쓸 수 있는 지 공작기계를 이리저리 조정해서 최적화된 생상 방법을 찾아내려 애썼다. 다른 사람들과 달리 정신없이 바쁘게 일하지도 않았고 옆에 놓인 상자에 조립품을 채워 넣지도 않았다. 그저 생각하고 실험했다. 할아버지에게 월요일은 앞으로의 시간을 효율적으로 쓰기 위해 계획을 짜는 날이었던 것이다.\np195 첫 이메일을 쓰고 수신자의 입장에서 생각해 본다. 상대방의 경험은 분명 당신과 다를 테니까\n이메일을 쓴 후 바로 보내지 않는다. 그 전에 다음의 안내를 따른다.\n이 메일 대신 수신자와 직접 만나 이야기를 하는게 가능한 지 생각해 본다. 직접 만드는 게 불가능하다면 자신이 쓴 이메일을 다시 한번 읽어보고, 상대방의 감정을 자극하거나 자신을 치켜세우는 내용이 담긴 문구는 삭제한다. 중요한 이메일이라면 자신이 쓴 글을 다른 사람에게 읽게 하고 솔직한 견해를 구한다\n자신의 감정을 누그러뜨리고 최대한 침착하게 이메일을 보냈는데도 상대방에게서 화가 섞인 답장을 받았다면 더 이상 글로 소통하지 말고 전화로 연락을 하거나 직접 만나도록 한다 p206 인생에 가치를 더해 주지 못하는 활동들을 목록에서 지워라. 불필요한 일을 버리는 것이 좋은 활동을 채워 넣는 것보다 살믈 더 풍요롭게 만든다.\n","date":"2015-05-18T14:30:24+09:00","permalink":"https://cychong47.github.io/post/2015/caeg-jugeora-ilman-haneun-sarameun-jeoldae-moreuneun-seumateuhan-seonggongdeul/","summary":"\u003ch2 id=\"p13\"\u003ep13\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e나는 사업을 하면서 수시로 수확체감의 법칙을 실감한다. 어떤 사업이든 일정 수준에 도달하면 노동이나 자본 등 생산 요소를 늘려도 결과물은 비례해서 증가하지 않는다.\u003cbr\u003e\n일과 성공 역시 마찬가지다. 들인 시관과 성과는 정비례하지 않는다. 6시간 일한다고 목표를 달성하지 못하는 것도 아니고 12시간 일한다고 두 배의 성과를 얻는 것도 아니다. 그런데도 여전히 많은 사람들이 50시간이 아니라 70시간을 일할 때 더 많은 일을 해낸다고 믿는다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch2 id=\"p15\"\u003ep15\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e우리가 12시간씩 일하며 인생은 원래 고달픈 거라고 스스로를 위로하는 동안 누군가는 획기적인 아이디어로 3시간 일하고 9시간 동안 여유를 즐긴다.\u003cbr\u003e\n인간은 주당 30시간에서 60시간 정도 일할 때 \u0026lsquo;최대의 행복감\u0026rsquo;을 느낀다고 한다. 일하는 시간이 적으면 자신의 존재 가치를 증명하고 자아실현을 할 충분한 기회를 갖지 못하고, 일하는 시간이 너무 길면 체력이 떨어지면서 삶에 대한 의욕도 사라진다. 잘 살기 위해 일을 하는 것인데 일하는데 모든 에너지를 다 써서 정작 좋아하는 것을 즐기지 못하게 되는 것이다.\u003c/p\u003e","title":"(책) 죽어라 일만 하는 사람은 절대 모르는 스마트한 성공들"},{"content":"\u0026lsquo;\u0026lsquo;단의 공식\u0026rsquo;\u0026rsquo; 버려라 : 중요한 것을 위해 덜 중요한 것을 버리는 것. \u0026lsquo;더 많이\u0026rsquo;를 버리고 핵심에 집중 세워라 : 왜 일해야 하는 지 사명을 세우고, 내가 누구인지 정체성을 세우고, 어디로 가야 할 지 길을 세워야 한다. 지켜라 : 단순함의 핵심은 지속 가능에 달려 잇다. p14 GE의 제프리 이멜트(Jeffrey Immelt) 회장은 2013년 10월 BBC와의 인터뷰에서 이렇게 설명했다. \u0026quot; 조직이 커지면서 중요하지 않은 일을 너무 많이 하고 있다. 단순화는 직원들이 중요하지 않은 일에 맞서 정말 중요한 일을 함께 하도록 돕는 도구다. 조직을 더 날렵하게 만들고, 관료주의를 없애고, 시장에 완전히 집중하는 것을 뜻한다\u0026quot;\np24 현대인은 가슴이 두근거리지 않는 것들에 둘러싸여 너무 많은 에너지를 쏟는다. 주변을 찬찬히 살펴보고 자신을 두근거리게 하는 물건만 골라 남김으로써, 자신이 정말 하고 싶은 일에만 집중할 수 있게 된다.\np48 직원의 동기부여다. 슈나르 회장은 \u0026ldquo;파타고니아 직원들이 열심히 일하는 이유는 일을 사랑할 뿐 아니라 그 일을 통해 세상에 기여할 수 있기 때문\u0026quot;이라며 \u0026ldquo;이 두가지가 결합되면 인간의 우수성을 이끌어내면서도 큰 사업적 성과를 거둔다는 두 가지 목표를 다 이룰 수 있다\u0026quot;고 설명했다.\n우리가 만든 제품을 소비자가 어떻게 평가하느냐를 넘어 소비자가 우리 제품을 이용해서 어떤 가치를 만들어 내는지(소비자의 시장 점유율 증가나 새로운 서비스 혹은 가치 창출 등) 를 알려주는 것이 직원들의 동기부여에 도움이 되지 않을까? 단순히 품질을 높여라 라는 무미건조한 말 보다는 우리의 행동이 우리의 노력이 어떤 가치를 만들어 내는지를 체감하게 해 준다면 동기부여에 도움이 되지 않을까?\n\u0026lsquo;나만 아니면 돼\u0026rsquo; 라는 생각은 \u0026lsquo;우리 부서 문제만 아니면 돼\u0026rsquo;로 이어진다. 이건 발생한 문제를 우리가 함께 해결해야 할 문제로 보는 것이 아니라 그 부서를, 부서장을 평가하려는 목적으로 사용하기 때문에 모두 방어적으로 반응하게 만드는 것이다. 결국 이런 문화를 만든 것은 다름 아닌 바로 당신들\u0026hellip;\np50 \u0026lsquo;소비하지 않으면 안 되는 시스템\u0026rsquo;과 \u0026lsquo;늘어나지 않는 유효수요\u0026rsquo;가 빚어내는 모순이 임계점에 도달했다.\np61 모든 것을 담기는 쉽다. 그러나 적게 담는 건 어렵다. 복잡하게 만들고 중언부언하기는 쉽다. 그러나 절제는 어렵다. 언젠가 마크 트웨인이 출판사에서 \u0026lsquo;이틀 내에 두 쪽짜리 단편 필요\u0026rsquo;라는 전보를 받았다. 트웨인은 이렇게 회신했다.\n\u0026lsquo;이틀 내에 두 쪽짜리는 불가. 30쪽 짜리는 가능. 두 쪽짜리는 30일 필요\u0026rsquo;\np70 우리가 자신만의 가치, 새로운 가치를 세워야 하는 또다른 이유가 있다. \u0026lt;기계와의 전쟁\u0026gt;의 에릭 브린욜프슨(Erik Brynjolfson) 교수의 표현을 빌리자면, \u0026lsquo;어떻게 하면 더 빨리, 더 많이 만들 것인가\u0026rsquo;를 고민하면 기계가 인간 노동력을 대체할 수 밖에 없다.\np72 \u0026ldquo;직원 교육에는 반드시 명심해야 할 두 가지가 있습니다. 첫째는 창의성을 길러 새로운 가치를 창출하는 한편, 단순 업무를 반복하지 않도록 가르치는 것입니다. 많은 구식 회사들은 \u0026lsquo;(회사와 관련된)\u0026rsquo; 모든 것을 하나하나 기억하고 단순 업무를 반복\u0026rsquo;하는 직원을 성실하다고 평가하지만, 생각해보세요. 이런 건 모두가 기계로 대체할 수 있습니다. 절대로 좋은 교육법이 아닙니다. 둘째는 인간과 인간 사이의 소통 능력을 개발하고 교육하는 겁니다. 예컨대 리더십, 팀워크, 협상력, 공감 능력, 가르치는 능력은 앞으로 점점 더 중요해질 겁니다. 기계는 이런 부분에서는 발전이 더디며 능숙하지 못하기 때문입니다.\u0026rdquo;\np 83 \u0026ldquo;회사를 운영하는 사람들과 그 안에서 실무를 처리하는 사람들 사이에 너무나 많은 중간관리자가 있습니다 .열정적이고 창의적인 사람들이 자기가 옳다고 생각하는 일을 하기 위해 5단계의 경영층을 설득해야 하는 상황에 놓인 것입니다\u0026rdquo;\np 112 \u0026ldquo;선택과 집중이 필요합니다. 아직 뇌 용량을 다 채우지 않은 어린이가 어떤 환경, 정보에 노출되는지가 그래서 중요하죠. 어릴 때는 뇌에 주입되는 관념, 개념, 정보가 신피질의 공간을 무섭게 채워가니까요\u0026rdquo;\n뇌는 처음엔 매우 빠른 속도로 성장하다 어느 순간에 이르면 성인이 될 때까지 계속 줄어든다고 한다. 그럼에도 불구하고 그 크기가 작아질수록 뇌는 점점 더 영리해진다\np 116 베인앤컴퍼니의 제임스 앨런(James Allen) 글로벌전략부문 대표는 \u0026ldquo;기업의 규모가 커지고 행정적으로 복잡해지면서 의사결정 과정에서 고객 의견이나 일선의 목소리가 제대로 반영되지 않는다. 결국 기업은 점차적으로 사명감을 잃게 되고 성장 과정에서 파생된 복잡성으로 인해 서서히 쇠락한다\u0026quot;고 지적했다\u0026rdquo;\n\u0026ldquo;성장은 복잡성을 유발하며, 복잡성은 성장의 조용한 암살자\u0026quot;라고 말했다. 복잡성은 소리 없이 조직을 죽인다.\np 118 뒤집어진 \u0026lsquo;U\u0026rsquo;자 형태의 복잡성과 성과 간의 관계는 2009년 데이비스(J. P. Davis)와 아이젠하트(K.M. Elsenhardt), 빙엄(C.B. Bingham)이 처음 제시했다. 그들은 팀 게임에서 규칙이 점점 많이 추가될수록 성과에 어떤 영향을 미치는지 측정했다. 처음에는 규칙이 증가할 수록 성과가 향상됐으나 나중엔 오히려 악화됐다. 단순히 표현하자면, 규칙을 너무 많이 늘리면 팀의 초점을 흐려 성과에 부정적인 영향을 미치는 것이다. 이를 \u0026lsquo;복잡성 곡선\u0026rsquo;이라 부른다.\np 122 사람에 의해 초래되는 복잡성이란, 직원들이 마치 일부러 그러는 것처럼 간단한 일도 복잡하게 만드는 것을 말한다. 일 처리 프로세스와 조직구조, 커뮤니케이션, 제품 등 모든 것을 간단하게 처리할 수 있는데, 쓸데없이 복잡하게 만드는 것이다. 복잡성이 저절로 생겨날 리 없다. 우리 자신에 의해 생겨난다. 이런 의미에서 단순함의 기업문화를 심고 유지하는 것이야말로 관리자의 가장 중요한 사명이라 할 수 있다.\n요즘 기업 내부에서는 엄청난 경영 정보가 생산되지만, 전혀 사용되지 않거나 불필요한 정보가 많다. 만일 관리자들이 무너가를 측정하고 보고하는 데 너무 많은 시간을 쏟는다면 경계 신호다.\np124 GE는 웹사이트에 직원 누구나 제안을 올릴 수 있게 하고, 우수 제안자의 얼굴과 이름을 게시\n우리도 하지만, 요식행위에 그치는 경우가 많다.\np129 단순함이란 단어 뒤에 숨은 키워드는 효율성, 상식, 그리고 자연스럽게 일하는 것이다. 자연스럽게 일한다면, 복잡한 해결책을 피할 수 있다. 지켜야 할 규칙이 적고 지시사항이 짧을수록, 지키기 쉽고 자연스러워진다 자연스럽게 일한다면, 복잡한 해결책을 피할 수 있다. 설명이 단순할수록, 이해하고 실행하기 쉬워진다. 단지 \u0026lsquo;설명이 전혀 필요하지 않을 만큼 단순한 일은 없다\u0026rsquo;는 것과 \u0026lsquo;하려는 일을 적절히 이해하지 않는 한 누구도 일을 즐길 수 없다\u0026rsquo;는 사실을 잊지 말자\u0026rdquo;\np166 \u0026lt;생각의 시대\u0026gt;라는 책을 쓴 인문학자 김용규는 \u0026ldquo;지식의 시대는 끝났다. 이제 생각의 시대\u0026quot;라고 강조했다.\n프랜시스 베이컨이 말한 \u0026ldquo;아는 것이 힘이다\u0026quot;라는 지식의 파워는 사라졌다. 이런 시대의 경쟁력은 그 많은 지식을 수시로 빼내 활용하면서 생각하는 능력에서 나온다고 김용규는 주장한다.\np180 \u0026ldquo;저는 제 일을 \u0026lsquo;어떻게\u0026rsquo; 하는 지 알고 있었고 \u0026lsquo;무엇을 \u0026rsquo; 하는 지도 알고 있었습니다. 그러나 \u0026lsquo;왜\u0026rsquo; 하는지는 몰랐던 겁니다.\np187 선병원의 이야기는 \u0026lsquo;왜\u0026rsquo; 일해야 하는 지, 중요한 것이 무엇인지 알면 \u0026lsquo;어떻게\u0026rsquo; 해야 할지의 길은 자연스럽게 찾을 수 있음을 알려주는 사례다. \u0026lsquo;왜\u0026rsquo;를 모르는 조직은 복잡하다. 무엇을, 어떻게 해야 할지 모르기 때문이다. \u0026lsquo;왜\u0026rsquo;를 아는 조직은 단순하다. 무엇을, 어떻게 해야 할지가 분명하기 때문에 괜한 일에 힘을 빼거나 시간을 낭비할 필요가 없다. 이것이 단순해지기 위해서는 \u0026lsquo;왜\u0026rsquo;를 세워야 하는 이유다.\np194 아버지는 항상 그녀와 오빠에게 이렇게 묻곤했다. \u0026ldquo;오늘은 무엇에 실패했니?\u0026rdquo; 실패한 게 없으면 아버지는 실망했다. 그녀의 아버지는 \u0026ldquo;실패란 성공하지 못하는 것이 아니라 아무것도 시도하지 않는 것\u0026quot;이라고 말하곤 했다. 그녀는 \u0026ldquo;이제 어른이 되어 내가 실패를 두려워하지 않는다는 사실에 대해 아버지에게 정말 감사하다\u0026rdquo; 고 말했다.\np208 \u0026ldquo;남의 말은 죽음에 이르는 독약이 될 수 있다\u0026rdquo;\n\u0026ldquo;두려움에 사로잡힌 사람은 다른 사람들의 허락만을 기다리며, 원하는 것은 가질 수 없는 사람인 체한다.\u0026rdquo;\n\u0026ldquo;나는 끊임없이 누군가와 나 자신을 비교하는 내면의 비판적인 목소리에 굴복하는 대신 그 목소리를 관찰하면서 비로소 두려움을 통제할 수 있었다\u0026rdquo;\np210 인상깊었던 대목은 한국 특유의 비교문화가 건전한 시민의식 형성을 저해한 요인 중의 하나라고 주장한 부분이다.\n\u0026ldquo;한국의 중산층이 가장 힘들게 여기는 일은 내 집 마련과 자녀 교육이다. 인생 전체를 놓고 봤을 때도 이 두 과제에 지나치게 에너지를 낭비하고 있다. 그러다보니 정작 민주사회의 주춧돌이 되어야 할 교양의 형성, 자기성찰과 반성의 문화는 발육부진을 겪고 있다.\np214 \u0026ldquo;만약 가지지 못한 것을 욕망한다면 가진 것을 멸시할 것이고, 삶은 충만함도 매력도 없이 흘러갈 것이다. 그리고 돌연 죽음이 나타나 머리맡에 버티고 설 것이다\u0026rdquo;\np226 \u0026ldquo;사람들은 실패를 피하려 한다. 하지만 실패가 생명이나 건강을 대가로 요구하는 경우는 많지 않다. 기껏해야 실패의 댓가는 조롱을 견디는 것이나 이미 실패를 경험한 이들이 침묵하며 동정하는 것을 견디는 정도다. 하지만 기껏해야 이 정도인 것이야말로 실패를 싫어하는 사람들이 어떤 시도조차 하지 않는 중요한 이유다\u0026rdquo;\np230 피터 드러커가 늘 역설했듯 기업의 가치란 그 기업이 하는 일이 아니라 그 회사의 제품을 사는 고객에 의해 정의되기 때문이다.\n\u0026ldquo;경영진의 책무 중 하나는 이러한 \u0026lsquo;외부 지향성\u0026rsquo;을 구성원들에게 끊임없이 상기시키는 것\u0026rsquo;이다.\n이것이 중요한 이유는, 기업 내부에 있는 사람들은 늘 안에만 눈이 머물러 자신이 만드는 상품과 잣니이 가진 기술에만 집중하는 경향이 있기 때문이다. 그러나 고객은 어떤 제품을 만들기 위해 기업이 얼마나 열심히 노력했는지에는 전혀 관심이 없다. 그것이 자신이 가진 문제를 해결하는데 도움이 될 수 있는지, 자신도 모르던 새로운 편의를 줄 수 있는지에만 관심을 갖는다.\n제품은 고객에게 어떤 혜택을 제공하느냐로 정의해야 합니다. 그래서 우리는 \u0026lsquo;이 제품은 지금 당신이 일하는 시간을 50퍼센트 줄여줍니다\u0026rsquo;라는 식으로 말합니다.\u0026rdquo;\np234 혁신이란 이처럼 다른 이의 결핍과 고통을 이해하고 공감하는데서 싹튼다.\np248 이런 일은 거의 대부분의 대기업에서 일어난다. 관료주의가 창궐하고, 꼭 내려야 하는 결정은 늪에 빠진 듯 계속 보류 상태에 있으며 일반 관리비도 엄청나게 늘어난다. 더 무서운 것은, 이런 일이 되풀이 될수록 종업원의 의욕과 사기가 저하되며 혁신이 지체된다는 점이다.\n베인앤컴퍼니에 따르면, 기업 직원들은 가용 시간의 25퍼센트를 가치가 낮거나 비효율적인 일에 허비한다.\np253 베인앤컴퍼니는 의사결정과 관련된 이런 다양한 역할을 \u0026lsquo;RAPID\u0026rsquo;란 말로 집약해 표현한다. Recommendation, Agree, Perform, Input, Decide의 머리글자를 딴 것이다.\n\u0026ldquo;어느 공동체나 기업에서 많은 사람이 함께 일하려면 규칙이 있어야 한다. 그러나 규칙이 복잡할수록 지키기가 어렵다. 복잡한 규칙은 마비를 부른다. 과거의 유산, 책임지는 데 대한 불안과 거부감은 관료주의의 온상이 된다. 우유부단은 더 많은 통계, 더 많은 조사, 더 많은 위원회, 더 많은 관료주의를 부른다. 관료주의는 조직을 복잡하게 하고 마비시킨다\u0026rdquo;\np256 픽사에선 그룹별로 작은 영화방에 모여 전날의 업무 진척 상황(미완성 작품)을 발표한 뒤 상사와 동료의 피드백을 받는 일일 리뷰 회의를 한다. 소파에 반쯤 누워 커피와 과자를 즐기면서 하는 회의지만, 피드백은 칼날처럼 날카롭다. 영화 하나를 만들기까지 이런 회의를 꼬박 2년 동안 한다고 한다. 처음엔 다른 사람에게 매일 자신의 작품을 보여주는 게 부끄럽다고 한다. 하지만 받아들일 수밖에 없다. 피드백을 통해 문제의 원인을 발견하고 수백 번, 수천 번 수정을 거치면 명작이 나오기 때문이다.\np260 현명한 기업들이 집중하는 다섯 가지. 전략의 집중. 고객에 대한 집중. 제품의 집중. 조직의 집중. 프로세스의 집중.\np270 \u0026ldquo;빨리 만들어내는 게 중요하고, \u0026lsquo;빨리 만드는 게 최고\u0026rsquo;라고 한다면 맥도널드의 방식을 다르는 게 최선이겠지요. 그러나 그렇게 따라 하면 그 분야에서 세계 최고인 맥도널드를 이길 수가 없습니다\u0026rdquo;\np289 피터 드러커가 말했듯 \u0026ldquo;애당초 할 필요가 없는 일을 지나치게 효율적으로 처리하는 것만큼 쓸데없는 일도 없다\u0026rdquo;\np290 업무 스킬이나 노하우를 축적하는 구조가 없었기 때문에 담당자가 없어지면 다시 처음부터 기술을 구축해야 했던 것이다. 그런 식으로는 급변하는 비즈니스 환경에 적응할 수 없었다.\np293 조직 구성원들에게 \u0026ldquo;지키자\u0026quot;고 독촉만 해서는 좋은 결과가 나올 수 없다는 것이다. 중요한 것은 지킬 수 있는 \u0026lsquo;구조\u0026rsquo;를 만드는 일이며, 그 책임의 대부분은 조직의 상층부에 있다.\n","date":"2015-05-12T12:40:15+09:00","permalink":"https://cychong47.github.io/post/2015/dan/","summary":"\u003ch2 id=\"단의-공식\"\u003e\u0026lsquo;\u0026lsquo;단의 공식\u0026rsquo;\u0026rsquo;\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e버려라 :  중요한 것을 위해 덜 중요한 것을 버리는 것.  \u0026lsquo;더 많이\u0026rsquo;를 버리고 핵심에 집중\u003c/li\u003e\n\u003cli\u003e세워라 :  왜 일해야 하는 지 사명을 세우고, 내가 누구인지 정체성을 세우고, 어디로 가야 할 지 길을 세워야 한다.\u003c/li\u003e\n\u003cli\u003e지켜라 :  단순함의 핵심은 지속 가능에 달려 잇다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"p14\"\u003ep14\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eGE의 제프리 이멜트(Jeffrey Immelt) 회장은 2013년 10월 BBC와의 인터뷰에서 이렇게 설명했다.\n\u0026quot; 조직이 커지면서 중요하지 않은 일을 너무 많이 하고 있다. 단순화는 직원들이 중요하지 않은 일에 맞서 정말 중요한 일을 함께 하도록 돕는 도구다. 조직을 더 날렵하게 만들고, 관료주의를 없애고, 시장에 완전히 집중하는 것을 뜻한다\u0026quot;\u003c/p\u003e","title":"(책) 단"},{"content":"Heavy Reading 2014 December\nhttp://contextream.com/media/docs/HR-ConteXtream-Fit-VNF-WP-12-8.pdf\nThe important Factors Driving NFV deployment is Service Agility \u0026amp; Flexibility\nIn a virtual environment, where applications are extracted from hardware, VNF de- signers face different challenges and opportunities. If operators are to achieve a step change in service agility, it should be possible to provision VNFs on a quasi-on- demand basis. Fit VNFs can be dedicated to a single function and then connected together using traffic steering (or \u0026ldquo;chaining\u0026rdquo;) mechanisms to create services.\nVNFs themselves should be designed for the cloud.\nThe base meaning is to take existing applications and transform (virtualize) them. This is not the wrong thing to do; indeed, it has potential benefits. However, experience from enterprise and Web services has shown that porting legacy functions to the cloud results in less than optimal architectures that are subject to disruption from \u0026ldquo;cloud native\u0026rdquo; services.\nVNF는 기존 Physical HW에서 동작하던 SW를 VM에서 동작시키는 것이므로, 기존 SW를 단순(?)히 VM에서 동작하도록 할 수도 있다. 그러나 이미 가상화를 먼저 겪은 enterprise나 web service에서 보듯 기존 기능을 포팅하는 것은 \u0026ldquo;cloud native\u0026rdquo; 하지 않아 최적화는 한계가 있다(구체적으로 어떤\u0026hellip; 한계)\nOn-demand provisioning \u0026amp; shorter lifecycle 1+N with rapid instantiation of new VNFs in event of failure rather than 1+1 with state replication Distributed across infrastruture Automated scale out Agile Our research is very clear that operators do not view \u0026ldquo;quick and dirty\u0026rdquo; ports of appliance software to a VM environment as satisfactory. They are concerned about the performance of \u0026ldquo;Frankenstein\u0026rdquo; applications running in the cloud and about their ability to manage such functions in an automated way.\nOperator는 가능한 빨라 가상화 환경에서 앱을 동작시키는 것에 만족하는 것이 아니라 Cloud에서 자동화된 방식으로 앱을 제어하길 원한다.\n\u0026lsquo;Fit VNF\u0026rsquo; The idea is to pare back the VNF to its core function and remove extraneous capabilities no longer needed in the cloud\nRemoving redundant software modules. - 샤시 관리는 VNF에서 Cloud management layer로 이동 Simplifying the VNF networking stack - Legacy app을 포팅한 경우 복잡한 networking stack을 가지고 있을 수 있다. 그런 복잡한 건 network fabric에게 맡기고 VNF는 좀 더 가볍게 본연의 NF 처리에 집중 Deconstruct multi-function nodes - NE는 기능에 따라 여러 개의 NF로 나눠 SFC로 묶을 수 있게 모듈화 한다. Modular Scaling - NF 단위로 scaling in/out Combination of Smarter NFVI and Slimmer VNF Extract connectivity and management functions from the VNF and migrate them to the cloud platform\nIn this way, operator can create a generic NFV cloud that can support services composed of the appropriate \u0026ldquo;Fit VNFs\u0026rdquo; In this way, the \u0026ldquo;Fit VNF\u0026rdquo; and \u0026ldquo;Smart Platform\u0026rdquo; become important enablers of service agility.\nRedundant functions are extracted from the application and migrated to the NFV Infrastructure (NFVI) layer, with the result that the VNF becomes \u0026ldquo;fitter\u0026rdquo; and the platform becomes \u0026ldquo;smarter\u0026rdquo;\nUltimately, VNFs could become library, or \u0026ldquo;catalog,\u0026rdquo; items that can be deployed on the NFV cloud platform, via instruction from the NFV service orchestrator, on an on- demand basis.\nWhat is migrated from VNF to NFVI Dynamic Virtual Connectivity Scalability to run on multiple cores/servers Load balancing and health checks Internal SFC to connect sub-function instances Elasticity to change scale to needs Distribution to multiple data centers while maintaining state Analytics collection Service awareness Subscriber awareness High availability and redundancy Open Platform NFV Vendor-specific platform -\u0026gt; OPNFV for independency of VNFs Carrier Grade Open Source NFVI reference platform Improve consistency and interoperability between NFV components NFVI, VIM and API to other NFV elements such as management and orchestration(MANO) Interoperable NFVI VNFI should be open platform to support VNFs from different vendors The more platform capability is available, VNFs can be simplified accordingly Where the NFVI is more capable (\u0026ldquo;intelligent\u0026rdquo;), and VNFs simpler, operators can more quickly deploy functions and provision services. By over-specifying the platform upfront, operators will lose the agility they desire and place undeliverable requirements on suppliers\n그렇다고 NFVI에 처음부터 과도한 smartness를 요구하면 operator가 원하는 agility를 얻지 못할 수 있다. 그러므로 점진적으로 NFVI의 기능을 추가해야 한다. This will likely result in a situation where less demanding functions will be the first to surrender their autonomy to the platform.\nMobile Core에서 간단한 기능들(Load balancer, video optimizer, HTTP proxies)는 Gi-LAN에서 지원하는 기능을 사용하는 것이 이 기능들을 포함하도록 EPC를 고치는 것보다 낫다.(?)\nProgrammable Networking requirements Programmable, dynamic connectivity between VNFs is, therefore, valuable. If an NFV service orchestrator can push rules to a platform that can quickly provision the VNFs need to support a service, and the associated service function paths, operators will move a big step closer to the agility they desire from NFV. This capability is a large component of what makes an NFV platform \u0026ldquo;smart\u0026rdquo; and is why SDN and network virtualization are important. DC의 경우보다 telecom의 경우 다른 점은 distributed VNFs and need to manage \u0026ldquo;subscriber aware\u0026rdquo; traffic flows at scale. In telecom networks, where there is likely to be distributed VNFs (placed according to performance requirements), the argument for a specialist SDN solution for NFV is stronger because the need to man- age application and subscriber state across locations. In summary Legacy app을 cloud 상황을 고려하지 않고 단순히 가상화 환경으로 porting하는 것은 Operator가 원하는 on-demand provisioning에 맞지 않고 성능 측면에서 최적화된 형태가 아니다 NFV 환경은 open platform이어야 operator가 원하는 agility를 얻을 수 있다. 다양한 업체의 VNF와 VNFI를 활용 VNF는 PNF와 달리 networking stack이나 HW 관리 등의 기능을 제거해서 NF 에 집중해야 한다. 이런 기능들을 cloud management platform 으로 옮겨 VNF를 가볍게 해야 한다. \u0026ldquo;Fit VNF\u0026rdquo; On-demand Provisioning가 SDN을 결합해야 operator가 원하는 service agility를 얻을 수 있다. ","date":"2015-01-08T15:33:34+09:00","permalink":"https://cychong47.github.io/post/2015/wp-designing-for-service-agility/","summary":"\u003cp\u003eHeavy Reading 2014 December\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://contextream.com/media/docs/HR-ConteXtream-Fit-VNF-WP-12-8.pdf\"\u003ehttp://contextream.com/media/docs/HR-ConteXtream-Fit-VNF-WP-12-8.pdf\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eThe important Factors Driving NFV deployment is Service Agility  \u0026amp; Flexibility\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIn a virtual environment, where applications are extracted from hardware, VNF de- signers face different challenges and opportunities. If operators are to achieve a step change in service agility, it should be possible to provision VNFs on a quasi-on- demand basis. Fit VNFs can be dedicated to a single function and then connected together using traffic steering (or \u0026ldquo;chaining\u0026rdquo;) mechanisms to create services.\u003c/p\u003e","title":"Designing for Service Agility"},{"content":"Small Cell Big Cell 256 user 이하를 small cell로 정의 mini-CRAN Paris Hill SOC을 이용하는 경우 RRH에서 LTE/3G DSP+DFE 까지 처리하고 Ethernet으로 IA core로 전달. Altiostar 구조와 유사한 듯 Wifi 와 3G/4G까지 지원하는 차세대 SOC 2/4/8 core까지 지원 Aricent와 협업하여 L1/L2/L3 Protocol stack 개발 ONP Red Rock Canyon Las Vegas에서 30분 가량 걸리는 거리 Switch와 NIC 통합 PCI-e를 지원해서 NIC없이 Xeon을 직접 연결할 수 있음. 150page 가량의 report ONP 1.1 버전. 1.2 버전은 각 OSS 버전을 업데이트할 계획 OpenStack Juno OpenDayLight Helium DPDK v1.8 Haswell 2600 v3 Ethernet Controller Fortvillle XL710 NTT lagopus SDN Controller OpenFlow 1.3 http://lagopus.github.io 2 RX, 4 Processing, 2 Tx cores Juniper Virtual NX - DPDK based router vMX can run in the most popular hypervisors, including: KVM, VMware, and Xen. The vMX can even run in Docker containers and on bare metal. Buyers will be able to buy either license in increments based on capacity, for example in 100M, 1G, or 10G sizes, or any combination thereof. http://www.juniper.net/us/en/products-services/routing/mx-series/vmx/ WindRiver CIE(Contents Inspection Engine) Intel Hyperscan 사용 http://www.intel.com/content/dam/www/public/us/en/documents/presentation/wind-river-intelligent-network-platform-presentation.pdf Titanium Server OPNFV 와 유사하게 OSS들의 조합으로 구성 Carrier Grade 요구에 맞게 hardening Carrier Grade Linux Carrier grade high-performance Kernel-based Virtual Machine (KVM) virtualization Carrier grade accelerated vSwitch - 20Gbps on 2 cores Carrier grade OpenStack Carrier grade middleware Lifecycle development tools http://www.windriver.com/products/titanium-server/ 1초내 VM 복구 등 Live migration in 200ms Communication Infrastructure Platform Broadwell-DE 10G 2개 포함 Intel Software Platform Solution Intel System Studio 3Ghz CPU에서 10Gbps를 지원하려면 201cycle. Spin lock에 60-90 cycle, task switch에 300 cycle Haswell은 20 core/CPU 지원. HT 켜고 QPI 연결하면 80개 logical core OVS 2.4에서 공식적으로 DPDK 지원 포함 Linux UIO is replaced by VFIO DPDK 1.7.0부터 VFIO 지원 Safe device assignment with VFIO VFIO PCI device assignment breaks free of KVM Documentation / vfio.txt VFIO : A User\u0026rsquo;s perspective ","date":"2014-12-09T10:38:08+09:00","permalink":"https://cychong47.github.io/post/2014/intel-embedded-tech-forum-2014/","summary":"\u003ch1 id=\"small-cell\"\u003eSmall Cell\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eBig Cell\u003c/li\u003e\n\u003cli\u003e256 user 이하를 small cell로 정의\u003c/li\u003e\n\u003cli\u003emini-CRAN\u003c/li\u003e\n\u003cli\u003eParis Hill SOC을 이용하는 경우 RRH에서 LTE/3G DSP+DFE 까지 처리하고 Ethernet으로 IA core로 전달. Altiostar 구조와 유사한 듯\n\u003cul\u003e\n\u003cli\u003eWifi 와 3G/4G까지 지원하는 차세대 SOC\u003c/li\u003e\n\u003cli\u003e2/4/8 core까지 지원\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eAricent와 협업하여 L1/L2/L3 Protocol stack 개발\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"onp\"\u003eONP\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eRed Rock Canyon\n\u003cul\u003e\n\u003cli\u003eLas Vegas에서 30분 가량 걸리는 거리\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eSwitch와 NIC 통합\u003c/li\u003e\n\u003cli\u003ePCI-e를 지원해서 NIC없이 Xeon을 직접 연결할 수 있음.\u003c/li\u003e\n\u003cli\u003e150page 가량의 report\u003c/li\u003e\n\u003cli\u003eONP 1.1 버전. 1.2 버전은 각 OSS 버전을 업데이트할 계획\n\u003cul\u003e\n\u003cli\u003eOpenStack Juno\u003c/li\u003e\n\u003cli\u003eOpenDayLight Helium\u003c/li\u003e\n\u003cli\u003eDPDK v1.8\u003c/li\u003e\n\u003cli\u003eHaswell 2600 v3\u003c/li\u003e\n\u003cli\u003eEthernet Controller Fortvillle XL710\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eNTT lagopus SDN Controller\n\u003cul\u003e\n\u003cli\u003eOpenFlow 1.3\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://lagopus.github.io\"\u003ehttp://lagopus.github.io\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e2 RX, 4 Processing, 2 Tx cores\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eJuniper Virtual NX - DPDK based router\n\u003cul\u003e\n\u003cli\u003evMX can run in the most popular hypervisors, including: KVM, VMware, and Xen. The vMX can even run in Docker containers and on bare metal.\u003c/li\u003e\n\u003cli\u003eBuyers will be able to buy either license in increments based on capacity, for example in 100M, 1G, or 10G sizes, or any combination thereof.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.juniper.net/us/en/products-services/routing/mx-series/vmx/\"\u003ehttp://www.juniper.net/us/en/products-services/routing/mx-series/vmx/\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"windriver\"\u003eWindRiver\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eCIE(Contents Inspection Engine)\n\u003cul\u003e\n\u003cli\u003eIntel Hyperscan 사용\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.intel.com/content/dam/www/public/us/en/documents/presentation/wind-river-intelligent-network-platform-presentation.pdf\"\u003ehttp://www.intel.com/content/dam/www/public/us/en/documents/presentation/wind-river-intelligent-network-platform-presentation.pdf\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eTitanium Server\n\u003cul\u003e\n\u003cli\u003eOPNFV 와 유사하게 OSS들의 조합으로 구성 Carrier Grade 요구에 맞게 hardening\n\u003cul\u003e\n\u003cli\u003eCarrier Grade Linux\u003c/li\u003e\n\u003cli\u003eCarrier grade high-performance Kernel-based Virtual Machine (KVM) virtualization\u003c/li\u003e\n\u003cli\u003eCarrier grade accelerated vSwitch - 20Gbps on 2 cores\u003c/li\u003e\n\u003cli\u003eCarrier grade OpenStack\u003c/li\u003e\n\u003cli\u003eCarrier grade middleware\u003c/li\u003e\n\u003cli\u003eLifecycle development tools\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.windriver.com/products/titanium-server/\"\u003ehttp://www.windriver.com/products/titanium-server/\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e1초내 VM 복구 등\u003c/li\u003e\n\u003cli\u003eLive migration in 200ms\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"communication-infrastructure-platform\"\u003eCommunication Infrastructure Platform\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eBroadwell-DE\n\u003cul\u003e\n\u003cli\u003e10G 2개 포함\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch1 id=\"intel-software-platform-solution\"\u003eIntel Software Platform Solution\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eIntel System Studio\u003c/li\u003e\n\u003cli\u003e3Ghz CPU에서 10Gbps를 지원하려면 201cycle. Spin lock에 60-90 cycle, task switch에 300 cycle\u003c/li\u003e\n\u003cli\u003eHaswell은 20 core/CPU 지원. HT 켜고 QPI 연결하면 80개 logical core\u003c/li\u003e\n\u003cli\u003eOVS 2.4에서 공식적으로 DPDK 지원 포함\u003c/li\u003e\n\u003cli\u003eLinux UIO is replaced by VFIO\n\u003cul\u003e\n\u003cli\u003eDPDK 1.7.0부터 VFIO 지원\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://lwn.net/Articles/474088/\"\u003eSafe device assignment with VFIO\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.linux-kvm.org/wiki/images/d/d1/2011-forum-VFIO.pdf\"\u003eVFIO PCI device assignment breaks free of KVM\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.mjmwired.net/kernel/Documentation/vfio.txt\"\u003eDocumentation / vfio.txt\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.linux-kvm.org/wiki/images/b/b4/2012-forum-VFIO.pdf\"\u003eVFIO : A User\u0026rsquo;s perspective\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","title":"Intel Embedded Tech Forum 2014"},{"content":"며칠 밖에 보지 않았지만, 그래도 내용을 분석해 보려고 했던 OVDK인데, 오늘 기사를 보니 Intel에서 공식적으로 OVDK의 개발 중단을 발표했단다.\nIntel Dead-Ends Its Fork of Open vSwitch\nData path(Fast path)를 커널 모듈에서 처리하는 OVS를 fork해서 DPDK를 이용해서 user space에 Fast Path를 만들려고 했는데 그러다 보니 역시 계속해서 발전하는 OVS의 기능을 수용하기 부담스러웠나 보다. 더군다나 OVS에서도 experimental feature이긴 하지만 DPDK를 이용하는 코드도 있다고 하니.\n내년 초에 나올 다음 버전 OVS에 공식 기능으로 들어가길 기대한다고.\nIntel’s new, mainstream-OVS code goes under the name DPDK-netdev and has been on Github since March. It’s available as an “experimental feature” in OVS version 2.3, according to an Intel message on the dpdk-ovs mailing list. Intel hopes to include the code officially in OVS 2.4, which OVS’ committers are hoping to release early next year.\n그나저나 OVDK를 사용하던 Ericsson과 NEC는 고민이 좀 되겠다.\nHe cites Ericsson and NEC as two companies that were following the OVDK path. Ericsson acknowledged being aware of the situation but declined to comment; NEC experts did not respond to a request for comment.\n6Wind는 별도로 자체 개발한 듯 하고\n6WIND has been showing its Open vSwitch acceleration since ONS 2013. 6WIND wasn’t involved in Intel’s new OVS work, Eraltan says, although the companies have worked together on DPDK in general.\n","date":"2014-11-27T14:47:38+09:00","permalink":"https://cychong47.github.io/post/2014/r-i-p-ovdk/","summary":"\u003cp\u003e며칠 밖에 보지 않았지만, 그래도 내용을 분석해 보려고 했던 OVDK인데, 오늘 기사를 보니 Intel에서 공식적으로 OVDK의 개발 중단을 발표했단다.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"https://www.sdncentral.com/news/intel-dead-ends-fork-open-vswitch/2014/11/\"\u003eIntel Dead-Ends Its Fork of Open vSwitch\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eData path(Fast path)를 커널 모듈에서 처리하는 OVS를 fork해서 DPDK를 이용해서 user space에 Fast Path를 만들려고 했는데 그러다 보니 역시 계속해서 발전하는 OVS의 기능을 수용하기 부담스러웠나 보다. 더군다나 OVS에서도 experimental feature이긴 하지만 DPDK를 이용하는 코드도 있다고 하니.\u003c/p\u003e\n\u003cp\u003e내년 초에 나올 다음 버전 OVS에 공식 기능으로 들어가길 기대한다고.\u003c/p\u003e","title":"R.I.P OVDK"},{"content":" Cavium Demonstrates Multiple OpenDataPlane Applications at Linaro Connect USA 2014 Cavium ThunderX 48 Core 2.5Ghz ARM Server SoC Cavium ThunderX 48 Core 2.5Ghz ARM Server SoC Cavium ThunderX is the world\u0026rsquo;s fastest ARM Processor, featuring 48 ARMv8 64bit cores at 2.5Ghz each, with two SoC\u0026rsquo;s possible per motherboard, this means 240Ghz of compuete power per Server Board. Providing extremely high performance at much lower power, much lower cost, much more optimized than any x86 server system. Cavium is shipping samples of their Server product by the end of this year with mass production scheduled for next year. http://armdevices.net/2014/06/06/cavium-thunderx-48-core-2-5ghz-arm-server-soc/\nLinaro: ODL controlling: ODP-Open vSwitch\nDownload ODP docs from http://opendataplane.org\nwget http://www.opendataplane.org/wp-content/uploads/2014/01/ODPIntroductionandOverview-2014Jan29.pdf wget http://www.opendataplane.org/wp-content/uploads/2013/12/ODPLaunchOverview1.pdf git clone https://git.linaro.org/lng/odp-architecture.git git clone https://git.linaro.org/lng/odp.git git clone https://git.linaro.org/lng/odp-apps.git git clone https://git.linaro.org/lng/odp-keystone2.git git clone https://git.linaro.org/lng/odp-netmap.git git clone http://git.linaro.org/lng/odp-dpdk.git\n","date":"2014-11-19T14:02:19+09:00","permalink":"https://cychong47.github.io/post/2014/odp/","summary":"\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=tUwE1-IRdIQ#t=28\"\u003eCavium Demonstrates Multiple OpenDataPlane Applications at Linaro Connect USA 2014\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=zmnjZUQPq5U\u0026amp;spfreload=10\"\u003eCavium ThunderX 48 Core 2.5Ghz ARM Server SoC\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003eCavium ThunderX 48 Core 2.5Ghz ARM Server SoC Cavium ThunderX is the world\u0026rsquo;s fastest ARM Processor, featuring 48 ARMv8 64bit cores at 2.5Ghz each, with two SoC\u0026rsquo;s possible per motherboard, this means 240Ghz of compuete power per Server Board. Providing extremely high performance at much lower power, much lower cost, much more optimized than any x86 server system. Cavium is shipping samples of their Server product by the end of this year with mass production scheduled for next year. \u003ca href=\"http://armdevices.net/2014/06/06/cavium-thunderx-48-core-2-5ghz-arm-server-soc/\"\u003ehttp://armdevices.net/2014/06/06/cavium-thunderx-48-core-2-5ghz-arm-server-soc/\u003c/a\u003e\u003c/p\u003e","title":"ODP"},{"content":" Application Performance Tuning and Future Optimizations in DPDK by Venky Venkatesan DPDK in a Virtual World by Bhavesh Davda Rashmin Patel High Performance Networking Leveraging the DPDK and the Growing Community by Thomas Monj alon Multi Socket Ferrari for NFV by Laszlo Vadkerti Andras Kovacs Lightning Fast IO with PacketDirect by Gabriel Silva A High Performance vSwitch of the User by the User for the User by Yoshihiro Nakajima Is It Time to Revisit the IP Stack in the Linux Kernel and KVM by Jun Xu Closing Remarks by Tim ODriscoll ","date":"2014-11-19T13:59:07+09:00","permalink":"https://cychong47.github.io/post/2014/dpdk-summit-2014-videos/","summary":"\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=qpfwDySweUA\"\u003eApplication Performance Tuning and Future Optimizations in DPDK\u003c/a\u003e by Venky Venkatesan\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=EgjX0chfIcI\u0026amp;spfreload=10\"\u003eDPDK in a Virtual World\u003c/a\u003e by Bhavesh Davda Rashmin Patel\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=mv8dB2GiaIw\u0026amp;spfreload=10\"\u003eHigh Performance Networking Leveraging the DPDK and the Growing Community\u003c/a\u003e by Thomas Monj    alon\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=907VShi799k\u0026amp;spfreload=10\"\u003eMulti Socket Ferrari for NFV\u003c/a\u003e by Laszlo Vadkerti Andras Kovacs\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=KaXfDjIhn0U\u0026amp;spfreload=10\"\u003eLightning Fast IO with PacketDirect\u003c/a\u003e by Gabriel Silva\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=PSVHVDqGjcg\u0026amp;spfreload=10\"\u003eA High Performance vSwitch of the User by the User for the User\u003c/a\u003e by Yoshihiro Nakajima\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=jZYPtYPXYuU\u0026amp;spfreload=10\"\u003eIs It Time to Revisit the IP Stack in the Linux Kernel and KVM\u003c/a\u003e by Jun Xu\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.youtube.com/watch?v=r-JA5NBybrs\u0026amp;spfreload=10\"\u003eClosing Remarks\u003c/a\u003e by Tim ODriscoll\u003c/li\u003e\n\u003c/ul\u003e","title":"DPDK Summit 2014 Videos"},{"content":"정말 하나같이 핵심적인 내용인데 정작 이걸 알아야 하는 사람은 이런 데 관심이 없겠지.\n출처 : 부실한 공유문화를 지배하는 개발자의 심리\n전반적으로 공유문화가 부실하게 된 것은 현재 개발자들의 책임은 아니다. 원래 문화라는게 우리의 선조, 선배들이 만들어 놓은 것을 따르면서 아주 약간씩 바뀌는 것이다. 개발문화도 그렇다. 지금까지 선배들이 그런 환경에서 그렇게 일해 왔기 때문에 그런 문화가 형성되었고 우리도 거기에 적응해서 일하고 있는 것이다.\n문화가 바뀌기 어려운 이유는 나 혼자 노력해서는 안되기 때문이다. 다른 사람들은 공유를 위해서 노력하지 않고 나 혼자 애를 쓰면 나만 두배로 손해를 본다. 이는 ‘죄수 딜레마’와 비슷하다.\n\u0026hellip;\n둘째, 과도한 프로세스는 오히려 독약이다.\n대기업에서 많이 벌어지는 일인데, 현재 역량이나 문화수준을 훨씬 뛰어넘는 과도한 시스템과 프로세스를 도입해서 강요하곤 한다. 이런 경우 겉으로는 규칙을 지키고 비싼 시스템을 착실히 쓰는 것 같지만 속을 보면 형식적으로 따르고 흉내만 내서 효율은 오히려 더 떨어진다. 이런 일이 벌어지는 이유는 스스로의 역량이나 문화 수준을 과대평가 하기 때문이기도 하다.\n제대로 된 CTO의 부재도 한몫 한다. 실전 경험이 부족한 SW 프로세스팀은 밑져야 본전 식으로 프로세스를 복잡하게 만들고 많은 문서를 요구하곤 한다. SW 프로세스팀도 이렇게 밖에 할 수 없는 많은 고충이 있다. 많은 문서 중에서 프로젝트에 실질적으로 필요한 문서는 한두개에 불과한 경우가 대부분이지만 회사에서는 나머지를 쉽게 포기하지 못한다. 이러다 보니 개발자들은 문서 따로 개발 따로 진행을 하고 문서는 개발에 별 도움도 안되고 공유의 목적으로도 의미가 없게 된다. 이런 식으로 문제가 발생하면 프로세스를 더 복잡하게 만드는 악순환이 진행된다.\n셋째, 개발자 보고 알아서 잘 해보라고 하면 안된다.\n풀뿌리식으로 개선이 될 수 있는 사안이 아니다. 시스템과 프로세스도 필요하고 경영진의 의지와 후원이 절대적이다. 가장 중요한 것은 공유문화를 이끌 리더가 필요하다는 것이다. CTO급의 인물이 있어서 흐지부지 되기 쉬운 공유 문화 개혁에 꾸준한 추진력을 실어줄 수 있어야 한다. 역량 수준에 따라서 여러가지 시스템도 필요하다.\n넷째, 나중에 몰아서 공유하면 실패한다.\n일기를 몰아서 쓰듯이 공유도 몰아서 하면 실패한다. 공유를 위해서 문서를 만들고 시스템에 기록을 하는 것이 목적이 되면 안된다. 이것들은 소프트웨어를 개발하는 과정이고 이렇게 개발을 해야 가장 빨리 효율적으로 개발할 수 있기 때문에 문서를 만들고 공유를 하는 것이다.\n공유를 위해서 숙제를 하듯이 정리를 해서 시스템에 지식을 올리고 공유하는 것보다 매 순간 필요한 것들을 즉시 등록하는 것이 좋다. 공유할 것, 물어 볼 것, 의논해야 할 것들을 일단 적당한 시스템에 올려 놓고 진행을 하는 것이다. 그러면 자연스럽게 과정이 공유가 된다. 즉, 공유는 개발의 과정이고 일부이지 산출물, 부산물들이 아니다.\n공유를 위해서 산출물을 만들어야 한다고 생각하는 순간 공유는 실패하고 산출물도 제대로 만들어 질리가 만무하다. 이렇게 만들어진 문서는 나중에 유지보수 시에도 활용도가 뚝 떨어진다. 공유목적으로도 실패한 것이다. 개발과정이 자연스러운 공유의 과정이 되도록 해야 한다.\n다섯째, 모든 사람이 다 너무 바쁘면 안된다.\n모든 개발자가 호떡집에 불난 것 같이 바쁜 회사가 많다. 가끔은 신입 개발자는 한가하고 고참들이 더 바쁜 경우도 있다. 이런 회사는 대부분 공유에 실패한다. 불 끄느라고 정신이 없어서 나머지는 눈에 들어오지도 않는다. 시니어 엔지니어가 될수록 시야도 넓어지고 생각도 많이 하고 여기저기 관여도 많이 해야 하기 때문에 정신없이 바쁘면 안된다.\n여섯째, 보안보다 공유가 우선이다.\n소프트웨어는 설계도면이 핵심이 아니다. 구성원들의 지식 공동체가 핵심이며 문서, 시스템, 경험, 지식의 복합체가 소프트웨어 회사 기술의 실체이다. 대부분의 SW회사는 HW분야에서 설계도면 빼돌리 듯 기술을 빼돌릴 수가 없다. 우리나라에서는 빈약한 공유문화 속에서 소수의 개발자가 거의 모든 정보를 독점하기 때문에 종종 기술을 빼돌리는 일이 벌어진다. 이런 상황에서는 보안을 아무리 강조해도 기술이 새나가는 것을 막을 수는 없다.\n드물게 보안이 더 중요한 SW회사도 있기는 하지만 극소수에 불과하다. 보안에 대한 과도한 우려 때문에 공유를 너무 불편하게 하는 회사가 의외로 많다. 보안이 별 이슈도 아닌 회사도 공유에 거부감이 있는 직원의 주장에 넘어가서 공유를 포기한 회사도 많다. 훌륭한 오픈소스가 판치는 마당에 소프트웨어 회사에서는 숨길 것이 그렇게 많지 않다. 특수한 분야의 몇몇 회사를 제외하고는 모든 직원에게 모든 정보를 오픈해도 별 문제가 안된다. 보안을 과도하게 강조하여 공유에 제약을 가하기 시작하면 공유는 반쪽짜리가 되어서 효율은 엄청나게 떨어지게 된다.\n","date":"2014-11-17T13:35:16+09:00","permalink":"https://cychong47.github.io/post/2014/peom-busilhan-gongyumunhwareul-jibaehaneun-gaebaljayi-simri/","summary":"\u003cp\u003e정말 하나같이 핵심적인 내용인데 정작 이걸 알아야 하는 사람은 이런 데 관심이 없겠지.\u003c/p\u003e\n\u003cp\u003e출처 : \u003ca href=\"http://www.cnet.co.kr/view/25939\"\u003e부실한 공유문화를 지배하는 개발자의 심리\u003c/a\u003e\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e전반적으로 공유문화가 부실하게 된 것은 현재 개발자들의 책임은 아니다. 원래 문화라는게 우리의 선조, 선배들이 만들어 놓은 것을  따르면서 아주 약간씩 바뀌는 것이다. 개발문화도 그렇다. 지금까지 선배들이 그런 환경에서 그렇게 일해 왔기 때문에 그런 문화가 형성되었고 우리도 거기에 적응해서 일하고 있는 것이다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e문화가 바뀌기 어려운 이유는 나 혼자 노력해서는 안되기 때문이다. 다른 사람들은 공유를 위해서 노력하지 않고 나 혼자 애를 쓰면 나만 두배로 손해를 본다. 이는 ‘죄수 딜레마’와 비슷하다.\u003c/p\u003e","title":"(펌) 부실한 공유문화를 지배하는 개발자의 심리"},{"content":"Cuckoo 알고리즘을 사용하여 Flow lookup과 flow update 성능을 높힌 것과 DPDK를 이용하여 패킷 처리 성능을 높힌 것\n출처 : Scalable, High Performance Ethernet Forwarding with CuckooSwitch\nDPDK DPDK를 이용한 IO 성능 개선한 것 외에 특이한 것은 없음. Cuckoo hashing 대개 FIB update를 위해 RCU(Read Copy Update)를 사용함. 이 경우 완전한 정보를 갖는 additional entry가 필요\n수정된 cuckoo algorithm을 기반으로 한 flow table 사용 Basic Cuckoo hashing\nensures 50% table space utilization 4-way associative hash table has 95% utilization\n\u0026lsquo;A cool and practical alternative to traditional hash tables\u0026rsquo; Only two cache-sized parallel memory accesses are required for lookup What means \u0026lsquo;4-way\u0026rsquo;? Each hash bucket has 4 entries??? - FIXME Check the paper 메모리 사용량 감소 및 multiple reader와 single writer가 동시에 접근할 수 있게 하여 lock 사용없이 FIB update 성능 개선\nCompact and concurrent memcache with dumber caching and smarter hashing \u0026lsquo;Optimitic concurrent cuckoo hashing\u0026rsquo; More optimization for \u0026hellip;. FIXME Compiler reorerding barriers\n\u0026lsquo;a sequence of memory writes at one core are guaranteed to appear in the same order at all remote CPUs\u0026rsquo; If one cores write W1,W2 and W3 and the R1 from some core observes the effect of W3, then the R2 and R3 which is issued after R1 also observed the same effect Check the words \u0026ldquo;compiler reordering barriers\u0026rdquo; ensure the compiler does not reorder the store and read instructions using a compiler reordering barrier between the read operations which should keep the instruction order __asm__ __volatile__(\u0026quot;\u0026quot; ::: \u0026quot;memory\u0026quot;) in gcc mark volatile for the fields to access Batch Hash table lookup\nIf the size of the hash table cannot fit the fast CPU cache size, then performance drops dramatically. For this, batching 16 packets for one lookup Combine all the packets in the buffers as a single batch and perform hash table lookup at the same time FIXME - How to batch lookups Prefetch\nFIXME Performance 10^9 entries 350M lookups/second 0.5M updates/second etc. RouteBricks(2009) - 35Gbps https://github.com/efficient/libcuckoo http://efficient.github.io/libcuckoo/ https://github.com/efficient/libcuckoo-c ","date":"2014-11-09T08:48:38+09:00","permalink":"https://cychong47.github.io/post/2014/cuckoo-switch/","summary":"\u003cp\u003eCuckoo 알고리즘을 사용하여 Flow lookup과 flow update 성능을 높힌 것과 DPDK를 이용하여 패킷 처리 성능을 높힌 것\u003c/p\u003e\n\u003cp\u003e출처 : \u003ca href=\"https://www.cs.cmu.edu/~binfan/papers/conext13_cuckooswitch.pdf\"\u003eScalable, High Performance Ethernet Forwarding with CuckooSwitch\u003c/a\u003e\u003c/p\u003e\n\u003ch2 id=\"dpdk\"\u003eDPDK\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eDPDK를 이용한 IO 성능 개선한 것 외에 특이한 것은 없음.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"cuckoo-hashing\"\u003eCuckoo hashing\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\n\u003cp\u003e대개 FIB update를 위해 RCU(Read Copy Update)를 사용함. 이 경우 완전한 정보를 갖는 additional entry가 필요\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e수정된 cuckoo algorithm을 기반으로 한 flow table 사용\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003eBasic Cuckoo hashing\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eensures 50% table space utilization\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e\n\u003cp\u003e4-way associative hash table has 95% utilization\u003c/p\u003e","title":"Cuckoo Switch"},{"content":"원제 : The year without pants\np42 방송에서 IDEO가 \u0026ldquo;Deep Dive\u0026quot;라는 아이디어 개발 기법을 써서 닷새 만에 쇼핑카트를 개선하는 과정을 보여주었다. 곧이어 수 많은 기업이 Deep Dive 기법을 어설프게 따라 했지만, 놀랍게도 결과는 그들의 기대에 못 미쳤다. IDEO의 회의 단계와 규칙을 그대로 따라 하고 아무리 노력한들 한 가지가 빠진 상태에서는 방송에서 본 것과 같은 결과가 나올 리 없었다. 문제의 누락된 요소이자 가장 중요한 요소는 바로 거기에 참여한 사람들이었다 나이트라인을 시청한 다른 기업들의 경우 IDEO처럼 디자인에 재능이 뛰어난 직원들이 근무하는 환경이 아니었다. 화면에서는 드러나지 않았지만, 이런 재능보다도 더 중요한 것은 IDEO 직원들이 공유하는 가치관과 태도였다. 이렇게 겉모양만 흉내 내는 것을 인류학 용어로는 \u0026lsquo;화물 숭배 Cargo cult\u0026rsquo;라고 하는데 원주민들이 유용한 화물을 실어다 주던 비행기가 다시 오기를 기원하면서 활주로를 꾸며놓고 의식을 거행하는 것을 가리킨다.\np43 아무리 기법이 훌륭해도 어리석은 직원을 현명한 직원으로 바꿔주지는 않는다. 또 불신이 형성될 수 밖에 없는 환경이라면 그 어떤 기법을 가져다 쓴다 해도 동료 간에 신뢰가 형성되는 마법을 부리지는 못한다.\n\u0026hellip; 가장 좋은 전략, 어쩌면 유일한 전략은 성공기업의 문화를 있는 그대도 살피는 것이다. 하지만 문화를 이해하는 일은 회의 기법이나 창의적 기법을 이해하기보다 훨씬 어렵다. 후자의 경우는 모두 논리에 기초하지만, 문화는 정서에 기초하기 때문에 문화를 다루는 것은 사뭇 두려운 일이기도 하다. 문화를 평가할 수 있는 역량을 지닌 사람도 드물지만, 용기를 내어 조직문화를 바꾸려는 시도를 한다 해도 그 변화가 미미한 수준에 그치는 경우가 태반이다\np46 뮬렌웨그는 대규모 프로젝트를 수행할 역량이 자신에게 있을지도 모른다고 생각했고, 이를 확인하려면 한번 도전해 보는 수밖에 없다고 판단했다.\np48 같은 곳에서 십 년이나 머물게 되면 영영 그곳을 떠나지 못할 거라는 두렴움이 들었다.\n한 기업에서 십 년 이상 일하면 인생의 재미를 발견하는 데 전혀 도움이 안 될 거라는 확신이 있었다.\np56 어느 기업이나 마찬가지겠지만, 특히 혁신을 표방하는 기업이라면 제품을 창작하는 이들이야말로 핵심 인재다. 이 외에 다른 역할을 맡은 이들을 제품 개발자들을 돕기 위해 존재한다고 봐도 무방하다. 이 같은 개념을 위반하는 대표적인 사례로는 정보통신 부서에서 자기네 업무의 효율성을 높이려고 제품 개발자들이 사용할 수 있는 장비에 대해 제한을 두는 행위 등이 있다. 만약 경영관리 및 지원부서와 제작부서 중에 효율성을 부서를 선택하야 한다면 그 대상은 지원업무를 담당하는 부서여야 한다. 경영진을 비롯해 지원업무를 담당하는 이들이 업무의 흐름을 좌지우지하면 제품의 품질만 떨어뜨릴 뿐이다.\np58 오토매틱 고용 계약서\n나는 배움을 중단하지 않을 것이다. 나는 내 앞으로 할당된 업무만 하는 사람이 되지 않을 것이다. 결코 현상유지에 만족하지 않을 것이다. 나는 열정적이고 충직한 고객들을 통해 지속 가능한 방식으로 우리 사업을 구축할 것이다. 동료를 도울 수 있는 기회를 절대 지나치지 않을 것이며, 개구리 올챙이 적 생각을 못하는 우를 범하지 않을 것이다. 나를 움직이는 것은 돈이 아니라 사람들에게 끼치는 영향력이다.\np62 회의에 대한 내 지론은 간단하다. 논의중인 내용이 중요하면 사람들은 집중한다는 것이다.\np86 수 많은 기업에서 단합대회를 기획하면서 승부수를 띄우는 지점은 \u0026lsquo;장소\u0026rsquo;다. 숲 속의 리조트나 특별한 도시로 여행을 가면 쳇바퀴 같은 일상에서 벗어나 직원들이 몸과 마음을 쇄신하고 새로운 방식으로 사고하게 될 거라고 기대한다. 하지만 그들은 장소가 바뀌어도 변하지 않는 제일 중요한 한 가지를 망각했다. 바로 기업문화다. 어디를 가든 일하는 방식을 은연중에 규정하는 가치관이나 태도 역시 함께 따라다니기 때문이다. 경영진들이 이런 행사를 주도할수록 혁신에서는 멀어지고 현상유지는 강화될 뿐 이다.\np101 중요한 것은 우리가 시장에 내놓은 제품의 품질이었다. 벨피오레는 또한 우리가 출시한 제품이 호평을 받는다면 그것은 순전히 개발자들 덕분이라고 말했다. 개발자들이 제일 중요했다. 개발자들은 단순히 생산부 직원이 아니라 장인들이다. 소프트웨어를 만드는 회사 내에서도 심장부에 해당하는 창의력 엔진이다.\np106 시사이드 워크숍 마지막 날, 모든 팀은 전 직원이 보는 앞에서 결과물을 선보였다. 팀원들과 함께 모두가 보는 앞에서 우리가 만든 결과물을 보여주는 기분은 짜릿했다. 내 기억에 가장 선명하게 남는 것은 오오~ 와~ 하고 내지르던 사람들의 감탄사였다. 오랫동안 일했던 전 직장에서 팀원들과 소프트웨어를 만드는 동안에는 들어보지 못했던 감탄사였다.\np110 우리는 오늘날의 기업들에게 미래지향적인 관점에서 의문을 제기해야 한다. 직원들에게 쓸데없이 짐만 되고 있는 불필요한 문화가 직장 내에 얼마나 많은가? 우리는 합리적으로 설명하지 못할 수많은 관행을 충실히 따르고 있다. \u0026hellip; 우리가 이러한 관행을 따르는 이유는 직장에 들어온 순간부터 그렇게 하도록 강요받았기 때문이고, 시간이 흐르면서 너무 익숙해진 탓에 이 관행들이 만들어진 전통이라는 사실조차 잊은 것이다.\n오토매틱의 기업문화를 결정짓는 핵심 요소는 전통보다 성과를 우선시한다는 것이다. .. 근로자의 실적을 평가하는 일차적인 잣대가 노동의 품질인 것은 너무나 당연하지 않은가? 그렇다면 방해가 되는 전통을 제거하고 도움이 되는 방법을 새로운 전통으로 마스는 것이 좋지 않는가?\np101 불필요한 전통을 제거하는 관리자는 진보한다. 제약을 걷어내 업무성과가 향상되어도 좋은 일이고, 업무성과에 변화가 없더라도 사기가 진작된다면 모두에게 좋은 일이다.\n아무것도 바뀌지 않는 조직이라면 박물관이지 살아 숨 쉬는 일터라고 볼 수 없다.\n뮬렌웨그는 이를 통해 새로운 것을 배우는 가장 좋은 방법은 자신의 신념을 실행에 옮기는 것이라는 믿음을 가지게 되었다.\n그는 몇 주씩 같은 문제를 논의하고 정교한 전략을 수립하는 데 골몰할 이유가 없다고 생각했다. 뮬렌웨그는 실험하고 데이터를 수집하고, 그리고 이 과정을 반복하는 편이 더 좋았다.\np102 새로운 것을 가장 빨리 배우는 길은 듬직한 사원에게 중요한 역할을 맡겨 그들 스스로 실험을 진행하도록 하는 것이었다.\np116 Tracy Kidder \u0026lsquo;\u0026lsquo;새로운 기계의 영혼(The soul of a new machine)\u0026rsquo;\np129 내가 스카이프로 누군가에게 \u0026ldquo;어떻게 지내요?\u0026ldquo;라고 물었을 때 상대가 \u0026ldquo;좋아요\u0026quot;라고 대답하면 나는 다시 \u0026ldquo;아니 정말로 어떻게 지내요?\u0026rdquo; 라고 묻곤 한다. 이 경우 더 많은 정보를 얻었다 해도 그것은 내가 억지로 얻어낸 답변이었고, 그들 가까이에서 내가 자연스럽게 관찰하면서 얻은 정보와는 달랐다. 오토매틱인들은 먼저 자기 자신을 잘 알고 온라인에서 적극적으로 자신을 표출할 필요가 있었다.\n모든 사람은 일대일로 만나면 사람이 달라진다. 개인적으로 만나면 그들은 대화에 온전히 집중한다. 회의에서 모든 결정이 이루어진다고 생각한다면 참으로 순진한 바보다. 회의실에 있는 모든 직원을 단 한 차례 연설로 설득할 수 있는 사람은 거의 없다. 그런 일은 영화에서나 가능하다. 두 사람 이상이 내 말을 듣고 있다면 반드시 하지 못하는 말이 있고 들리지 않는 말이 있다.\np136 프로그램을 직접 짜지 못하면서 어떻게 개발자들을 관리할 수 있느냐는 것이다. 나는 두 가지가 해결된다면 어떤 것을 만들든 사람들을 관리할 수 있다고 믿는다. 그 두 가지는 명확성과 신뢰다. 목표와 평가 기준을 서로가 명확하게 한다면, 목표에 도달하기 위해 수행하는 업무에 관해 동일한 언어를 구사할 수 있다. 내가 잘 모르는 기술적 사안이 문제가 될 때 나를 항상 구해 준 질문은 \u0026ldquo;그 문제가 사용자 경험에 어떤 영향을 미치나요?\u0026rdquo; \u0026hellip; 하지만 사용자 관점에서 사고하는 것은 자신이 잘 모르는 기술적 문제가 실제로 미칠 영향력을 이해할 수 있는 멋진 방법이다.\n사용자 경험에 관한 질문을 던지는 것은 개발 업무의 우선순위를 정하는 가장 중요한 방법이다.\np141 사람들의 민낯을 보고 싶다면 불을 질러보아야 한다. 만사가 잘 돌아가고 있을 때 우리는 사람들의 제일 좋은 면만 보게 딘다. 뭔가 불에 타야만 사람들의 진면모를 볼 수 있다.\np144 오토매틱은 \u0026lsquo;\u0026lsquo;깨진창 이론\u0026rsquo;을 믿었다. 정기적으로 사소한 문제들을 고쳐나가면 더 큰 문제들을 에방할 수 있다는 의미이다.\np151 선도적인 소프트웨어 기업인 IBM이 1970년대에 근로자들의 생산성을 평가하면서 이런 방법을 썼다는 우스개소리가 있다. 개발자들이 얼마나 많은 코드를 작성했는지 코드 줄 수를 추적하기로 했다. \u0026hellip; 하지만 프로그래밍은 양적으로 측정할 수 있다는 전제는 틀렸다. 뛰어난 개발자일수록 프로그램을 완성하는데 필요한 코드는 더 늘어나는 것이 아니라 더 줄어든다. 프로그래밍의 속성에 무지한 사람만이 생각할 수 있었던 시대착오적인 평가 방법이었다.\n하지만 지금도 이 이론을 신봉하는 좀비들이 넘쳐난다. 당장 주위를 둘러보자.\n현대의 수많은 관리자들이 신봉하는 말이 있다. \u0026ldquo;평가한 대로 거둔다\u0026rdquo; 구굴을 비롯한 여러 기업에서는 모든 의사결정과 목표, 활동에 영향을 주는 요소를 측정하는 지표를 만들어야 한다고 주장한다. 현대의 기업들은 이 같은 평가지표를 널리 추종하지만, 나아갈 바를 알아내려고 마련한 바로 그 평가지표 때문에 길을 잃기도 쉬다.\n관리자들이 모든 사람이 볼 수 있도록 점수판을 걸어놓으면 그때부터 예기치 않은 일이 벌어진다. 근로자들은 자기도 모르게 매시간 그 점수판을 확인하고, 그 점수를 높이는 방향으로 일을 진행하고, 점수판에 드러나지 않는 다른 요소를 희생하는 일도 감수한다.\n\u0026hellip;\n평가지표상 좋은 점수를 받으려고 정도를 벗어나게 되면 제품이나 서비스 품질에 오히려 부정적 영향을 미칠 것이고, 이는 소비자들이 본능적으로 알아차리기 마련이다. 핵심성과지표를 도입하고 숫자 중심으로 사고하는 경영진들은 일이 잘못되면 으레 더 정교한 성과지표, 더 많은 성과지표를 만들어야 문제를 해결할 수 있다고 믿는다. 그런 식으로 성과지표가 하나둘 늘어난다. 처음에는 반짝하고 효괄ㄹ 낼지 모르지만, 머지않아 똑같은 일이 반복되고 문제는 증폭된다. 모든 평가지표는 우리를 유횩한다. 명석한 사람들이 아무리 좋은 의도로 만든 평가지표라도 거기에 시선을 고정하면 어리석은 결정을 하게 되고, 점점 더 빨리 자멸의 길로 달려간다. 데이터가 사람을 대신해 결정을 내려주지는 않는다. 데이터는 적절하게 사용하면 문제를 더 명확하게 인식하는 데 도움이 되지만, 데이터가 곧 의사결정 전부는 아니다. 조언의 역실이 존재하는 것처럼 \u0026lsquo;데이터의 역설\u0026rsquo;도 존재한다. 아무리 많은 데이터를 갖고 있어도 그 데이터를 어떻게 해석하고 적용할 것인지를 결정하려면 결국 우리 직관에 의지해야 한다는 것이다.\n다시 말해, 핵심성과지표(KPI)를 평가하기 위한 좋은 핵심성과지표는 존재하지 않는다.\np160 혹시 생길지 모를 나쁜 일들을 예방할 목적으로 공정관리를 하는 것을 나는 방어적인 관리라고 부른다. 방어적으로 프로젝트를 관리하는 경우에는 나쁜 일들을 예방하는 데 집착한 나머지 좋은 일들이 일어나는 것까지 막게 된다. 더러는 아무 일도 일어나지 못하게 막는다는 사실을 인식하지 못한다.\np161 대개의 프로젝트는 확정된 종합 계획에 따라 움직이지만, 오토매틱에서는 이 같은 일정이 없었기 때문에 직원들은 기간 내에 일을 끝내지 못할까 봐 전전긍긍하는 마음 없이 작게나마 늘 서비스를 개선하고 있다는 성취감을 맛봤다.\np177 건축가들은 설계를 마치고 나면 사라져서 다시 현장에서 보기 힘들다는 비난을 자주 받곤 한다. 자신들의 선택이 ㅇ적절했는지 아닌지 건물이 개장한 후에 확인해야 하는데, 그 같은 관리를 하지 않는 경우가 많기 때문이다. 여직원을 표 파는 로봇처럼 취급하지 말고 사소한 사안이라도 변화를 줄 수 있는 재량권을 주었다면 어땠을까? 만약 그랬다면 날마다 지겹도록 듣는 질문을 분석해 표지판이나 안내책자를 개선하고, 자신의 도움 없이도 더 많은 사람이 편하게 길을 찾을 수 있도록 시스템을 개선할 수도 있을 것이다.\n가령, 오토매틱처럼 아테네 교통국의 모든 신임 경영진이 일선에서 3주간 현장 업무를 체험한다면, 고객 관점에서 매표소 업무를 새롭게 규정하고 역무원들에게 재량권을 허용해 서비스를 개선할 수도 있지 않을까?\np187 성당식 비전을 수립한 다음에 그것들을 시장식 개발 방법으로 구현할 수 있음을 회사에 증명하고 싶었다.\np188 핵심서비스보다 주변 서비스에 더 투자하는 일은 없어야 한다고 판단했다. 그렇게 되면 과감하게 전략을 펼치지 못하고 늘 방어직인 경영 기조로 흐르게 된다.\nWordpress 댓글 시스템으로 인수한 시스템과 자체 개발 시스템 중 어디에 투자할 것 인가를 두고 고민.\np197 품질관리를 전담하는 팀이 없기 때문에 직원들 모두가 품질에 책임을 지는 분위기였다. 품질관리 전담팀이 있는 기업에서는 쉽게 찾아볼 수 없는 모습이다. 신생기업이나 소규모 팀 체제에서는 모두가 서로 돕기 때문이다. \u0026hellip; 과게 MS에서는 게으름을 피우거나 자기 일에 책임지지 않고 허튼 핑계를 대는 부작용을 방지하는 차원에서 ㅇ리부러 인원ㅇ르 줄여 소규모로 팀을 유지하곤 했다. 인원 부족이 심각하면 불행한 사태가 발생하지만, 적당히 줄이되 재량권을 부여하면 직원들의 사기와 생산성이 진작된다. 열정적인 사람들은 어려운 과제를 오히려 즐길 줄 안다.\np207 만약 가족이든 회사든 어떤 조직이 왜 현재와 같은 모습인지 알고 싶다면 먼저 윗사람을 살펴보라. 그 조직에서 가장 힘이 쎈 사람이 날마다 어떻게 행동하느냐에 따라 그 조직의 문화가 달라진다. 만약 당신이 다니는 직장에서 직원들이 서로 언성을 높이는 일이 잦다면, 그 원인은 조직에서 힘이 제일 센 사람에게 찾아야 한다. 동료에게 언성을 높이는 사람을 바로 그 사람이 채용했고, 그 직원의 행동을 도중에 제지하거나 따로 불러서 주의를 시키지 않았기 때문이다. 그 사람을 해고하는 극단적인 결정을 내릴 수도 있겠고, 어쨌거나 최고 의사결정권자가 어떤 조치를 했다면 그런 다툼은 사라졌을 것이다.\n불량한 태도로 회의를 하는 직원들이 있다면 반드시 그곳에는 누가 됐든 어떤 조치를 할 수 있는 결정권자가 있기 마련이다. 한 조직의 문화는 그 사람이 어떻게 행동하느냐에 달렸다. 의사결정권자가 침묵했다면 지금 일어난 일을 용인한다는 신호를 보낸 것이나 마찬가지다. 그 대신에 \u0026ldquo;좋은 아이디어입니다\u0026quot;라든가 \u0026ldquo;핵심을 찌르는 질문을 주셔서 감사합니다\u0026quot;라고 의견을 표명할 경우에는 모두가 그 뜻을 알아차리고 그 같은 행동이 강화될 가능성이 크다. 윗사람의 태도를 보고 자신의 행동을 결정하는 것은 인간의 본능이다. 대화하는 장소가 어디든 그곳에는 평판이나 영향력이 가장 높은 사람이 있기 마련이다. 그리고 그 사람이 하는 선택이 하나둘 쌓여서 조직문화라는 것이 만들어진다.\n팀장으로서 충분한 권한과 재량권을 보장받았기 때문에 우리 팀이 나중에 실패한다면 그것은 어디까지나 내 책임이었다.\np212 우리는 제품에 포함할 수많은 기능 중에 가장 간단하고, 가장 쉽고, 가장 가치 있는 기능만 추려내 먼저 배포하기로 했다(흔히들 Minimum Visible Product라고 한다.\np224 \u0026lsquo;어떤 방법이 업무 생산성을 높이는지 판단하는 것은 일하는 종업원의 몫이다\u0026rsquo;\np229 사내 정치는 이메일을 불필요하게 양산하는 원인이 되기도 한다.\n이메일은 발신자에게 권한이 있다\n이메일은 닫힌 채널이다\n이메일은 시간이 흐르면 사라진다\np234 내가 작성한 글에 근본적인 문제를 제기하는 것으로 포문을 여는 바람에 몇 차례 소득 없는 논쟁을 벌인 적이 있다.\np236 내가 이해하지 못하는 부분에 대해서는 늘 상사에게 설명을 요구했다. 이때 내가 원하는 것은 지시가 아니라 가르침이다. 상대가 내 주장이 틀렸다고 입증하든 내가 논쟁에서 패하든 내가 무언가를 배울 수 있다면 나는 개의치 않는다. 하지만 시키는 대로 하는 일에는 소질이 없다. 상사가 아랫사람을 설득하기 위해 얼마나 노력하는 사람이냐에 따라 나는 훌륭한 직원이 될 수도 있고 형편없는 직원이 될 수도 있다.\np241 조직에 정말로 필요한 관리자는 일주일에 80시간 근무를 요구하며 직원들을 다그치는 사람이 아니라, 좋은 인재를 알아보고 건전한 갈등을 촉진하며 직원들을 방해하지 않는 사람을 경영진이 알게 될 수도 있다.\np242 P2에 올라오는 글이나 작업 코드는 누구나 볼 수 있기 때문에 정탐하려고 마음만 먹는다면 게으름을 피우는 직원들을 쉽게 찾아낼 수 있었다. 그러나 그런 걸 정탐하고 다니는 사람은 없었고, 따라서 얼마든지 게으름을 피울 수 있는 상황이었지만 그런 사람들은 극소수였다. 내가 본 그 어떤 회사보다도 오토매틱인들은 생산성 면에세 탁월했다.\np248 같은 시공간에 함게 있으면서 신규 기능을 세상에 내보내는 일은 정말이지 짜릿한 경험이다.\np250 일정에 심각한 문제가 생겼다. 위기관리가 필요한 전형적인 상황에서\n직접 문제를 진단한다. 다른 개발자에게 부탁해 문제를 진단한다. 변화를 준다. 프로젝트를 더 단순하게 만들면 도움이 되기도 한다. 요구사항 단순화 프로젝트를 폐기한다. 계속 진행한다. 추가 일정으로 해결 p252 관리자가 자신이 고용한 인재보다 일련의 규칙을 더 신뢰할 때 방법론은 불필요하게 갈등을 유발하는 도구로 전락하는 수가 많다. 나는 형편없는 팀을 이끌고 위대한 방법론을 실행하느니 훌륭한 팀을 이끌고 형편없는 방법론을 실행하는 편을 택하겠다.\np258 우리는 개발자들이 독립적으로 작업할 수 있도록 업무를 할당했는데, 지나고 보니 이 단순한 방식이 사실은 가장 생산성이 떨어지는 방식이었다.\np265 \u0026ldquo;XX 프로젝트는 무척 중요합니다\u0026quot;라고 말하는 상사가 그냥 헛소리를 지껄인 것인지 아닌지는 자원을 얼마나 공급하는지를 보면 쉽게 확인할 수 있다. 리더가 자신이 한 말에 상응한 자원을 제공하지 않는다면 무능한 사람이거나 가식적인 사람, 아니면 두 가지 모두에 해당하는 사람이다. 하고자 하는 일이 중요하다면 그것을 입증해야 하고,중요성은 늘 다른 프로젝트에 대한 상대적인 의미를 지닌다. 지원들을 움직이려고 공약을 남발하듯이 매번 중요성을 강조하면 안 된다.\np266 내가 신경 쓰는 부분은 일정을 수립하는 것보다다도 작업을 세분화하는 것이었고, 그래야 작업 단계를 설정할 수 있었다. 우수한 프로젝트 관리자라면 누구나 그렇듯이 나는 항상 작업 일람표를 요구했고, 그것들을 우선순위에 따라 정리했다.\np300 얼마든지 위험을 무릅쓸 수 있는 자유가 주어졌는데 정작 위험을 기피하는 문화라니, 나로서는 이해가 가지 않았다.\np345 노동에 관해 여러 가지 관념이 있지만, 그중에서도 가장 위험한 생각은 노동에서 재미와 의미를 찾으려 들지 말라는 것이다. 현대인들은 우리가 일하면서 돈을 받는 것은 그 만큼 재미도 없고 의미도 없는 일을 해서 받는 보상이라고 여긴다. \u0026hellip; 마음 깊은 곳에서는 자기가 하는 일이 자신을 위해서나 남을 위해서나 무의미하다는 사실을 알기 때문이다. 돈은 지위를 부여하지만, 지위가 삶의 의미를 부여하지 는 않는다. 사람들은 자신의 영혼을 가혹하게 홀대한 만큼 많은 돈을 번다.\np346 노동의 역사는 기본적으로 생존의 문제에서부터 시작되었다. 인간은 살아남기 위해 사냥을 하고 채집을 했다. 그 시절에는 노동과 노동 이외의 삶을 이분법적으로 나누는 일은 거의 없었다. 일과 생활의 구분이 없어서 삶이 비참했디기보다는 오히려 의미 있었을 가능성이 큰다. 아무리 고된 활동이라도 모든 활동은 개인에게 의미가 있었다.\nRichard Donkin 에서 1903년에 처음 세상에 알려진 호주 원주민 요론트 족에 대해 쓰고 있다. 이들 부족은 이전까지 현대인들과 접촉이 전혀 없었는데, 노동과 놀이를 전혀 구분하지 않는 오랜 전통을 지니고 있었다.\n요론트 족이 쓰는 말에는 \u0026lsquo;워크woq\u0026rsquo;라는 낱말이 있는데, 이는 여러 가지 잡다한 일과 허드렛일을 지칭한다. 하지만 이 허드렛일 - 즉 \u0026lsquo;워크\u0026rsquo; - 에는 사냥이 포함되지 않는다. 수렵채집 사회에서 생존에 가장 중요한 활동인 사냥은 노동으로 여기지 않은 것이다. 이 원시 부족에게 노동은 어쩔 수 없이 해야 하는 어떤 일로 보인다. 이 개념 - 하고 싶지 않은 일이 노동이다 - 은 우리 현대인에게도 매우 익숙한 노동의 개념 중 하나다\nreference 코드 수로 생산성을 판단하는 경우 문제점 ","date":"2014-10-19T03:55:01+09:00","permalink":"https://cychong47.github.io/post/2014/caeg-baji-beosgo-ilhamyeon-andoenayo/","summary":"\u003cp\u003e원제 : The year without pants\u003c/p\u003e\n\u003ch3 id=\"p42\"\u003ep42\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e방송에서 IDEO가 \u0026ldquo;Deep Dive\u0026quot;라는 아이디어 개발 기법을 써서 닷새 만에 쇼핑카트를 개선하는 과정을 보여주었다. 곧이어 수 많은 기업이 Deep Dive 기법을 어설프게 따라 했지만, 놀랍게도 결과는 그들의 기대에 못 미쳤다. IDEO의 회의 단계와 규칙을 그대로 따라 하고 아무리 노력한들 한 가지가 빠진 상태에서는 방송에서 본 것과 같은 결과가 나올 리 없었다. \u003cstrong\u003e문제의 누락된 요소이자 가장 중요한 요소는 바로 거기에 참여한 사람들이었다\u003c/strong\u003e 나이트라인을 시청한 다른 기업들의 경우 IDEO처럼 디자인에 재능이 뛰어난 직원들이 근무하는 환경이 아니었다. 화면에서는 드러나지 않았지만, 이런 재능보다도 더 중요한 것은 IDEO 직원들이 공유하는 가치관과 태도였다.\n이렇게 겉모양만 흉내 내는 것을 인류학 용어로는 \u0026lsquo;화물 숭배 Cargo cult\u0026rsquo;라고 하는데 원주민들이 유용한 화물을 실어다 주던 비행기가 다시 오기를 기원하면서 활주로를 꾸며놓고 의식을 거행하는 것을 가리킨다.\u003c/p\u003e","title":"(책) 바지 벗고 일하면 안되나요?"},{"content":" 우선 할 것은 모든 과제의 진행상황을 투명하게 볼 수 있는 시스템만들기 엑셀로 관리하고 있는 정보에 대해 최적의 대안을 찾아 엑셀 사용을 최소화 하기 파일 서버에 단순히 모으고 있는 자료를 DB화. 적어도 하나의 과제에 관련된 문서를 한눈에 볼 수 있게 하고, 검색이 가능하도록 변경 File based DB 시스템 대체 방안. 필요하다면 기존 요구사항만 기존 담당자들로부터 받고, 새로운 생각을 가진 사람들에게 대안을 제안하도록 Code Coverage 100% 같은 비효율적인 업무 없애기 Inventory 정보 투명화. 어떤 실험 자산을 어떻게 사용하고 있는지, 부서간 공유. 분야별 정보 공유할 수 있는 공간 만들고, 정보 공유 독려. 무슨무슨 TF니 WG를 만들기 보다 스스로 정보를 공유하도록 만들기(보다 구체적인 방안 필요) 메일을 통한 정보 공유 최소화. 메일과 같은 휘발성 매체가 아닌(적어도 사내에서는 휘발성이 높음) CMS에 기록해서 이력 관리가 쉽도록 모든 공유 정보는 CMS에 기록(위키 등) Unit Test 강화. 불필요한 코드 삭제 유도 비현실적이고, 불합리한 무리한 패키지 개발 계획 조정. 1년에 최대 2개만 개발 SIT단계 이후 진행되는 pre-SIT 같은 바보같은 업무 없앰 TC 개수 관리 같은 의미없는 숫자기반 관리 지양 아침 8시 회의 같은 어이없는 회의 금지 SE Lab 강화. 모 부서와의 전쟁. 미개하고, 무례하고, 개념없는 놈들. 비효율적인 문서 작성 기반의 업무 보고 대안 강구. 부서 혹은 부문 별 wish list 관리. 각 부서는 제기된 요청사항에 대해 검토 후 선정된 결과에 대해 기능 구현/개선. 단 선정 내용에 대해 필히 공유(그렇지 않으면 의미 있는 것보다는 쉬운 것을 선정할 수 있으므로) ","date":"2014-10-14T14:47:49+09:00","permalink":"https://cychong47.github.io/post/2014/naege-gweonhani-issdamyeon/","summary":"\u003col\u003e\n\u003cli\u003e우선 할 것은 모든 과제의 진행상황을 투명하게 볼 수 있는 시스템만들기\u003c/li\u003e\n\u003cli\u003e엑셀로 관리하고 있는 정보에 대해 최적의 대안을 찾아 엑셀 사용을 최소화 하기\u003c/li\u003e\n\u003cli\u003e파일 서버에 단순히 모으고 있는 자료를 DB화. 적어도 하나의 과제에 관련된 문서를 한눈에 볼 수 있게 하고, 검색이 가능하도록 변경\u003c/li\u003e\n\u003cli\u003eFile based DB 시스템 대체 방안. 필요하다면 기존 요구사항만 기존 담당자들로부터 받고, 새로운 생각을 가진 사람들에게 대안을 제안하도록\u003c/li\u003e\n\u003cli\u003eCode Coverage 100% 같은 비효율적인 업무 없애기\u003c/li\u003e\n\u003cli\u003eInventory 정보 투명화. 어떤 실험 자산을 어떻게 사용하고 있는지, 부서간 공유.\u003c/li\u003e\n\u003cli\u003e분야별 정보 공유할 수 있는 공간 만들고, 정보 공유 독려. 무슨무슨 TF니 WG를 만들기 보다 스스로 정보를 공유하도록 만들기(보다 구체적인 방안 필요)\u003c/li\u003e\n\u003cli\u003e메일을 통한 정보 공유 최소화. 메일과 같은 휘발성 매체가 아닌(적어도 사내에서는 휘발성이 높음) CMS에 기록해서 이력 관리가 쉽도록\u003c/li\u003e\n\u003cli\u003e모든 공유 정보는 CMS에 기록(위키 등)\u003c/li\u003e\n\u003cli\u003eUnit Test 강화. 불필요한 코드 삭제 유도\u003c/li\u003e\n\u003cli\u003e비현실적이고, 불합리한 무리한 패키지 개발 계획 조정. 1년에 최대 2개만 개발\u003c/li\u003e\n\u003cli\u003eSIT단계 이후 진행되는 pre-SIT 같은 바보같은 업무 없앰\u003c/li\u003e\n\u003cli\u003eTC 개수 관리 같은 의미없는 숫자기반 관리 지양\u003c/li\u003e\n\u003cli\u003e아침 8시 회의 같은 어이없는 회의 금지\u003c/li\u003e\n\u003cli\u003eSE Lab 강화.\u003c/li\u003e\n\u003cli\u003e모 부서와의 전쟁. 미개하고, 무례하고, 개념없는 놈들.\u003c/li\u003e\n\u003cli\u003e비효율적인 문서 작성 기반의 업무 보고 대안 강구.\u003c/li\u003e\n\u003cli\u003e부서 혹은 부문 별 wish list 관리. 각 부서는 제기된 요청사항에 대해 검토 후 선정된 결과에 대해 기능 구현/개선. 단 선정 내용에 대해 필히 공유(그렇지 않으면 의미 있는 것보다는 쉬운 것을 선정할 수 있으므로)\u003c/li\u003e\n\u003c/ol\u003e","title":"내게 권한이 있다면"},{"content":" 창의적인 아이디어를 만들기가 쉽지 않을 텐데, 나름의 노하우가 있다면? 후배들에게 ‘아이디어를 좀 내봐, 너 좋은 아이디어 없냐?’ 하는 회의는 의미 없다. 아이디어가 있으면 이미 이야기했을 것이다. 내가 중요하게 생각하는 것은 회의에 참석한 캐릭터의 특성을 파악하는 것이다. ‘저 친구는 어떤 성향인지, 뭘 좋아하고 싫어하는지, 편견이 심한지 그렇지 않은지, 판단은 믿을 만한지’ 등등. 스태프들의 캐릭터를 파악하고 있어야 한다.\n멋진데. 이런 게 진정한 관리자의 덕목이 아닐까\nPD로 일하는 데 도움이 되었던 경험이 있다면? 아무래도 대학 다닐 때 연극했던 경험이 제일 소중하다. 마음 맞는 사람들이 모여서 공통의 목표를 향해 진짜 미친 듯이, 자기의 모든 것을 포기하면서 비등점을 향해 달려 나간다. 그리고 공연이 딱 끝나고 나면 모두 운다. 수십명이 함께. 그 일이 진짜 짜릿하다. ‘내가 하고 싶은 일이 이런 일이구나’라는 걸 그때 처음 느꼈고, 이 비슷한 일이면 아무거나 상관없다는 생각이 들었다. 그래서 시트콤 작가 모집 광고를 보고 지원하기도 했고, 영화사에 조연출로 들어가기도 했다.\n요즘 너무너무 재미가 없는데 이런 게 없어 그런 것 같다. 뭔가를 위해 함께 일하고, 함께 그 성과를 즐기는 거. 1년에 수 많은 패키지를 개발하지만 \u0026ldquo;뭔가를 이뤘다\u0026quot;라고 할 만한 것이 없다. 도전이라고 할만한 것도 없지만, 그냥 공장에서 찍어내는 듯한 일을 하고 있으니 성취감은 찾아볼 수 없다. 그래서 점점 매너리즘에 빠지고 있는 듯 한데 위에서도 SW를 공장 일처럼 만들고 있는듯한 느낌이다. 그냥 문제 없는 코드 만들면 최고라는 분위기.\nhttp://m.sisainlive.com/news/articleView.html?idxno=21316\n","date":"2014-10-07T15:30:34+09:00","permalink":"https://cychong47.github.io/post/2014/nayeongseog-pd/","summary":"\u003cblockquote\u003e\n\u003cp\u003e창의적인 아이디어를 만들기가 쉽지 않을 텐데, 나름의 노하우가 있다면?\n후배들에게 ‘아이디어를 좀 내봐, 너 좋은 아이디어 없냐?’ 하는 회의는 의미 없다. 아이디어가 있으면 이미 이야기했을 것이다. 내가 중요하게 생각하는 것은 회의에 참석한 캐릭터의 특성을 파악하는 것이다. ‘저 친구는 어떤 성향인지, 뭘 좋아하고 싫어하는지, 편견이 심한지 그렇지 않은지, 판단은 믿을 만한지’ 등등. 스태프들의 캐릭터를 파악하고 있어야 한다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e멋진데. 이런 게 진정한 관리자의 덕목이 아닐까\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003ePD로 일하는 데 도움이 되었던 경험이 있다면?\n아무래도 대학 다닐 때 연극했던 경험이 제일 소중하다. 마음 맞는 사람들이 모여서 공통의 목표를 향해 진짜 미친 듯이, 자기의 모든 것을 포기하면서 비등점을 향해 달려 나간다. 그리고 공연이 딱 끝나고 나면 모두 운다. 수십명이 함께. 그 일이 진짜 짜릿하다. ‘내가 하고 싶은 일이 이런 일이구나’라는 걸 그때 처음 느꼈고, 이 비슷한 일이면 아무거나 상관없다는 생각이 들었다. 그래서 시트콤 작가 모집 광고를 보고 지원하기도 했고, 영화사에 조연출로 들어가기도 했다.\u003c/p\u003e","title":"나영석 PD"},{"content":"근태를 처리하지 못해 하루 최소 근무시간인 4시간을 채우고 포럼 장소인 리츠칼튼 호텔로 달려(버스타고) 감. 다행히 오후 세션 시작 시간인 1시 10분 전에 도착했지만 덕분에 점심도 못 먹고 끝날 때까지 있어야 했다. 먹은 거라곤 사탕 몇 개.\n트랙 2개인데, 다른 쪽 트랙에서도 듣고 싶은 게 있었지만 트랙 1을 끝까지 들었다.\nQuanta Taiwan Company CPU와 switch 를 상호 선택할 수 있도록 함. 상용 스위치 칩 사용 Intel Alta and RRC(w/ Aricent OS) Intel ONS Broadcom Trident and Tomahawk Cavium Xpliant 다양한 CPU 사용 가능 Intel, Freescale, Cavium, Broadcom(XLP) OCE, ONIE(Open Network Install Environment) Fetch Network OS from the booter(boot loader -\u0026gt; ONIE -\u0026gt; fetch network OS) Similar to loadable OS 표준 I/F가 있다고 하네. http://opencompute.org ONIE Slideshare Open Network Linux Linux distribution for \u0026ldquo;bare metal\u0026rdquo; switches Quanta Ubuntu ONL is sponsored by BigSwitch homepage North Bound I/F OpenFlow RestFul OpEN API ??? Restful API in switch Switch provide RestFul API directly. Baremetal OS 64-bit OS for x86-64 based computers Written in Assembly Puppet, Chef Puppet is a tool designed to manage the configuration of Unix-like and MS systems. The user describe system resources and their state, either using Puppet\u0026rsquo;s declarative language or a Ruby DSL. Puppet Puppet-openstack Chef Chef-openstack Chef for OpenStack Chef is a systems and clouds infrastructure automation framework that makes it easy servers and applications to any physical, virtual, or cloud location, no matter the size of the infrastructure. MLAG(Multi-Chassis Link Aggregation) Extension of LAG up to node-level. Not covered by IEEE 802.1AX-2008 Vendor-specific implementation Support OF 1.3 One customer build their hypersclae datacenter with qunata\u0026rsquo;s h/W and their inhouse OS, but still use ONIE Advantech For Enterprise and Telecom market All QuickAssist Accelerator support Netronome as I/O processor FlowNIC acceleration card Flow Processor as Accelerated switch NFP-6840 for high-end Use 6wind solution NEC NFV Commercial Ready solution NEC R\u0026amp;D on Virtualization from 2009 National POC 500K Subscribers POC(VoLTE) 투자 비용은 mobile network이 가장 크게 증가함. 동시에 data revenue의 증가도 가장 큼. How to reduce TCO virtualization based resource utilization Programmable scalable reliable network Flexible automated configuration centralized control \u0026amp; management Average 39%(CAPEX + OPEX) CAPEX 28% - New feature OPEX System Upgrade 89% reduction OPEX Floor Site rental 66% Component Redhat or HP for OS and hypervisor HP or Dell Intel DPDK, NIC OpenStack Shift from ATCA NF to COTS NF M2M Service Platform over NFV CONNEXIVE Platofrm(virtualized platform) for M2M Services Pluribus http://pluribusnetworks.com Startup from 2010 Pretty interesting Netvisor and Server-switch architecture H/W is from advantech for some product Utilize many open-sources ISC Internet Switch consortium Quagga Convert legacy designed switch to server based based design Legacy switch use proprietary chip and small control processor Server use powerful CPU for control processor and commercial NIC Switch chip is used to replace NIC Switch chip을 PCIe를 통해 CPU에 직접 연결. DMA를 통해 직접 스위치 내부 테이블을 제어. Netvisor cover multiple boxes - illumos container??? illumos is a free and open-source Unix OS derived from the OpenSolaris http://illumos.org or wiki.illumos.org Bhyve hypervisor - 30x faster than KVM? BSD hypervisor http://hbyve.org Runs FreeBSD 9+, OpenBSD and Linux guests Fabric Cluster - build standard based ethernet fabric as ONE logical switch Time Machine analytics Can track of flows on a specific time period in the past Netvisor Fabric-Connect Brocade Last night(14/9/23), announce brocade controller AWS 계정을 이용하면 demo를 직접 사용해 볼 수 있다고 Linear performance as the number of cores are increased while other\u0026rsquo;s performance is saturated Yahoo Japan use Brocade VCS fabric for hadoop environment. ","date":"2014-09-28T14:09:56+09:00","permalink":"https://cychong47.github.io/post/2014/intel-sdnnfv-forum-korea-2014/","summary":"\u003cp\u003e근태를 처리하지 못해 하루 최소 근무시간인 4시간을 채우고 포럼 장소인 리츠칼튼 호텔로 달려(버스타고) 감. 다행히 오후 세션 시작 시간인 1시 10분 전에 도착했지만 덕분에 점심도 못 먹고 끝날 때까지 있어야 했다. 먹은 거라곤 사탕 몇 개.\u003c/p\u003e\n\u003cp\u003e트랙 2개인데, 다른 쪽 트랙에서도 듣고 싶은 게 있었지만 트랙 1을 끝까지 들었다.\u003c/p\u003e\n\u003ch2 id=\"quanta\"\u003eQuanta\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eTaiwan Company\u003c/li\u003e\n\u003cli\u003eCPU와 switch 를 상호 선택할 수 있도록 함.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"상용-스위치-칩-사용\"\u003e상용 스위치 칩 사용\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eIntel Alta and RRC(w/ Aricent OS)\n\u003cul\u003e\n\u003cli\u003eIntel ONS\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eBroadcom Trident and Tomahawk\u003c/li\u003e\n\u003cli\u003eCavium Xpliant\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"다양한--cpu-사용-가능\"\u003e다양한  CPU 사용 가능\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eIntel, Freescale, Cavium, Broadcom(XLP)\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"oce-onieopen-network-install-environment\"\u003eOCE, ONIE(Open Network Install Environment)\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eFetch Network OS from the booter(boot loader -\u0026gt; ONIE -\u0026gt; fetch network OS)\u003c/li\u003e\n\u003cli\u003eSimilar to loadable OS\u003c/li\u003e\n\u003cli\u003e표준 I/F가 있다고 하네.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://opencompute.org\"\u003ehttp://opencompute.org\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://opencomputeproject.github.io/onie/docs/overview/index.html\"\u003eONIE\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.slideshare.net/natmorris/onie-open-network-install-environment-osdc-2014-netways-berlin\"\u003eSlideshare\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"open-network-linux\"\u003eOpen Network Linux\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eLinux distribution for \u0026ldquo;bare metal\u0026rdquo; switches\u003c/li\u003e\n\u003cli\u003eQuanta Ubuntu\u003c/li\u003e\n\u003cli\u003eONL is sponsored by BigSwitch\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.opennetlinux.org\"\u003ehomepage\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"north-bound-if\"\u003eNorth Bound I/F\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eOpenFlow\u003c/li\u003e\n\u003cli\u003eRestFul\u003c/li\u003e\n\u003cli\u003eOpEN API  ???\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"restful-api-in-switch\"\u003eRestful API in switch\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eSwitch provide RestFul API directly.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.returninfinity.com/baremetal.html\"\u003eBaremetal OS\u003c/a\u003e\n\u003cul\u003e\n\u003cli\u003e64-bit OS for x86-64 based computers\u003c/li\u003e\n\u003cli\u003eWritten in Assembly\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003ePuppet, Chef\n\u003cul\u003e\n\u003cli\u003ePuppet is a tool designed to manage the configuration of Unix-like and MS systems. The user describe system resources and their state, either using Puppet\u0026rsquo;s declarative language or a Ruby DSL.\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.puppetlabs.com\"\u003ePuppet\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://wiki.openstack.org/wiki/Puppet-openstack\"\u003ePuppet-openstack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://www.getchef.com/check\"\u003eChef\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://www.slideshare.net/mattray/openstack-deployment-with-chef\"\u003eChef-openstack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://docs.getchef.com/openstack.html\"\u003eChef for OpenStack\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eChef is a systems and clouds infrastructure automation framework that makes it easy servers and applications to any physical, virtual, or cloud location, no matter the size of the infrastructure.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eMLAG(Multi-Chassis Link Aggregation)\n\u003cul\u003e\n\u003cli\u003eExtension of LAG up to node-level.\u003c/li\u003e\n\u003cli\u003eNot covered by IEEE 802.1AX-2008\u003c/li\u003e\n\u003cli\u003eVendor-specific implementation\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eSupport OF 1.3\u003c/li\u003e\n\u003cli\u003eOne customer build their hypersclae datacenter with qunata\u0026rsquo;s h/W and their inhouse OS, but still use ONIE\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"advantech\"\u003eAdvantech\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eFor Enterprise and Telecom market\u003c/li\u003e\n\u003cli\u003eAll QuickAssist Accelerator support\u003c/li\u003e\n\u003cli\u003eNetronome as I/O processor\n\u003cul\u003e\n\u003cli\u003eFlowNIC acceleration card\u003c/li\u003e\n\u003cli\u003eFlow Processor as Accelerated switch\u003c/li\u003e\n\u003cli\u003eNFP-6840 for high-end\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eUse 6wind solution\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"nec-nfv-commercial-ready-solution\"\u003eNEC NFV Commercial Ready solution\u003c/h2\u003e\n\u003ch3 id=\"nec\"\u003eNEC\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eR\u0026amp;D on Virtualization from 2009\u003c/li\u003e\n\u003cli\u003eNational POC\u003c/li\u003e\n\u003cli\u003e500K Subscribers POC(VoLTE)\u003c/li\u003e\n\u003cli\u003e투자 비용은 mobile network이 가장 크게 증가함.\u003c/li\u003e\n\u003cli\u003e동시에 data revenue의 증가도 가장 큼.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"how-to-reduce-tco\"\u003eHow to reduce TCO\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003evirtualization based resource utilization\u003c/li\u003e\n\u003cli\u003eProgrammable scalable reliable network\u003c/li\u003e\n\u003cli\u003eFlexible automated configuration\u003c/li\u003e\n\u003cli\u003ecentralized control \u0026amp; management\u003c/li\u003e\n\u003cli\u003eAverage 39%(CAPEX + OPEX)\n\u003cul\u003e\n\u003cli\u003eCAPEX 28% - New feature\u003c/li\u003e\n\u003cli\u003eOPEX System Upgrade 89% reduction\u003c/li\u003e\n\u003cli\u003eOPEX Floor Site rental 66%\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch3 id=\"component\"\u003eComponent\u003c/h3\u003e\n\u003cul\u003e\n\u003cli\u003eRedhat or HP for OS and hypervisor\u003c/li\u003e\n\u003cli\u003eHP or Dell\u003c/li\u003e\n\u003cli\u003eIntel DPDK, NIC\u003c/li\u003e\n\u003cli\u003eOpenStack\u003c/li\u003e\n\u003cli\u003eShift from ATCA NF to COTS NF\u003c/li\u003e\n\u003cli\u003eM2M Service Platform over NFV\n\u003cul\u003e\n\u003cli\u003eCONNEXIVE Platofrm(virtualized platform) for M2M Services\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"pluribus\"\u003ePluribus\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"http://pluribusnetworks.com\"\u003ehttp://pluribusnetworks.com\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eStartup from 2010\u003c/li\u003e\n\u003cli\u003ePretty interesting\u003c/li\u003e\n\u003cli\u003eNetvisor and Server-switch architecture\u003c/li\u003e\n\u003cli\u003eH/W is from advantech for some product\u003c/li\u003e\n\u003cli\u003eUtilize many open-sources\n\u003cul\u003e\n\u003cli\u003eISC Internet Switch consortium\u003c/li\u003e\n\u003cli\u003eQuagga\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eConvert legacy designed switch to server based based design\n\u003cul\u003e\n\u003cli\u003eLegacy switch use proprietary chip and small control processor\u003c/li\u003e\n\u003cli\u003eServer use powerful CPU for control processor and commercial NIC\u003c/li\u003e\n\u003cli\u003eSwitch chip is used to replace NIC\u003c/li\u003e\n\u003cli\u003eSwitch chip을 PCIe를 통해 CPU에 직접 연결. DMA를 통해 직접 스위치 내부 테이블을 제어.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eNetvisor cover multiple boxes -\u003c/li\u003e\n\u003cli\u003eillumos container???\n\u003cul\u003e\n\u003cli\u003eillumos is a free and open-source Unix OS derived from the OpenSolaris\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://illumos.org\"\u003ehttp://illumos.org\u003c/a\u003e or wiki.illumos.org\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eBhyve hypervisor - 30x faster than KVM?\n\u003cul\u003e\n\u003cli\u003eBSD hypervisor\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://hbyve.org\"\u003ehttp://hbyve.org\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003eRuns FreeBSD 9+, OpenBSD and Linux guests\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eFabric Cluster - build standard based ethernet fabric as \u003cstrong\u003eONE logical switch\u003c/strong\u003e\u003c/li\u003e\n\u003cli\u003eTime Machine analytics\n\u003cul\u003e\n\u003cli\u003eCan track of flows on a specific time period in the past\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eNetvisor Fabric-Connect\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"brocade\"\u003eBrocade\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eLast night(14/9/23), announce brocade controller\u003c/li\u003e\n\u003cli\u003eAWS 계정을 이용하면 demo를 직접 사용해 볼 수 있다고\u003c/li\u003e\n\u003cli\u003eLinear performance as the number of cores are increased while other\u0026rsquo;s performance is saturated\u003c/li\u003e\n\u003cli\u003eYahoo Japan use Brocade VCS fabric for hadoop environment.\u003c/li\u003e\n\u003c/ul\u003e","title":"Intel SDN/NFV Forum Korea 2014"},{"content":"오래만에 재밌는 책을 봤다.\n해커를 위한 책이라고 하지만, 해킹에 관한 기법보다는 network application을 작성하는데 유용한 scapy, dpkt 그리고 정규식에 대한 설명이 유용하다. 마침 요 근래 업무용으로 Python을 이용해서 패킷 만들고, 송/수신하는 유틸리티를 만들고 있어 Impacket 모듈을 많이 사용했는데 그것보다 scapy 가 훨씬 편해 보인다.\n새 책을 사긴 그렇고 중고책을 하나 구할 까 했는데 알라딘에서 중고책 매입가가 4천원 대. 작년 초에 나온 책인데 너무 싸게 매입하는 게 아닌가\n일단 책 보면서 유용하다 싶은 내용을 몇 가지 주제로 나눠 정리했다.\n소스 코드를 받을 수 있는 곳은 github COMPANION MATERIALS 예제를 하나하나 보면 참 배울게 많아 보인다.\nSemaphore screenLock = Semaphore(value = 1) screenLock.acquire() screeLock.release(() pxssh library s = pxssh.pxssh() s.login(host, user, password) s.sendline(xxx) s.prompt() scapy haslayer() is powerful to check if packet has known protocol\nfrom scapy.all import *\nif pkt.haslayer(IP) if pkt.haslayer(TCP) if pkt.haslayer(ICMP) To see the file name use scapy\n$ scapy Welcome to Scapy \u0026gt;\u0026gt;\u0026gt; ls(IP) ... CH4, 7-testFastFlux.py - pcap 파일을 읽어 특정 데이터를 가진 경우 확인\ndef handlePkt(pkt): if pkt.haslayer(DNSRR): rrname = pkt.getlayer(DNSRR).rrname rdata = pkt.getlayer(DNSRR).rdata pkts = rdpcap('fastFlux.pcap') for pkt in pkts: handlePkt(pkt) CH4, 6-spoofDetect.py - sniff해서 특정 데이터를 가진 패킷 확인\ndef testTTL(pkt): try: if pkt.haslayer(IP): ipsrc = pkt.getlayer(IP).src ttl = str(pkt.ttl) conf.iface = 'eth0' sniff(filter=\u0026quot;tcp port 21\u0026quot;, prn=testTTL, store=0) # filter is optional Make a packet easily\nIPlayer = IP(src=\u0026quot;1.1.1.1\u0026quot;, dst=\u0026quot;2.2.2.2\u0026quot;) TCPlayer = TCP(sport=123, dport=456) pkt = IPlayer / TCPlayer send(pkt) or pkt = IP(src=\u0026ldquo;1.1.1.1\u0026rdquo;, dst=\u0026ldquo;2.2.2.2\u0026rdquo;) / TCP(dport=456) / Raw(load=\u0026quot;^\\xB0\\x02\\x89\\x06\\xFE\\xC8\\x89F\\x04\\xB0\\x06\\x89F\u0026quot;) send(pkt, iface=\u0026ldquo;eth0\u0026rdquo;, count=10)\npkt = IP(src=\u0026quot;1.1.1.1\u0026quot;, dst=\u0026quot;2.2.2.2\u0026quot;) / TCP(dport=456) / Raw(load=\u0026quot;Amanda\u0026quot;) send(pkt, iface=\u0026quot;eth0\u0026quot;, count=10) Too see the packet has string XXX=YYY and get YYY\nraw = raw.sprintf(\u0026quot;%Raw.load%\u0026quot;) name=re.findall(\u0026quot;(?i)XXX=(.*)\u0026amp;\u0026quot;, raw) Too see the string \u0026ldquo;Amanda\u0026rdquo; with tcpdump, use -A option which means ASCII\nCH5, 7-uavSniff.py - good example of using Class\nDPKT module p144 CH4, 4-googleEarthPcap.py\nIP 주소를 이용해 IP의 물리적인 위치 정보를 찾고, 이를 이용해 google earth에 표시하기 위해 KML 파일 생성\ndpkt를 이용한 패킷 분석\ndpkt는 pip로 설치 불가\nfor ts, buf in pcap: ethernet = dpkt.ethernet.Ethernet(buf) ip = eth.data src = socket.ntoa(ip.src) p147 dpkt을 이용한 HTTP 분석\n상위 protocol header를 가리킬 때 x.data 사용\n5-findDDoS.py\ntcp = ip.data http = dpkt.http.Request(tcp.data) if http.method == 'GET': uri = http.uri.lower() if '.zip' in uri: print \u0026quot;bingo\u0026quot; p149 tcp = ip.data sport = tcp.sport dport = tcp.dport if '!lazor' in tcp.data.lower(): print \u0026quot;bingo\u0026quot; except KeyboardInterrupt:\ntry: foobar() except KeyboardInterrupt: sys.exit(0) Regular Expression \u0026gt;\u0026gt;\u0026gt; print re.findall(\u0026quot;(?i)XXX=(.*)\u0026quot;, \u0026quot;!#ASFDASFASDFAS#$%$#XXX=YYY\u0026quot;) ['YYY'] \u0026gt;\u0026gt;\u0026gt; print re.findall(\u0026quot;XXX=(.*)\u0026quot;, \u0026quot;!#ASFDASFASDFAS#$%$#XXX=YYY\u0026quot;) ['YYY'] 왜 `(?i)`를 사용하는 걸까? \u0026gt;\u0026gt;\u0026gt; re.findall(r'[0-9a-zA-Z]{3}', \u0026quot;123 2314 13\u0026quot;) ['123', '231'] Mechanize module # -*- coding: utf-8 -*- import mechanize def viewPage(url): browser = mechanize.Browser() page = browser.open(url) source_code = page.read() print source_code viewPage('http://www.syngress.com/') Twitter API CH6, 9-twitterInterests.py Template #!/usr/bin/python # -*- coding: utf-8 -*- def main(): parser = optparse.OptionParser('usage %prog -i \u0026lt;interface\u0026gt;') parser.add_option('-i', dest='interface', type='string', help='specify interface to listen on') (options, args) = parser.parse_args() if options.interface == None: print parser.usage exit(0) else: conf.iface = options.interface try: print '[*] Starting Credit Card Sniffer.' sniff(filter='tcp', prn=findCreditCard, store=0) except KeyboardInterrupt: exit(0) if __name__ == '__main__': main() Template(Class) #!/usr/bin/python # -*- coding: utf-8 -*- class testThread(threading.Thread): def __init__(self): threading.Thread.__init__(self) # add intialize variables or initialization functions def run(self): # main function of this class def main(): testInstance = testThread() testInstance.start() ","date":"2014-09-27T16:43:27+09:00","permalink":"https://cychong47.github.io/post/2014/caeg-violent-python/","summary":"\u003cp\u003e오래만에 재밌는 책을 봤다.\u003c/p\u003e\n\u003cp\u003e해커를 위한 책이라고 하지만, 해킹에 관한 기법보다는 network application을 작성하는데 유용한 scapy, dpkt 그리고 정규식에 대한 설명이 유용하다.\n마침 요 근래 업무용으로 Python을 이용해서 패킷 만들고, 송/수신하는 유틸리티를 만들고 있어 Impacket 모듈을 많이 사용했는데 그것보다 scapy 가 훨씬 편해 보인다.\u003c/p\u003e\n\u003cp\u003e새 책을 사긴 그렇고 중고책을 하나 구할 까 했는데 알라딘에서 중고책 매입가가 4천원 대. 작년 초에 나온 책인데 너무 싸게 매입하는 게 아닌가\u003c/p\u003e\n\u003cp\u003e일단 책 보면서 유용하다 싶은 내용을 몇 가지 주제로 나눠 정리했다.\u003c/p\u003e","title":"(책) Violent Python"},{"content":"p230 OKR(Objectives and Key Results) 는 원래 인텔의 앤디 그로브(Andy Grove)가 고안한 경영기법이다. \u0026hellip; 무었을 하고 싶어하는지만 정하는 것이 아니라, 측정 가능하게 업무(핵심결과)를 나눠야 한다는 내용이었다.\nOKR은 구글문화의 핵심이 되었다. 모든 직원이 나름의 OKR을 분기별로, 연도별로 세워서 승인을 받아야 한다. 그 뿐만이 아니라 팀 수준, 부서 수준, 심지어 회사 수준의 OKR도 구축했다(회사 수준의 OKR은 중요한 구상이나 시래를 만회하려 할 때 구축했다) 1년에 네 차례씩 구글 직원 모두 멈춰 서서 부서별 회의를 갖고 OKR 진전상황을 확인한다.\n이러한 제도를 구글이 관료제화 되어가는 신호가 아닐까 생각하는 사람도 있을 것이다. 실제 업무를 못하게 될 정도로 잡일 프로젝트를 도입한 것이 아닌가 궁금할지도 모른다. 하지만 구글 직원들은 그렇게 생각하지 않는다. 그들은 OKR을 하나의 데이터로 여긴다. 성과를 측정하는 수단으로 계량화가 가능한 방식이기 때문이다. OKR은 측정이 가능하다는 점, 거기에 핵심이었다. \u0026lsquo;지메일을 성공시키겠다\u0026rsquo;가 아니라 \u0026lsquo;지메일을 9월에 발족하여 11월까지 사용자 수를 100만 명으로 늘리겠다\u0026rsquo;라고 계획하는 것이다. 마리아 메이어는 이렇게 말한다. \u0026ldquo;수치가 없으면 핵심결과가 아니죠\u0026rdquo; OKR은 야망을 구체화시킨다. 도어는 위험을 받아들일 수 있도록 허용해 주기도 합니다.\u0026quot; OKR은 목표를 도달하지 못한다는 것보다 초과 달성했을 경우에 더 문제가 된다. 미리 목표를 편안하게 설정해서 편안하게 업무를 했다는 뜻이 되기 때문이다. 구글은 목표치를 초과달성한 직원을 도전적이지 않다고 여긴다.\nOKR은 목표를 달성한 것을 1로 보며 가장 적절한 성적은 0.7~0.8점이다. 분기마다 다음 분기의 OKR을 설정하며 6주일 후 관리자에게 진행상황을 보고한다. 이때의 실적은 교통신호체계로 표시된다. 분기 말로 갈수록 OKR은 자체평가하고, 1점을 얻는 경우, 즉 100퍼센트 달성을 하는 경우에는 다른 평가자가 다시 한번 점검한다.\nOKR은 단순히 개인의 성과를 관리하기 위한 도구가 아니다. OKR은 개개인의 임무가 무엇인지 공개하는 수단이기도 하다. 구글의 모든 직원은 인트라넷 MOMA의 직원정보에 OKR을 공개한다. 심지어 래리와 세르게이의 OKR도 공개된다. \u0026ldquo;우리는 회사를 합리적인 조직으로 운영하고 싶었어요. 투명성이 높으면 더욱 좋죠. 분기마다 무엇을 이루고 싶은지 한두 페이지로 모두 함께 소통할 수 있다면 얼마나 좋겠습니까?\u0026rdquo; 대기업에는 보통 고질적인 탈개성화가 일어난다. OKR 공유 또한 대기업화를 막기 위한 고육지책 중 하나다. 처음 기업을 시작할 때는 모두 서로 알며 무엇을 하는지도 안다. 직원 수가 2만 명이 넘는 지금도 여전히 구글은 직원간의 친화성을 높이기 위해 노력한다. MOMA 외에도 구글 직원이라면 누구나 프로젝트 데이터베이스에 접속하여 현재 회사가 엔지니어링과 제품관리자, 제품, 엔지니어링 등을 어떻게 나눴는지 알아볼 수 있다. 새로운 멋진 프로젝트를 찾는 직원은 \u0026lsquo;아이디어\u0026rsquo;라고 하는 섹션에 접속하여 동료들이 어떤 일손을 구하는 지 알 수 있다.\nOKR template This Is The Internal Grading System Google Uses For Its Employees — And You Should Use It Too How Google Set Goals:OKRs OKRs are about the company’s goals and how each employee contributes to those goals. Performance evaluations – which are entirely about evaluating how an employee performed in a given period – should be independent from their OKRs\np280 \u0026ldquo;아마 정부를 포함해서 세계 어느 곳보다도 대규모로 redundant network을 연결시켜 놓은 곳이 구글일 겁니다\u0026rdquo;\np364 우리는 구글이이게, 절감도 다르게 할 겁니다. 우리가 GM이나 엑손이었다면 넥타이를 맨 사람으로 가득 찬 위원회를 하나 만들어서 외부 컨설턴트를 고용해가지고는 \u0026lsquo;해결책\u0026rsquo;이라고 쓴 메모를 돌리겠죠. 구글에서는 우리 직원에게 이렇게 말합니다.\u0026lsquo;낭비 요소가 있는지 당싱이 알려주세요\u0026rsquo; 구글은 그 작업을 위해 따로 인력을 고용하고 웹기반의 툴을 만들어서 데이터위주로 만든 낭비요소 분석기를 만들었다. \u0026hellip; 모든 카페의 소비량과 사용량에 대한 데이터를 모으고, 사무실 내 부엌 사용패턴을 측정한 다음에 스프레드시트에 데이터를 집어 넣어 피봇 테이블 기능을 써서 사용빈도가 낮은 카페를 발견했다.\np370 구글 인사팀은 직원의 지위에 대해 9가지의 단계로 이뤄진 시스템을 만들었다. \u0026hellip; 구글은 직원들이 현재 사다리에서 어느 정도 단계에 올라있는지조차 알려주지 않는데, 이는 통상적인 구글의 내부적인 투명성을 생각해본다면 이례적인 일이다. 보크는 이런 비밀주의가 \u0026lsquo;인지적 휴리스틱(Cognitive Heuristic)때문이라고 설명할 터였다. 인지적 휴리스틱이란 사람들이 자신보다 직급이 높은 상관의 말을 따라야 한다고 생각하게 만드는 무의식적인 사고 과정을 말한다. \u0026ldquo;대초원에 있거나 대기업에 있으면 도움이 될 테지만 구글에서는 도움이 안 됩니다. 에릭이나 래리는 어느 누구라도 어떤 이에게 \u0026lsquo;당신 말이 틀렸어요\u0026rsquo;라고 말하고 왜 틀렸는지 10가지 이유를 말할 수 있는 관계가 되어야 한다고 생각합니다\u0026rdquo; 이 과정에서 직급은 거추장스러울 뿐이다.\n혁신을 바란다면 가장 먼저 해야 할 게 이게 아닌가 싶다. 호칭이 뭐 대수냐고? 하지만 그 호칭이 들어가는 순간 상대방의 의견에 반하는 말을 하려면 수 배의 용기가 필요하다. 그런 용기를 가진 사람을 오히려 골라내야 한다고? 필요한 것이 뭔가? 용기를 가진 뛰어난 인재인가? 아니면 좋은 의견/생각 그 자체인가? 답은 명확하지 않나?\np385 보안이 중요하지만 구글은 직원을 신뢰할 수 없다는 생각을 참을 수가 없었다. \u0026hellip; 회사가 당신을 좀도둑으로 취급하고, 회사문을 나설 때마다 가방을 뒤지는 곳에서 진정한 구글 직원이 될 리 있겠는가?\n자연스럽게 회사나 자신을 분리한다. 이 회사는 그저 직장일 뿐이라고. 그걸 원한다면야\n","date":"2014-09-27T13:33:25+09:00","permalink":"https://cychong47.github.io/post/2014/0gwa-1ro-sesangeul-bagguneun-gugeul-geu-modeun-iyagiin-the-flex/","summary":"\u003ch3 id=\"p230\"\u003ep230\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eOKR(Objectives and Key Results) 는 원래 인텔의 앤디 그로브(Andy Grove)가 고안한 경영기법이다.\n\u0026hellip;\n무었을 하고 싶어하는지만 정하는 것이 아니라, 측정 가능하게 업무(핵심결과)를 나눠야 한다는 내용이었다.\u003cbr\u003e\nOKR은 구글문화의 핵심이 되었다. 모든 직원이 나름의 OKR을 분기별로, 연도별로 세워서 승인을 받아야 한다. 그 뿐만이 아니라 팀 수준, 부서 수준, 심지어 회사 수준의 OKR도 구축했다(회사 수준의 OKR은 중요한 구상이나 시래를 만회하려 할 때 구축했다) 1년에 네 차례씩 구글 직원 모두 멈춰 서서 부서별 회의를 갖고 OKR 진전상황을 확인한다.\u003cbr\u003e\n이러한 제도를 구글이 관료제화 되어가는 신호가 아닐까 생각하는 사람도 있을 것이다. 실제 업무를 못하게 될 정도로 잡일 프로젝트를 도입한 것이 아닌가 궁금할지도 모른다. 하지만 구글 직원들은 그렇게 생각하지 않는다. 그들은 OKR을 하나의 데이터로 여긴다. 성과를 측정하는 수단으로 계량화가 가능한 방식이기 때문이다. OKR은 측정이 가능하다는 점, 거기에 핵심이었다. \u0026lsquo;지메일을 성공시키겠다\u0026rsquo;가 아니라\n\u0026lsquo;지메일을 9월에 발족하여 11월까지 사용자 수를 100만 명으로 늘리겠다\u0026rsquo;라고 계획하는 것이다. 마리아 메이어는 이렇게 말한다. \u0026ldquo;수치가 없으면 핵심결과가 아니죠\u0026rdquo; OKR은 야망을 구체화시킨다. 도어는\n위험을 받아들일 수 있도록 허용해 주기도 합니다.\u0026quot; OKR은 목표를 도달하지 못한다는 것보다 초과 달성했을 경우에 더 문제가 된다. 미리 목표를 편안하게 설정해서 편안하게 업무를 했다는 뜻이 되기 때문이다. 구글은 목표치를 초과달성한 직원을 도전적이지 않다고 여긴다.\u003c/p\u003e","title":"(책) 0과 1로 세상을 바꾸는 구글 그 모든 이야기(In the Flex)"},{"content":"혼창통by 이지훈\n8p 혼 : 가슴 벅차게 하는 비전이 사람을 움직인다.\n창 : 끊임없이 \u0026ldquo;왜\u0026quot;라고 물어라, 그러면 열린다. 통 : 만나라, 또 만나라. 들어라 잘 들어라.\n16p IBM, P\u0026amp;G, Cisco, CEMEX 이 기없들의 공통점은 무엇일까? 그렇다 공룡처럼 몸집이 큰 기업들이다. 공룡인데도 민첩하다. 한가지 공통점은 회사 전체가 보다 큰 가치, 가슴을 울렁이게 하는 원대한 비전을 공유한다는 사실이다. 하버드경영대학원의 로자베스모스 캔터 교수(Rosabeth Moss Kanter) \u0026ldquo;모든 직원이 보다 큰 가치를 공유하게 되면 일선에서 어떤 문제가 부딛쳐도, 혹은 본사로부터 아무리 떨어진 곳에서 일하더라도 자발적으로 문제의 해결을 주도하게 된다\u0026rdquo;\n17p 손정의 소프트뱅크 회장은 비전의 중요성을 강조하면서 이렇게 말했다. \u0026ldquo;눈앞을 보기 때문에 멀미를 느끼는 것이다. 몇백 킬로미터 앞을 보라. 그곳은 잔잔한 물결처럼 평온하다. 나는 그런 장소에 서서 오늘을 지켜보고 사업을 하고 있기 때문에 전혀 걱정하지 않는다\u0026rdquo;\n18p 현실에 만족하고 안주하는 순간, 창은 시들고 만다. 다른 사람들이 선택한 쉬운 길을 거부하고, 늘 \u0026ldquo;왜\u0026quot;라고 물으며 새롭고 어려운 길을 갈 때에야 비로소 창이 싹튼다. 창은 손이 진흙으로 더러워지는 것을 두려워하지 않는 실험정신이고, 실패를 찬양하는 도전정신이다.\n33p 무언가 디지털화할 수 있는 것은 결국 공짜 버전이 나오고 만다. 결국 당신의 숙제는 어떻게 공짜와 경쟁할 수 있느냐는 것이다. 공짜 버전이 제공하지 못하는 것을 제공하라. \u0026lsquo;아이튠즈\u0026rsquo;가 제공한 것은 편리함이었다. 제품을 파는 시대에서 서비스를 파는 시대로 바뀌고 있다.\n43p 많은 리더들이 \u0026lsquo;어떻게 하면 구성원들에게 동기를 부여해 스스로 일하게 만들 수 있을까?\u0026rsquo; 라는 문제를 고민한다. 돈은 결코 정답이 아니다. 물론 누구나 돈이 필요하긴 하지만, 돈으로 사람을 움직이는 데는 한계가 있는 법이다. 경영자라면 이해득실을 전부 버려도 포기해서는 안 되는 죽어도 지키고 싶은 무엇을 최소한 한 가지는 마음속 깊이 갖고 있어야 한다. 그래야 사람의 마음을 움직일 수 있다. 그것이 바로 철학이고 혼일 것이다. 혼은 \u0026lsquo;사람을 움직이는 힘\u0026rsquo;이다.\n46p 나는 사람들이 어떻게 그렇게 사는 지 상상을 할 수 없어요. 내가 보기에 정말 미친 것 같거든요. 아무리 높은 연봉이라도 일상생활의 일부로서 즐거움이 없는 삶을 나는 살 수 없습니다. 자본주의 체계란 놀라울 정도로 못돼먹은 겁니다. 80%이상의 사람들이, 생계를 위해 하는 일에서 아무런 즐거움을 엊지 못한다고 합니다. 대부분 사람들의 인생이 그렇습니다. 정말 미쳤어요.\n49p 케네디 토머스 \u0026lt;열정과 몰입의 방법, Intrinsic Motivation at work\u0026gt; 사람들은 4가지 조건이 충족될 경우 일에서 재미와 열정을 느낀다. 1. 자신이 가치있는 일을 하고 있다고 느낄 때 2. 그 일을 할 때 자신에게 선택권이 있다고 느낄 때 3. 그 일을 할 만한 기술과 지식이 있다고 느낄 때 4. 실제로 진보하고 있다고 느낄 때\n51p 세계와 경쟁한다는 것이 진정 어떤 의미인지 알고 있는 지\u0026hellip;66p다른 사람들의 생각에 얽매이지 마십시오. 타인의 소리들이 여러분 내면의 진정한 목소리를 방해하지 못하게 하십시오. 그리고 가장 중요한 것은 여러분의 심장과 직관이 이끄는 대로 살아갈 수 있는 용기를 가지는 것입니다. 이미 여러분의 심장과 직관은 당신이 진짜로 원하는 것이 무엇인지를 알고 있습니다. 나머지는 다 부차적인 것입니다.\n70p 나는 만약 어떤 일에서 재미와 즐거움을 더 이상 찾을 수 없다면 드디어 다른 일을 찾아야 할 때가 된 것이라고 믿는다. 행복하지 않게 시간을 보내기에는 인생이 너무 짧다. 아침에 일어나면서부터 스트레스를 견뎌야 하고, 비참한 기분으로 일터로 나간다면 삶에 대한 올바른 태도가 아니다.\n72p 좋아하지 않는 직장이지만 그래도 계쏙 남아 일해야만 하는 사람에게는. 인생은 긍정적으로 바라보는 사람에게 문을 열어준다. 일을 하면서 만나게 되는 사람들과 함께 즐거움을 찾아야 한다.\n73p \u0026lsquo;나는 골치 아프고 힘든 일이 잔쯕 있을 때는 그 일이 해결되었을 때의 기쁨을 생각하면서 출근합니다\u0026rdquo; 개인은 일의 주인이 되어야 한다. 그래야 진정한 성공을 맛볼 수 있다. 기업은 조직원을 일의 주인으로 만들어야 한다. 그것이 조직원과 기업이 함께 성장하는 길이다.\n84p 돈으로는 사람을 움직일 수 없습니다. 사람을 움직이려면 마음 깊은 곳에서 타오르는 동기를 부여해야 합니다. 이를 위해서는 이윤을 뛰어넘는 숭고한 경영철학과 경영자의 인격이 필요합니다.\n90p 중요한 사실은 내발적 동기가 외발적 동기보다 더 지속성이 있고, 더 좋은 결과를 가져오며, 더 큰 심리적 안정을 가져온다는 점이다. 내발적 동기의 경우, 활동에 집중하는 것 자체가 보상이 되므로 언제까지나 높은 동기가 부여될 수 있고, 활동이 계쏙 유지돼 자연스럽게 좋은 성과를 내게 된다.\n92p \u0026lsquo;당근과 채찍\u0026rsquo; 전략으로 상징되는 전통적인 기업의 보상 시스템은 종업원이 스스로 일하려는 동기, 즉 내발적 동기를 오히려 꺾을 수 있다는 점이다.\n95p 천이유천 이란 중국 속담을 새기기 다닌다고 했다. 하늘 위에 또 하늘이 있다는 뜻이다. \u0026ldquo;제 성격에는 자만의 DNA가 흐르고 있습니다. 조금만 방심해도 우쭐해지기 쉬운 성격이죠. 그래서 늘 자만하지 않도록 스스로를 일깨우고 조심하고 있습니다\u0026rdquo;\n96p 첫째가 중국의 개혁 개방 둘째가 높은 목표를 세우고 그것을 실현하기 위해 늘 노력한 갓 셋째가 언제나 공부하는 것\n96p 간부는 큰 엔진이고, 그 밖의 모든 직원들은 큰 엔진과 함께 돌아가는 작은 엔진이 되어야 합니다. 밑의 직원들이 엔진에 따라 움직이는 기어가 되어서는 절대로 안됩니다. 어떻게 하면 일을 더 잘할 수 있을 지 스스로 생각하게 만들어야 합니다. 이렇게 해야 원동력이 더 커지게 됩니다.\n99p 마케팅 1.0 소비자 머리에 호소 2.0 감성에 호소 3.0 영혼에 호소. 환경에 신경 쓰고 사회에 좋은 일도 하는 회사라면 내게 특별히 무엇을 주지 않더라도 그냥 좋다.\n104p 혼은 \u0026lsquo;사람을 움직이는 힘\u0026rsquo;이며 \u0026lsquo;내가 여기에 있어야 하는 이유\u0026rsquo;이고 \u0026lsquo;개인을 뛰어넘는 대의\u0026rsquo;이다. 혼은 우리를 움직이게 하고, 버티게 하고, 극복하게 하는 근본적인 힘.\n119p 사람들의 태도와 정신을 바꾸는 것이 중요합니다. 처음에는 불편해도 스스로에게 강제하고 단계적으로 반복 훈련을 하면 습관이 됩니다. 습관은 들이기는 어렵지만 나중에는 자연스럽고 편안해지죠. 개인뿐 아니라 조직이나 기관도 이런 식으로 변해야 합니다.\n127p 끊임없이 노력해야 하고 아주 작은 디테일까지 세심한 주의를 기울여야 하며, 리스크를 감수하더라도 실행에 옮겨야 한다.\n129p 다니엘 핑크 우리가 왜 새로워지고 창조적이지 않으면 안되는 지. 1. 아시아 - 아시아의 신흥시장 인력이 급성장한 경우, 루틴한 업무는 일상재가 될 것이다. 남들이 하지 않는 창조적인 일을 하지 않으면 안 된다. 2. 자동화 - 기계와 소프트웨어가 인간의 노동과 두뇌를 대신해가고 있다. 컴퓨터가 대체할 수 없는 인간의 우뇌만이 할 수 있는 창조적인 일을 하지 않으면 안된다. 3. 풍요 - 생활이 풍족해지면서 사람들의 새로운 욕구를 충족시키는 창의성 있는 인재가 날로 중요해진다. 당장은 사람들이 필요하다고 느끼지 못하지만, 사람들의 잠재된 욕구를 충족시킬 수 있는 상품을 개발하는 역량이 중요하다.\n136p 다니엘 핑크 이제 우리에게는 펙트들이 너무나 넘쳐난다. 그런 팩트들을 스토리로, 문맥으로 엮어내지 못하면 팩트는 증발된다.\n139p 마에다 총장은 권위적 리더쉽고, 창조적 리더쉽을 제시 권위적 리더쉽 - 채찍 중시, 위계질서 중시, \u0026lsquo;예스 혹은 노\u0026rsquo;의 명쾌함 중시, 옳은 판단인지 따지기, 장군처럼 생각하기, 실수 회피, 제한된 피드백만의 허용 창조적 리더쉽 - 당근 중시, 네트워크 중시, \u0026lsquo;아마도\u0026rsquo;와 같은 모호함 인정, 현실적 판단인지 따지기, 예술가처럼 생각하기, 실수로부터의 학습 환영, 무제한적 비판 허용\n144p 이처럼 창을 얻기 위해서는 마음이 열려 있어야 한다. 우리는 어떤 결정을 내리면 자신의 생각이 틀릴 수도 있다는 생각에에 대해 개방적으로 되기 어렵다. 자신의 결정의 근거를 부정하는 모든 사실에 대해 마음을 닫기 쉽다. 그러나 창을 얻기 위해서는 다른 사람의 충고와 비판에 열려 있어야 한다.\n145p 소설가 베르나르 베르베르 \u0026lsquo;풍부하고 다양한 호기심은 타고 나는 것이지만, 그 이후에는 끊임없이 정보와 지식을 습득하는 노력이 필요합니다. 나는 날마다 배웁니다. 뭔가 새로운 것을 하지 않은 날에는 \u0026lsquo;시간을 잃어버렸다\u0026rsquo;고 여깁니다.\n161p 아마존 베조스의 선택 기준 Regret minimization framework 자신이 여든 살이 되었을 때를 가정해서 인생을 뒤돌아 보았을 때 후회할 일을 가장 줄이는 방법을 생각.\n164p 큰 생각을 하려면 자신을 색다른 경험에 수없이 노출시켜보라.\n164p 무용가 트와일라 타프는 사전에서 단어를 찾을 때, 그 단어 바로 앞, 뒷 단어도 함께 읽는 다고. 다음 번에 좋은 아이디어가 어디에서 올지 모르기 때문에. 한 번에 성격이 다른 여러 작품을 동시에 하고, 한 작품이 끝나면 그와 전혀 성격이 다른 작품에 도전하는 것도 창조성을 유지하는 그녀만의 노하우\n165p 우뇌형 인간의 5가지 조건. 다니엘 핑크 1. 디자인이란 언어를 익히라. 2. 스토리를 만들라 3. 큰 그림으로 생각하라 4. 공감하라 5. Play하라168p미국 속담 에 \u0026lsquo;평소 알고 있던 악마가 낫다\u0026rsquo;. 그만큼 사람들은 변화를 싫어하는 보수적 본성이 있다.\n174p 지식 e 시즌 4. 경로 의존성(Path Dependency) 한 번 일정한 경로에 의존하기 시작하면 나중에 그 경로가 비효율적이라는 것을 알고도 여전히 그 경로를 벗어나지 못한다는 사고의 관습\n190p 실패한 사람이 무엇을 해야 할 지 생각하지 않으면, 실패를 반복할 수 밖에 없다. 실패의 원인과 과정을 깊이 있게 생각하지 않으면, 실패는 실패의 어머니일 뿐이다. 실패는 도전과 발전을 위해 그 원잉늘 분석하고 거기서 창조적인 아이디어를 도출해낼 때, 비로소 가치가 있는 것이다. 부주의아 오판으로 똑같은 실수를 연발하는 것은 절대 용서받을 수 없는 실패다.\n195p 창은 혼을 노력과 근성으로 치환하는 과정이며 매일 새로워지는 일이고 익숙한 것과의 싸움이다. 어느 날 갑자기 찾아오는 것이 아니라 노력하고 도전하는 하루하루가 쌓여야 비로소 발현되는 것이 창이다.\n239p 호리바 마사오 \u0026lt;남의 말을 듣기 마라\u0026gt; 나와 같이 일하는 사람은 나와 다른 생각을 갖고 있어야만 존재 가치가 있는 법이다. 나와 똑같은 생각을 가지고 있다면 차라리 그 월급을 내게 달라\n244p 조직 내의 진정한 소통은 위에서 아래로 흐르는 탑다운의 일방적 방식으로는 결코 이룰 수 없다. 진정한 소통은 아래에서 위로, 오른쪽에서 왼쪽으로 360도 어느 쪽에서든 자유롭게 흐르는 것이다. 톱다운 커뮤니케이션은 조직 전체를 톱, 한 사람의 능력 안에 머물게 한다. 그러나 360도 커뮤니케이션은 구성원 모두가 아이디어와 능력을 발휘할 수 있게 함으로써 조직 역량에 한계가 없어진다.\n245p 가와시마 기요시 혼다 전 사장 최근 2~3년간 내가 말한 사항들이 사내에서 8할이나 통과됐다. 6할이 넘으면 원맨 경영의 폐해가 나타나는 위험신호라고 하는데, 그렇다면 지금 혼다가 위험하다는 얘기가 아닌가?\n246p 지난 20년간 조사한 수백 명의 관리자 중 70%는 보스의 일이 실패하리라는 것을 알면서도 피드백이나 충고를 하지 않은 것으로 나탔다. 직원이 경영자에게 문제를 제기할 정도면 가볍게 하는 말이 결코 아닐 것이기 때문이다. 물이 흐르지 못하면 고여서 썩기 마련이듯, 소통이 원할하지 못한 조직은 결국 문제가 발생하기 마련이다. 이것이 경영자가 직원들이 자유롭게 말할 수 있는 환경과 분위기를 조성해야 하는 이유다. 직원 또한 소신껏 자신의 의견을 개진해야 하는 이유다.\n252p 포스코 정준양 회장 리더는 VIP가 되어야 한다. 리더라면 Vision을 제시할 수 있어야 하고, Insight 통찰력과 철학 Philosophy를 갖고 있어야 한다고 주장했다.\n254p 1977년부터 1997년 사이에 태어난 N세대의 특징은 - 선택의 자유를 최고의 가치로 여기고 - 협업에 익숙하며 - 사실 여부를 늘 검증하려고 하고 - 재미와 스피드를 추구한다.\n258p 사일로(Silo) 바이오기업 몬산토 휴 그랜트 사장 무엇보다 연구 인력과 경영 관리 파트의 직원들이 함께 모여 일을 하기 시작했어요. 많은 기술 중심 회사들은 연구 인력과 경영 인력이 따로 근무하고, 별로 교류하지 않습니다. 그리고 위계 서열이 뚜렷하죠(경영 관리 인력이 주도권을 잡는다는 의미)\n269p SAS 좋은 복지 프로그램을 제공하면 직원들 스스로 회사를 다니는 일에 가치를 느끼고 만족해가기 때문이에요. 회사가 직원을 만족시키면 직원들은 좋은 제품을 개발해 외부 소비자를 만족시킨다. 고객을 행복하게 하려면 고객과 만나는 쌔스의 직원들이 행복해야 합니다.\n271p 직원이 행복해야 고객이 행복할 수 있다는 점만은 어떤 조직에나 통용된다는 점이다. 직원이 행복하지 않은데, 어떻게 동기를 부여받을 거이며, 어떻게 스스로 열심히 일해 좋은 제품과 서비스를 창출할 것인가? 조직의 통은 조직원들의 만족과 행복을 끌어내고, 이것은 다시 고객의 만족과 행복으로 이어진다. 만족과 행복은 끊임없이 확대재생산되는 것이다.\n273p 그렇다면 어떻게 해야 조직원이 위에서 내려오는 과업에 대해서도 마치 내발적 동기에 의해 하는 일처럼 스스로 신이 나서 열심히 하게 만들 수 있을가? 이와 관련해 에드워드 데시 교수를 비롯한 자기 결정성 이론 심리학자들이 개발한 개념이 내재화 Internalization이다. 즉 외부 요인에 의해 자극되거나 통제되는 행동의 경우에도 조직이 인간의 3가지 기본적 욕구를 충복만이 환경을 구축해 지원할 경우, 사람들은 일을 스스로의 것으로 내재화하고 통홥하게 된다는 것이다.275p데시 교수는 일견 재미없는 일일지라도 그것을 왜 해야 하는 지 근본적인 이유를 제시하고, 그 일에 대한 상대방의 관점과 느낌을 존중해주며, 스스로 선택하는 경험을 많이 할 수 있게 하고, 일에 대한 압력을 최소화하라고 조언한다.\n277p 20세기 초반 이후로 관리자들의 임무란 \u0026lsquo;어떻게 하면 웬만한 실력의 기술자들을 데려와서 같은 일을 빠르고 정확히 반복하게 만들까\u0026quot;였죠. 기업의 경영 구조 자체가 혁신을 생상하도록 설계된 것이 아니라 같은 일을 반복하도록 설계돼 있기 때문입니다.\n278p 리더의 역할은 직원 저마다가 가진 재능과 지식을 효율적으로 한데 모으는 것이지, 그들이 무작정 일을 더 열심히 하도록 만드는 게 아닙니다. 똑똑한 사람들이 일을 많이 하도록 하는 게 결코 중요한 문제가 아닌 거죠.\n279p 피터 센게 교수 내가 보기에 아무도 도발하지 않는 조직은 가장 위험한 조직입니다. 깊은 곳에 문제점이 있는데도 자칫 계속 문제를 썩힐 수 도 있으니까요. 건강한 조직은 서로 속을 터놓고 애기하기 때문에 문제를 실시간으로 파악하고 해결할 수 있습니다. \u0026lsquo;내가 이런 말을 해서 일자리를 잃으면 어떻게 하지?\u0026rsquo;, \u0026lsquo;이 얘기를 했는데 누군가 나를 비웃으면?\u0026rsquo; 이라는 걱정들로 가득 찬 조직은 희망이 없는 조직이죠. 겉으로는 통제가 잘 되는 것처럼 보이기 때문에 CEO를 흐뭇하게 만들 수도 있지만, 수면 아래엔 문제점들이 그득할 것입니다. 센게 교수에 따르면 두려움으로 경영되는 조직은 방어직 사고에 의해 억압된 조직이라고 표현할 수 있다. 이런 조직 속에선 모든 사람들이 항상 다른 사람에게 \u0026lsquo;내가 그 문제에 대한 답을 갖고 있다\u0026rsquo;는 확신을 주기 위해 노력한다. 그렇기 때문에 어떤 상황에서도 자심감 찬 모습만을 보이기 위해 분투한다. 뿐만 아니라 자기 자신이나 다른 사람을 \u0026lsquo;부끄럽게 만드는\u0026rsquo; 이슈들을 제기하는 것을 매우 꺼리게 된다. 중요한 이슈이긴 하지만 어렵거나 당황스러운 주제에 대해 얘기하는 것을 피하는 것이다. 이런 폐해를 없애기 위해서는 모든 구성원이 비전을 공유하고, 같이 머리를 맞대=고, 함께 살아남기 위해 노력한다는 정신을 심어야 한다는 것이 그의 주장이다.\n282p Gore사 상사나 부하가 없는 완전한 수평 조직이어서 모두가 동료(Associate)로 불리운다. 빌 고어는 더글러스 맥그리거 Douglas McGregors의 Y이론에 대한 믿음을 바탕으로 독특한 조직을 만들었다. Y이론이란 성선설로 인간은 오락이나 휴식뿐 아니라 자존과 헌신에 대해서도 본성적으로 욕구가 있으므로, 자발적으로 일할 마음을 갖게 하면 능력의 극대화가 가능하다는 분석이다.\n288p 리더의 책무는 매일 회사를 빠져나가는 그 90%의 중요 자산이 내일 다시 회사로 돌아와서 재미있게 일하도록 하는 것이다.\n","date":"2014-09-24T14:26:24+09:00","permalink":"https://cychong47.github.io/post/2014/caeg-hon-cang-tong/","summary":"\u003cp\u003e혼창통by 이지훈\u003c/p\u003e\n\u003ch3 id=\"8p\"\u003e8p\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e혼 : 가슴 벅차게 하는 비전이 사람을 움직인다.\u003cbr\u003e\n창 : 끊임없이 \u0026ldquo;왜\u0026quot;라고 물어라, 그러면 열린다.\n통 : 만나라, 또 만나라. 들어라 잘 들어라.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"16p\"\u003e16p\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003eIBM, P\u0026amp;G, Cisco, CEMEX 이 기없들의 공통점은 무엇일까? 그렇다 공룡처럼 몸집이 큰 기업들이다. 공룡인데도 민첩하다. 한가지 공통점은 회사 전체가 보다 큰 가치, 가슴을 울렁이게 하는 원대한 비전을 공유한다는 사실이다. 하버드경영대학원의 로자베스모스 캔터 교수(Rosabeth Moss Kanter) \u0026ldquo;모든 직원이 보다 큰 가치를 공유하게 되면 일선에서 어떤 문제가 부딛쳐도, 혹은 본사로부터 아무리 떨어진 곳에서 일하더라도 자발적으로 문제의 해결을 주도하게 된다\u0026rdquo;\u003c/p\u003e","title":"(책) 혼. 창. 통."},{"content":"VirtualBox에 DPDK 설치하기 참고\nVirtualBox 설치하기 통상적인 절차대로 VirtualBox를 설치하고, Ubuntu 14.04 LTS 설치한다. DPDK는 32bit와 64bit를 모두 지원하지만 64비트를 사용하는 것이 좋다. Application에 따라 많은 양의 Memory를 사용할 수도 있으므로.\nNIC 카드 추가 VirtualBox가 지원하는 NIC에 Intel 82540EM과 82545EM이 있다. 둘 다 DPDK에서 지원하는 1G NIC이다. 이 중에서 82545EM 카드를 2개 추가한다.\nVirtualBox의 Guest OS를 종료시킨 상태에서 환경 설정에서 Network \u0026gt; Adapter 항목에서 Adapter 2, Adapter 3를 활성화시킨다.\n그 결과 총 3개의 NIC이 설치되었다.\n그리고 interface 속성을 Bridged Adapter 형태로 설정한다.(Bridged Adapter는 NAT 없이 외부(Host OS를 통해)와 통신할 수 있는 방식이다. NAT를 사용하지 않으므로 Bridged Adapter에는 외부와 직접 통신할 수 있도록 고유한 IP를 할당하거나, 외부에서 IP 할당을 해야 한다)\nSSE 사용하기 근래 버전의 DPDK는 SSE가 필수다(hash 라이브러리등에서) SSE를 사용하려면 아래와 같이 설정한다. 괄호 안의 Ubuntu 14.04는 VM 이름이다.\nmini-2011:~ cychong$ VBoxManage setextradata \u0026quot;Ubuntu 14.04\u0026quot; VBoxInternal/CPUM/SSE4.1 1 mini-2011:~ cychong$ VBoxManage setextradata \u0026quot;Ubuntu 14.04\u0026quot; VBoxInternal/CPUM/SSE4.2 1 DPDK 설치 git clone git://dpdk.org/dpdk DPDK 빌드 export RTE_SDK=/home/cychong/dpdk export RTE_ARCH=x86_64 export RTE_TARGET=x86_64-native-linuxapp-gcc make config T=x86_64-native-linuxapp-gcc l2fwd 실행하기 Build cychong@ubuntu:~/dpdk/examples/l2fwd$ make CC main.o LD l2fwd INSTALL-APP l2fwd INSTALL-MAP l2fwd.map igb_uio 커널 모듈 설치 DPDK application은 User-level application으로 PCI를 통해 연결된 NIC에 접근하기 위해 User-Space IO(1, 2 참고)를 이용하므로 커널 모듈을 설치해야 한다.\ncychong@ubuntu:~/dpdk$ sudo insmod /lib/modules/4.13.0-32-generic/kernel/drivers/uio/uio.ko cychong@ubuntu:~/dpdk$ sudo insmod x86_64-native-linuxapp-gcc/kmod/igb_uio.ko lspci 명령을 보면 Virtualbox에는 총 3개의 NIC가 존재하고, 이중 PCI ID 00:03.0은 Host OS와의 통신에 사용되는 Adapter 1이므로 이를 제외한 나머지 2개 00:08.0과 00:09.0을 DPDK용으로 사용한다.\ncychong@ubuntu:~$ lspci |grep Intel |grep 8254 00:03.0 Ethernet controller: Intel Corporation 82540EM Gigabit Ethernet Controller (rev 02) 00:08.0 Ethernet controller: Intel Corporation 82545EM Gigabit Ethernet Controller (Copper) (rev 02) 00:09.0 Ethernet controller: Intel Corporation 82545EM Gigabit Ethernet Controller (Copper) (rev 02) Kernel에 포함된 device driver igb에 연결되어 있는 어댑터를 뺏어온다.\ncychong@ubuntu:~/dpdk$ sudo ./tools/dpdk_nic_bind.py --status Network devices using DPDK-compatible driver ============================================ \u0026lt;none\u0026gt; Network devices using kernel driver =================================== 0000:00:03.0 '82540EM Gigabit Ethernet Controller' if=eth0 drv=e1000 unused=igb_uio *Active* 0000:00:08.0 '82545EM Gigabit Ethernet Controller (Copper)' if=eth1 drv=e1000 unused=igb_uio 0000:00:09.0 '82545EM Gigabit Ethernet Controller (Copper)' if=eth2 drv=e1000 unused=igb_uio Other network devices ===================== \u0026lt;none\u0026gt; 위에서 eth1, eth2를 DPDK용으로 사용하기 위해 아래와 같이 우선 unbind하고 igb_uio에 bind한다.\ncychong@ubuntu:~/dpdk$ sudo ./tools/dpdk_nic_bind.py -u 0000:00:08.0 cychong@ubuntu:~/dpdk$ sudo ./tools/dpdk_nic_bind.py -u 0000:00:09.0 cychong@ubuntu:~/dpdk$ sudo ./tools/dpdk_nic_bind.py --bind=igb_uio 0000:00:08.0 cychong@ubuntu:~/dpdk$ sudo ./tools/dpdk_nic_bind.py --bind=igb_uio 0000:00:09.0 L2fwd 실행하기 cychong@ubuntu:~/dpdk$sudo examples/l2fwd/build/l2fwd -c 0x2 --no-huge -w 00:0:08.0 -w 00:0:09.0 -n1 -- -q 8 -p 3 cychong@ubuntu:~/dpdk$ sudo examples/l2fwd/build/l2fwd -c 0x2 --no-huge -w 00:0:08.0 -w 00:0:09.0 -n1 -- -q 8 -p 3 EAL: Detected lcore 0 as core 0 on socket 0 EAL: Detected lcore 1 as core 1 on socket 0 EAL: Support maximum 64 logical core(s) by configuration. EAL: Detected 2 lcore(s) EAL: cannot open VFIO container, error 2 (No such file or directory) EAL: VFIO support could not be initialized EAL: Setting up memory... EAL: TSC frequency is ~2321680 KHz EAL: WARNING: cpu flags constant_tsc=yes nonstop_tsc=no -\u0026gt; using unreliable clock cycles ! EAL: WARNING: Master core has no memory on local socket! EAL: Master core 1 is ready (tid=ef771840) EAL: PCI device 0000:00:08.0 on NUMA socket -1 EAL: probe driver: 8086:100f rte_em_pmd EAL: PCI memory mapped at 0x7fd5ef71b000 PMD: eth_em_dev_init(): port_id 0 vendorID=0x8086 deviceID=0x100f EAL: PCI device 0000:00:09.0 on NUMA socket -1 EAL: probe driver: 8086:100f rte_em_pmd EAL: PCI memory mapped at 0x7fd5ef6fb000 PMD: eth_em_dev_init(): port_id 1 vendorID=0x8086 deviceID=0x100f Lcore 1: RX port 0 Lcore 1: RX port 1 Initializing port 0... PMD: eth_em_rx_queue_setup(): sw_ring=0x7fd5eb358c80 hw_ring=0x7fd5ed71eb00 dma_addr=0x7fd5ed71eb00 PMD: eth_em_tx_queue_setup(): sw_ring=0x7fd5eb356b80 hw_ring=0x7fd5ed72eb00 dma_addr=0x7fd5ed72eb00 PMD: eth_em_start(): \u0026lt;\u0026lt; done: Port 0, MAC address: 08:00:27:41:5F:94 Initializing port 1... PMD: eth_em_rx_queue_setup(): sw_ring=0x7fd5eb356580 hw_ring=0x7fd5ed73eb00 dma_addr=0x7fd5ed73eb00 PMD: eth_em_tx_queue_setup(): sw_ring=0x7fd5eb354480 hw_ring=0x7fd5ed74eb00 dma_addr=0x7fd5ed74eb00 PMD: eth_em_start(): \u0026lt;\u0026lt; done: Port 1, MAC address: 08:00:27:2B:31:74 Checking link statusdone Port 0 Link Up - speed 1000 Mbps - full-duplex Port 1 Link Up - speed 1000 Mbps - full-duplex L2FWD: entering main loop on lcore 1 L2FWD: -- lcoreid=1 portid=0 L2FWD: -- lcoreid=1 portid=1 Port statistics ==================================== Statistics for port 0 ------------------------------ Packets sent: 0 Packets received: 0 Packets dropped: 0 Statistics for port 1 ------------------------------ Packets sent: 0 Packets received: 0 Packets dropped: 0 Aggregate statistics =============================== Total packets sent: 0 Total packets received: 0 Total packets dropped: 0 ==================================================== 다음에는 패킷 송수신 관련 기능을 실제로 시험해 본다. DPDK와 같은 user-mode IO를 사용하는 경우의 핵심인 PMD(Poll Mode Driver)를 이용해서 외부에서 수신되는 패킷을 처리하는 것과, DPDK 1.7에 추가된 Pcap 파일 혹은 ring을 이용해서 패킷을 받는 경우를 알아본다.\n참고 ","date":"2014-09-23T15:37:21+09:00","permalink":"https://cychong47.github.io/post/2014/dpdk-on-virtualbox/","summary":"\u003ch1 id=\"virtualbox에-dpdk-설치하기\"\u003eVirtualBox에 DPDK 설치하기\u003c/h1\u003e\n\u003cp\u003e\u003ca href=\"http://plvision.eu/blog/deploying-intel-dpdk-in-oracle-virtualbox/#\"\u003e참고\u003c/a\u003e\u003c/p\u003e\n\u003ch1 id=\"virtualbox-설치하기\"\u003eVirtualBox 설치하기\u003c/h1\u003e\n\u003cp\u003e통상적인 절차대로 VirtualBox를 설치하고, Ubuntu 14.04 LTS 설치한다. DPDK는 32bit와 64bit를 모두 지원하지만 64비트를 사용하는 것이 좋다. Application에 따라 많은 양의 Memory를 사용할 수도 있으므로.\u003c/p\u003e\n\u003ch2 id=\"nic-카드-추가\"\u003eNIC 카드 추가\u003c/h2\u003e\n\u003cp\u003eVirtualBox가 지원하는 NIC에 Intel 82540EM과 82545EM이 있다. 둘 다 DPDK에서 지원하는 1G NIC이다. 이 중에서 82545EM 카드를 2개 추가한다.\u003c/p\u003e\n\u003cp\u003eVirtualBox의 Guest OS를 종료시킨 상태에서 환경 설정에서 \u003ccode\u003eNetwork \u0026gt; Adapter\u003c/code\u003e 항목에서 Adapter 2, Adapter 3를 활성화시킨다.\u003c/p\u003e\n\u003cp\u003e그 결과 총 3개의 NIC이 설치되었다.\u003c/p\u003e","title":"DPDK on VirtualBox"},{"content":"p24 만약 직원이 자신이 하려는 도전에 따르는 책임을 받아들이려고 한다면, 많은 조직이 책임을 더 부여하려고 할 것이다.\np32 Rolf Dobelli 스마트한 생각들, 스마트한 선택들 \u0026lsquo;확증 편향\u0026rsquo;. 사람은 자신이 확실하는 일에 대해 옳다고 증명해주는 증거들만 철석같이 믿지요.\n\u0026lsquo;사회적 검증\u0026rsquo;도 대단히 안 좋고 위험한 행동 오류.\n권력이나 권위 있는 사람들의 말을 무조건 믿는 \u0026lsquo;권위자 편향\u0026rsquo; 또한 위험. 전 세계적으로 경제학자 수는 100만 명이 넘지만 단 1명도 2008년 금융 위기를 정확히 예측하지 못했다. 당장 눈앞에 펼쳐진 자료들을 과신하는 \u0026lsquo;가용성 편형\u0026rsquo;\np34 확증 편향에 빠지는 것은 경계해야 합니다. 몇 차례 옳은 결정을 내렸다고 해서 차츰 자기 결정을 과신하는 확증 편향에 빠지기 쉽지요. 큰 권력을 가진 리더일수록 직언을 하는 참모가 반드시 2~3명은 있어야 합니다. 결정을 내리기 전 이 사람들에게 의견을 묻고 일부러 반대 의견을 내달라고 하십시오. CEO들은 사실 매우 외롭습니다. 누군가 자기 의견에 반대해주길 바라지요. 자기 관점과 다른 관점에서 의견을 듣고 싶어합니다.\np35 나쁜 리더의 가장 흔한 공통점은 \u0026lsquo;사회적 검증\u0026rsquo; 오류를 자주 범한다는 것입니다. 경쟁사의 특정 제품이 성공을 거두면 나쁜 리더들은 자기 부하들에게 \u0026lsquo;왜 저런 걸 못 만드느냐\u0026rsquo;고 질책합니다. 그 원인이 자신한테 있을지 도 모르는데. 그러다가 결국 복제 제품을 내 놓는 겁니다. 이는 곧 업계에서 한 걸음 뒤처지는 것을 의미하지요.\n또 다른 공통점은 나쁜 리더 대부분이 마이크로 매니저라는 점입니다. 회사의 사소한 일이나 직원 개개인의 일거수일투족까지 관리 감독하려 들지요. 그러나 돌이켜보면 한 회사가 성공을 거두려면 올바른 산업에 진출했는가가 더 결정적입니다. 즉 당신이 노를 잘 젓는것도 중요하지만, 그보다 애당초 좋은 배에 타는 게 훨씬 낫다는 겁니다.\np86 Sam Horn 텅 후(Tongue-Fu) 의 핵심은 한마디로 요약하자면 \u0026lsquo;선택\u0026rsquo;입니다. 남들의 도발에 어떻게 대응할지, 무시할 지 등. \u0026hellip;\n선택 1 \u0026ldquo;상대를 바꾼다\u0026rdquo; 불가능 선택 2 \u0026ldquo;상황을 바꾼다\u0026rdquo; 요청, 부탁 등\n선택 3 \u0026quot; 나를 바꾼다\u0026quot; \u0026lsquo;세상을 바꿀 수 없으니 내가 바꿔어야겠다\u0026quot;고 마음먹고 행동 패턴을 바꾸는 것\np89 예를 들어 업무가 너무 많아 야근이 잦은 게 문제라면 지난 주 당신의 출퇴근 및 업무 시간을 정확히 적어둔 차트를 보여주세요. 상사가 시킨 일을 처리하는 데 정확히 몇 시간씩 걸렸는지 보여주세요.\n절대로 \u0026lsquo;일이 너무 많아요\u0026rsquo;하고 투정부리지 마세요.\np90 Howard Stevenson 명예 교수 부하를 질책할 때는 \u0026lsquo;~했어야지\u0026rsquo;라는 표현을 피하세요. \u0026lsquo;지각할 것 같으면 전화했어야지!\u0026rsquo; 이런 문장은 말의 톤은 상대에 대한 존중이 없고 짜증을 부릅니다. 부하는 자기가 잘못했어요 \u0026lsquo;이미 지나간 일을 지금 와서 어쩌라는 거야\u0026rsquo;하며 반감을 갖지요. \u0026lsquo;했어야지\u0026rsquo;대신 미래 지향적 단어 \u0026lsquo;다음부터는\u0026lsquo;을 쓰도록 하세요. 이 한마디로 상사는 비판자에서 조언자로 바뀝니다.\np97 전환점이란 지금까지 달려오던 것과 전혀 다른 쪽으로 완전히 방향을 트는 것을 말합니다. 단지 살짝 변화만 주는 차원이 아니에요. 중요한 것은 그 전환점에 우리의 잠재력을 이끌어낼 엄청한 힘이 있다는 겁니다. 미셸은 회사가 조직을 개편하고 자신에게 어떤 기회를 주는지에 따라 행동하기로 결정했어요. 그러나 그냥 좋은 방향으로 풀리기만 기다렸지요. 저는 그냥 기다리지 말고 주도적으로 회사에 자기 목소리를 내야 한다고 조언했어요. 이런 게 바로 인생의 전환점입니다.\np98 경주마는 단순히 골인 지점만 보고 달립니다. 반면에 야생마는 가야 할 곳이 어딘지 피할 곳이 어딘지 끊임없이 생각하고 때로는 천천히 달리기도 하지요. 경주마는 달리기 위해 생각을 멈추지만 야생마는 생각하기 위해 달기리를 멈춥니다.\np126 Daniel Pink 고객 스스로도 모르는 문제를 발견하기 위해서는 고객에게 적절한 질문을 던저야 한다는 것이다. 그는 과거에 최고의 세일즈맨은 고객의 질문에 대답하는 데 능통했다면, 요즘 최고의 세일즈맨은 고객에게 좋은 질문을 하는 사람이라고 한다. 좋은 질문을 하려면, 질문 리스트를 만든 뒤 각 질문의 장단점을 생각하며 질문의 우선순위를 정하는 연습을 하라고 그는 조언했다.\np148 한국도 조직 위계질서가 세계에서 아주 강한 곳 중 하나라고 생각합니다. 사람들이 창의적인 생각을 자유롭게 표현하고 실현할 기회가 주어지지 않은 상태에서 창의적 인재가 나오기 어려울 것이라고 생각합니다.\np250 Olivia Lum, Hyflux CEO 우리는 개별 연구원들이 시장 가치가 없는 연구 분야에 매몰되지 않도록 물산업 시장 전문가들을 연구에 투입합니다. 연구원들에게 시장이 필요로 하는 상품이 무엇인지 교육시키고 분야 간 소통을 원활하게 해 통합적 사고를 하도록 합니다.\np253 어떤 꿈이든 지 꿈을 가지셍. 꿈을 갖고 노력하다보면 기회가 찾아옵니다. 기회는 당신이 만드는 것입니다. 그리고 그 기회를 잡으세요. 꿈이 없으면 당신의 모든 것이 끝납니다. 꿈꾸는 것을 멈추지 마세요.\np262 자오위핑, 백가강단(CCTV) 업무나 시장 상황이 비교적 단순한 기업에서는 조조의 방식이 성공하기 쉽습니다. 반면 업무가 복잡하고 변화가 급할수록 유비형 방식이 성공하기 쉽습니다. 간단하고 단순한 업계는 통제해야만 잘 돌아가고, 복잡한 쪽은 전문가들이 능력을 잘 발휘할 수 있도록 지지해야 조직이 잘 돌아가게 마련이니가요. 지금까지는 조조형 리더가 많았지만, 앞으로는 기업 문화가 바뀌면서 유비의 방식이 더 중요해질 것입니다.\n이상작 중간 관리자로는 제갈량, 이상적 일선 직원으로는 조자룡을 들었다. 제갈량은 만사 일처리가 착실하고 디테일을 잘보면서도 큰 그림을 놓치지 않았습니다. 위로는 보스의 신임을 얻고 아래로는 병사들의 존경을 받았지요. 조자룡은 능력이 뛰어나고 충성심이 강했습니다.\np265 구성원들의 능력에 따라 각기 다른 비전을 제시해야 합니다. 비교적 능력이 약하고 평범한 집단에는 편안함과 만족을 보장해주면 족합니다. 하지만 능력이 뛰어나고 자존감이 강한 구성원이 모인 집단에서는 그런 만족감만으로는 직원들을 붙들어둘 수 없습니다. 이상이나 이념, 가치관을 실현해줄 수 있어야 합니다. 이들이 자아를 실현하고 꿈을 이룰 수 있도록 비전을 줘야 합니다.\np277 John Rice GE 부회장 GE는 늘 배우는 문화를 가진 회사입니다. 오늘의 나는 작년의 나보다 더 나은 리더가 돼야 합니다. 또한 내년에는 올해보다 더 성장해야 하고요. 이는 실수에서 배우고, 새로운 나라와 문화, 시장, 제품에서 늘 배우려는 문화가 있어야만 가능합니다.\np278 뭔가 하나라도 남달리 잘하는 게 있는 사람인가입니다. \u0026hellip; 요즘 같은 세상에서 직장을 가지려면 처음엔 뭔가 하나라도 남들보다 잘하는 게 있어야 합니다. 일단 뭔가 하나에 강한 상태로 출발하고, 다른 일반적인 기술들은 승진을 해가면서 배우면 됩니다.\np322 Teresa Amabile 성과를 높이기 위한 가장 좋은 방법은 직원들에게 긍정적 기분을 만들어주는 것이다. 사람이 기뻐할 때 자신의 업무 환경에 대해 긍정적으로 인식하고, 자신의 업무에 강력한 동기 부여를 받을 때 가장 창의적이 된다는 것이다. 최고의 기분을 유지하는 하루를 만드는 방법은 매일 사소한 업무라도 의미 있는 작은 성공을 맛보게 해주는 것 입니다.\np326 인정을 받은 안 받는 일에서 성과를 내는 것 자체가 더 중요한 겁니다. 의미 있는 일을 하고 거기서 뭔가 진전을 이뤄낸다면 사람은 긍정적 감정을 갖게 됩니다. 동료와 사이가 좋아지고, 강력한 동기 부여가 됩니다. 게다가 뭔가 인정을 받기 위해선 업무에서 어떤 형태로든 작은 성공을 맛봐야 해요. 실제로 성과를 내지 않았는데 인정을 받는다면 직원은 매우 냉소적으로 바뀝니다.\np328 직원이 업무에게 진전하게 하려면 관리자는 어떻게 해야 할까? 첫째, 일단 명확한 목표를 심어준다. 둘째, 명확한 목표를 심은 뒤에는 자율성을 부여해야 한다. 사소한 일에 간섭하고 시시콜콜한 내용까지 지시하는 것은 최악이다. 심리적 안정감을 주는 기업 문화가 필요하다. 실패했다고 부하직원을 억누르고 비난하고 비판하고 처벌하는 행위를 멈춰야 한다.\n","date":"2014-09-21T12:21:48+09:00","permalink":"https://cychong47.github.io/post/2014/caeg-deo-inteobyu/","summary":"\u003ch3 id=\"p24\"\u003ep24\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e만약 직원이 자신이 하려는 도전에 따르는 책임을 받아들이려고 한다면, 많은 조직이 책임을 더 부여하려고 할 것이다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch3 id=\"p32-rolf-dobelli-스마트한-생각들-스마트한-선택들\"\u003ep32 Rolf Dobelli 스마트한 생각들, 스마트한 선택들\u003c/h3\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u0026lsquo;확증 편향\u0026rsquo;. 사람은 자신이 확실하는 일에 대해 옳다고 증명해주는 증거들만 철석같이 믿지요.\u003cbr\u003e\n\u0026lsquo;사회적 검증\u0026rsquo;도 대단히 안 좋고 위험한 행동 오류.\u003cbr\u003e\n권력이나 권위 있는 사람들의 말을 무조건 믿는 \u0026lsquo;권위자 편향\u0026rsquo; 또한 위험. 전 세계적으로 경제학자 수는 100만 명이 넘지만 단 1명도 2008년 금융 위기를 정확히 예측하지 못했다. \u003cbr\u003e\n당장 눈앞에 펼쳐진 자료들을 과신하는 \u0026lsquo;가용성 편형\u0026rsquo;\u003c/p\u003e","title":"(책) 더 인터뷰"},{"content":"김진애\np32 뒤를 돌아보면, \u0026ldquo;1년 동안 공부만 할 거야!\u0026ldquo;하고 결단하고 그 결단을 독하게 지켰던 체험을 통해 얻은 가장 큰 자산은 \u0026lsquo;독해야 할 때 독해질 수 있다;는 자신감이다. 이 자신감은 내 일생 내내 큰 자산이 되었다. \u0026lsquo;필요하다면 유혹을 끊어낼 수 있다. 잔가지들에 연연해하지 않을 수 있다. 내 온 자신을 던질 수 있다. 몰입할 수 있다\u0026rsquo;는 믿음은 중요하다. 한번 독해지기를 경험해보면 언제나 독해질 수 있는 것이다.\np77 무시당하는 느낌이 없어졌다. 조롱당하는 느낌, 모욕당하는 느낌도 없어졌다. 기대를 받는다는 느낌도 생겼다. \u0026ldquo;이거 해도 되나?\u0026rdquo; 자문하던 주저감이 줄어들었다. \u0026ldquo;이거 말해도 되나? 이런 거 물어봐도 되나?\u0026rdquo; 같은 자기검열도 사라졌다.\n\u0026hellip;\n사람 대접받는다는 느낌, 같은 사람으로 대할 수 있고 대해질 수 있다는 느낌이었다. 서로의 차이는 있지만 가능성은 누구에게나 열려 있고 역할은 누구에게나 주어질 수 있다는 분위기였다.\n새로 얻은 중요한 깨달음이 있다. \u0026lsquo;말해야 한다\u0026rsquo;는 것이다. 말하지 않으면 아는 것도 아는 게 아니며, 자신의 의견을 말해야 비로소 상대와 통할 수 있고, 말로 표현되어야 생각이 정제되고 발전되며, 말하는 행위 자체가 상대에 대한 존중이라는 분위기였다. 얼마나 큰 변화이랴. \u0026lsquo;말을 하면 상처만 커진다\u0026rsquo;는 생각 때문에 어릴 적에 입을 닫고 답답해했고, 자라면서는 \u0026lsquo;말하면 다친다. 말조심해야 한다\u0026rsquo;는 압박 때문에 갑갑했던 \u0026lsquo;말의 족쇄\u0026rsquo;가 드디어 풀렸다.\np113 그 파워는 바로 \u0026lsquo;통찰력\u0026rsquo;에서 나온다. 핵심 개념을 세우고 개념을 스토리로 전개하는 파워. 어떻게 90분 동안 이렇게 마음을 흔들어놓을 수 있나? 통찰력이란 그렇게 중요하다. 전체를 통찰하는 힘, 구조를 파악하는 힘, 핵심을 파악하는 힘, 개념을 세우는 힘, 전체와 부분의 연관성을 이해하는 힘, 이런 지적 \u0026lsquo;통찰력\u0026rsquo;은 우리 모두 지향해야 할 파워다.\np141 창업하면서 꼭 각오해야 할 것이 있다. \u0026lsquo;세상은 별로 당신에게 관심이 없다\u0026rsquo;는 냉정한 사실이다. 다른 사람들의 성공적 창업 스토리를 주목해주는 것은 TV나 강연회에서나 일어나는 일이다. 현실에서는 \u0026lsquo;당신은 대체재로 보일 것이다. 당신은 도구로 보일 것이다. 당신은 소모재로 보일 것이다\u0026rsquo;라는 엄연한 사실이 기다린다. 이 냉정한 현실을 냉철하게 받아들이자. 그리고 실망과 좌절과 손해와 분노를 딛고 살아남자. 또 새로운 가능성을 모색해보자.\np158 하기 싫어도 해야 하는 일을 할 때, 나는 배울 것 한 가지를 아예 미리 정해놓는다. 사실 아무리 하기 싫더라도 배울 것 하나 없는 일은 이 세상에 없다. 게다가 아무리 하기 싫은 일이라도 열심히 하다 보면 일 자체에 빠지게 되기도 한다. 인간의 본능 중 하나인 성실성이 작동하는 것이다. 여기에 긍정적인 동기 한 가지만 곁들이면 속으로 회심의 미소 하나 지을 게 생긴다.\np186 언어의 기본은 듣기가 먼저인 것이다. 언어의 순수함, 아름다움, 세련됨을 즐기게 되고 또한 조악하고 천박하고 비논리적인 언어를 분별하게 되는 이점과 함께, 많이 들을 수록 이야기하는 능력도 따라서 자란다. 사람들은 누구나 이야기를 잘하고 싶어 한다. 이야기를 잘하려면 먼저 잘 듣자.\np229 가장 근사한 팀이란, 위아래 가리지 않고, 왜 이 일을 하는지에 대한 가치를 공유하고, 일하자고 만났으면 5분 만에 일로 돌입하고, 서로의 시간을 아껴주고, 서로의 특성을 독려하고, 서로의 능력을 키워주며, 소모적인 실적 경쟁이 아니라 일의 대승적인 퍼포먼스를 위하여 생산적인 경쟁 협력을 하는 팀이다. 그런 팀워크가 가동된다면 얼마나 좋을까\n좋은 팀워크에 필요한 것은 수도 없이 많다. 그중 팀장의 리더십 역할에 대해서는 아무리 강조해도 지나치지 않다. 팀에 기원을 불어넣어주고 힘을 키워주는 것이 팀장의 역할이다. 그렇다고 팀워크의 리더십에 하나의 정답만이 있는 것은 아니다. 때로는 카리스마가 필요하고, 때로는 헌신이 필요하며, 당근과 채직을 적절히 구사해야 하기도 하고, 왜 이 일을 하는지에 대한 가치를 공유할 수 있도록 해야 하며, 밀고 당기는 리듬도 필요하고, 에너지의 높낮이를 조절하는 호흡도 필요하다.\np243 거대한 수레바퀴가 돌아가는 이런 사회에서 자신만은 살아남을 수 있다고 생각하는가? 자신만은 살아남아야 한다고 생각하는가? 이렇게 생각하기 시작하는 순간, 과잉 경쟁의 잔혹한 수레바쿠에 치이는 대가를 감수해야 할 것이다. 자본과 권력이란 워낙 잔혹하다. 당신이 아무리 우수하고 탁월하더라도 이용당하며, 시시때때로 밟히고, 어느 시점에는 배신을 당할 것이다. 그 자리에 연연할수록 잔혹한 수레바퀴 사이에 끼어서 으스러질 위험만 커진다. 조직의 논리 속에서 개인의 능력이란 아주 미미한 변수가 될 뿐이다.\np245 사회의 유연성을 높이는 과제는 별도로 하더라도, 우리 자신의 유연성을 높이는 것은 우리 자신이 해야 할 일이다. 당신의 유연성을 높여라. 다양한 옵션에 눈을 열어라. 한 분야에서 오랫동안 일을 하더라도 일하는 환경은 끊임없이 바뀌는 것이 정상이다. 일하는 프로젝트가 바귀고, 주제도 바뀌고, 직책도 바뀌고, 일하는 조직도 바뀐다. 특정한 일을 통해 그 어떤가를 배웠으면, 그 다음 단계를 생각하고, 관련되는 다른 일을 구상하라. 아직 변화를 실천으로 옮기지 못했다 하더라도 머릿속에 시나리오를 계속 만들어두라. 실천으로 옮길 \u0026lsquo;때\u0026rsquo;는 반드시 올 것이다.\n매너리즘에 빠지기 전에 떠나자. \u0026lsquo;숙련된 조교\u0026rsquo;라는 말이 있다. 일에 숙달되는 것은 좋은 일이지만 계속해서 숙달된 조교만 하다가는 매너리즘에 빠지고야 만다. 지금 하는 일에 숙달되었다고 생각되면 이제 떠날 때가 되었고 다른 일을 찾을 때가 되었다. 변화란 항상 위험을 동반하는지라, 주변에서 말리고 가족들이 말리고 또 주저하는 자신을 느끼게 될 것이다. 그러나 위험이 다가오기 전에 주체적인 선택을 하는 것일 뿐이다. 잘리기 전에 먼저 떠나자. 정체하기 전에 먼저 새 길을 찾자. 떠나기를 강요받기 전에 자신이 선택해서 새로운 길을 찾아 나서는 것이 길게 보면 훨씬 더 좋다.\np249 바로 지금, 지금과는 다른 삶의 옵션을 준비해두자. 어차피 우리 인생은 제2, 제3의 인생을 살아야 할 만큼 길기도 하다. 5년 후에 어디에서 어떠한 일을 할 것인가? 10년 후에는 또 어디에서 어떠한 역할을 할 것인가? 오직 한 가지 일만 들이파는 것으로써만 인생이 완성될 수는 없다. 주제는 하나이되 수없는 변주를 해나가야 자신의 음악이 완성되는 것이다.\n관건은 타이밍이다. 언제 어떻게 새로운 일감을 찾아서 자신의 일로 만드느냐 하는 것이다. 인생의 티이밍은 참으로 중요하다. 평생을 생각하고 타이밍을 고민해보자.\np250 공부하고 일하는 방식은 변하지 않는다. 말하자면, 고기 잡는 방식은 크게 바뀌지 않는다. 다만 잡는 고기와 배 띄우는 바다가 달라지는 것뿐이다. 당신이 학교와 프로 생활에서 배우는 공부와 일하기 방식은 큰 흐름 속에서 하나의 단계일 뿐이다. 그 어느 자리에서 그 어느 일을 통해 잘 배우고 깨달음을 얻었다면, 이제 다음 과정을 생각해 보라. 새로운 도전과 모험을 향하여!\np256 어떻게 세종 시대, 정조 시대에는 그렇게 탁월한 인물들이 많이 나왔을까? 서구의 르네상스 시대에는 그렇게 근사한 인물들이 쏟아졌을가? 라는 화두다. \u0026hellip; 인물을 발탁하고 좋은 일들을 발굴하는 \u0026lsquo;리더\u0026rsquo;의 역할도 분명 클 것이다. 당시의 정치 리더들은 강력한 혁신 리더들어었으니 말이다. 그런데 아마 그 시대에 일어났음직한 수순은, \u0026lsquo;개인의 리더\u0026rsquo;에서 \u0026lsquo;그룹 리더십\u0026rsquo;으로 발전되었을 것 아닐까? 좋은 사람은 좋은 사람들을 끌어들이고, 인물은 인물을 알아본다. 탁워할 일은 시기와 질투의 대상이 아니라 더욱 탁월한 일들을 자극하게 되는 것이다. 사람들은 이런 선순환 구조에 더욱 자극을 받고 더욱 노력하고 모색했던 상태였을 것이다. 탁월한 공부생태계가 자연적으로 만들어졌던 행복한 상황이었을 것이다.\np258 우리가 리더를 인정하는 것은 어떤 경우에나 총괄 지휘가 필요하다는 것을 알기 때문이다. 우리가 리더의 리더십을 인정하는 것은 그 리더가 꼭 특출하거나 훌륭해서만은 아니다. 리더십이 흔들리면 플레이가 당장 깨질 위험이 높기 때문에 인정하는 것뿐이다. 리더란 잠시 잠깐 책임과 권한을 가지는 것일 뿐이다. 리더가 진정한 리더십을 똑독하게 고민한다면, 자신의 리더십으로 어떻게 그룹의 리더십을 끌어낼 수 있을까 고민해야 한다. 리더는 자신이 그 자리에 있는 이유는 바로 그 때문이고, 자신이 물러난 이후에도 사회의 리더십이 뿌리내리는 것의 중요성을 알아야 한다.\np268 21세기적으로 착하려면 도덕성만으로는 안된다. 마음만으로는 안 된다. 아주 영리해야 한다. 머리를 써야 하고, 시간을 들여 정보를 파악해야 하고, 거짓말을 분별해내야 하고, 왜 착한 소비가 결국 나와 우리를 위해 좋은 지 논리를 펼칠 수 있어야 한다. 그리고 그것을 개인의 착한 행위에 그치는 것이 아니라 동료와 친구와 이웃과 사회에 전파하는 설득력까지 가져야 한다.\np269 \u0026lsquo;장금아, 너의 선의를 믿는다. 그러나 선의를 가지고도 능력이 없으면 사람을 상하게 할 수 있다. 너는 할 수 있겠느냐?\u0026rsquo;\np270 세상은 항상 착한 사람, 착한 동기를 가진 사람을 속이려 들고 무시하려 든다. 성실함과 부지런한과 배려심을 악용하려 든다. \u0026hellip; 경제 감각은 필수다. 어떤 경우에나 돈 감각, 경영 감각, 산업 감각, 거시경제 감각을 갖고 있어야 설득력 있는 대안을 만들어낼 수 있다. 사회의 많은 대안들은 이익을 어떻게 만드느냐, 누구에게 이익이 가느냐, 누가 일할 수 있게 만드느냐, 어떻게 안정을 꾀하느냐에 대한 대안이 포함되어야 설득력을 가지며 그래야 통한다.\n","date":"2014-09-11T15:40:52+09:00","permalink":"https://cychong47.github.io/post/2014/caeg-wae-gongbuhaneunga/","summary":"\u003cp\u003e김진애\u003c/p\u003e\n\u003ch1 id=\"p32\"\u003ep32\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e뒤를 돌아보면, \u0026ldquo;1년 동안 공부만 할 거야!\u0026ldquo;하고 결단하고 그 결단을 독하게 지켰던 체험을 통해 얻은 가장 큰 자산은 \u0026lsquo;독해야 할 때 독해질 수 있다;는 자신감이다.  이 자신감은 내 일생 내내 큰 자산이 되었다. \u0026lsquo;필요하다면 유혹을 끊어낼 수 있다. 잔가지들에 연연해하지 않을 수 있다. 내 온 자신을 던질 수 있다. 몰입할 수 있다\u0026rsquo;는 믿음은 중요하다. 한번 독해지기를 경험해보면 언제나 독해질 수 있는 것이다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003ch1 id=\"p77\"\u003ep77\u003c/h1\u003e\n\u003cblockquote\u003e\n\u003cp\u003e무시당하는 느낌이 없어졌다. 조롱당하는 느낌, 모욕당하는 느낌도 없어졌다. 기대를 받는다는 느낌도 생겼다. \u0026ldquo;이거 해도 되나?\u0026rdquo; 자문하던 주저감이 줄어들었다. \u0026ldquo;이거 말해도 되나? 이런 거 물어봐도 되나?\u0026rdquo; 같은 자기검열도 사라졌다.\u003cbr\u003e\n\u0026hellip;\u003cbr\u003e\n사람 대접받는다는 느낌, 같은 사람으로 대할 수 있고 대해질 수 있다는 느낌이었다. 서로의 차이는 있지만 가능성은 누구에게나 열려 있고 역할은 누구에게나 주어질 수 있다는 분위기였다.\u003c/p\u003e","title":"(책) 왜 공부하는가"},{"content":" 휴식을 취하라 다양한 활동에 대해 각각의 컴퓨터 모니터를 설치하라. 종이로 된 할 일 목록을 사용하라 한 이메일을 복수의 카테고리로 분류하라. 필요할 때는 통째로 없애라. 간단한 업무와 장기 프로젝트를 위한 시간을 따로 지정하라. 결정을 내릴 때 그 가치보다 더 많은 시간을 들이지 말라 잠을 자라. 직장에서 낮잠을 자라. 지나치게 정리하지 말라 일은 직장에 두고 와라. 출처 : 정보 과다의 시대, 머릿속 정리법 10가지\n","date":"2014-09-10T14:55:07+09:00","permalink":"https://cychong47.github.io/post/2014/peom-meorisog-jeongribeob-10gaji/","summary":"\u003col\u003e\n\u003cli\u003e휴식을 취하라\u003c/li\u003e\n\u003cli\u003e다양한 활동에 대해 각각의 컴퓨터 모니터를 설치하라.\u003c/li\u003e\n\u003cli\u003e종이로 된 할 일 목록을 사용하라\u003c/li\u003e\n\u003cli\u003e한 이메일을 복수의 카테고리로 분류하라.\u003c/li\u003e\n\u003cli\u003e필요할 때는 통째로 없애라.\u003c/li\u003e\n\u003cli\u003e간단한 업무와 장기 프로젝트를 위한 시간을 따로 지정하라.\u003c/li\u003e\n\u003cli\u003e결정을 내릴 때 그 가치보다 더 많은 시간을 들이지 말라\u003c/li\u003e\n\u003cli\u003e잠을 자라. 직장에서 낮잠을 자라.\u003c/li\u003e\n\u003cli\u003e지나치게 정리하지 말라\u003c/li\u003e\n\u003cli\u003e일은 직장에 두고 와라.\u003c/li\u003e\n\u003c/ol\u003e\n\u003cp\u003e출처 : \u003ca href=\"http://kr.wsj.com/posts/2014/08/22/%EC%A0%95%EB%B3%B4-%EA%B3%BC%EB%8B%A4%EC%9D%98-%EC%8B%9C%EB%8C%80-%EB%A8%B8%EB%A6%BF%EC%86%8D-%EC%A0%95%EB%A6%AC%EB%B2%95-10%EA%B0%80%EC%A7%80/\"\u003e정보 과다의 시대, 머릿속 정리법 10가지\u003c/a\u003e\u003c/p\u003e","title":"(펌) 머리속 정리법 10가지"},{"content":"\n추가 해야 할 내용\nMovingCastle에 대한 추가 백업? 혹은 Mini 2011을 이중 백업. Wordpress Blog 내용만 추가로 백업 필요. Ghost Blog 추가 백업 ","date":"2014-09-10T13:40:43+09:00","permalink":"https://cychong47.github.io/post/2014/time-machine-backup/","summary":"\u003cp\u003e\u003cimg src=\"/images/2014/Sep/TimeMachine-Backup-20140910.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e추가 해야 할 내용\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eMovingCastle에 대한 추가 백업?\u003c/li\u003e\n\u003cli\u003e혹은 Mini 2011을 이중 백업.\u003c/li\u003e\n\u003cli\u003eWordpress Blog 내용만 추가로 백업 필요.\u003c/li\u003e\n\u003cli\u003eGhost Blog 추가 백업\u003c/li\u003e\n\u003c/ul\u003e","title":"Time Machine backup"},{"content":"(책) 빅데이터 승리의 과학\nTechnology 팀 오바마 2012년 선거 당시 2008년 당시의 SNS를 활용하는 수준을 넘어서 통합적인 선거 지원을 위해 빅데이터 기술 활용. 선거 특성에 맞는 AWS 를 이용해서 인프라를 구축하고, R 언어를 활용. 하둡은 실시간성이 부족하여 제한적으로 사용. 디지털 팀의 CDS(Chief Digital Strategist)는 31살 Joe Rosparse, CTO는 하퍼 리드(33)등을 고용.\n벤처기업 엔지니어 출신. 혁신을 좋아하고, 기존 틀과 문화에 얽매이지 않고 오직 해결책에만 관심을 둠. 리드는 50명에 이르는 Technology 팀 멤버를 구성. Twitter, Google, Facebook, Craiglist, Quora, orbits, IBM, MS 등에서 일하는 인력들이 합류. \u0026ldquo;외뿔고래(Narwhal)\u0026ldquo;라고 불린 IT 통합 프로젝트 . 하나의 애플리케이션이나 서비스가 아니라 아키텍쳐였으며 전체를 아우르는 API의 집합 서로 다른 형태의 DB를 통합하여 하나처럼 작동하는 시스템 구축. RestFul API를 이용해서 구축 모든 애플리케이션이 오직 외뿔고래 API를 통해서만 DB에 접근할 수 있게 함. 외뿔고래 API를 이용해서 각각의 앱들을 모두 분리시킴으로써 각각의 앱들을 개별적으로 확장할 수 있게 하고, 앱들 간의 데이터를 공유하게 함. 이전 선거 실패에 대한 반성 2000년에 이어 2004년 선거까지 연거푸 패배의 쓴 잔을 마신 민주당 케리 후보 캠프에서 활동했던 사람들과 진보진영의 시민사회단체 활동가 20여 명이 2004년 대선이 끝난 후 2박3일간의 모임을 가졌다. 그 자리에서 그들은 민주당과 진보진영의 문제점과 개선방안에 대해서 치열하게 토론을 갖고, 그 동안 민주당과 시민사회단체들이 너무 선언적인 활동에만 치우치고 자기들끼리만 연대하여 활동하였으며 선거운동은 대부분 상층 정치전략가들에 의해서 좌우되었다고 반성하였다. 그들은 민주당이 선거에서 승리하기 위해서는 대중 속으로 더 파고들어야 하고 더 효율적이고 실질적인 조직활동을 해야 한다고 결론 내렸다.\nHadoop system 하둡 = HDFS(분산 데이터 저장) + MapReduce(분산 데이터 처리)\nMapReduce\n파일들이 각기 어디에 위치하고 있는지 기록학 파악하는 지도(맵)를 간소화(reduce)하여 보다 신속하게 파일들의 색인을 구축하고 검색을 용이하게 해주는 색인 체계 Hadoop\n최소 3군데에 동일 데이터를 저장하여 H/W 오류 시에도 동작할 수 있게 함. 데이터를 소프트웨어가 있는 서버로 옮기는 것보다 데이터가 있는 서버로 소프트웨어를 보내 처리하고 그 결과만 원래 소프트웨어가 있던 서버로 보내서 통합 확장성이 커서 한번에 다룰 수 있는 파일의 양이 매우 많다. 기가/테라 바이트 크기의 파일 처리도 가능. 하나의 클러스터에 수천 개의 노드(컴퓨터)를 둘 수 있고, 하나의 인스턴스(작업)에 수천만 개의 파일을 지원 이식성 및 호환성이 뛰어남 단점\nHadoop과 MapReduce는 파일을 대규모로 저장하고 처리하는 데에는 큰 장점을 갖지만, 실시간 분석에는 단점이 있다. 배치 처리를 기본으로 함으로 처리 지연 발생 특수한 목적의 데이터 분석을 위해서 비정형적인 Ad-hoc query를 만들고 처리하려면 개발자들의 노력이 많이 필요함. 구글도 몇 년 전부터 Hadoop은 데이터의 저장과 처리에 주로 사용하고, 데이터의 query와 분석을 위해서는 Dremell이라는 플랫폼을 갭라하여 함께 사용하는 중 오바마 캠프는 HP Vertica라는 SQL 기반의 대용량병렬 처리(Massively Parallel Processing) database platform 선택\n행동 심리학 Craig Fox 교수를 중심으로 행동과학가 컨소시엄(Consortium of Behavioral Scientists) - Nudge, 설득의 심리학 등의 작가. 왜곡된 루머에 대처하는 가장 좋은 전략은 자신에 대한 공격을 부정하는 것이 아니라 그것을 이길 수 있는 다른 긍정적 표현을 강하게 하는 것. \u0026ldquo;아바마와 무슬림\u0026rdquo; -\u0026gt; \u0026ldquo;나는 무슬람이 아니다\u0026rdquo;(X) \u0026ldquo;오바마는 기독교도다\u0026rdquo;(O) 한 사람이 어떤 일을 하기 위해서 간단한 계획을 세운다면 그런 계획이 없었을 때보다 그 일을 실제로 하게 될 가능성이 높아진다\n","date":"2014-09-09T03:41:02+09:00","permalink":"https://cychong47.github.io/post/2014/caeg-bigdeiteo-seungriyi-gwahag/","summary":"\u003cp\u003e(책) 빅데이터 승리의 과학\u003c/p\u003e\n\u003ch2 id=\"technology-팀\"\u003eTechnology 팀\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e오바마 2012년 선거 당시 2008년 당시의 SNS를 활용하는 수준을 넘어서 통합적인 선거 지원을 위해 빅데이터 기술 활용.\u003c/li\u003e\n\u003cli\u003e선거 특성에 맞는 AWS 를 이용해서 인프라를 구축하고, R 언어를 활용. 하둡은 실시간성이 부족하여 제한적으로 사용.\u003c/li\u003e\n\u003cli\u003e디지털 팀의 CDS(Chief Digital Strategist)는 31살 Joe Rosparse, CTO는 하퍼 리드(33)등을 고용.\u003cbr\u003e\n벤처기업 엔지니어 출신. 혁신을 좋아하고, 기존 틀과 문화에 얽매이지 않고 오직 해결책에만 관심을 둠.\n리드는 50명에 이르는 Technology 팀 멤버를 구성. Twitter, Google, Facebook, Craiglist, Quora, orbits, IBM, MS 등에서 일하는 인력들이 합류.\u003c/li\u003e\n\u003cli\u003e\u0026ldquo;외뿔고래(Narwhal)\u0026ldquo;라고 불린 IT 통합 프로젝트 . 하나의 애플리케이션이나 서비스가 아니라 아키텍쳐였으며 전체를 아우르는 API의 집합\u003c/li\u003e\n\u003cli\u003e서로 다른 형태의 DB를 통합하여 하나처럼 작동하는 시스템 구축. RestFul API를 이용해서 구축\u003c/li\u003e\n\u003cli\u003e모든 애플리케이션이 오직 외뿔고래 API를 통해서만 DB에 접근할 수 있게 함. 외뿔고래 API를 이용해서 각각의 앱들을 모두 분리시킴으로써 각각의 앱들을 개별적으로 확장할 수 있게 하고, 앱들 간의 데이터를 공유하게 함.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"이전-선거-실패에-대한-반성\"\u003e이전 선거 실패에 대한 반성\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e2000년에 이어 2004년 선거까지 연거푸 패배의 쓴 잔을 마신 민주당 케리 후보 캠프에서 활동했던 사람들과 진보진영의 시민사회단체 활동가 20여 명이 2004년 대선이 끝난 후 2박3일간의 모임을 가졌다. 그 자리에서 그들은 민주당과 진보진영의 문제점과 개선방안에 대해서 치열하게 토론을 갖고, 그 동안 민주당과 시민사회단체들이 너무 선언적인 활동에만 치우치고 자기들끼리만 연대하여 활동하였으며 선거운동은 대부분 상층 정치전략가들에 의해서 좌우되었다고 반성하였다. 그들은 민주당이 선거에서 승리하기 위해서는 대중 속으로 더 파고들어야 하고 더 효율적이고 실질적인 조직활동을 해야 한다고 결론 내렸다.\u003c/p\u003e","title":"(책) 빅데이터 승리의 과학"},{"content":"초보적인 실수를 반복한다고 구박하지만,\n자기들은 기본적인 패키지 운영도 못하면서 누굴 구박하는지. 조직간 알력 해결도 못하면서. 같은 일을 서로 더 힘들게 하는 문화를 만들어 놓고서.\n매일 같이 비상이다 위기다 라고 협박만 하면서.\n잘못된 일정 따위는 사과하지 않으면서.\n특정 부서의 오기로 만들어진 과제 일정 차질에 대해서는 아무 말도 안하면서.\n뭐가 잘났다고.\n","date":"2014-09-08T09:12:34+09:00","permalink":"https://cychong47.github.io/post/2014/cobojeogin-silsureul-banboghandago-gubaghajiman/","summary":"\u003cp\u003e초보적인 실수를 반복한다고 구박하지만,\u003cbr\u003e\n자기들은 기본적인 패키지 운영도 못하면서 누굴 구박하는지. 조직간 알력 해결도 못하면서. 같은 일을 서로 더 힘들게 하는 문화를 만들어 놓고서.\u003cbr\u003e\n매일 같이 비상이다 위기다 라고 협박만 하면서.\u003cbr\u003e\n잘못된 일정 따위는 사과하지 않으면서.\u003cbr\u003e\n특정 부서의 오기로 만들어진 과제 일정 차질에 대해서는 아무 말도 안하면서.\u003cbr\u003e\n뭐가 잘났다고.\u003c/p\u003e","title":"초보적인 실수를 반복한다고 구박하지만"},{"content":"TPP 3. Provide Options, Don\u0026rsquo;t make Lame excuses 검토 결과 부정적일 때, 그냥 안된다고 하지말고 대안을 같이 제시하자. \u0026ldquo;이거 해 봤어?\u0026rdquo; \u0026ldquo;이거 고려했어\u0026rdquo; 같이 나올 수 있는 질문에 대해 미리 고민하고 대응할 것. 여기서 대응이란 질문에 대한 답을 제시할 수 있도록 미리 준비하라는 것. 실제로 고려해 보고, 실제로 시도해보고 나서 할 수 있으면 최고.\n무조건 안된다고 하지 말고, 대안을 제시하자. 안된다고 말하기 보다는 그 문제를 해결하기 위해 뭘 할 수 있는 지 제시하자.\nTPP 4. Don\u0026rsquo;t live with broken windows 잘못된 디자인, 잘못된 결정, 허접한 코드를 고치지 않은 형태로 두지 말아라. 발견했으면 반드시 조치를 해라. 필요하면 해당 코드를 코멘트로 막아버리고, 지원되지 않는다는 출력문을 내라. 차라리 그게 문제를 더 일으키는 것 보다 낫다.\n이런 \u0026ldquo;깨진 유리창\u0026quot;이 있으면 코드를 개선할 생각을 안하기 마련이다. \u0026ldquo;어차피 이런 코드인데 뭐, 대충 작성하지 뭐\u0026quot;라는 생각을 갖게 한다.\n반대로 잘 작성된 코드가 있으면 그 코드에 대해서는 신경을 쓰게 마련이다. 좋은 코드로 남도록 잘 다듬으려고.\nTPP 4. Be a catalyst for change 돌 스프 혹은 개구리.\n마을의 모든 사람들이 즐길 수 있도록 한 병사와 같은 촉매 역할을 할 것. 결국 모두가 승리하는 결과를 얻을 수 있다.\n뭔가를 하려는데 사람들의 동의가 필요하고, 예산도 한정되어 있고, 복잡한 이해관계가 엮여있다. 이럴때는 우선 작은 걸 잘 만들어서 보여준다. 그리고 \u0026ldquo;여기에 이런 기능이 있으면 더 좋을 듯 한데\u0026quot;라며 별로 중요하지 않은 것처럼 말한다. 그리고는 그 기능을 해야 할 사람이나 예산을 가진 사람이 참여하고 싶어하는 걸 기다린다.\n사람들은 성공하는 것에는 쉽게 참여한다(People find it easier to join on ongoing success)\nTPP 6. Remember the big picture 마을 사람들 입장에서 보면 결과론적으로 모두 즐거운 식사를 했겠지만, 간과해서는 안되는 것은 작은 것(재료들)이 하나씩 투자되었다는 것을 눈치채지 못했다는 것이다.\n때로는 작은 것들이 모여 morale과 팀을 깬다.\n개구리가 되지 마라. 항상 큰 그림에 집중해야 한다. 꾸준히 내가 하는 것뿐만 아니라 주변에서 일어나는 것들을 검토해야 한다.\n지나치게 완벽한 프로그램을 만들기 위해 노력하지 말라. 그럴 수도 없다. It may not be perfect. Don’t worry : I could never be perfect\n","date":"2014-09-08T08:48:49+09:00","permalink":"https://cychong47.github.io/post/2014/the-pragmatic-programmer/","summary":"\u003ch3 id=\"tpp-3-provide-options-dont-make-lame-excuses\"\u003eTPP 3. Provide Options, Don\u0026rsquo;t make Lame excuses\u003c/h3\u003e\n\u003cp\u003e검토 결과 부정적일 때, 그냥 안된다고 하지말고 대안을 같이 제시하자. \u0026ldquo;이거 해 봤어?\u0026rdquo; \u0026ldquo;이거 고려했어\u0026rdquo; 같이 나올 수 있는 질문에 대해 미리 고민하고 대응할 것. 여기서 대응이란 질문에 대한 답을 제시할 수 있도록 미리 준비하라는 것. 실제로 고려해 보고, 실제로 시도해보고 나서 할 수 있으면 최고.\u003c/p\u003e\n\u003cp\u003e무조건 안된다고 하지 말고, 대안을 제시하자. 안된다고 말하기 보다는 그 문제를 해결하기 위해 뭘 할 수 있는 지 제시하자.\u003c/p\u003e","title":"The Pragmatic Programmer"},{"content":"우선 Synology NAS에서 webdav를 켜는 건 기본이고\nDevonthink의 Sync tab에서 타입을 webdav로 하면 아래와 같은 입력 창이 나오는데 여기에 서버 주소 등 필요한 정보를 적으면 된다. 이때 path는 user name으로 로그인했을 때 기준으로 하면 됨. 즉 Full path를 적으면 되는데 처음 입력할 때는 /home/Documents/Devonthink로 입력했는데 나중에 다시 보면 저렇게 바뀌어 있다.\n이제 두 대의 맥을 이렇게 운영하련다.\n동기화 관련 참고자료\nDropbox를 사용할 때 동시에 여러 Mac에서 동기화된 DB를 열지 않도록 하는 applescript Devonthink DB가 깨졌을 때 복구하는 방법 웹페이지 일부만 스크랩하는 방법 ","date":"2014-09-06T15:39:33+09:00","permalink":"https://cychong47.github.io/post/2014/synology-webdav-devonthink/","summary":"\u003cp\u003e우선 Synology NAS에서 webdav를 켜는 건 기본이고\u003cbr\u003e\n\u003cimg src=\"/images/2014/Sep/Synology_webdav.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003eDevonthink의 Sync tab에서 타입을 webdav로 하면 아래와 같은 입력 창이 나오는데 여기에 서버 주소 등 필요한 정보를 적으면 된다. 이때 path는 user name으로 로그인했을 때 기준으로 하면 됨. 즉 Full path를 적으면 되는데 처음 입력할 때는 \u003ccode\u003e/home/Documents/Devonthink\u003c/code\u003e로 입력했는데 나중에 다시 보면 저렇게 바뀌어 있다.\u003cbr\u003e\n\u003cimg src=\"/images/2014/Sep/Devonthink_webdav.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e이제 두 대의 맥을 이렇게 운영하련다.\u003cbr\u003e\n\u003cimg src=\"/images/2014/Sep/Devonthink-sync.png\" alt=\"\"\u003e\u003c/p\u003e\n\u003cp\u003e동기화 관련 참고자료\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"http://jmjeong.com/use-devonthink-at-home-and-work/\"\u003eDropbox를 사용할 때 동시에 여러 Mac에서 동기화된 DB를 열지 않도록 하는 applescript\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://binnyon.tistory.com/78\"\u003eDevonthink DB가 깨졌을 때 복구하는 방법\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"http://namsieon.com/1473\"\u003e웹페이지 일부만 스크랩하는 방법\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e","title":"Synology + Webdav + Devonthink"},{"content":" \u0026lt;인생의 목적\u0026gt;\n우리는 살기 위해, 그리고 경험하기 위해 태어났습니다.\n바쁜 일정 속에서도 스스로에게 되뇌이곤 합니다.\n인간은 일하기 위해 태어난 것이 아니라, 인생이라는 선물을 즐기기 위해 태어났다고. 우리는 일하기 위해 존재하는 것이 아니라, 조금 더 세상을 나아지게 하기 위해 여기 있다고.\n당신이 당신의 인생을 일에 올인하고 있다면, 분명 후회의 순간이 찾아옵니다.\n당신이 직장에서 성공하고 있다면 더더욱 항상 기억해야합니다. 우리는 삶을 위해 삽니다. 그리고 일은 절대 삶보다 중요할 수 없습니다.\n인생의 목적은 삶을 사는 것이지 일하는 게 아니다. 일도 삶의 일부로 해석해야지, 일이 목적이 되어서는 안된다는\n\u0026lt;불평과 불만\u0026gt;\n절대 불평과 불만을 습관으로 만들지 마십시오.\n가끔 하는 불평은 괜찮습니다. 그러나 만약 습관적으로 불평하고 있다면, 주의하세요. 불평은 술과 같습니다. 더 마실수록 더 목말라집니다.\n성공으로 가는 길목에서 당신은 깨닫게 될 것입니다. 성공한 사람들은 투덜대지 않고, 자주 불평하지 않습니다.\n세상은 당신이 한 말은 기억하지 않습니다. 그러나 당신이 이룬 것은 기억합니다.\n불평과 불만을 습관으로 만들지 말라\u0026hellip;\n\u0026lt;명심해야 할 두 가지\u0026gt;\n당신의 태도는 당신의 능력보다 중요합니다. 당신의 결정이 당신의 역량보다 결정적입니다.\n태도!!!\n출처 : 일과 인생에서 성공하고 싶은 청년들이 꼭 읽어야 할 글\n","date":"2014-09-03T04:21:54+09:00","permalink":"https://cychong47.github.io/post/2014/peom-salmyi-mogjeog/","summary":"\u003cblockquote\u003e\n\u003cp\u003e\u0026lt;인생의 목적\u0026gt;\u003c/p\u003e\n\u003cp\u003e우리는 살기 위해, 그리고 경험하기 위해 태어났습니다.\u003c/p\u003e\n\u003cp\u003e바쁜 일정 속에서도 스스로에게 되뇌이곤 합니다.\u003c/p\u003e\n\u003cp\u003e인간은 일하기 위해 태어난 것이 아니라, 인생이라는 선물을 즐기기 위해 태어났다고. 우리는 일하기 위해 존재하는 것이 아니라, 조금 더 세상을 나아지게 하기 위해 여기 있다고.\u003c/p\u003e\n\u003cp\u003e당신이 당신의 인생을 일에 올인하고 있다면, 분명 후회의 순간이 찾아옵니다.\u003c/p\u003e\n\u003cp\u003e당신이 직장에서 성공하고 있다면 더더욱 항상 기억해야합니다. 우리는 삶을 위해 삽니다. 그리고 일은 절대 삶보다 중요할 수 없습니다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e인생의 목적은 삶을 사는 것이지 일하는 게 아니다. 일도 삶의 일부로 해석해야지, 일이 목적이 되어서는 안된다는\u003c/p\u003e","title":"(펌) 삶의 목적"},{"content":" 나는 매주 금요일 오후가 되면 구글이라는 회사의 위력을 다시금 실감한다. 알려진 대로 구글은 매주 금요일마다 전 직원이 모이는 TGIF라는 행사가 있다.\n정말 지금도 이걸 하고 있다니 놀랍기만 하다. 회사 규모가 커져서 못할 줄 알았는데.\n과연 우리 회사의 임원들은 같은 시간에 뭘 하고 있을까? 구글보다 비즈니스의 폭이 넓어서 더 많은 회의가 필요해서?\n이들 두 창업자의 가장 큰 관심사는 구글 비즈니스가 아니라, 구글러들의 행복과 문화를 어떻게 하면 좀 더 발전시켜나갈 것인가에 있다. 이들은 직원들이 진정으로 행복한 삶을 살면서 사명감을 갖고 일할 수 있는 비전을 제시한다. 우리 스스로가 행복해야, 우리가 세상을 바꾸고 행복하게 만들 수 있다는 경영 철학 때문이다. 나는 \u0026lsquo;행복하게 일해야 행복한 제품을 만들고, 세상 사람들이 다 같이 행복할 수 있다\u0026rsquo;는 아름다운 이야기를 매주 들으면서 나 스스로도 그렇게 바뀌어가고 있다.\n아직도 이런 말을 들을 때마다 반신반의한다. 정말 저 큰 회사의 대표가 회사보다 직원들의 행복을 먼저 생각한다라는 말. 정말?\n구글은 5만 명의 직원이 거대한 목표 아래 일사불란하게 달려가는 조직이 아니다. 올해의 매출목표 따위의 말은 존재하지도 않는다.\n정말? 정말 정말 정말??\n2011년 구글 부사장인 Matt Cutts는 TED 강연에서 \u0026lsquo;30일 동안 새로운 것에 도전하기. Try something new for 30days\u0026rsquo;란 주제로 강연을 한 적이 있다. 대략적인 내용은 다음과 같다.\n\u0026ldquo;정말 뭔가를 간절하게 원한다면 30일이면 충분히 그 일을 해낼 수 있습니다. 좋든 싫든 어차피 이 한 달은 흘러가는 시간입니다. 한 번 시험 삼아 실행에 옮겨본 들 손해 볼 일은 없지요. 작지만 지속적으로 실행에 옮길 수 있는 변화들은 오래가는 법입니다\u0026rdquo;\n내가 가장 필요한 거. Just Do It\n어느 한 분야에 흥미와 관심을 갖고 인터넷상에서 그 지식을 끝없이 흡수하고 싶다면 영어 독해 능력을 키우는데 힘써야 한다. 늘 필요한 정보를 찾아 나의 지식창고에 쌓아가는 훈련을 해야 한다. \u0026lsquo;시간 죽이기\u0026rsquo;식의 게임하기와 영화나 만화 보는 시간, 카톡 하는 시간은 나에게 살이 되고 피가 되는 지식과 정보를 내다버리고 있는 \u0026lsquo;헛된\u0026rsquo; 시간일 수 있다.\n흐흠\u0026hellip;..\n소프트웨어 엔지니어는 누구든지 작성하는 프로그램 코드에 리뷰를 받아야 한다. 그게 코드가 아니라 단 한 줄의 코멘트라 할지라도 마찬가지다. 코드가 틀렸거나, 덜 효과적인 방법을 사용했거나, 주석문에 영어 오자가 있다면 다른 구글의 리뷰어들에 의해서 다듬어진다. 이러한 과정을 통해 구글러들은 점점 더 효율적인 프로그래밍을 할 수 있도록 키워진다. MIT를 수석으로 졸헙한 사람이라도 마찬가지다.\n모난 돌들이 서로 부딛히면서 다듬어지는 과정을 겪는 것처럼, 구글의 모든 소프트웨어 엔지니어들은 서로의 결과물을 리뷰해주고, 때로는 서로의 논리와 지식을 내세워 논쟁하면서 문제를 해결해나간다. 프로그램뿐만 아니고 생각하는 방법, 문제를 푸는 방법, 프로젝트를 바라보는 관점까지 서로 리뷰를 주고받으면서 부족한 생각이나 지식을 발전시켜 나간다. 그 결과 \u0026lsquo;100의 능력을 가지고 구글에 들어온 엔지니어들은 시간이 지나면서 그 이상의 능력을 가지게 된다.\n그렇다. 리뷰는 그 사람의 코드에 틀린 점이 있는 지를 보는 것 이상으로 그 코드의 수준을 높이는 작업이어야 한다. 지금 하고 있는 게 그런지\u0026hellip; 그런 생각으로 다른 사람의 코드를 보고, 다른 사람 역시 그런 마음으로 코드 리뷰어의 코멘트를 바라보는 지. 혹시 공격과 수비로 생각하는 건 아닌 지.\n캘린더나 스케줄러 앱을 이용해서 시간을 30분 단위로 쪼개고 그 시간대로 움직이는 연습을 하면 된다.\n시간 관리의 중요성을 다시금 생각하게 한다.\n모든 구글러는 면접에 참여해야 하는 의무를 가지고 있다. 누들러의 티를 벗고 구글에 익숙해질 때 쯤이면 면접 교육을 받는다.\n의무가 아니라서 그런지. 면접위원을 해 본적은 있지만, 한번도 어떻게 해야 하는 지 교육을 받는 적이 없다. 교육은 커녕 기준도 들은 적이 없다는\u0026hellip;.\n어느 구글러와 일의 삶의 균형에 대해 얘기를 나눈 적이 있다. 그는 정시에 칼퇴근하고 그 이후에는 전혀 업무에 관심을 갖지 않는 것을 일과 삶의 균형이라고 보지는 않았다. 아무리 바쁘게 일을 하고 업무량이 많더라도, 내가 정말 하고 싶거나 해야 하는 것들을 자유롭게 할 수 있는 것, 그것이 바로 일과 삶의 균형이라는 결론을 내렸다. 구글러들은 일과 삶의 밸런스를 시간 개념으로 구별하는 것이 아니라, 자유로움과 자기 결정력에 따라 구분한다.\n시간이나 장소의 관점이 아닌 자유도 측면에서 바라봐야 진정으로 일과 삶의 균형이 된다는 말인데\u0026hellip;\n","date":"2014-08-31T13:29:59+09:00","permalink":"https://cychong47.github.io/post/2014/caeg-gugeuleun-skyreul-moreunda/","summary":"\u003cblockquote\u003e\n\u003cp\u003e나는 매주 금요일 오후가 되면 구글이라는 회사의 위력을 다시금 실감한다. 알려진 대로 구글은 매주 금요일마다 전 직원이 모이는 TGIF라는 행사가 있다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e정말 지금도 이걸 하고 있다니 놀랍기만 하다. 회사 규모가 커져서 못할 줄 알았는데.\u003cbr\u003e\n과연 우리 회사의 임원들은 같은 시간에 뭘 하고 있을까? 구글보다 비즈니스의 폭이 넓어서 더 많은 회의가 필요해서?\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e이들 두 창업자의 가장 큰 관심사는 구글 비즈니스가 아니라, 구글러들의 행복과 문화를 어떻게 하면 좀 더 발전시켜나갈 것인가에 있다.  이들은 직원들이 진정으로 행복한 삶을 살면서 사명감을 갖고 일할 수 있는 비전을 제시한다. 우리 스스로가 행복해야, 우리가 세상을 바꾸고 행복하게 만들 수 있다는 경영 철학 때문이다.  나는 \u0026lsquo;행복하게 일해야 행복한 제품을 만들고, 세상 사람들이 다 같이 행복할 수 있다\u0026rsquo;는 아름다운 이야기를 매주 들으면서 나 스스로도 그렇게 바뀌어가고 있다.\u003c/p\u003e","title":"(책) 구글은 SKY를 모른다"},{"content":"출처 : 20 Life Lessons Everyone Can Master By The Age 40\n1. Everything will be okay, and if it’s not, it’s certainly not the end of the world. 내가 포기할 때 실패한 끝난 거다.\n2. Find what you love and own it! 3. Don’t fear mistakes. 4. You deserve respect. 5. Romance is NOT the same as love. 6. It’s never too late to live a life that makes you proud. 7. Remain calm in all situations. 8. You win some, you lose some. 9. The term ‘Overnight Success’ really means 2 to 10 years. Everything takes time and the best things in life are earned through consistency and patience. This doesn’t necessarily mean that if you just work hard, you’ll have everything you ever wanted. There’s definitely such a thing as working smarter. In order to discover ways to work ‘smarter’ it takes years of experience.\n10. Maintain your focus. Having good focus is directly connected to self-discipline. There will always be distractions, especially in the digital age. Making every single party and social event just isn’t as important now. Use your experience, wisdom and instincts to focus on what’s truly important in life.\n11. Not everyone is always going to like you. 12. You simply cannot control everything and everyone. 13. Energy is everywhere and you can use yours to either work for you, or against you. Disliking, not forgiving and trying to change others takes more energy then just letting it go and minding your own business. Now that you’ve mastered this, you can choose wisely where to expend energy to create the ideal life for you.\n14. Don’t sweat the small stuff. It’s not that you condone everything that happens, or everything that people do and say. It has more to do with accepting people and places exactly as is and still being able to thrive among them.\n작은 거에 집착하지 말라는\n15. Money is not the measure of success. 16. It’s not about what you have. It’s about what you do with what you have. 17. You really do reap what you sow. 18. Happiness doesn’t just come to you automatically. You make it with your thoughts and actions. 제목 그대로.\n19. The past has passed for a reason. So let it go. Let it go. 과거로부터는 잘한 점이건 잘못한 점이건 교훈만 기억하고, 과거의 성공, 실패 모두 잊자.\n20. Life is short and can end in an instant. Live it to the fullest. 한 순간에 인생이 끝날 수도 있다. 매 순간 후회없이 살자.\n","date":"2014-08-24T12:17:51+09:00","permalink":"https://cychong47.github.io/post/2014/peom-20-life-lessons-everyone-can-master-by-the-age-40/","summary":"\u003cp\u003e출처 : \u003ca href=\"http://www.lifehack.org/articles/communication/20-life-lessons-everyone-can-master-the-age-40.html?ref=tp\u0026amp;n=2\"\u003e20 Life Lessons Everyone Can Master By The Age 40\u003c/a\u003e\u003c/p\u003e\n\u003ch4 id=\"1-everything-will-be-okay-and-if-its-not-its-certainly-not-the-end-of-the-world\"\u003e1. Everything will be okay, and if it’s not, it’s certainly not the end of the world.\u003c/h4\u003e\n\u003cp\u003e내가 포기할 때 실패한 끝난 거다.\u003c/p\u003e\n\u003ch4 id=\"2-find-what-you-love-and-own-it\"\u003e2. Find what you love and own it!\u003c/h4\u003e\n\u003ch4 id=\"3-dont-fear-mistakes\"\u003e3. Don’t fear mistakes.\u003c/h4\u003e\n\u003ch4 id=\"4-you-deserve-respect\"\u003e4. You deserve respect.\u003c/h4\u003e\n\u003ch4 id=\"5-romance-is-not-the-same-as-love\"\u003e5. Romance is NOT the same as love.\u003c/h4\u003e\n\u003ch4 id=\"6-its-never-too-late-to-live-a-life-that-makes-you-proud\"\u003e6. It’s never too late to live a life that makes you proud.\u003c/h4\u003e\n\u003ch4 id=\"7-remain-calm-in-all-situations\"\u003e7. Remain calm in all situations.\u003c/h4\u003e\n\u003ch4 id=\"8-you-win-some-you-lose-some\"\u003e8. You win some, you lose some.\u003c/h4\u003e\n\u003ch4 id=\"9-the-term-overnight-success-really-means-2-to-10-years\"\u003e9. The term ‘Overnight Success’ really means 2 to 10 years.\u003c/h4\u003e\n\u003cblockquote\u003e\n\u003cp\u003eEverything takes time and the best things in life are earned through consistency and patience. This doesn’t necessarily mean that if you just work hard, you’ll have everything you ever wanted. There’s definitely such a thing as working smarter. In order to discover ways to work ‘smarter’ it takes years of experience.\u003c/p\u003e","title":"(펌) 20 Life Lessons Everyone Can Master By The Age 40"},{"content":"어떻게 하면 더 나은 소프트웨어를 만들 수 있을까? – 인터뷰 시리즈 part 1, Fernando Jimenez Moreno와 함께\n출처 : http://hacks.mozilla.or.kr/2014/08/how-can-we-write-better-software-interview-series-part-1/\n영문 원본 : https://hacks.mozilla.org/2014/07/how-can-we-write-better-software-interview-series-part-1/\nTelefonica에서 근무하고 있으면서 MozillaOS 개발에 참여하고 있는 사람의 인터뷰 기사\nCode Reviewer 업무를 함에 있어 참고할 만한 좋은 내용이 많아 옮겨 본다.\n우리가 모질라와 함께 일한 것은 2011년으로 거슬러 올라갑니다. 두 회사 모두에게 잘 맞는 공통된 작업 절차를 찾기까지 꽤 많은 시간이 걸렸습니다. 제말은, 우리는 텔코(telco) 문화에서 일하던 사람입니다. 텔코 문화에서는 대부분의 작업들이 폐쇄적이고 비밀입니다. 이것은 모질라의 공개적이고 투명한 문화와는 반대죠.\nTelco 문화가 왜 폐쇄적이어야 할까? Telco 문화가 폐쇄적이라기 보다 Mozilla와 같은 Web 기반 기술을 사용하는 회사나 조직의 문화가 공개적이고 투명한 게 아닐까 싶다. Telco가 아니라 자동차 산업도 폐쇄적일 거라고 생각\n우리는 텔레포니카에서 애자일 방법론을 쓰고 있었는데, 당시 모질라는 애자일 방법론을 쓰고 있지 않았습니다. 우리는 양쪽 모두에게 맞는 작업 절차를 찾아야 했습니다. 그러기 위해 꽤 많은 시간이 필요했습니다. 작업 절차에 대해 의논하기 위해 아주 많이 만났고, 아주 많이 토론했습니다. 다른 텔코 회사들과 일하는 것의 경우는 지금까지 무척 만족합니다. 특히 텔레노르와 잘 협조하고 있습니다. 아직까지 우리는 그들(텔레노르)과 정보를 공유할 때 조심합니다. 왜냐하면 궁극적으로 그들은 우리의 경쟁사니까요. 하지만 그렇다고 해서 파이어폭스 계정 시스템 개발 같은 공동의 목표를 위해 협조 못한다는 말은 아닙니다.\nTelefonica가 Agile을 사용하고, Mozilla가 그렇지 않다는 게 의외네. 반대가 아닐까 싶었는데 NFV관련 내용을 봐도 그렇고 Telefonia가 상당해 개발 지향적인 듯\n많은 원칙이 적용되고, 많은 회사가 참여하는 프로젝트의 경우 스타일가이드, 도구, 프로세스 등의 공통 표준이 얼마나 중요한가요?\n글쎄요, 나는 소프트웨어 엔지니어링에 대해 일반적으로 말할 때 표준이 중요하다고 합니다. 하지만, 나는 그것을 SCRUM이라고 부르던, KANBAN이라고 부르던, SCRUMBAN이라고 부런던 상관하지 않습니다. 마찬가지로 Git 워크플로우를 따르던, Mercurial 워크플로우를 따르던, 아니면 구글의 자바스크립트 스타일가이드를 따르던, 모질라의 자바스크립트 스타일가이드를 따르던 상관하지 않습니다. 어떤 공통의 프로세스와 표준은 반드시 필요합니다. 특히 대규모의 엔지니어링 그룹의 경우는 더욱 그렇습니다. 오픈소스 프로젝트나 모질라 프로젝트가 이에 해당합니다. 공통 표준에 대해 말하자면, 규칙은 매우 간단합니다. 보통의 경우 이런 표준과 공통 프로세스들을 정의하고 토론하는데 너무 많은 시간을 소비하는 나머진 진정한 개발 목표를 잃어버리는 수가 있습니다. 나는 이런 공통 표준이 결국은 도구일뿐이라는 사실을 잊으면 안된다고 생각합니다. 우리 개발자들과 우리 매니저들을 돕는 도구지요. 공통 표준에 대해 유연하게 접근하는 지혜가 필요합니다.\n우리는 코드를 리뷰할 때 코딩 스타일을 많이 보곤합니다. 하지만 결과적으로 우리가 원하는 것은 코드를 수정해서 문제를 해결하는 것입니다. 만약 코딩 스타일에 문제가 있다면 고치면 됩니다. 연습삼아 패치를 남기는 상황이라면 일단 패치 코드를 버그 시스템에 기록으로 남겨 두세요. 그러면 코드 리뷰어가 기회 있을 때 코멘트할 것입니다.\n다소 모호한 답변인 듯. 표준이 필요하다는 듯 한데 또 그 표준에 대해서는 유연하게 접근하자는 말. 모호하다. 동시에 여러 style을 사용해도 문제가 없다는 건지\n당연히 코딩 스타일보다 동작을 보는 게 중요하지. 코딩 스타일에 문제가 있으면 고치면 된다는 말은 코드도 문제가 있으면 고치면 된다는 거랑 뭐가 다른 걸까?\n코드를 리뷰할 때 무엇을 살펴보나요?\n일반적으로 제가 가장 먼저 확인하는 것은 정확성입니다. 그러니까, 패치 코드는 원래 의도했던 문제를 실제로 해결해야 합니다. 그리고 당연히 부가적인 문제를 일으켜서는 안됩니다. 어떤 회귀적 문제도 일으켜서는 안됩니다. 시간이 허락되면 패치 코드를 제가 직접 테스트합니다. 패치 코드가 어떻게 동작하는지 알고 싶어서 이기도 하고, 아주 중요한 패치 코드일 경우 제대로 동작하는지 회귀적 문제를 일으키지는 않는지 확인하고 싶어서 이기도 합니다. 또 코드가 효율적으로 동작하는지 안전한지 살펴봅니다. 패치 코드에 대한 테스트 슈트 작성이 가능해 보이면 거의 언제나 테스트 슈트 작성을 요구합니다. 마지막으로 전반적인 코드의 품질, 문서, 코딩스타일, 기여정도, 프로세스의 정확성 등을 살펴봅니다\n직접 리뷰어가 테스트까지 한다는 게 의외(?). 가능하면 언제나 테스트 슈트 작성을 요구한다는 것이 인상적이다.\n당신은 지금까지 제가 겪은 다른 어떤 리뷰어보다 더 일관성을 강조했습니다. 다른 어떤 리뷰어보다 말이죠.\n글쎄요. 일관성은 코드의 전반적인 품질을 향상시킵니다. 리뷰할 때, 나는 종종 “nit:”라는 코멘트를 남깁니다. 이건 모질라에서 아주 일반적인 코멘트인데, “이 코드를 수정하면 좋겠습니다. 만약 수정하지 않더라도 리뷰 결과는 긍정적입니다. 하지만 이 코드가 조금 더 수정되기를 희망합니다.”라는 뜻입니다.\n동작은 하겠지만, 수정했으면 좋겠다라는 의미. 나도 이런 코멘트를 많이 하는 편인데 사람에 따라 받아들이는 게 달라서 고민. 물론 이렇게 의켠을 주는 거슨 받아들이는 사람이 판단하라는 의미이긴 하지만\u0026hellip;\n개발자로서 당신은 엄격한 리뷰를 배우는 기회로 삼으려 했단 말이지요? 그렇다면 리뷰어로서 리뷰를 가르치는 수단으로 사용하기도 했나요?\n예, 물론입니다. 그러니까 패치 코드를 리뷰하는 것은 가르치는 일입니다. 리뷰어는 코드를 작성한 사람에게 옳다고 생각하는 것을 말하는 것입니다. 때때로 코멘트를 뒷받침할만한 이론이나 이유가 불분명할 때도 있지만, 리뷰어는 자기 주장을 해야 합니다. 리뷰어는 가능한 최선의 이유를 설명해야 하고 최선의 진보를 이뤄내야 합니다.\n코드 리뷰어의 의견은 코드 리뷰어의 생각을 말하는 것. 당연히 잘못된 생각이 있을 수 있으므로. 다만 위 글처럼 근거가 부족한 경우 설득하기 어렵다. 개발자들은 누구보다 자존심이 강하고 자신만의 스타일을 가지고 있는 것들이라.\n","date":"2014-08-24T10:55:06+09:00","permalink":"https://cychong47.github.io/post/2014/peom-eoddeohge-hamyeon-deo-naeun-sopeuteuweeoreul-mandeul-su-isseulgga/","summary":"\u003cp\u003e어떻게 하면 더 나은 소프트웨어를 만들 수 있을까? – 인터뷰 시리즈 part 1, Fernando Jimenez Moreno와 함께\u003c/p\u003e\n\u003cp\u003e출처 : \u003ca href=\"http://hacks.mozilla.or.kr/2014/08/how-can-we-write-better-software-interview-series-part-1/\"\u003ehttp://hacks.mozilla.or.kr/2014/08/how-can-we-write-better-software-interview-series-part-1/\u003c/a\u003e\u003cbr\u003e\n영문 원본 : \u003ca href=\"https://hacks.mozilla.org/2014/07/how-can-we-write-better-software-interview-series-part-1/\"\u003ehttps://hacks.mozilla.org/2014/07/how-can-we-write-better-software-interview-series-part-1/\u003c/a\u003e\u003c/p\u003e\n\u003cp\u003eTelefonica에서 근무하고 있으면서 MozillaOS 개발에 참여하고 있는 사람의 인터뷰 기사\u003cbr\u003e\nCode Reviewer 업무를 함에 있어 참고할 만한 좋은 내용이 많아 옮겨 본다.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e우리가 모질라와 함께 일한 것은 2011년으로 거슬러 올라갑니다. 두 회사 모두에게 잘 맞는 공통된 작업 절차를 찾기까지 꽤 많은 시간이 걸렸습니다. 제말은, 우리는 텔코(telco) 문화에서 일하던 사람입니다. 텔코 문화에서는 대부분의 작업들이 폐쇄적이고 비밀입니다. 이것은 모질라의 공개적이고 투명한 문화와는 반대죠.\u003c/p\u003e","title":"(펌) 어떻게 하면 더 나은 소프트웨어를 만들 수 있을까?"},{"content":"세미나 내용 Controller \u0026ndash;(OpenFlow)\u0026ndash; ovs-switchd \u0026ndash;(netlink)\u0026ndash; Datapath Datapath is in the kernel space OVDK move the kernel based OVS to user space. ovs-switched talk to OVDK with UDP 기존 OVDK는 port별 task handler(각각 별도의 core에서 동작) 그 결과 많은 core 필요 WR 이야기처럼 VM간 혹은 VM과 외부와의 통신을 담당하는 OVS용으로 많은 core를 사용하면 실제로 VM이 사용할 수 있는 core 개수가 줄어들어 문제 virtIO 사용시 VM에서 동작하는 application이 kernel stack의 필요한 경우 결국 OVDK와 VM내 커널 space간 copy가 필요함 최신 버전에서는 VM에서도 KNI based virtIO를 이용하도록 개선함. 확인 필요 Rainbow platform DPDK의 log library를 이용해서 외부 log server로 실시간으로 메시지 보냄. sFlow나 netFlow는 실시간이 아니라고. 음.. log library에 대한 확인 필요. 쓸만하면 log library를 별도로 만들지 말고 이걸 사용하는 것도 좋을 듯. log server는 NoSQL을 이용한 분석 서버라고 분석 서버에서 실시간 분석해서 의심되는 패킷을 받으면 OVS들에 명령을 내려 별도 DPI 서버로 경유하도록 해서 쉽게 Service Chaining 을 구현할 수 있다. DPDK를 접한 지는 오래 되었지만 초반에 한번 플랫폼이 정리된 후 크게 개선하지 못했다. 딱히 요구사항이 없어서 나름 안정된 걸 건드릴 이유를 찾지 못한 것이 표면적인 이유지만, 실은 기능 혹은 성능 개선을 해서 얻는 실질적인 장점이 별로 없어서.\n대신 DPDK가 나올 때마나 계속해서 새 버전을 이용할 수 있도록 미리미리 준비는 했지만.\nDPDK 내부를 공부하는 것도 흐지부지 하고, 그렇다고 가상화를 제대로 한 것도 아니고. 쩝.\n","date":"2014-08-21T12:11:18+09:00","permalink":"https://cychong47.github.io/post/2014/sdn-expert-group-semina-play-with-dpdk/","summary":"\u003ch1 id=\"세미나-내용\"\u003e세미나 내용\u003c/h1\u003e\n\u003cul\u003e\n\u003cli\u003eController \u0026ndash;(OpenFlow)\u0026ndash; ovs-switchd \u0026ndash;(netlink)\u0026ndash; Datapath\u003c/li\u003e\n\u003cli\u003eDatapath is in the kernel space\u003c/li\u003e\n\u003cli\u003eOVDK move the kernel based OVS to user space.\n\u003cul\u003e\n\u003cli\u003eovs-switched talk to OVDK with UDP\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e기존 OVDK는 port별 task handler(각각 별도의 core에서 동작)\n\u003cul\u003e\n\u003cli\u003e그 결과 많은 core 필요\u003c/li\u003e\n\u003cli\u003eWR 이야기처럼 VM간 혹은 VM과 외부와의 통신을 담당하는 OVS용으로 많은 core를 사용하면 실제로 VM이 사용할 수 있는 core 개수가 줄어들어 문제\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003evirtIO 사용시 VM에서 동작하는 application이 kernel stack의 필요한 경우 결국 OVDK와 VM내 커널 space간 copy가 필요함\n\u003cul\u003e\n\u003cli\u003e최신 버전에서는 VM에서도 KNI based virtIO를 이용하도록 개선함. 확인 필요\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003eRainbow platform\n\u003cul\u003e\n\u003cli\u003eDPDK의 log library를 이용해서 외부 log server로 실시간으로 메시지 보냄. sFlow나 netFlow는 실시간이 아니라고. 음..\u003c/li\u003e\n\u003cli\u003elog library에 대한 확인 필요. 쓸만하면 log library를 별도로 만들지 말고 이걸 사용하는 것도 좋을 듯.\u003c/li\u003e\n\u003cli\u003elog server는 NoSQL을 이용한 분석 서버라고\u003c/li\u003e\n\u003cli\u003e분석 서버에서 실시간 분석해서 의심되는 패킷을 받으면 OVS들에 명령을 내려 별도 DPI 서버로 경유하도록 해서 쉽게 Service Chaining 을 구현할 수 있다.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003eDPDK를 접한 지는 오래 되었지만 초반에 한번 플랫폼이 정리된 후 크게 개선하지 못했다. 딱히 요구사항이 없어서 나름 안정된 걸 건드릴 이유를 찾지 못한 것이 표면적인 이유지만, 실은 기능 혹은 성능 개선을 해서 얻는 실질적인 장점이 별로 없어서.\u003c/p\u003e","title":"SDN expert group 세미나 - Play with DPDK"},{"content":" 그러나 생각하기 위한 시간을 내는 것으로는 부족해 보인다. 자신의 믿음에 부합되는 정보만을 찾는 편향이 인간에게는 있다고 했다. 혼자 생각한다고 그런 편향에서 벗어날 수 있을 것 같지는 않다.\n▶그렇다. 아파트 가격이 오를 것이라고 믿으면 그에 부합되는 증거만을 보려고 한다. 반대되는 증거는 보려 하지 않는다. 그렇기 때문에 우리는 우리 곁에 \u0026lsquo;최고 이의 제기자(chief challenger officer)\u0026lsquo;를 둬야 한다. 내 의견에 이의를 제기하는 사람 말이다. 리더일수록 더욱 그래야 한다.\n에릭 슈밋 구글 회장의 회의 진행 방식도 좋다. 그는 회의에서 미심쩍은 얼굴을 하고 있는 사람을 찾는다. 그리고는 “당신의 견해는 무엇이냐”고 묻는다. 이는 자신과 다른 의견을 청취하기 위해서다.\n자신의 의견에 대해 동의하는 사람들의 의견만 듣고자 하는 리더는 갖다 버려야. 자신의 생각의 잘못된 점에 대해 기꺼히 지적할 수 있는 사람과 그런 문화를 만들지 못한 리더는 잘못된 결정의 모든 책임을 스스로 져야 한다. 듣기 싫은 소리를 듣지 못하게 만든 사람은 바로 본인이므로.\n차라리 혼자 생각할 시간 가져라\n","date":"2014-08-20T14:43:09+09:00","permalink":"https://cychong47.github.io/post/2014/carari-honja-saenggaghal-sigan-gajyeora/","summary":"\u003cblockquote\u003e\n\u003cp\u003e그러나 생각하기 위한 시간을 내는 것으로는 부족해 보인다. 자신의 믿음에 부합되는 정보만을 찾는 편향이 인간에게는 있다고 했다. 혼자 생각한다고 그런 편향에서 벗어날 수 있을 것 같지는 않다.\u003cbr\u003e\n▶그렇다. 아파트 가격이 오를 것이라고 믿으면 그에 부합되는 증거만을 보려고 한다. 반대되는 증거는 보려 하지 않는다. 그렇기 때문에 우리는 우리 곁에 \u0026lsquo;최고 이의 제기자(chief challenger officer)\u0026lsquo;를 둬야 한다. 내 의견에 이의를 제기하는 사람 말이다. 리더일수록 더욱 그래야 한다.\u003cbr\u003e\n에릭 슈밋 구글 회장의 회의 진행 방식도 좋다. 그는 회의에서 미심쩍은 얼굴을 하고 있는 사람을 찾는다. 그리고는 “당신의 견해는 무엇이냐”고 묻는다. 이는 자신과 다른 의견을 청취하기 위해서다.\u003c/p\u003e","title":"차라리 혼자 생각할 시간 가져라"},{"content":"p19\n\u0026lsquo;인생은 해석\u0026rsquo;이라는 말이 있다. 인생을 살면서 많은 사건을 겪게 되는데, 그 사건들을 어떻게 해석하느냐에 따라 삶의 방향이 달라진다는 뜻이다. 마찬가지로 우리가 살고 있는 시대를 명확하게 바라보고 해석할 필요가 있다. 그에 다라 우리가 삶을 사는 방식과 이 사회가 문제에 대처해나가는 방향은 완전히 달라진다.\n해석에 따라 어떻게 나에게 의미를 갖는 지가 달라진다.\np109\n문제는 목표과 자세다. 성공의 지름길만 걸어가는 왕도는 없다. 오히려 외도를 하면서도, 전혀 다른 커뮤니티에 참여하면서 기회를 포착하기도 한다. 도전을 통해 얻은 시행착오오 처절한 조절도 커리어에는 오히려 큰 도움이 된다.\np109\n여러분들은 앞날을 내다보면서 점들을 연결할 수는 없습니다. 여러분들은 단지 과거를 돌이켜보는 와중에 그것들을 연결할 수 있을 뿐입니다. 그러니 여러분은 그 점들이 미래에 어떤 식으로든 연결된다는 사실을 믿어야만 합니다. 여러분의 배짱, 운명, 인생, 업, 그게 무엇이든 간에 여러분은 믿음을 가져야만 합니다. 이런 방식은 절대로 저를 실망시키지 않았습니다. 그리고 제 인생에 힘이 되었습니다.\n스티브 잡스의 말. 미래를 예측할 수는 없지만 현재가 반드시 미래에 중요한 영향을 준다는 점은 분명하다는\n그런 점의 조합을 축적된 커리어로 만드는 것은 본인에게 달려 있다. 똑같은 일을 하더라도 그것을 돈만 받으면 된다는 소모적인 시간 때우기로 볼것이냐, 미래를 위한 발판으로 삶을 것이냐에 따라 미래는 전혀 다르게 다가올 것이다. 누군가에게는 없어져버리는 비용이요, 또 다른 누군가에게는 장래를 위한 투자다.\np113\n꿈? 그게 어떻게 네 꿈이야? 움직이질 않는데? 그건 별이지. 하늘에 떠 있는, 가질 수도 없는, 시도조차 못 하는 쳐다만 봐야 하는 별. 네가 뭔가를 해야 될 거 아냐. 조금이라도 부딪치고 애를 쓰고 하다못해 계획이라도 세워봐야 거기에 네 냄새든 색깔이든 발라지는 거 아냐!\np121\n제품 기획자는 나름대로 차별화 전략을 마련해서 만반의 준비를 한다. 그런데 사람들이 흔히 범하는 오류 중 하나는 \u0026lsquo;왜\u0026rsquo;라는 근본적인 질문을 던지지 않는 것이다.\n단순히 고객이 원해서가 아니라 고객의 왜 원하는 지를 생각해야 한다.\np123\n결국 \u0026ldquo;왜\u0026quot;라는 질문을 던지고, 그것을 실험해서 구현한 기업이 승자가 되었다.\np127\nEmmanuel Pastreich교수(페스트라이쉬)는 창의적인 생각에 대해 다음과 같이 정의한다. \u0026ldquo;창의적인 생각은 새로운 무엇인가를 창조하는 것이 아닌, 우리 주변의 것을 다르게 보고 생각함으로써 그것에 또 다른 생명을 부여하는 것이다.\u0026rdquo;\np129\n산업화 시대에는 어느 한 분야만 잘해도 조직의 일원으로서 공헌할 수 있었다. 그러나 융합의 시대에는 개인의 총제적 역량이 중요하다. 자기 자신의 강점을 살릴 수 있는 열린 교육이 필요하다. 젊은 시절부터 비좁은 공간으로 밀어 넣은 상태에서 사회에 진출한 후 열린 마인드를 가지라고 하는 것은 앞뒤가 맞지 않는다. 절반의 지식만 가지고 사회에 나온 젊은이들은 다가올 미래 사회에 적응하기가 힘들다.\np192\n자기 기술을 가진 기업은 사업의 주도권을 쥐게 된다. 자기 기술이 없다면 사업 협력 자체를 할 수 없다. 또한 기술이 없다면 문제를 해결할 능력도 없고, 아예 대화에 끼어들 수도 없다. 물론 그 기술은 경쟁력 있는 기술을 의미한다.\n","date":"2014-08-17T14:29:31+09:00","permalink":"https://cychong47.github.io/post/2014/nuga-miraereul-gajil-geosinga/","summary":"\u003cp\u003ep19\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u0026lsquo;인생은 해석\u0026rsquo;이라는 말이 있다. 인생을 살면서 많은 사건을 겪게 되는데, 그 사건들을 어떻게 해석하느냐에 따라 삶의 방향이 달라진다는 뜻이다. 마찬가지로 우리가 살고 있는 시대를 명확하게 바라보고 해석할 필요가 있다. 그에 다라 우리가 삶을 사는 방식과 이 사회가 문제에 대처해나가는 방향은 완전히 달라진다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e해석에 따라 어떻게 나에게 의미를 갖는 지가 달라진다.\u003c/p\u003e\n\u003cp\u003ep109\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e문제는 목표과 자세다. 성공의 지름길만 걸어가는 왕도는 없다. 오히려 외도를 하면서도, 전혀 다른 커뮤니티에 참여하면서 기회를 포착하기도 한다. 도전을 통해 얻은 시행착오오 처절한 조절도 커리어에는 오히려 큰 도움이 된다.\u003c/p\u003e","title":"(책) 누가 미래를 가질 것인가?"},{"content":"회사라고 치자. 계열사에 회장이 떴다. 회장이 계열사 직원들로부터 소원수리를 받았다. 심각한 문제다. 그런데 사장들이 뻔히 문제점을 알고 있으면서 무시하고 아무 일도 안하고 있는 거다. 그러면 어떻게 될까?\n당장 질책이 떨어지고, 문제의 경중의 따라 사장이 짤릴 수도 있다.\n지금 교황이 방한한 일을 그렇게 보면 과대해석일까?\n교황은 와서 세월호 등을 포함해 대한민국에서 소외되고 있는 많은 사람들을 만난다. 바쁜 그 며칠간의 일정이 그렇다. 하지만 일년 내내 대한민국에 있는 추기경이라는 사람은 뭐가 그리 바쁜 지 힘없고 고통받는 이들을 외면해 왔다. 도대체 뭐에 써먹는 추기경인지. 자기가 챙겨야 할 고통받는 사람들은 최소한 재산이 넉넉하거나 권력이 있어야 하나보다.\n교황이 온다고 반대 집회하는 기독교(일부겠지만 설마)인 들은 뭐 논할 가치가 없는 것들이니 입을 가치도 없고\n교황이 온다고 경제가 살아난다고 기사 쓰는 쓰레기 언론. 참 천박하다 천박해.\n","date":"2014-08-16T14:30:53+09:00","permalink":"https://cychong47.github.io/post/2014/jonggyoyi-cabyeoldoen-sarang/","summary":"\u003cp\u003e회사라고 치자. 계열사에 회장이 떴다. 회장이 계열사 직원들로부터 소원수리를 받았다. 심각한 문제다. 그런데 사장들이 뻔히 문제점을 알고 있으면서 무시하고 아무 일도 안하고 있는 거다. 그러면 어떻게 될까?\u003c/p\u003e\n\u003cp\u003e당장 질책이 떨어지고, 문제의 경중의 따라 사장이 짤릴 수도 있다.\u003c/p\u003e\n\u003cp\u003e지금 교황이 방한한 일을 그렇게 보면 과대해석일까?\u003c/p\u003e\n\u003cp\u003e교황은 와서 세월호 등을 포함해 대한민국에서 소외되고 있는 많은 사람들을 만난다. 바쁜 그 며칠간의 일정이 그렇다. 하지만 일년 내내 대한민국에 있는 추기경이라는 사람은 뭐가 그리 바쁜 지 힘없고 고통받는 이들을 외면해 왔다. 도대체 뭐에 써먹는 추기경인지. 자기가 챙겨야 할 고통받는 사람들은 최소한 재산이 넉넉하거나 권력이 있어야 하나보다.\u003c/p\u003e","title":"종교의 차별된 사랑"},{"content":"p76 이 아이디어를 MIT 경영대학원 교수인 Glen Urban에게 가져갔을 때 그는 \u0026ldquo;이 아이디어는 당신이 생각하는 것보다 훨씬 스케일이 크다. 두 배의 속도로 움직이고, 두 배 크게 생각해야 한다\u0026quot;고 조언했다.\n\u0026ldquo;이 아이디어는 당신이 생각하는 것보다 훨씬 스케일이 크다. 그러므로 도전하지 말아라\u0026rdquo; 라고 말할 줄 알았는데\u0026hellip;\np85 자포스 CEO 토니. 회사를 판매한 경우 그 돈을 가지고 할 수 있는 일을 나열해 봤더니 대부분의 것들이 회사를 팔지 않고도 할 수 있는 일이 대부분이었다고. 시간이 부족할 뿐. 그래서 회사를 판매하지 않기로 결심했다고\nExit하는 것이 목적이 아니라 자신이 하고 싶은 일을 하는 것이 목적이었으므로 가능한 생각. 그 덕분에 처음 제안받는 것 보다 훨씬 큰 금액으로 회사를 넘길 수 있긴 했지만\np92 짐 : 지금까지 스탠퍼드 학생을 많이 채용했는데, 사람을 채용할 때는 무엇을 가장 중점점으로 보았나요?\n마크 : 첫째는 지능(raw intelligence)입니다. 10년의 경력을 가진 사람을 뽑을 수도 있습니다. 그런 사람은 필요한 걸 금방 만들어내겟지요. 그러나 경험이 없더라도 똑똑한 사람은 순식간에 필요한 걸 다 배운 후, 결국은 10년 경력자가 해결하지 못하는 문제를 해결해냅니다. 둘째는 우리가 추구하는 것과 얼마나 잘 맞는지를 봅니다. 똑똑하고 기술이 있다 하더라도 우리의 비전을 믿지 않는다면 열심히 일하지 않겠죠.\n마크는 회삭의 비전을 공유한 유능한 인재들이 자신의 일에 집중할 수 있도록 배려하는 것을 그 무엇보다 중요하게 생각하고, 실제로 그것을 운영 방침으로 실천하고 있는 것이다.\nCEO의 생각이 돈을 버는 것 보다는 자신이 생각하는 것을 이루는 것이고, 그걸 위해 노력하는 인재들이 불편을 겪지 않도록 하는 것을 최우선으로 한다. 멋지지 않나? 과연 그런 회사가 얼마나 될까? 자신의 목숨을 부지하기 위해 일하는 사람도 있을 것이고, 주주들이나 이사회의 요구를 만족시키기 위해 하는 사람도 있을 텐데.\np98 파괴적 기술(Disruptive Technology). Clayton M. Christensen 교수의 저서 \u0026lt;혁신 기업의 딜레마, Innovator\u0026rsquo;s Dilemma\u0026gt;\np101 넷플릭스가 끊임없이 새로운 골리앗과 다윗들의 도전을 받으면서도 지속적으로 성장할 수 있었던 요인은 무엇일까? 나는 그 답을 넷플릭스의 파괴적 혁신과 기업문화 속에서 찾았다.\n자신의 기존 cash cow를 과감하게 포기하지 않으면 쉽게 레드오션이 되는 것을 피할 수 없다. 물론 경우에 따라서는 확실한 시장 지배력을 가졌다면 그 시장을 손쉽게 포기하는 것은 어려울 것이다. 그만한 새로운 시장을 만들어 내는 것도 쉬운 일은 아니니. 하지만, 시장 지배력이 낮은 회사라면 과감히 그 시장을 포기하고 새로운 시장을 만들어내는 것도 고려해야 한다. 얼마 안되는 그리고 점점 경쟁이 심해지고, 점점 작아지는 시장 점유율을 유지하기 위해 들이는 노력은 점점 그 성과가 줄어들 것이다.\np108 넷플릭스의 기업문화 Values are what we value(우리의 가치는 우리가 가치있게 여기는 것) High Performance Free \u0026amp; Responsibility Context, not Control Highly Aligned, Loosely Coupled Pay Top of Market Promotions \u0026amp; Development Netflix Culture\np108 Values are what we value 대부분의 회사들이 내세우는 가치는 실제와 거리가 먼 경우가 많다. 어떤 회사가 내세우는 가치 중 하나가 \u0026lsquo;용기\u0026rsquo;였다고 하자. 옳지 않은 방향으로 갈 때 바른말을 할 수 있는 용기 말이다. 하지만 실제로는 바른말을 하지 않은 사람이 보상을 받거나 승진한다면, 회사의 가치는 그저 공허한 말에 불과할 뿐이고, 직원들은 더 깊은 좌절에 빠질 것이다. 회사의 승진 원칙은 매우 중요하다. 직원들은 대개 회사에서 승진한 사람이 추구하는 것이 회사가 중요하게 여기는 가치라고 생각한다. 엉뚱한 사람이 승진하면, 직원들은 \u0026lsquo;아, 이 회사에서 중요하게 생각하는 것은 도덕성, 전문성, 팀워크가 아니라 상사에게 얼마나 잘 보이느냐구나\u0026rsquo;라고 생각하게 된다.\n책에서는 미국 회사 \u0026lsquo;엔론\u0026rsquo;의 예를 들었지만, 내 생각에는 이명박네 가훈이 \u0026lsquo;정직\u0026rsquo;이라고 하는 걸 드는게 더 쉽게 이해가 될 듯 하다.(웃기고 자빠졌네)\n넷플릭스가 정의하는 멋진 일터는 \u0026lsquo;끝내주는 동료들이 있는 곳이다\u0026rsquo;. 최고의 동료들을 끌어오는 데 효과적인 일들만 한다는 것을 명시해놓앗다.\n\u0026hellip; 회사에서 자신에게 영감을 주고 함께 있으면 기분 좋은 사람들이 줄어든다면, 그 조직은 곧 떠나고 싶어진다. \u0026lsquo;끝내주는 사람들\u0026rsquo;이 회사에 많다는 것은 아주 중요하다. 끝내주는 사람이 많다면 그들은 또 다른 끝내주는 사람을 데려올 것이고, 그들은 다른 끝내주는 사람들 때문에 조직에 남게 된다.\n그런데 회사 규모가 커지면 할 일은 많고 사람은 부족해진다. 그래서 평범한 사람들을 채용하기 시작한다. 처음에는 괜찮다. 그러나 평범한 사람이 많아지면 회사 분위기가 이상하게 흘러간다. 끝내주는 사람들은 평범한 사람들에게 둘러싸야 좌절감을 느끼고 회사를 떠난다. 결국 평범한 사람들만 남은 회사는 내리막길을 걷기 마련이다.\n이 부분에 대해서는 조금 이해하기 어렵다. 그럼 평범한 사람은 좋은 문화를 가진 회사에 들어가지도 말라는 것인지? 왜 평범한 사람들이 많아지만 회사 분위기가 이상하게 흘러간다고 단정하는 걸까? 평범한 사람들을 데리고 좋은 문화나 제품을 만들 수 있는 능력을 가진 \u0026ldquo;끝내주는 사람\u0026quot;은 없다는 건가? 오직 자기와 수준이 비슷한 끝내주는 사람들하고만 일을 해야 끝내주는 결과를 낸다는 건 지나친 비약이 아닐까?\np109 넷플릭스 - 자유와 책임 넷플릭스는 \u0026lsquo;책임감 있는 사람은 자유가 있을 때 더 큰 성과를 내고, 그 자유를 누릴 자격이 있다\u0026quot;고 말한다.\n대부분의 회사는 규모가 커질수록 자유를 제약한다. 실수를 방지하기 위해서다. 실수로 인한 피해가 커지면 성과가 좋은 직원들의 비율이 낮아지고, 결국은 시장 상황이 바뀌면서 회사가 망하기 때문이다.\n그들은 복잡성이 증가하는 것보다 빠른 속도로 인재의 비율을 높여갓다. 즉 사업의 복잡성이 높아짐에 따라 그 보다 빨리 우수한 직원의 비율을 늘려나간 것이다.\n이를 달성하는 구체적인 방법은 업계 최고의 보상을 해주고, 가치가 높은 사람들을 끌어오고, 높은 성과를 내는 문화를 계속해서 발전시켜 나가는 것이다. 또한 자유의 정도를 높이기 위해 프로세스를 끊임없이 개선해 나간다. 단 실수를 방지한다는 명목으로 자꾸 새로운 규칙을 만들지는 않는다.\n마지막 문장은 절대 동감. 다만 위 글에서 설명한 것처럼 넷플릭스는 \u0026lsquo;끝내주는 사람\u0026rsquo;들로 구성된 조직이라 저게 가능한 것인지? \u0026lsquo;평범한\u0026rsquo; 사람들이 더 많은 조직에는 적용할 수 없는 것인지 궁금하다. 그래서 그렇게 일반 회사에는 쓸데없는 프로세스가 많고, 체크리스트가 시간이 갈수록 계속해서 늘어나는 것인지.\np110 - 넷플릭스에 가장 유리한 방향으로 할 것 \u0026lsquo;마치 자신의 돈인 것처럼 쓰기\u0026rsquo;\np111 능력계발에 관해서도, 높은 성과를 내는 사람들은 그들이 뛰어난 사람들과 큰 도전에 둘러써야 있는 한 경험과 관찰, 토론 등을 통해 스스로 성장한다고 믿는다. 즉 교육이나 멘토링 등의 형식적인 프로그램은 능력계발에 거의 효과가 없다고 생각한다.\n우수한 인재들은 회사가 별도로 교육을 하지 않아도 스스로 기회를 찾아 배우고 성장한다. 그것이 그들에게 즐거움을 주기 때문이다. 단 그들은 회사에 성장하고 배울 기회가 없다고 느끼면 주저없이 떠날 것이다.\n125 Dropbox 투자자들은 미팅을 할 때마다 시장이 이미 기존 제품들로 포화상태고, 그 제품들 중 돈을 많이 버는 회사는 없으며, 그 회사들이 해결하려는 문제도 사람들에게는 그다지 중요하지 않다고 했다. 드루는 물었다. \u0026ldquo;그 다른 제품들을 써봤냐요?\u0026rdquo; \u0026ldquo;예\u0026quot;라고 대답하면 그는 또 물었다. \u0026ldquo;부드럽게 동작하던가요?\u0026rdquo; 그 대답은 항상 \u0026ldquo;아니오\u0026quot;였다. 그렇지만 벤처케피털리스트들은 드루의 비전을 이해할 수 없었다. 드루는 소프트웨어가 \u0026lsquo;마법처럼 동작하면\u0026rsquo; 사람들이 몰려들 것이라고 믿었다.\n이미 많은 솔류션이 존재해도, 그 솔류션이 문제를 우아하게 해결하고 있지 못한다면 분명 시장은 아직 있는 것이다.\n149 \u0026lsquo;성장\u0026rsquo;이 빠른 회사에서 정보는 한 달만 지나도 모두 무의미한 것이 되어버리기 때문이다.\n성장이 빠르지 않은 회사에서도 정보는 금방 썩게 된다. 인정하지 않을 뿐이지.\n","date":"2014-08-15T14:58:34+09:00","permalink":"https://cychong47.github.io/post/2014/seupin-is/","summary":"\u003ch2 id=\"p76\"\u003ep76\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e이 아이디어를 MIT 경영대학원 교수인 Glen Urban에게 가져갔을 때 그는 \u0026ldquo;이 아이디어는 당신이 생각하는 것보다 훨씬 스케일이 크다. 두 배의 속도로 움직이고, 두 배 크게 생각해야 한다\u0026quot;고 조언했다.\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003e\u0026ldquo;이 아이디어는 당신이 생각하는 것보다 훨씬 스케일이 크다. 그러므로 도전하지 말아라\u0026rdquo; 라고 말할 줄 알았는데\u0026hellip;\u003c/p\u003e\n\u003ch2 id=\"p85\"\u003ep85\u003c/h2\u003e\n\u003cblockquote\u003e\n\u003cp\u003e자포스 CEO 토니. 회사를 판매한 경우 그 돈을 가지고 할 수 있는 일을 나열해 봤더니 대부분의 것들이 회사를 팔지 않고도 할 수 있는 일이 대부분이었다고. 시간이 부족할 뿐. 그래서 회사를 판매하지 않기로 결심했다고\u003c/p\u003e","title":"(책) 스핀 잇"},{"content":"SDN이 주로 operator 입장에서 비용 절감, 관리 용이, 혁신 용이, 자동화(programmable)의 장점을 이야기하는데 NTT DOCOMO는 실제로 이런 방법을 통해 사용자에게 제공할 수 있는 가치(end-user value)에 대해 이야기한다.\n조금 과장하면 앞 선 장점 나열은 비-애플인 듯하고, 후자는 애플의 발표인 듯. 단순히 Operator에게 비용뿐만 아니라 인지도를 올릴 수 있는 방법을 제시한다는 면에서 참 느낌이 다르다.\nSDN: Helping Real People in a Real Crisis | 6WIND Blog\n","date":"2014-08-15T13:04:09+09:00","permalink":"https://cychong47.github.io/post/2014/sdnyi-jinjeonghan-gaci/","summary":"\u003cp\u003eSDN이 주로 operator 입장에서 비용 절감, 관리 용이, 혁신 용이, 자동화(programmable)의 장점을 이야기하는데 NTT DOCOMO는 실제로 이런 방법을 통해 사용자에게 제공할 수 있는 가치(end-user value)에 대해 이야기한다.\u003c/p\u003e\n\u003cp\u003e조금 과장하면 앞 선 장점 나열은 비-애플인 듯하고, 후자는 애플의 발표인 듯. 단순히 Operator에게 비용뿐만 아니라 인지도를 올릴 수 있는 방법을 제시한다는 면에서 참 느낌이 다르다.\u003c/p\u003e\n\u003cp\u003e\u003ca href=\"http://www.6windblog.com/sdn-helping-real-people-in-a-real-crisis/\"\u003eSDN: Helping Real People in a Real Crisis | 6WIND Blog\u003c/a\u003e\u003c/p\u003e","title":"SDN의 진정한 가치"},{"content":"화웨이가 어떻게 지금과 같이 세계 2위의 통신업체가 될 수 있었는지 CEO인 런정페이를 중심으로 그 비결을 설명한 책.\n늙지 않는 조직을 만들기 위해 끊임없이 노력하고 일괄 사퇴 후 재취업과 같은 극단적인 선택도 마다하지 않은 화웨이. 시스코가 괜히 건드려 무료 홍보해주고(마치 애플이 삼성을 고소해 홍보해 줬다는 것과 유사) 모토롤라가 CEO가 바뀌지 않았으면 화웨이의 시스템 사업을 인수해서 지금의 화웨이가 없었을 텐데. 만일 모토로라가 화웨이의 사업을 인수했다 해도 모토로라의 시스템 사업은 망했을 거라고 생각. 화웨이는 런정페이가 없으면, 혹은 그가 만들어 놓은 문화와 시스템이 동작하지 않으면 다른 회사와 다름이 없으므로.\n전체적으로 중국인 입장에서 쓴 글이라 칭찬 일변도라는 점이 거슬리지만 결과론적으로 지금과 같은 거대업체가 된 것을 부정할 수 없으므로 배는 아프지만 인정할 수 밖에…\n\u0026ldquo;무릇 발전은 다른 사람이 아닌 내 손으로 쥐어야 합니다.\u0026rdquo;\n아웃 소싱을 폄하하는 것은 결코 아니지만 결국 핵심 기술은 내재화하지 않으면 의미가 없다. 핵심 기술이 아닌 부분을 아웃소싱한 후 그 위에 나만의 핵심 기술을 이용한 부가가치를 추가하지 않으면\u0026hellip;\n\u0026ldquo;제도와 문화가 신은 아니지만 그 힘은 실로 거대합니다\u0026rdquo;\n주먹구구식으로 운영되는 조직은 커질 수 없다. 문화의 중요성을 강조.\n모토로라는 고객 니즈에 더디게 반응한 것은 물론, 자신이 만든 틀 안에 갇혀 고객을 무시하고 상식을 외면한 채 오로지 기술 제일주의를 고집했다.\n이리듐 프로젝트. 모토로라가 몰락하게 된 직접적인 계기가 된. 성공했으면 어떻게 되었을까 싶기도 하다. 지금처럼 3GPP 그런 스펙 다 무시하고 있지 않았을까?\n화웨이가 지난 20여 년 동안 \u0026lsquo;유성\u0026rsquo;이라는 명단에 들어가지 않을 수 있었던 가장 중요한 요소 중 하나는, 자본의 유횩과 지배에서 벗어나려고 발버둥쳤다는 점이다.\n오직 ROI만 논하는 자본주의가 위대한 기업을 절름발이로 만든 것을 보고 이렇게 생각했다고\n\u0026ldquo;단시간 안에 매주 40시간씩 일한다고 산업 전환이나 업그레이드가 그렇게 쉽게 진행될 수 있을까요? 매주 40시간씩 일하면 일반 노동자를 생산할 수는 있겠지만 음악가, 무용가, 과학자, 프로그래머, 상인 등은 만들어낼 수 없습니다.\u0026rdquo;\n아프다. 그리고 두렵다.\n\u0026ldquo;기업이 발전하려면 낭과 패의 세 가지 특징을 모두 지니고 있어야 합니다.\n첫째, 민감함 후각,\n둘째, 불굴의 진취성,\n셋째, 팀플레이 정신.\u0026rdquo;\n앞다리가 길고 뒷다리가 짧은 늑대가 \u0026lsquo;낭\u0026rsquo;, 반대인 늑대가 \u0026lsquo;패\u0026rsquo;란다. 그래서 두 짐승이 같이 나란히 걷다가 사이가 벌어지면 순간 균형을 잃고 넘어져 당황하게 되는 것을 가리켜 낭패라고 한단다.\nIT기업에게 가장 중요한 건 재능 있는 사람이죠. 꿈을 가진 사람들이 함께 모여 일하도록 하려면, 이들을 더욱 단단히 묶어놓고 생사고락을 함께하는 운명 공동체로 만들어야 합니다.\n인재가 제일 중요한 건 어느 분야나 똑같다. 인재를 특별히 대우하는 것은 적어도 바라지 않더라도 홀대하지는 말아야 .\n2011년 말 현재, 14만 6000명에 달하는 화웨이 직원 중에 6망 5596명이 자사 지분을 보유하고 있다. 상장사 중에서 주주가 가장 많이 분산되어 있고, 직원의 자사 지분 보유율이 가장 높은 유일한 사례라 하겠다.\n정말 특이한 형태의 회사\n미국의 클린턴 정부는 National Information Infrastructure(Information Super Highway) 프로젝트를 본격적으로 추진하면서 국가적 차원에서 아이디어가 중심이 되는 시대, 동시에 파괴를 수반한 창조의 시대가 도래했다고 선포했다. 요컨대 구제도의 산물에 대한 철저한 파괴라는 대가를 치르며 공격적으로 아이디어와 혁신을 추진했다.\n과거의 부정을 포함한 혁신\n\u0026ldquo;장기적으로 개방 정책을 추진한 화웨이의 전략은 단 한 번도 흔들린 적이 없습니다. 어떠한 순간에도 굴하지 말고 세상을 향해 문을 활짝 열어놓으십시오. 문을 닫은 상태에서 외부 에너지를 흡수하지 못한다면 결국 자신만 성장하지 못합니다. 그리고 자신에게는 항상 엄격하십시오. 정확하고 객관적으로 자신을 대할 줄 알아야 합니다. 그렇지 않으면 개방은 지속될 수 없습니다\u0026rdquo;\n","date":"2014-08-14T14:41:23+09:00","permalink":"https://cychong47.github.io/post/2014/hwaweiyi-widaehan-neugdaemunhwa/","summary":"\u003cp\u003e화웨이가 어떻게 지금과 같이 세계 2위의 통신업체가 될 수 있었는지 CEO인 런정페이를 중심으로 그 비결을 설명한 책.\u003c/p\u003e\n\u003cp\u003e늙지 않는 조직을 만들기 위해 끊임없이 노력하고 일괄 사퇴 후 재취업과 같은 극단적인 선택도 마다하지 않은 화웨이. 시스코가 괜히 건드려 무료 홍보해주고(마치 애플이 삼성을 고소해 홍보해 줬다는 것과 유사) 모토롤라가 CEO가 바뀌지 않았으면 화웨이의 시스템 사업을 인수해서 지금의 화웨이가 없었을 텐데. 만일 모토로라가 화웨이의 사업을 인수했다 해도 모토로라의 시스템 사업은 망했을 거라고 생각. 화웨이는 런정페이가 없으면, 혹은 그가 만들어 놓은 문화와 시스템이 동작하지 않으면 다른 회사와 다름이 없으므로.\u003c/p\u003e","title":"(책) 화웨이의 위대한 늑대문화"},{"content":"출처 Heavy-ReadingQosmosDPI-SDN-NFVWhite-PaperJan2014.pdf 2014년 1월 전반적인 내용 The largest use case (by number of vendors citing it) is service assurance for QoS/QoE; the second largest is policy control (PCEF), which we believe is the largest use case by volume Half of respondents said that encryption of protocols is reducing the effectiveness of DPI . Packet metric analysis (heuristics) was identified as the main remedy - packet size, spacing, frequency DPI 용도 Service Awarence (QoS, QoE)가 가장 높음(60%) Policy Control(PCEF)도 비슷 3GPP TDF 기능. 표준 내용 확인 필요 Service Analystics system도 높은 관심 가입자 수준에서 분석하려는 의도가 많아짐. Customer prefrences and load/characteristics Real-time analytics Real-time subscriber data analysis and RAN congenstion control at cell level Pose hard challenge to engineers. Accurate real-time detection of application and protocols is essential. 대부분의 대형 벤더가 자체 DPI 솔류션 확보. 작은 업체일 수록 third-party solution 사용 대략 응답자의 30%가 third-party solution 사용하나, 대형 벤더의 응답율이 높아 실제 사용률은 더 높을 듯 암호화된 패킷 때문에 Packet Metric analysis(size, spacing, frequency) 등 DPI 이상의 기술로 해결해 가야 함. NFV는 새로운 제품 개발의 H/W 및 S/W 설계에 영향을 줄거라는 의견이 92%로 지배적. 그렇지만, 가상화 할때 고려하는 H/W platform으로는 COTS만큼 자체 H/W를 고려하고 있음 아직 어떤 것이 H/W platform인지 맞는 것인지 확신이 없기 때문에 그만큼 보수적으로 자체 플랫폼을 고려하는 것으로 분석됨. 그렇지만 appliance-selling(H/W) 모델에서 usage-selling(Software license) 모델로 이동할 거라는 예상 NFV와 표준화된 third-party component의 출현은 점점 outsouring 비율을 높일 거라는 예상. NFV/SDN을 고려한 DPI DPI는 Switch node의 Hypervisor(OVS), VM 내(DPI VNFC-Virtual Network Function) 그리고 Controller에 위치할 것으로 보임 VM내 DPI(DPI VNFC)는 ETSI ISG(July 2013)에서 정리한 공식 use case중 하나. ","date":"2014-08-12T15:10:23+09:00","permalink":"https://cychong47.github.io/post/2014/dpi-traffic-analysis-in-networks-based-on-nfv-and-sdn/","summary":"\u003ch2 id=\"출처\"\u003e출처\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"http://www.qosmos.com/wp-content/uploads/2014/01/Heavy-Reading_Qosmos_DPI-SDN-NFV_White-Paper_Jan2014.pdf\"\u003eHeavy-ReadingQosmosDPI-SDN-NFVWhite-PaperJan2014.pdf\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e2014년 1월\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"전반적인-내용\"\u003e전반적인 내용\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eThe largest use case (by number of vendors citing it) is service assurance for QoS/QoE; the second largest is policy control (PCEF), which we believe is the largest use case by volume\u003c/li\u003e\n\u003cli\u003eHalf of respondents said that encryption of protocols is reducing the effectiveness of DPI . Packet metric analysis (heuristics) was identified as the main remedy - packet size, spacing, frequency\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"dpi-용도\"\u003eDPI 용도\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eService Awarence (QoS, QoE)가 가장 높음(60%)\u003c/li\u003e\n\u003cli\u003ePolicy Control(PCEF)도 비슷\u003c/li\u003e\n\u003cli\u003e3GPP TDF 기능. 표준 내용 확인 필요\u003c/li\u003e\n\u003cli\u003eService Analystics system도 높은 관심\n\u003cul\u003e\n\u003cli\u003e가입자 수준에서 분석하려는 의도가 많아짐.\u003c/li\u003e\n\u003cli\u003eCustomer prefrences and load/characteristics\u003c/li\u003e\n\u003cli\u003eReal-time analytics\u003c/li\u003e\n\u003cli\u003eReal-time subscriber data analysis and RAN congenstion control at cell level\u003c/li\u003e\n\u003cli\u003ePose hard challenge to engineers.\u003c/li\u003e\n\u003cli\u003eAccurate real-time detection of application and protocols is essential.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e대부분의 대형 벤더가 자체 DPI 솔류션 확보. 작은 업체일 수록 third-party solution 사용\n\u003cul\u003e\n\u003cli\u003e대략 응답자의 30%가 third-party solution 사용하나, 대형 벤더의 응답율이 높아 실제 사용률은 더 높을 듯\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003cli\u003e암호화된 패킷 때문에 Packet Metric analysis(size, spacing, frequency) 등 DPI 이상의 기술로 해결해 가야 함.\u003c/li\u003e\n\u003cli\u003eNFV는 새로운 제품 개발의 H/W 및 S/W 설계에 영향을 줄거라는 의견이 92%로 지배적.\n\u003cul\u003e\n\u003cli\u003e그렇지만, 가상화 할때 고려하는 H/W platform으로는 COTS만큼 자체 H/W를 고려하고 있음\u003c/li\u003e\n\u003cli\u003e아직 어떤 것이 H/W platform인지 맞는 것인지 확신이 없기 때문에 그만큼 보수적으로 자체 플랫폼을 고려하는 것으로 분석됨.\u003c/li\u003e\n\u003cli\u003e그렇지만 appliance-selling(H/W) 모델에서 usage-selling(Software license) 모델로 이동할 거라는 예상\u003c/li\u003e\n\u003cli\u003eNFV와 표준화된 third-party component의 출현은 점점 outsouring 비율을 높일 거라는 예상.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"nfvsdn을-고려한-dpi\"\u003eNFV/SDN을 고려한 DPI\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003eDPI는 Switch node의 Hypervisor(OVS), VM 내(DPI VNFC-Virtual Network Function) 그리고 Controller에 위치할 것으로 보임\n\u003cul\u003e\n\u003cli\u003eVM내 DPI(DPI VNFC)는 ETSI ISG(July 2013)에서 정리한 공식 use case중 하나.\u003c/li\u003e\n\u003c/ul\u003e\n\u003c/li\u003e\n\u003c/ul\u003e","title":"DPI \u0026 Traffic analysis in networks based on NFV and SDN"},{"content":"Network 장비를 만드는 방법 중 가장 흔한 방법이 Networking에 최적화된 processor를 제공하는 업체로부터 processor를 구입하고, 그 processor와 함께 제공되는 SDK를 사용하는 것이다. 그러다보니 특정 업체의 processor를 위해 만든 S/W를 다른 processor로 포팅하는 경우 많은 부분을 수정해야 하는 경우가 많다.\n당연한 이야기지만, 특정 processor에 종속적인 부분은 해당 processor가 제공하는 H/W accelerator 를 이용하는 코드나 해당 processor의 특성에 맞게 설계된 구조 등이다. 다른 processor로 포팅하는 경우 \u001c전자의 경우는 새로운 processor에서 대응되는 API등이 제공되면 비교적 쉽게 변경할 수 있다. 후자의 경우는 좀 더 근본적인 문제라 다른 차원의 문제가 되지만. 예를 들어 특정 업체는 processor 차원에서 packet ordering을 제공하는 경우가 있다. 그러므로 이 경우 multi-core 환경에서 여러 core들은 서로 다른 core가 같은 flow(순서가 보장되어야 하는 패킷들의 흐름)에 속하는 패킷을 처리하는 지 신경 쓸 필요없이 패킷을 처리하고, 패킷을 최종적으로 전송할 때만 순서를 맞추는 작업을 H/W 기능을 이용해서 수행하면 된다. 반면 이런 H/W 기능이 없는 경우 근본적으로 flow별로 서로 다른 core에게 전달되도록 하는 등의 고려가 필요할 수 있다.\n아무튼 특정 processor 하나만 사용하는 경우가 아니라 동시에 여러 가지 processor를 이용하거나, 특정 processor가 단종되거나 성능이나 기능상의 이유로 다른 processor로 대체되는 경우 기존에 해당 processor를 위해 작성한 S/W를 포팅해야 하는 고통을 피할 수 없다.\n통상 이렇게 processor의 H/W 기능을 활용하여 고속으로 패킷을 처리하는 부분을 Data Plane이라고 하고, Data Plane의 동작에 필요한 작업이 수행하는 부분을 Control Plane이라고 한다. 예를 들면 패킷 처리에 필요한 라우팅 테이블 설정 등이 Control Plane이 수행하는 대표적인 업무 중 하나다.\nOpenDataPlane은 각 processor에서 제공하는 SDK와 이를 이용해 개발한 S/W간의 의존성을 제공할 수 있도록 abstraction layer를 하나 정의한 것이다.\n그림 출처 : http://www.opendataplane.org/\n그러므로 ODP의 성공은 SDK를 제공하는 업체의 협력이 핵심이다. 만일 업체의 협력이 없다면 누군가는 매번 업체의 SDK가 나올 때마다 해당 업체의 SDK를 ODP API에 맞게 수정하는 작업을 해야 할 것이다.\n현재 ODP는 다음과 같은 업체 들이 지원하고 있다. 주로 Silicon vendor가 핵심이고, 이를 이용할 업체도 몇 몇 있다.\napplied micro\nARM\nBroadcom (XLP processor를 개발한 RMI를 현재 보유)\nCavium (Multi-Core 환경에서 많이 사용하는 Octeon Processor 개발)\nFreescale\nTexas Instruments\nLinaro (ARM의 확대를 위한 다양 분야에서의 S/W를 ARM 으로 포팅하기 위해 노력하고 있는 open source community. Linux Kernel 3.14 기준으로 3번째 Contributor라고. ARM을 이용한 가상화 역시 Linaro가 주축으로 밀고 있다.)\nLSI\nMontavista(Cavium에서 인수했으므로 당연히 Octeon Processor의 M/S 확대를 위해서라도 열심히 할 듯)\nNSN\nCISCO\n참고로 Intel DPDK는 없다.\n재밌는(?) 건 openDataplane.org도 wordpress를 기반으로 하고 있다는. 정말 WP가 blog가 아니라 CMS 계를 평정했다고 들었는데 실감된다.\n참고로 홈페이지가 접속되지 않는 곳을 위해 소스 코드나 문서등은 git repository를 통해 접근할 수 있다.\nhttps://git.linaro.org/lng/odp.git https://git.linaro.org/lng/odp-architecture.git https://git.linaro.org/lng/odp-apps.git [1] http://www.opendataplane.org/supporters/\n[2] https://wiki.linaro.org/LEG/Engineering/Virtualization\n[3] http://www.linaro.org/projects/\n","date":"2014-05-24T14:15:25+09:00","permalink":"https://cychong47.github.io/post/2014/opendataplane/","summary":"\u003cp\u003eNetwork 장비를 만드는 방법 중 가장 흔한 방법이 Networking에 최적화된 processor를 제공하는 업체로부터 processor를 구입하고, 그 processor와 함께 제공되는 SDK를 사용하는 것이다. 그러다보니 특정  업체의 processor를 위해 만든 S/W를 다른 processor로 포팅하는 경우 많은 부분을 수정해야 하는 경우가 많다.\u003c/p\u003e\n\u003cp\u003e당연한 이야기지만, 특정 processor에 종속적인 부분은 해당 processor가 제공하는  H/W  accelerator 를 이용하는 코드나 해당 processor의 특성에 맞게 설계된 구조 등이다. 다른 processor로 포팅하는 경우 \u001c전자의 경우는 새로운 processor에서 대응되는 API등이 제공되면 비교적 쉽게 변경할 수 있다. 후자의 경우는 좀 더 근본적인 문제라 다른 차원의 문제가 되지만. 예를 들어 특정 업체는 processor 차원에서 packet ordering을 제공하는 경우가 있다. 그러므로 이 경우 multi-core 환경에서 여러 core들은 서로 다른  core가 같은 flow(순서가 보장되어야 하는 패킷들의 흐름)에 속하는 패킷을 처리하는 지 신경 쓸 필요없이 패킷을 처리하고, 패킷을 최종적으로 전송할 때만 순서를 맞추는 작업을 H/W 기능을 이용해서 수행하면 된다. 반면 이런 H/W 기능이 없는 경우 근본적으로 flow별로 서로 다른 core에게 전달되도록 하는 등의 고려가 필요할 수 있다.\u003c/p\u003e","title":"OpenDataPlane"},{"content":"You\u0026rsquo;re live! Nice. We\u0026rsquo;ve put together a little post to introduce you to the Ghost editor and get you started. You can manage your content by signing in to the admin area at \u0026lt;your blog URL\u0026gt;/ghost/. When you arrive, you can select this post from a list on the left and see a preview of it on the right. Click the little pencil icon at the top of the preview to edit this post and read the next section!\nGetting Started Ghost uses something called Markdown for writing. Essentially, it\u0026rsquo;s a shorthand way to manage your post formatting as you write!\nWriting in Markdown is really easy. In the left hand panel of Ghost, you simply write as you normally would. Where appropriate, you can use shortcuts to style your content. For example, a list:\nItem number one Item number two A nested item A final item or with numbers!\nRemember to buy some milk Drink the milk Tweet that I remembered to buy the milk, and drank it Links Want to link to a source? No problem. If you paste in url, like http://ghost.org - it\u0026rsquo;ll automatically be linked up. But if you want to customise your anchor text, you can do that too! Here\u0026rsquo;s a link to the Ghost website. Neat.\nWhat about Images? Images work too! Already know the URL of the image you want to include in your article? Simply paste it in like this to make it show up:\nNot sure which image you want to use yet? That\u0026rsquo;s ok too. Leave yourself a descriptive placeholder and keep writing. Come back later and drag and drop the image in to upload:\n![A bowl of bananas]\nQuoting Sometimes a link isn\u0026rsquo;t enough, you want to quote someone on what they\u0026rsquo;ve said. It was probably very wisdomous. Is wisdomous a word? Find out in a future release when we introduce spellcheck! For now - it\u0026rsquo;s definitely a word.\nWisdomous - it\u0026rsquo;s definitely a word.\nWorking with Code Got a streak of geek? We\u0026rsquo;ve got you covered there, too. You can write inline \u0026lt;code\u0026gt; blocks really easily with back ticks. Want to show off something more comprehensive? 4 spaces of indentation gets you there.\n.awesome-thing { display: block; width: 100%; } Ready for a Break? Throw 3 or more dashes down on any new line and you\u0026rsquo;ve got yourself a fancy new divider. Aw yeah.\nAdvanced Usage There\u0026rsquo;s one fantastic secret about Markdown. If you want, you can write plain old HTML and it\u0026rsquo;ll still work! Very flexible.\nThat should be enough to get you started. Have fun - and let us know what you think :)\n","date":"2014-05-10T03:45:21+09:00","permalink":"https://cychong47.github.io/post/2014/welcome-to-ghost-2/","summary":"\u003cp\u003eYou\u0026rsquo;re live! Nice. We\u0026rsquo;ve put together a little post to introduce you to the Ghost editor and get you started. You can manage your content by signing in to the admin area at \u003ccode\u003e\u0026lt;your blog URL\u0026gt;/ghost/\u003c/code\u003e. When you arrive, you can select this post from a list on the left and see a preview of it on the right. Click the little pencil icon at the top of the preview to edit this post and read the next section!\u003c/p\u003e","title":"Welcome to Ghost"}]