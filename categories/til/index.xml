<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Til on Keep calm and Write something</title><link>https://cychong47.github.io/categories/til/</link><description>Recent content in Til on Keep calm and Write something</description><generator>Hugo</generator><language>en-us</language><lastBuildDate>Sun, 18 Feb 2024 00:00:00 +0000</lastBuildDate><atom:link href="https://cychong47.github.io/categories/til/index.xml" rel="self" type="application/rss+xml"/><item><title>Add extra data to python log message</title><link>https://cychong47.github.io/post/2024/2024-02-18-prepend-data-to-python-logger/</link><pubDate>Sun, 18 Feb 2024 00:00:00 +0000</pubDate><guid>https://cychong47.github.io/post/2024/2024-02-18-prepend-data-to-python-logger/</guid><description>&lt;h2 id="tldr"&gt;TL;DR&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;QueueHandler&lt;/code&gt;를 사용해서 process-safe logger를 만들고&lt;/li&gt;
&lt;li&gt;&lt;code&gt;LoggerAdapter&lt;/code&gt;를 활용해서 매 로그 메시지마다 특정 정보가 자동으로 출력.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="mainpy"&gt;main.py&lt;/h2&gt;
&lt;div class="highlight"&gt;&lt;pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"&gt;&lt;code class="language-python" data-lang="python"&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#75715e"&gt;#!/usr/bin/env python3&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;import&lt;/span&gt; logging
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;import&lt;/span&gt; logging.handlers
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;import&lt;/span&gt; multiprocessing
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; worker &lt;span style="color:#f92672"&gt;import&lt;/span&gt; worker_process
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#f92672"&gt;from&lt;/span&gt; my_logger &lt;span style="color:#f92672"&gt;import&lt;/span&gt; logger_process
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;&lt;span style="color:#66d9ef"&gt;if&lt;/span&gt; __name__ &lt;span style="color:#f92672"&gt;==&lt;/span&gt; &lt;span style="color:#e6db74"&gt;&amp;#34;__main__&amp;#34;&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#75715e"&gt;# Configure logging&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; logging&lt;span style="color:#f92672"&gt;.&lt;/span&gt;basicConfig(level&lt;span style="color:#f92672"&gt;=&lt;/span&gt;logging&lt;span style="color:#f92672"&gt;.&lt;/span&gt;DEBUG)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#75715e"&gt;# Create a queue for logging&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; log_queue &lt;span style="color:#f92672"&gt;=&lt;/span&gt; multiprocessing&lt;span style="color:#f92672"&gt;.&lt;/span&gt;Queue()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#75715e"&gt;# Create worker processes&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; num_workers &lt;span style="color:#f92672"&gt;=&lt;/span&gt; &lt;span style="color:#ae81ff"&gt;2&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; processes &lt;span style="color:#f92672"&gt;=&lt;/span&gt; []
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#66d9ef"&gt;for&lt;/span&gt; i &lt;span style="color:#f92672"&gt;in&lt;/span&gt; range(num_workers):
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; p &lt;span style="color:#f92672"&gt;=&lt;/span&gt; multiprocessing&lt;span style="color:#f92672"&gt;.&lt;/span&gt;Process(target&lt;span style="color:#f92672"&gt;=&lt;/span&gt;worker_process, args&lt;span style="color:#f92672"&gt;=&lt;/span&gt;(i, log_queue))
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; processes&lt;span style="color:#f92672"&gt;.&lt;/span&gt;append(p)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; p&lt;span style="color:#f92672"&gt;.&lt;/span&gt;start()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#75715e"&gt;# Create a logger process for process-safe loggging&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; p &lt;span style="color:#f92672"&gt;=&lt;/span&gt; multiprocessing&lt;span style="color:#f92672"&gt;.&lt;/span&gt;Process(target&lt;span style="color:#f92672"&gt;=&lt;/span&gt;logger_process, args&lt;span style="color:#f92672"&gt;=&lt;/span&gt;(log_queue,))
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; processes&lt;span style="color:#f92672"&gt;.&lt;/span&gt;append(p)
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; p&lt;span style="color:#f92672"&gt;.&lt;/span&gt;start()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#75715e"&gt;# Wait for all processes to finish&lt;/span&gt;
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#66d9ef"&gt;try&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#66d9ef"&gt;for&lt;/span&gt; p &lt;span style="color:#f92672"&gt;in&lt;/span&gt; processes:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; p&lt;span style="color:#f92672"&gt;.&lt;/span&gt;join()
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; &lt;span style="color:#66d9ef"&gt;except&lt;/span&gt; &lt;span style="color:#a6e22e"&gt;KeyboardInterrupt&lt;/span&gt;:
&lt;/span&gt;&lt;/span&gt;&lt;span style="display:flex;"&gt;&lt;span&gt; print(&lt;span style="color:#e6db74"&gt;&amp;#34;Uset interrupt. Stop&amp;#34;&lt;/span&gt;)
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;h2 id="workerpy"&gt;worker.py&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;logger&lt;/code&gt;를 직접 사용하는 대신 &lt;code&gt;LoggerAdapter&lt;/code&gt;를 사용해서 각 process의 추가 정보를 함께 출력.&lt;/p&gt;</description></item><item><title>iOS shortcut - 사진 meta 정보 삭제</title><link>https://cychong47.github.io/post/2021/2021-08-17-remove-meta-data-from-image/</link><pubDate>Tue, 17 Aug 2021 09:22:39 +0900</pubDate><guid>https://cychong47.github.io/post/2021/2021-08-17-remove-meta-data-from-image/</guid><description>&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2021/08/2021-08-17-IMG_6772.jpg" alt=""&gt;&lt;/p&gt;</description></item><item><title>100 Tips for a better life</title><link>https://cychong47.github.io/post/2021/2021-02-06-100-tips-for-a-better-life/</link><pubDate>Sat, 06 Feb 2021 09:12:00 +0900</pubDate><guid>https://cychong47.github.io/post/2021/2021-02-06-100-tips-for-a-better-life/</guid><description>&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2021/02/2021-02-06-IMG_0296.jpg" alt=""&gt;&lt;/p&gt;</description></item><item><title>goodlinks supports export finally</title><link>https://cychong47.github.io/post/2021/2021-02-05-goodlinks-supports-export-finally/</link><pubDate>Fri, 05 Feb 2021 23:25:00 +0900</pubDate><guid>https://cychong47.github.io/post/2021/2021-02-05-goodlinks-supports-export-finally/</guid><description>&lt;p&gt;macstories.net에서 추천 글을 보고 구입했던 Goodlinks app.
구입까지 하면서 까지 기대했던 기능은 그간 pocket을 이용하던 read-it-later 용도였는데 아쉽게도 추천글에 비해 부족한 점이 많았다.
무엇보다 이건 앱을 설치하자 마자 부푼 기대감에 그간 pocket에 모아둔 2만개가 넘는 글들을 모두 한번에 옮겨서 그런 듯 하다. 무려 2014년부터 모았던 글들인데 그 덕분인지 여러가지 예상하지 못했던 문제점이 눈에 띄었다.&lt;/p&gt;
&lt;p&gt;가장 큰 문제는 앱에서 글을 다운로드 하는데 너무 데이터를 많이 사용한다는 점. 앱 특성상 저장된 글의 내용 자체를 다운로드 해서 보여주는데 어떤 문제가 있는 지 불과 몇 시간 만에 1GB의 데이터를 사용해 버렸다. 마침 월 말이라 다행히 여유가 좀 있었지만 그 속도대로 가면 며칠 남은 월말까지 데이터를 모두 사용해 버릴 것 같아서 결국 셀룰러르 데이터를 사용하지 못하게 설정을 변경해야 했다.&lt;/p&gt;</description></item><item><title>How to get CPU utilization data with python</title><link>https://cychong47.github.io/post/2020/2020-10-22-how-to-get-cpu-utilization-data-with-python/</link><pubDate>Thu, 22 Oct 2020 05:46:49 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-10-22-how-to-get-cpu-utilization-data-with-python/</guid><description>&lt;p&gt;Python을 이용해서 손 쉽게 CPU 사용량 정보를 알아낼 수 있는 방법.
Physical core 별, logical core 별(Hyper-threading을 켠 경우), 각 core 별 사용량 정보 등을 쉽게 알아낼 수 있다. 이거 C로 짜려면 은근 귀찮은데.
어떻게 해당 정보들을 알아내는 지 궁금하네. 코드를 한번 봐야겠군.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2020/10/2020-10-22-IMG_1027.jpg" alt=""&gt;&lt;/p&gt;</description></item><item><title>Remove docker images referenced in multiple repos</title><link>https://cychong47.github.io/post/2020/2020-09-08-remove-docker-images-referenced-multiple-repos/</link><pubDate>Tue, 08 Sep 2020 23:38:16 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-09-08-remove-docker-images-referenced-multiple-repos/</guid><description>&lt;p&gt;docker image를 GHCR(GitHub Container Registry)에 업로드한 다음 같은 image ID를 갖는 여러 항목이 나타났다.
그동안 local machine에 있던 docker image를 GHCR에 업로드 했으니 더 이상 local host에 이미지가 없어도 되지 않을까 하는 생각에 원래 있던 image를 삭제하려고 하는데 이 경우 에러가 발생한다.&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~/work/slackbot$ docker images |grep slackbot
my-slackbot latest 16cdaacd672e 5 days ago 133MB
ghcr.io/cychong47/my-slackbot 0.1 16cdaacd672e 5 days ago 133MB
ghcr.io/cychong47/slackbot 0.1 16cdaacd672e 5 days ago 133MB
cychong@mini1:~/work/slackbot$ docker images |grep pocket
pocket-retagger latest 942ef4cc7a60 2 days ago 285MB
ghcr.io/cychong47/pocket-retagger latest 942ef4cc7a60 2 days ago 285MB
cychong@mini1:~/work/slackbot$ docker images |grep ghost
ghost 3.8.0 a6ab8e0a010a 6 months ago 394MB
ghcr.io/cychong47/ghost 3.8.0 a6ab8e0a010a 6 months ago 394MB
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;그래서인지 docker image로 삭제하려고 하면 에러가 난다.&lt;/p&gt;</description></item><item><title>Add new Helm Chart</title><link>https://cychong47.github.io/post/2020/2020-09-07-add-new-helm-chart/</link><pubDate>Mon, 07 Sep 2020 21:40:44 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-09-07-add-new-helm-chart/</guid><description>&lt;h1 id="helm-chart-추가하기"&gt;helm chart 추가하기&lt;/h1&gt;
&lt;h2 id="charts-디렉토리-아래에-추가할-helm-chart-만들기"&gt;&lt;code&gt;charts&lt;/code&gt; 디렉토리 아래에 추가할 helm chart 만들기&lt;/h2&gt;
&lt;p&gt;이번에는 기존에 만들어 사용하던 &lt;code&gt;ghost&lt;/code&gt; chart를 등록해 본다.
일단 &lt;code&gt;ghost&lt;/code&gt; chart를 아래와 같이 &lt;code&gt;charts/ghost&lt;/code&gt; 디렉토리에 복사하고 lint 검사.&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~/work/helm/my-helm-chart$ helm lint charts/ghost/
==&amp;gt; Linting charts/ghost/
[INFO] Chart.yaml: icon is recommended

1 chart(s) linted, 0 chart(s) failed
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="helm-chart-패키징"&gt;Helm chart 패키징&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~/work/helm/my-helm-chart$ helm package charts/*
Successfully packaged chart and saved it to: /home/cychong/work/helm/my-helm-chart/my-ghost-0.1.0.tgz
Successfully packaged chart and saved it to: /home/cychong/work/helm/my-helm-chart/nginx-0.2.0.tgz
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~/work/helm/my-helm-chart$ ls *.tgz
my-ghost-0.1.0.tgz nginx-0.2.0.tgz
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="chart-indexing"&gt;Chart indexing&lt;/h2&gt;
&lt;p&gt;Helm chart 들을 indexing. Indexing 후 &lt;code&gt;index.yaml&lt;/code&gt; 파일을 보면 이전에는 &lt;code&gt;nginx&lt;/code&gt;만 있었는데 &lt;code&gt;my-ghost&lt;/code&gt;라는 새로운 chart가 추가된 걸 확인할 수 있다.&lt;/p&gt;</description></item><item><title>Slackbot get the song list</title><link>https://cychong47.github.io/post/2020/2020-09-03-slackbot-get-the-song-list/</link><pubDate>Thu, 03 Sep 2020 00:00:00 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-09-03-slackbot-get-the-song-list/</guid><description>&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2020/09/2020-09-03-IMG_0258.jpg" alt=""&gt;&lt;/p&gt;</description></item><item><title>Automate Blog Posting with GitHub Action</title><link>https://cychong47.github.io/post/2020/2020-08-19-automate-blog-posting-with-github-action/</link><pubDate>Wed, 19 Aug 2020 23:01:58 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-08-19-automate-blog-posting-with-github-action/</guid><description>&lt;p&gt;&lt;a href="https://ruddra.com/hugo-deploy-static-page-using-github-actions/"&gt;https://ruddra.com/hugo-deploy-static-page-using-github-actions/&lt;/a&gt; 에 있는 내용대로 git repository의 &lt;code&gt;.github/workflows&lt;/code&gt; 아래 &lt;code&gt;main.yml&lt;/code&gt; 몇 가지만 수정했더니 잘 동작하는 듯.&lt;/p&gt;
&lt;p&gt;이미 Hugo용 github repo를 가지고 있으므로 내가 추가로 해야 할일은&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;GitHub 계정에서 Access Token 만들어서 Git repository에 &lt;code&gt;Secret&lt;/code&gt;로 추가&lt;/li&gt;
&lt;li&gt;GitHub Action 파일 작성 - &lt;code&gt;.github/workflows/main.yml&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;일단 이거면 끝.&lt;/p&gt;
&lt;h2 id="githubworkflowsmainyml"&gt;&lt;code&gt;.github/workflows/main.yml&lt;/code&gt;&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;name: CI
on: push
jobs:
 deploy:
 runs-on: ubuntu-latest
 steps:
 - name: Git checkout
 uses: actions/checkout@v2

 - name: Update theme
 # (Optional)If you have the theme added as submodule, you can pull it and use the most updated version
 run: git submodule update --init --recursive

 - name: Setup hugo
 uses: peaceiris/actions-hugo@v2
 with:
 hugo-version: &amp;#34;0.74.2&amp;#34;

 - name: Clean public directory
 run: rm -rf public
 - name: Build
 # remove --minify tag if you do not need it
 # docs: https://gohugo.io/hugo-pipes/minification/
 run: hugo --minify

 - name: Deploy
 uses: peaceiris/actions-gh-pages@v3
 with:
 personal_token: ${{ secrets.TOKEN }}
 external_repository: cychong47/cychong47.github.io
 publish_dir: ./public
 # keep_files: true
 user_name: Chaeyong Chong
 user_email: cychonggmail.com
 publish_branch: master
 cname: cychong47.github.io
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;수정한 부분은 Hugo 버전, &lt;code&gt;Deploy&lt;/code&gt; 의 &lt;code&gt;external_repository&lt;/code&gt;, &lt;code&gt;user_name&lt;/code&gt;, &lt;code&gt;user_email&lt;/code&gt;, &lt;code&gt;cname&lt;/code&gt; 정도 뿐.&lt;/p&gt;</description></item><item><title>Publish hugo post from iPad</title><link>https://cychong47.github.io/post/2020/2020-08-11-publish-hugo-post-from-ipad/</link><pubDate>Tue, 11 Aug 2020 14:16:01 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-08-11-publish-hugo-post-from-ipad/</guid><description>&lt;p&gt;iPhone 이나 iPad에서 사진을 골라 사진과 markdown 파일을 만들어 Working Copy를 통해 git repo에 업로드하는 Shortcut을 마련했다.&lt;br&gt;
Shortcut의 원본은 이 블로그(&lt;a href="https://marcus.nordaaker.com/post/posting-to-hugo-from-ios/"&gt;Posting to Hugo from iOS&lt;/a&gt;에서 얻었다.&lt;br&gt;
Front formatter만 일부 수정하면 그대로 사용할 수 있을 정도로 내가 기대하는 workflow가 구현이 되어 있었다. 실은 문법도 잘 모르면서 괜히 손을 댔다 제대로 동작 안하게 했다 다시 고치느라 시간만 보냈다는.&lt;/p&gt;
&lt;p&gt;이 Shortcut이 하는 일은 위 블로그에도 자세하게 설명되어 있지만(친절한 분&amp;hellip;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;넘겨 받은 사진을 가로 1280 픽셀 크기로 조정&lt;/li&gt;
&lt;li&gt;블로그 타이틀 입력&lt;/li&gt;
&lt;li&gt;사진명을 &lt;code&gt;오늘 날짜-블로그 타이틀로 만든 slug.jpg&lt;/code&gt; 로 변경해서 working copy를 이용해서 hugo의 &lt;code&gt;static&lt;/code&gt; 디렉터리에 commit&lt;/li&gt;
&lt;li&gt;사진을 링크하는 markdown을 같은 형식 &lt;code&gt;오늘 날짜-블로그 타이틀로 만든 slug.md&lt;/code&gt;을 &lt;code&gt;content&lt;/code&gt; 디렉터리에 commit&lt;/li&gt;
&lt;li&gt;&lt;code&gt;git push&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;이 과정을 거치면 아래와 같이 git repo에 jpg 파일 하나와 md 파일 하나가 만들어진다.&lt;br&gt;
&lt;figure&gt;&lt;img src="https://cychong47.github.io/images/2020/08/2020-08-11-publish-hugo-post-from-ipad.jpg"
 alt="Publish hugo post from iPad" width="1280"&gt;
&lt;/figure&gt;
&lt;/p&gt;</description></item><item><title>Limitation of free tier</title><link>https://cychong47.github.io/post/2020/2020-08-11-limit-of-free-tier/</link><pubDate>Tue, 11 Aug 2020 14:12:28 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-08-11-limit-of-free-tier/</guid><description>&lt;p&gt;1 physical core도 안되는 CPU를 사용하는 free timer의 한계인가?&lt;/p&gt;
&lt;figure&gt;&lt;img src="https://cychong47.github.io/images/2020/08/2020-08-11-limit-of-free-tier.jpg"
 alt="Limit of free tier" width="1280"&gt;
&lt;/figure&gt;

&lt;p&gt;덧) 저 일이 있은 후에는 또 안정적으로 돌고 있다는&amp;hellip;
날짜별로 통계를 뽑아봐야겠다.&lt;/p&gt;</description></item><item><title>K8s Vertical Pod Autoscaler</title><link>https://cychong47.github.io/post/2020/2020-07-31-vertical-pod-autoscaler/</link><pubDate>Fri, 31 Jul 2020 00:01:03 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-07-31-vertical-pod-autoscaler/</guid><description>&lt;p&gt;VPA는 K8s에서 &lt;code&gt;Scale-in/out&lt;/code&gt;에 대한 기능을 제공.&lt;/p&gt;
&lt;p&gt;현재 동작하고 있는 pod에 대해 pod restart 없이 할당된 resource를 변경하는 것은 아직 미지원인듯&lt;/p&gt;
&lt;h2 id="github의-vpa-repo"&gt;github의 VPA repo&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler"&gt;https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Updating running pods is an experimental feature of VPA. Whenever VPA updates the pod resources the pod is recreated, which causes all running containers to be restarted. The pod may be recreated on a different node.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://stupefied-goodall-e282f7.netlify.app/contributors/design-proposals/autoscaling/vertical-pod-autoscaler/"&gt;https://stupefied-goodall-e282f7.netlify.app/contributors/design-proposals/autoscaling/vertical-pod-autoscaler/&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In-place updates&lt;/p&gt;
&lt;p&gt;In-place Pod updates (#5774) is a planned feature to allow changing resources (request/limit) of existing containers without killing them, assuming sufficient free resources available on the node. Vertical Pod Autoscaler will greatly benefit from this ability, however it is not considered a blocker for the MVP.&lt;/p&gt;</description></item><item><title>No Podcast Update?</title><link>https://cychong47.github.io/post/2020/2020-06-26-no-podcast-update/</link><pubDate>Fri, 26 Jun 2020 22:11:32 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-06-26-no-podcast-update/</guid><description>&lt;p&gt;음&lt;/p&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2020/06/20200626_1315_IMG_4474.PNG" alt=""&gt;&lt;/p&gt;
&lt;p&gt;이건 무슨 상황일까?&lt;br&gt;
mp3 파일은 레코딩이 제대로 되었고, md 파일도 만들었는데 site를 rebuild했다는 메시지가 오질 않는다. 안그래도 Telegram 을 이용해서 메시지를 보내는 기능을 추가해야 겠다고 생각했을때 아래처럼 정상적으로 동작하는 경우가 아니라 뭔가 문제가 있는 상황을 어떻게 알 수 있을까 하는 고민을 했었는데 생각보다 일찍 그 상황(아마도 많은 경우 중 하나 겠지만) 이 온 듯했다.
이렇게 메시지가 안 온 것으로 뭔가 문제가 있다는 걸 판단하는 건 비효율적인 방법이라 보다 적극적으로 어떤 비정상 상황이고, 가능하면 왜 그런 지도 파악해서 메시지를 보내게 할 필요가 있다는 생각을 했었는데&amp;hellip;&lt;/p&gt;</description></item><item><title>Find container with its name</title><link>https://cychong47.github.io/post/2020/2020-06-22-docker-ps-with-name/</link><pubDate>Mon, 22 Jun 2020 23:54:09 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-06-22-docker-ps-with-name/</guid><description>&lt;p&gt;&lt;a href="https://stackoverflow.com/questions/34496882/get-docker-container-id-from-container-name"&gt;Get docker container id from container name&lt;/a&gt;&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;docker ps -aqf &amp;#34;name=containername&amp;#34;
docker ps -aqf &amp;#34;name=^containername$&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;-q&lt;/code&gt; for quiet. output only the ID&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-a&lt;/code&gt; for all. works even if your container is not running&lt;/li&gt;
&lt;li&gt;&lt;code&gt;-f&lt;/code&gt; for filter.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;^&lt;/code&gt; container name must start with this string&lt;/li&gt;
&lt;li&gt;&lt;code&gt;$&lt;/code&gt; container name must end with this string&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Git Tips</title><link>https://cychong47.github.io/page/git/</link><pubDate>Sat, 20 Jun 2020 21:54:31 +0900</pubDate><guid>https://cychong47.github.io/page/git/</guid><description>&lt;h2 id="open-vim-tabs-with-changed-files"&gt;Open vim tabs with changed files&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;vim -p `git diff --name-only`
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;vim -p&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt; -p[N] Open N tab pages. When N is omitted, open one tab page for each file. 
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;git diff --name-only&lt;/code&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;pre&gt;&lt;code&gt; --name-only
 Show only names of changed files.
&lt;/code&gt;&lt;/pre&gt;
&lt;/blockquote&gt;</description></item><item><title>Disable Password for Private Github Repo</title><link>https://cychong47.github.io/post/2020/2020-06-19-disable-password-for-private-github-repo/</link><pubDate>Fri, 19 Jun 2020 06:41:02 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-06-19-disable-password-for-private-github-repo/</guid><description>&lt;p&gt;github가 제공하는 private repository를 사용하니 ID와 암호를 매번 물어보길래 찾아 보니 이렇게 해결할 수 있다고.&lt;/p&gt;
&lt;p&gt;source : &lt;a href="https://stackoverflow.com/questions/8588768/how-do-i-avoid-the-specification-of-the-username-and-password-at-every-git-push"&gt;How do I avoid the specification of the username and password at every git push?&lt;/a&gt;&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;$ git config credential.helper store
$ git push https://github.com/repo.git

Username for &amp;#39;https://github.com&amp;#39;: &amp;lt;USERNAME&amp;gt;
Password for &amp;#39;https://USERNAME@github.com&amp;#39;: &amp;lt;PASSWORD&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;To set the timeout for &amp;ldquo;not-asking password&amp;rdquo;&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;git config --global credential.helper &amp;#39;cache --timeout 7200&amp;#39;
&lt;/code&gt;&lt;/pre&gt;</description></item><item><title>Grain of Salt</title><link>https://cychong47.github.io/post/2020/2020-06-14-grain-of-salt/</link><pubDate>Sun, 14 Jun 2020 08:08:31 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-06-14-grain-of-salt/</guid><description>&lt;p&gt;From OS X dictionary&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Grain of salt&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Pliny the Elder&amp;rsquo;s Naturalis Historia may be the origin of the phrase.&lt;/p&gt;
&lt;p&gt;To take something with a &amp;ldquo;grain of salt&amp;rdquo; or &amp;ldquo;pinch of salt&amp;rdquo; is an English language idiom that means to view something with skepticism or not to interpret something literally.[1]
In the old-fashioned English units of weight, a grain weighs approximately 60 mg, which is about how much table salt a person might pick up between the fingers as a pinch.
History&lt;/p&gt;</description></item><item><title>Record CBS radio in every day</title><link>https://cychong47.github.io/post/2020/2020-06-14-record-cbs-with-cron/</link><pubDate>Sun, 14 Jun 2020 06:49:23 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-06-14-record-cbs-with-cron/</guid><description>&lt;h2 id="record"&gt;record&lt;/h2&gt;
&lt;h2 id="find-out-duration-of-mp3-file"&gt;Find out duration of mp3 file&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://superuser.com/questions/63399/get-mp3-length-in-linux-freebsd"&gt;&lt;code&gt;mp3info&lt;/code&gt;, &lt;code&gt;exiftool&lt;/code&gt; or &lt;code&gt;ffmpeg&lt;/code&gt; can be used to get the duration of mp3 file&lt;/a&gt;&lt;br&gt;
Though &lt;code&gt;mp3info&lt;/code&gt; and &lt;code&gt;exiftool&lt;/code&gt; can be used to the exiting mp3 file while the ffmpeg give the duration on recording process.&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;$ mp3info -p &amp;#34;%S\n&amp;#34; Cinema_20200614.mp3
15
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Exiftool does not give the correct duration.&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;$ exiftool Cinema_20200614.mp3
ExifTool Version Number : 11.88
File Name : Cinema_20200614.mp3
Directory : .
File Size : 235 kB
File Modification Date/Time : 2020:06:14 07:16:03+09:00
File Access Date/Time : 2020:06:14 07:47:47+09:00
File Inode Change Date/Time : 2020:06:14 07:16:03+09:00
File Permissions : rw-rw-r--
File Type : MP3
File Type Extension : mp3
MIME Type : audio/mpeg
MPEG Audio Version : 1
Audio Layer : 3
Audio Bitrate : 64 kbps
Sample Rate : 44100
Channel Mode : Stereo
MS Stereo : Off
Intensity Stereo : Off
Copyright Flag : False
Original Media : False
Emphasis : None
ID3 Size : 45
Encoder Settings : Lavf58.29.100
Duration : 0:00:30 (approx)
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="setup-cron-job"&gt;Setup cron job&lt;/h2&gt;
&lt;p&gt;Use &lt;code&gt;crontab&lt;/code&gt; which enables user to have a separated &lt;a href="https://phoenixnap.com/kb/set-up-cron-job-linux%5D"&gt;cron job&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Setup podcast blog - beginning</title><link>https://cychong47.github.io/post/2020/2020-06-13-setup-podcast-blog-0/</link><pubDate>Sat, 13 Jun 2020 16:44:23 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-06-13-setup-podcast-blog-0/</guid><description>&lt;p&gt;오늘 운전하는 시간이 마침 오전 11시라 CBS &lt;code&gt;신지혜의 영화음악&lt;/code&gt;을 들을 수 있었다.
어릴 적 부터 좋아하던 영화 음악을 괘 오래동안 듣게 해주고 있는 프로그램.&lt;br&gt;
편안한 목소리와 다양한 좋은 영화 음악을 들을 수 있어 &lt;code&gt;정은영의 영화음악&lt;/code&gt; 이후 가장 좋아하는 라디오 프로그램이 되었다.
그런데 문제는 라디오 방송 시간이 오전 11시라 회사생활을 하면서 쉽게 듣기 어려운 상황이라는 거.&lt;/p&gt;
&lt;p&gt;2년 전에는 OS X에 cron을 이용해서 자동으로 녹음을 한 후 NAS로 파일을 옮겨서 &lt;code&gt;DS Audio&lt;/code&gt; 앱으로 듣기도 했는데 파일 기반으로 되어 있다 보니 내가 어떤 파일을 들었는 지 알기가 어려웠다. 라디오를 녹음한 거다 보니 파일 이름에 쓸만한 것이 날짜 정도인데 그러다 보니 파일을 구분하기가 어렵다는 거. 거기에 &lt;code&gt;DS Audio&lt;/code&gt; 앱이 그닥인 점도 한 몫을 했고.&lt;/p&gt;</description></item><item><title>NVIDIA vRAN Solution</title><link>https://cychong47.github.io/post/2020/nvidia-vran-solution/</link><pubDate>Wed, 20 May 2020 15:01:44 +0900</pubDate><guid>https://cychong47.github.io/post/2020/nvidia-vran-solution/</guid><description>&lt;p&gt;&lt;a href="https://devblogs.nvidia.com/building-accelerated-5g-cloudran-at-the-edge/"&gt;https://devblogs.nvidia.com/building-accelerated-5g-cloudran-at-the-edge/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="mellanox-connectx-6-dx-smartnic"&gt;Mellanox ConnectX-6 Dx SmartNIC&lt;/h2&gt;
&lt;p&gt;exceeds stringent industry-standard timing specifications for eCPRI-based RANs by ensuring clock accuracy of 16ns or less&lt;/p&gt;
&lt;p&gt;5T for 5G enables packet-based, ethernet RANs to provide precise time-stamping of packets for delivering highly accurate time references to 5G fronthaul and backhaul networks.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;5T-for-5G, or time-triggered transmission technology for telco&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://news.developer.nvidia.com/new-real-time-smartnic-technology-5t-for-5g/"&gt;https://news.developer.nvidia.com/new-real-time-smartnic-technology-5t-for-5g/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://news.developer.nvidia.com/wp-content/uploads/2020/05/pasted-image-0-17-624x271.png" alt="img"&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Real-time transmission hardware acceleration&lt;/strong&gt;: 5T-for-5G simplifies time synchronization and data transmission across servers, GPUs, radios, and baseband units in wireless network rollouts, making 5G rollouts easier and more efficient.&lt;/p&gt;</description></item><item><title>WordPress 로그인 불가 문제 해결</title><link>https://cychong47.github.io/post/2020/recover-broken-users-table/</link><pubDate>Fri, 08 May 2020 23:36:45 +0900</pubDate><guid>https://cychong47.github.io/post/2020/recover-broken-users-table/</guid><description>&lt;p&gt;말썽쟁이(?) wordpress 블로그가 또 문제를 일으켰다.&lt;br&gt;
이번에도 로그인이 안되는 현상인데 &lt;a href="https://cychong47.github.io/post/wordpress-admin-login-fail/"&gt;지난 번&lt;/a&gt;과는 다른 에러 메시지가 나온다. 즉 지난 번 해결책은 소용이 없을 거라는 불길한 예감이.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2020/05/wordpress_login_error_account_is_missing.png" alt="wordpress_login_error_account_is_missing"&gt;&lt;/p&gt;
&lt;p&gt;로그인 계정 자체가 없다는 이 어이없는 상황.&lt;/p&gt;
&lt;p&gt;그래서 지난 번에 유용하게 사용했던 phpmyadmin을 이용해서 DB 정보를 확인해봤다.
(다행히 MySql, wordpress 와 함께 실행시켜놓은 phpmyadmin container가 동작하고 있어서 지난 번과 같이 &lt;code&gt;8181&lt;/code&gt; 포트로 접속하면 된단. 다만 로그인 암호를 기억하지 못하고 있는 나 대신 Safari가 기억하고 있어서 그냥 접속했다는)&lt;/p&gt;</description></item><item><title>내게 권한이 있다면 - 그 이후</title><link>https://cychong47.github.io/post/2020/if-i-have-authority-5-years-later/</link><pubDate>Fri, 08 May 2020 14:03:04 +0900</pubDate><guid>https://cychong47.github.io/post/2020/if-i-have-authority-5-years-later/</guid><description>&lt;p&gt;&lt;a href="https://cychong47.github.io/post/naege-gweonhani-issdamyeon/"&gt;내게 권한이 있다면&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;이런 글을 쓴 적이 있었네. 우연히 ghost 블로그에 이전 글들이 2개씩 존재하는 걸 발견해서 중복된 글을 지우는 과정에서 이런 글을 썼다는 걸 알아냈다. 중복 글은 아마도 ghost 버전을 2에서 3으로 올리는 과정이나 복구하는 과정에서 발생한 듯 한데. 그 덕에 각 글들이 실제로 작성된 날짜정보는 사라지고 가장 오래된 글도 2년 전(2018) 정도로 나오는데 실제 내용은 2014년 글도 있다는.&lt;/p&gt;
&lt;p&gt;덕분에 이 글을 언제 썼는 지, 그 당시 어떤 일을 하고 있었는 지는 정확하지 않지만 글을 읽다 보니 어렴풋이 왜 이런 생각을 그때 했는 지 알겠다 싶다. 그간 많은 일이 있었고, 글의 제목에 있는 대로 &amp;lsquo;권한&amp;rsquo;을 갖거나 위임받아 운영한 적이 있었으니 그 결과를 하나씩 따져본 후 각 항목별로 &lt;code&gt;O&lt;/code&gt;, &lt;code&gt;X&lt;/code&gt;를 구분해 봤다. 관련 업무를 하지 않아 실행(혹은 시도)해 보지 못한 항목은 &lt;code&gt;-&lt;/code&gt;로 구분했다.
적어도 정보를 excel로 관리하던 행태는 피한 듯 하다. 나름 자부심을 가지고 있는 건(아무도 알아주지 않지만) 십 수년 전에 시도했던 것과 같이 회사에 wiki를 제대로 활용해서 업무를 진행한 덕에 엑셀 사용을 최소화하고, 관련된 사람들이 쉽게 정보를 공유하고, 찾을 수 있도록 wiki를 기반으로 일을 진행했다. 덕분에 검색이 가능한 CMS 환경을 갖췄지만, 한 가지 아쉬운 점은 페이지 수가 많다보니 실제로 가치가 큰 정보를 찾는 게 쉽지 않았다는 점이다. tag(confluence wiki에서는 label이라고 부르는) 사용을 잘 활용하면 되었을 텐데 이 부분에 대해서는 아쉬움이 남는다.&lt;/p&gt;</description></item><item><title>새로운 경험 들</title><link>https://cychong47.github.io/post/2020/new-things-in-last-4-years/</link><pubDate>Thu, 07 May 2020 14:34:55 +0900</pubDate><guid>https://cychong47.github.io/post/2020/new-things-in-last-4-years/</guid><description>&lt;p&gt;지난 2016년 난생 처음으로 자발적으로 부서를 옮긴 후에 경험한 것들.&lt;br&gt;
그 전의 십수년간에는 해보지 않은 많은 새로운 경험들을 가질 수 있었다. 주변의 도움 덕에. 특히 날 믿어주는 지인 덕에 이런 새로운 경험을 해 봐서 재밌었다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;팀으로 일하기&lt;/li&gt;
&lt;li&gt;Agile practice 해보기. Scrum meeting, Daily meeting, 회고 등&lt;/li&gt;
&lt;li&gt;재밌게 일하기&lt;/li&gt;
&lt;li&gt;의미를 가지며 일하기&lt;/li&gt;
&lt;li&gt;의미있는 TF하기&lt;/li&gt;
&lt;li&gt;Leading(TF, 파트)&lt;/li&gt;
&lt;li&gt;외국 연구소, 사업자 직접 만나서 대화하기&lt;/li&gt;
&lt;li&gt;정보를 입수해 가공해서 잘 전달하기&lt;/li&gt;
&lt;li&gt;정보를 집중해서 관리하는 사이트 구축하기&lt;/li&gt;
&lt;li&gt;사람들 독려하기&lt;/li&gt;
&lt;li&gt;주간 리포트를 통해 업무 진행 공유하기&lt;/li&gt;
&lt;li&gt;정치 맛 보기(이건 좀 힘들었네)&lt;/li&gt;
&lt;li&gt;새로운 분야의 일 - Bearer Processing, OAM, MAC, PHY,&lt;/li&gt;
&lt;li&gt;가상화 인프라 구축 - OpenStack, container&lt;/li&gt;
&lt;li&gt;상용 솔류션 도입 - DB, Container platform&lt;/li&gt;
&lt;li&gt;신기술을 컴파일해서 우리 것에 적용방안 찾기 (가상화 TF)&lt;/li&gt;
&lt;li&gt;전화 영어로 일하기&lt;/li&gt;
&lt;li&gt;밤 늦은 시간에 사업자마 해외 연구소와 콜하기&lt;/li&gt;
&lt;li&gt;전략적으로 판단하기 (무조건 아는 걸 다 이야기하면 안되는)&lt;/li&gt;
&lt;li&gt;팀 빌드의 중요성 옆에서 보기&lt;/li&gt;
&lt;li&gt;다른 사람 평가하기&lt;/li&gt;
&lt;li&gt;회사 평가 시스템 이해(TO는 생각보다 많이 적다, 연봉 캡, 동기부여의 수단은 별로 없다)&lt;/li&gt;
&lt;li&gt;아는 것과 남들 특히 다른 생각을 가진 사람들을 설득하는 것이 어떤 지 배우기&lt;/li&gt;
&lt;li&gt;영어로 업무하기. 외국 업체나 해외연구소 혹은 외국 인력과 함께 일하기&lt;/li&gt;
&lt;li&gt;해외 연구소와 함께 일하기. Wiki등을 이용하여 협업하고, 주간 콜을 통해 업무 상황 공유.&lt;/li&gt;
&lt;li&gt;사내 정치 맛 보기&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;그 전의 십수년간 경험한 것보다 훨씬 많은, 다양한 일들을 짧은 시간 동안 경험한 듯. 덕분에 새로운 사람들도 많이 만날 수 있었고, 이전과 다른 입장에서 일할 수 있는 기회도 가졌다. 그 전에는 SW architecture 측면에서 가장 아래쪽에 가까운 분야를 했다면, 그것보다는 보다 높은 layer의 업무도 해보고, 극단적으로 사업자와 대화를 하는 상당히 높은 게층의 일(계급이 아니라&amp;hellip;)도 해보고, 무형의 결과물을 만들어내는 일도 잠시나마 해 봤다.&lt;/p&gt;</description></item><item><title>Backup Ghost Database Periodically</title><link>https://cychong47.github.io/post/2020/2020-03-03-backup-ghost-database-periodically/</link><pubDate>Tue, 03 Mar 2020 00:00:00 +0900</pubDate><guid>https://cychong47.github.io/post/2020/2020-03-03-backup-ghost-database-periodically/</guid><description>&lt;p&gt;This ghost-backup container will backup in every 3am&lt;/p&gt;
&lt;h1 id="start-ghost-backup-container"&gt;Start ghost-backup container&lt;/h1&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~/Documents/docker-daily-backup$ docker run --name ghost-backup -d -v /home/cychong/Documents/docker-daily-backup:/backups --volumes-from 388c84247267 bennetimo/ghost-backup
ea33f148122bbe0d90a502bfd884e4c988e9f8837921f725ca7317afff7fa149
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id="instant-backup"&gt;Instant backup&lt;/h1&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~/Documents/docker-daily-backup$ ls -al
total 8
drwxrwxr-x 2 cychong cychong 4096 Mar 3 23:25 .
drwxr-xr-x 5 cychong cychong 4096 Mar 3 23:25 ..
cychong@mini1:~/Documents/docker-daily-backup$ docker exec ghost-backup backup
Tue Mar 3 14:27:27 UTC 2020: Checking if a mysql container exists on the network at mysql:3306
Tue Mar 3 14:27:33 UTC 2020: ...no mysql container exists on the network. Using sqlite mode
Tue Mar 3 14:27:33 UTC 2020: creating backup: 20200303-1427...
Tue Mar 3 14:27:33 UTC 2020: backing up ghost database
Tue Mar 3 14:27:33 UTC 2020: creating ghost db archive (sqlite)...
Tue Mar 3 14:27:33 UTC 2020: ...completed: /backups/backup-db_20200303-1427.gz
Tue Mar 3 14:27:33 UTC 2020: backing up ghost content files
Tue Mar 3 14:27:33 UTC 2020: creating ghost content files archive...
Tue Mar 3 14:27:40 UTC 2020: ...completed: /backups/backup-ghost_20200303-1427.tar.gz
Tue Mar 3 14:27:40 UTC 2020: backing up ghost json file
Tue Mar 3 14:27:40 UTC 2020: ...checking if a ghost container exists on the network at ghost:2368
Tue Mar 3 14:27:41 UTC 2020: ...no ghost service found on the network
Tue Mar 3 14:27:41 UTC 2020: ...skipping: Your ghost service was not found on the network. Configure GHOST_SERVICE_NAME and GHOST_SERVICE_PORT
Tue Mar 3 14:27:41 UTC 2020: purging old backups (set to retain the most recent 30)
Tue Mar 3 14:27:41 UTC 2020: ...found 1 database files (purging 0)
Tue Mar 3 14:27:41 UTC 2020: ...found 1 ghost content archive files (purging 0)
Tue Mar 3 14:27:41 UTC 2020: ...found 0 ghost json files (purging 0)
Tue Mar 3 14:27:41 UTC 2020: completed backup to /backups
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id="check-backup-output"&gt;Check backup output&lt;/h1&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~/Documents/docker-daily-backup$ ls -al
total 67236
drwxrwxr-x 2 cychong cychong 4096 Mar 3 23:27 .
drwxr-xr-x 5 cychong cychong 4096 Mar 3 23:25 ..
-rw-r--r-- 1 root root 1829326 Mar 3 23:27 backup-db_20200303-1427.gz
-rw-r--r-- 1 root root 67004766 Mar 3 23:27 backup-ghost_20200303-1427.tar.gz
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id="reference"&gt;reference&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://hub.docker.com/r/bennetimo/ghost-backup/?ref=login"&gt;https://hub.docker.com/r/bennetimo/ghost-backup/?ref=login&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Upgrade kubenetes to 1.17.2-0</title><link>https://cychong47.github.io/post/2020/new-things-in-last-4-years/</link><pubDate>Thu, 30 Jan 2020 00:00:00 +0900</pubDate><guid>https://cychong47.github.io/post/2020/new-things-in-last-4-years/</guid><description>&lt;h1 id="preparation"&gt;preparation&lt;/h1&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~$ sudo apt update
[sudo] password for cychong:
Ign:1 http://dl.google.com/linux/chrome/deb stable InRelease
Get:2 http://dl.google.com/linux/chrome/deb stable Release [943 B]
Get:3 http://dl.google.com/linux/chrome/deb stable Release.gpg [819 B]
...
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id="get-the-lastest-version"&gt;Get the lastest version&lt;/h1&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~$ sudo apt-cache policy kubeadm
kubeadm:
 Installed: 1.16.1-00
 Candidate: 1.17.2-00
 Version table:
 1.17.2-00 500
 500 http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 1.17.1-00 500
 500 http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 1.17.0-00 500
 500 http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
...
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~$ apt-cache madison kubeadm
 kubeadm | 1.17.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.17.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.17.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.16.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.16.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.16.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.16.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.16.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.16.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.16.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.15.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.15.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.15.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.15.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.15.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.15.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.15.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.15.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.15.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.15.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.14.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.14.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.14.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.14.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.14.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.14.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.14.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.14.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.14.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.14.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.14.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.13.12-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.13.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.13.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.13.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.13.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.13.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.13.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.13.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.13.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.13.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.13.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.13.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.13.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.12.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.12.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.12.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.12.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.12.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.12.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.12.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.12.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.12.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.12.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.12.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.11.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.11.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.11.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.11.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.11.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.11.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.11.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.11.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.11.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.11.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.11.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.10.13-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.10.12-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.10.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.10.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.10.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.10.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.10.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.10.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.10.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.10.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.10.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.10.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.10.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.10.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.9.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.9.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.9.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.9.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.9.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.9.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.9.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.9.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.9.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.9.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.9.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.9.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.15-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.14-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.13-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.12-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.1-01 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.0-01 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.8.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.16-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.15-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.14-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.11-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.3-01 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.7.0-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.6.13-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.6.12-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.6.11-01 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.6.10-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.6.9-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.6.8-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.6.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.6.6-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.6.5-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.6.4-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.6.3-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.6.2-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.6.1-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
 kubeadm | 1.5.7-00 | http://apt.kubernetes.io kubernetes-xenial/main amd64 Packages
cychong@mini1:~$ sudo apt-mark unhold kubeadm &amp;amp;&amp;amp; sudo apt-get install -y kubeadm=1.17.2-00 &amp;amp;&amp;amp; sudo apt-mark hold kubeadm
Canceled hold on kubeadm.
Reading package lists... Done
Building dependency tree 
Reading state information... Done
The following packages will be upgraded:
 kubeadm
1 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.
Need to get 8061 kB of archives.
After this operation, 4907 kB disk space will be freed.
Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.17.2-00 [8061 kB]
Fetched 8061 kB in 3s (3164 kB/s) 
(Reading database ... 248932 files and directories currently installed.)
Preparing to unpack .../kubeadm_1.17.2-00_amd64.deb ...
Unpacking kubeadm (1.17.2-00) over (1.16.1-00) ...
Setting up kubeadm (1.17.2-00) ...
kubeadm set on hold.
cychong@mini1:~$ sudo apt-get update &amp;amp;&amp;amp; apt-get install -y --allow-change-held-packages kubeadm=1.17.2-00
Ign:2 http://dl.google.com/linux/chrome/deb stable InRelease 
Hit:3 https://download.docker.com/linux/ubuntu bionic InRelease 
Hit:4 http://dl.google.com/linux/chrome/deb stable Release 
Hit:5 http://archive.ubuntu.com/ubuntu bionic InRelease 
Hit:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease 
Hit:8 http://ppa.launchpad.net/x2go/stable/ubuntu bionic InRelease 
Hit:9 http://archive.ubuntu.com/ubuntu bionic-backports InRelease 
Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease 
Hit:10 http://archive.ubuntu.com/ubuntu bionic-security InRelease 
Reading package lists... Done 
E: Could not open lock file /var/lib/dpkg/lock-frontend - open (13: Permission denied)
E: Unable to acquire the dpkg frontend lock (/var/lib/dpkg/lock-frontend), are you root?
cychong@mini1:~$ sudo apt-get install -y --allow-change-held-packages kubeadm=1.17.2-00
Reading package lists... Done
Building dependency tree 
Reading state information... Done
kubeadm is already the newest version (1.17.2-00).
0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.
cychong@mini1:~$ kubeadm version
kubeadm version: &amp;amp;version.Info{Major:&amp;#34;1&amp;#34;, Minor:&amp;#34;17&amp;#34;, GitVersion:&amp;#34;v1.17.2&amp;#34;, GitCommit:&amp;#34;59603c6e503c87169aea6106f57b9f242f64df89&amp;#34;, GitTreeState:&amp;#34;clean&amp;#34;, BuildDate:&amp;#34;2020-01-18T23:27:49Z&amp;#34;, GoVersion:&amp;#34;go1.13.5&amp;#34;, Compiler:&amp;#34;gc&amp;#34;, Platform:&amp;#34;linux/amd64&amp;#34;}
cychong@mini1:~$ sudo kubeadm upgrade plan
[upgrade/config] Making sure the configuration is correct:
[upgrade/config] Reading configuration from the cluster...
[upgrade/config] FYI: You can look at this config file with &amp;#39;kubectl -n kube-system get cm kubeadm-config -oyaml&amp;#39;
[preflight] Running pre-flight checks.
[upgrade] Making sure the cluster is healthy:
[upgrade] Fetching available versions to upgrade to
[upgrade/versions] Cluster version: v1.16.1
[upgrade/versions] kubeadm version: v1.17.2
[upgrade/versions] Latest stable version: v1.17.2
[upgrade/versions] Latest version in the v1.16 series: v1.16.6

Components that must be upgraded manually after you have upgraded the control plane with &amp;#39;kubeadm upgrade apply&amp;#39;:
COMPONENT CURRENT AVAILABLE
Kubelet 1 x v1.16.1 v1.16.6

Upgrade to the latest version in the v1.16 series:

COMPONENT CURRENT AVAILABLE
API Server v1.16.1 v1.16.6
Controller Manager v1.16.1 v1.16.6
Scheduler v1.16.1 v1.16.6
Kube Proxy v1.16.1 v1.16.6
CoreDNS 1.6.2 1.6.5
Etcd 3.3.15 3.3.17-0

You can now apply the upgrade by executing the following command:

	kubeadm upgrade apply v1.16.6

_____________________________________________________________________

Components that must be upgraded manually after you have upgraded the control plane with &amp;#39;kubeadm upgrade apply&amp;#39;:
COMPONENT CURRENT AVAILABLE
Kubelet 1 x v1.16.1 v1.17.2

Upgrade to the latest stable version:

COMPONENT CURRENT AVAILABLE
API Server v1.16.1 v1.17.2
Controller Manager v1.16.1 v1.17.2
Scheduler v1.16.1 v1.17.2
Kube Proxy v1.16.1 v1.17.2
CoreDNS 1.6.2 1.6.5
Etcd 3.3.15 3.4.3-0

You can now apply the upgrade by executing the following command:

	kubeadm upgrade apply v1.17.2

_____________________________________________________________________

cychong@mini1:~$ sudo kubeadm upgrade apply v1.17.2
[upgrade/config] Making sure the configuration is correct:
[upgrade/config] Reading configuration from the cluster...
[upgrade/config] FYI: You can look at this config file with &amp;#39;kubectl -n kube-system get cm kubeadm-config -oyaml&amp;#39;
[preflight] Running pre-flight checks.
[upgrade] Making sure the cluster is healthy:
[upgrade/version] You have chosen to change the cluster version to &amp;#34;v1.17.2&amp;#34;
[upgrade/versions] Cluster version: v1.16.1
[upgrade/versions] kubeadm version: v1.17.2
[upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y
[upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd]
[upgrade/prepull] Prepulling image for component etcd.
[upgrade/prepull] Prepulling image for component kube-apiserver.
[upgrade/prepull] Prepulling image for component kube-controller-manager.
[upgrade/prepull] Prepulling image for component kube-scheduler.
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager
[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver
[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd
[upgrade/prepull] Prepulled image for component kube-controller-manager.
[upgrade/prepull] Prepulled image for component kube-apiserver.
[upgrade/prepull] Prepulled image for component kube-scheduler.
[upgrade/prepull] Prepulled image for component etcd.
[upgrade/prepull] Successfully prepulled the images for all the control plane components
[upgrade/apply] Upgrading your Static Pod-hosted control plane to version &amp;#34;v1.17.2&amp;#34;...
Static pod: kube-apiserver-mini1 hash: 66d5b6802b69fcb461e22c159ef72783
Static pod: kube-controller-manager-mini1 hash: 98ded181cb6da00c408078fe0832bddf
Static pod: kube-scheduler-mini1 hash: e05eb744bc3406614b4a55dd00e7af9f
[upgrade/etcd] Upgrading to TLS for etcd
Static pod: etcd-mini1 hash: 9e59bd8449d154ddd6acfbbb3a74181f
[upgrade/staticpods] Preparing for &amp;#34;etcd&amp;#34; upgrade
[upgrade/staticpods] Renewing etcd-server certificate
[upgrade/staticpods] Renewing etcd-peer certificate
[upgrade/staticpods] Renewing etcd-healthcheck-client certificate
[upgrade/staticpods] Moved new manifest to &amp;#34;/etc/kubernetes/manifests/etcd.yaml&amp;#34; and backed up old manifest to &amp;#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-01-30-22-21-26/etcd.yaml&amp;#34;
[upgrade/staticpods] Waiting for the kubelet to restart the component
[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)
Static pod: etcd-mini1 hash: 9e59bd8449d154ddd6acfbbb3a74181f
Static pod: etcd-mini1 hash: 9b305733637de70ef82ca5b0b18c65e1
[apiclient] Found 1 Pods for label selector component=etcd
[upgrade/staticpods] Component &amp;#34;etcd&amp;#34; upgraded successfully!
[upgrade/etcd] Waiting for etcd to become available
[upgrade/staticpods] Writing new Static Pod manifests to &amp;#34;/etc/kubernetes/tmp/kubeadm-upgraded-manifests216455436&amp;#34;
W0130 22:22:01.351368 10213 manifests.go:214] the default kube-apiserver authorization-mode is &amp;#34;Node,RBAC&amp;#34;; using &amp;#34;Node,RBAC&amp;#34;
[upgrade/staticpods] Preparing for &amp;#34;kube-apiserver&amp;#34; upgrade
[upgrade/staticpods] Renewing apiserver certificate
[upgrade/staticpods] Renewing apiserver-kubelet-client certificate
[upgrade/staticpods] Renewing front-proxy-client certificate
[upgrade/staticpods] Renewing apiserver-etcd-client certificate
[upgrade/staticpods] Moved new manifest to &amp;#34;/etc/kubernetes/manifests/kube-apiserver.yaml&amp;#34; and backed up old manifest to &amp;#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-01-30-22-21-26/kube-apiserver.yaml&amp;#34;
[upgrade/staticpods] Waiting for the kubelet to restart the component
[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)
Static pod: kube-apiserver-mini1 hash: 66d5b6802b69fcb461e22c159ef72783
Static pod: kube-apiserver-mini1 hash: 4d9a965c0a14a45ea3d7db1e023096d4
[apiclient] Found 1 Pods for label selector component=kube-apiserver
[upgrade/staticpods] Component &amp;#34;kube-apiserver&amp;#34; upgraded successfully!
[upgrade/staticpods] Preparing for &amp;#34;kube-controller-manager&amp;#34; upgrade
[upgrade/staticpods] Renewing controller-manager.conf certificate
[upgrade/staticpods] Moved new manifest to &amp;#34;/etc/kubernetes/manifests/kube-controller-manager.yaml&amp;#34; and backed up old manifest to &amp;#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-01-30-22-21-26/kube-controller-manager.yaml&amp;#34;
[upgrade/staticpods] Waiting for the kubelet to restart the component
[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)
Static pod: kube-controller-manager-mini1 hash: 98ded181cb6da00c408078fe0832bddf
Static pod: kube-controller-manager-mini1 hash: 98ded181cb6da00c408078fe0832bddf
Static pod: kube-controller-manager-mini1 hash: 85a33dac6d806801ba5efe4a4544194c
[apiclient] Found 1 Pods for label selector component=kube-controller-manager
[upgrade/staticpods] Component &amp;#34;kube-controller-manager&amp;#34; upgraded successfully!
[upgrade/staticpods] Preparing for &amp;#34;kube-scheduler&amp;#34; upgrade
[upgrade/staticpods] Renewing scheduler.conf certificate
[upgrade/staticpods] Moved new manifest to &amp;#34;/etc/kubernetes/manifests/kube-scheduler.yaml&amp;#34; and backed up old manifest to &amp;#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2020-01-30-22-21-26/kube-scheduler.yaml&amp;#34;
[upgrade/staticpods] Waiting for the kubelet to restart the component
[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)
Static pod: kube-scheduler-mini1 hash: e05eb744bc3406614b4a55dd00e7af9f
Static pod: kube-scheduler-mini1 hash: 9c994ea62a2d8d6f1bb7498f10aa6fcf
[apiclient] Found 1 Pods for label selector component=kube-scheduler
[upgrade/staticpods] Component &amp;#34;kube-scheduler&amp;#34; upgraded successfully!
[upload-config] Storing the configuration used in ConfigMap &amp;#34;kubeadm-config&amp;#34; in the &amp;#34;kube-system&amp;#34; Namespace
[kubelet] Creating a ConfigMap &amp;#34;kubelet-config-1.17&amp;#34; in namespace kube-system with the configuration for the kubelets in the cluster
[kubelet-start] Downloading configuration for the kubelet from the &amp;#34;kubelet-config-1.17&amp;#34; ConfigMap in the kube-system namespace
[kubelet-start] Writing kubelet configuration to file &amp;#34;/var/lib/kubelet/config.yaml&amp;#34;
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[addons]: Migrating CoreDNS Corefile
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

[upgrade/successful] SUCCESS! Your cluster was upgraded to &amp;#34;v1.17.2&amp;#34;. Enjoy!

[upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven&amp;#39;t already done so.
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id="calico"&gt;calico&lt;/h1&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~$ wget https://docs.projectcalico.org/manifests/calico.yaml
--2020-01-30 22:34:28-- https://docs.projectcalico.org/manifests/calico.yaml
Resolving docs.projectcalico.org (docs.projectcalico.org)... 206.189.89.118, 2400:6180:0:d1::57a:6001
Connecting to docs.projectcalico.org (docs.projectcalico.org)|206.189.89.118|:443... connected.
HTTP request sent, awaiting response... 200 OK
Length: 20935 (20K) [application/x-yaml]
Saving to: ‘calico.yaml.2’

calico.yaml.2 100%[===========================================================================================================================================&amp;gt;] 20.44K --.-KB/s in 0.07s 

2020-01-30 22:34:29 (275 KB/s) - ‘calico.yaml.2’ saved [20935/20935]
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex="0"&gt;&lt;code&gt;618 - name: CALICO_IPV4POOL_CIDR
619 value: &amp;#34;10.201.0.0/24&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~$ kubectl apply -f calico.yaml
configmap/calico-config unchanged
customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org unchanged
clusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchanged
clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchanged
clusterrole.rbac.authorization.k8s.io/calico-node configured
clusterrolebinding.rbac.authorization.k8s.io/calico-node unchanged
daemonset.apps/calico-node configured
serviceaccount/calico-node unchanged
deployment.apps/calico-kube-controllers configured
serviceaccount/calico-kube-controllers unchanged
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id="kubelet-and-kubectl"&gt;kubelet and kubectl&lt;/h1&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~$ sudo apt-mark unhold kubelet kubectl &amp;amp;&amp;amp; sudo apt-get install -y kubelet=1.17.2-00 kubectl=1.17.2-00 &amp;amp;&amp;amp; sudo apt-mark hold kubelet kubectl
kubelet was already not hold.
kubectl was already not hold.
Reading package lists... Done
Building dependency tree 
Reading state information... Done
The following packages will be upgraded:
 kubectl kubelet
2 upgraded, 0 newly installed, 0 to remove and 44 not upgraded.
Need to get 27.9 MB of archives.
After this operation, 14.8 MB disk space will be freed.
Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubectl amd64 1.17.2-00 [8738 kB]
Get:2 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubelet amd64 1.17.2-00 [19.2 MB]
Fetched 27.9 MB in 6s (4994 kB/s) 
(Reading database ... 248932 files and directories currently installed.)
Preparing to unpack .../kubectl_1.17.2-00_amd64.deb ...
Unpacking kubectl (1.17.2-00) over (1.16.1-00) ...
Preparing to unpack .../kubelet_1.17.2-00_amd64.deb ...
Unpacking kubelet (1.17.2-00) over (1.16.1-00) ...
Setting up kubelet (1.17.2-00) ...
Setting up kubectl (1.17.2-00) ...
kubelet set on hold.
kubectl set on hold.
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id="wrap-up"&gt;wrap-up&lt;/h1&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~$ sudo systemctl restart kubelet
cychong@mini1:~$ kubectl get nodes
NAME STATUS ROLES AGE VERSION
mini1 Ready master 144d v1.17.2
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id="reference"&gt;reference&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/"&gt;https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Ghost theme 변경 - Fizzy</title><link>https://cychong47.github.io/post/2019/change-ghost-theme-fizzy/</link><pubDate>Tue, 10 Dec 2019 14:09:19 +0900</pubDate><guid>https://cychong47.github.io/post/2019/change-ghost-theme-fizzy/</guid><description>&lt;p&gt;&lt;a href="https://github.com/huangyuzhang/Fizzy-Theme"&gt;https://github.com/huangyuzhang/Fizzy-Theme&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;오늘 우연히 발견한 ghost theme. 중국 친구가 만든 것 같은데 꽤 괜찮다.
검색 기능에 필요한 Content API key 등만 Site Header에 추가하면 검색 기능을 이용할 수 있고, TOC도 지원이 된다는. 특히 중국 친구가 만든 거라 그런지 한글 검색도 잘 지원된다.&lt;/p&gt;
&lt;p&gt;한 동안 이 테마로 지내면 될 듯.&lt;/p&gt;</description></item><item><title>Mac mini 2009 upgrade</title><link>https://cychong47.github.io/post/2019/mac-mini-2009-upgrade/</link><pubDate>Mon, 18 Nov 2019 15:11:08 +0900</pubDate><guid>https://cychong47.github.io/post/2019/mac-mini-2009-upgrade/</guid><description>&lt;p&gt;swap을 사용하지 못하는 kubenertes를 사용해서 ghost pod/container를 구동하니 메모리가 부족하다고 종료되어 버린다.&lt;/p&gt;
&lt;p&gt;확인해 보니 서버로 사용하고 있는 mac mini 2009에 장착된 RAM이 4G였다.
흠&amp;hellip;&lt;/p&gt;
&lt;p&gt;인터넷에서 &lt;a href="https://support.apple.com/kb/sp505?locale=en_US"&gt;mac mini 2009의 HW 사양&lt;/a&gt;을 찾아 보니 DDR3 1066 MHz라고. 그리고 다른 블로그를 찾아 보니 그 보다 나중에 나온 더 높은 클럭의 RAM을 실장해도 동작하는 데는 문제가 없단다. 다만 지금은 사용하지 않는 DDR3 제품이라 구하는 게 문제일 듯.
하지만 혹시나 하고 예전에 모아둔 메모리 더미를 뒤져보니 딱 맞는 메모리가 있었다. 1066 MHz에 4G짜리 2개. 정말 안성맞춤.&lt;/p&gt;</description></item><item><title>Upgrade ghost to v3.0</title><link>https://cychong47.github.io/post/2019/upgrade-ghost-to-v3-0/</link><pubDate>Tue, 05 Nov 2019 14:58:16 +0900</pubDate><guid>https://cychong47.github.io/post/2019/upgrade-ghost-to-v3-0/</guid><description>&lt;ul&gt;
&lt;li&gt;부제 1. pod가 동작하지 않을때 원인 찾기&lt;/li&gt;
&lt;li&gt;부제 2. helm upgrade 명령을 이용하여 업데이트 하기&lt;/li&gt;
&lt;li&gt;부제 3. sqlite를 이용해서 ghost.db 직접 수정하기&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;values.yaml에 명시되어 있는 ghost docker image의 버전 정보를 2.31.0에서 3.0.2 최신 버전으로 업데이트 후 아래 명령어로 업데이트&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;$ helm upgrade --debug my-ghost ghost-with-helm
[debug] Created tunnel using local port: &amp;#39;45263&amp;#39;

[debug] SERVER: &amp;#34;127.0.0.1:45263&amp;#34;

REVISION: 6
RELEASED: Tue Nov 5 22:25:19 2019
CHART: ghost-0.1.0
USER-SUPPLIED VALUES:
{}

COMPUTED VALUES:
affinity: {}
env:
 node_env: production
 url: http://sosa0sa.com:2368
fullnameOverride: &amp;#34;&amp;#34;
image:
 pullPolicy: Always
 registry: docekr.io
 repository: ghost
 tag: 3.0.2
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Helm upgrade는 완료되었지만 ghost 블로그가 접속이 되지 않는다. 상태를 확인해 보니&lt;/p&gt;</description></item><item><title>What if helm command refuse to execute</title><link>https://cychong47.github.io/post/2019/what-if-helm-command-refuses/</link><pubDate>Tue, 05 Nov 2019 14:47:41 +0900</pubDate><guid>https://cychong47.github.io/post/2019/what-if-helm-command-refuses/</guid><description>&lt;p&gt;helm 명령을 입력했는데 다음과 같은 에러 메시지를 내면서 실행을 거부한다.&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;$ helm ls
snap-confine has elevated permissions and is not confined but should be. Refusing to continue to avoid permission escalation attacks
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;에러 메시지를 찾아보니 보안 관련된 내용이 이슈라고
다음과 같이 하면 해결된다.&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;$ sudo systemctl enable --now apparmor.service
Synchronizing state of apparmor.service with SysV service script with /lib/systemd/systemd-sysv-install.
Executing: /lib/systemd/systemd-sysv-install enable apparmor
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;하지만 이제는 helm의 client와 server 버전이 맞지 않다는 에러&lt;/p&gt;</description></item><item><title>kubelet이 실행되지 않을때</title><link>https://cychong47.github.io/post/2019/what-if-kubelet-is-not-started/</link><pubDate>Tue, 05 Nov 2019 14:43:35 +0900</pubDate><guid>https://cychong47.github.io/post/2019/what-if-kubelet-is-not-started/</guid><description>&lt;p&gt;mini1 리붓 후 ghost 접속이 안됨.&lt;/p&gt;
&lt;p&gt;docker를 직접 실행시키는 wordpress는 정상적으로 실행&lt;/p&gt;
&lt;p&gt;그래서 kubectl get svc 명령을 치니 접속이 안된다고.&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;$ ps -ef |grep kube
cychong 7461 2486 0 23:26 pts/0 00:00:00 grep --color=auto kube
$ service kubelet status
● kubelet.service - kubelet: The Kubernetes Node Agent
 Loaded: loaded (/lib/systemd/system/kubelet.service; enabled; vendor preset: enabled)
 Drop-In: /etc/systemd/system/kubelet.service.d
 └─10-kubeadm.conf
 Active: activating (auto-restart) (Result: exit-code) since Mon 2019-11-04 23:26:47 KST; 5s ago
 Docs: https://kubernetes.io/docs/home/
 Process: 7664 ExecStart=/usr/bin/kubelet $KUBELET_KUBECONFIG_ARGS $KUBELET_CONFIG_ARGS $KUBELET_KUBEADM_ARGS $KUBELET_EXTRA_ARGS (code=exited, status=255
 Main PID: 7664 (code=exited, status=255)
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex="0"&gt;&lt;code&gt;$ journalctl -xeu kubelet
Nov 04 23:28:32 mini1 kubelet[8695]: I1104 23:28:32.418274 8695 server.go:773] Client rotation is on, will bootstrap in background
Nov 04 23:28:32 mini1 kubelet[8695]: I1104 23:28:32.427223 8695 certificate_store.go:129] Loading cert/key pair from &amp;#34;/var/lib/kubelet/pki/kubelet-clien
Nov 04 23:28:32 mini1 kubelet[8695]: I1104 23:28:32.580296 8695 server.go:644] --cgroups-per-qos enabled, but --cgroup-root was not specified. defaulti
Nov 04 23:28:32 mini1 kubelet[8695]: F1104 23:28:32.580915 8695 server.go:271] failed to run Kubelet: running with swap on is not supported, please disa
Nov 04 23:28:32 mini1 systemd[1]: kubelet.service: Main process exited, code=exited, status=255/n/a
Nov 04 23:28:32 mini1 systemd[1]: kubelet.service: Failed with result &amp;#39;exit-code&amp;#39;.
Nov 04 23:28:42 mini1 systemd[1]: kubelet.service: Service hold-off time over, scheduling restart.
Nov 04 23:28:42 mini1 systemd[1]: kubelet.service: Scheduled restart job, restart counter is at 30.
-- Subject: Automatic restarting of a unit has been scheduled
-- Defined-By: systemd
-- Support: http://www.ubuntu.com/support
--
-- Automatic restarting of the unit kubelet.service has been scheduled, as the result for
-- the configured Restart= setting for the unit.
Nov 04 23:28:42 mini1 systemd[1]: Stopped kubelet: The Kubernetes Node Agent.
-- Subject: Unit kubelet.service has finished shutting down
-- Defined-By: systemd
-- Support: http://www.ubuntu.com/support
--
-- Unit kubelet.service has finished shutting down.
Nov 04 23:28:42 mini1 systemd[1]: Started kubelet: The Kubernetes Node Agent.
-- Subject: Unit kubelet.service has finished start-up
-- Defined-By: systemd
-- Support: http://www.ubuntu.com/support
--
-- Unit kubelet.service has finished starting up.
--
-- The start-up result is RESULT.
Nov 04 23:28:42 mini1 kubelet[8795]: Flag --cgroup-driver has been deprecated, This parameter should be set via the config file specified by the Kubelet&amp;#39;s
Nov 04 23:28:42 mini1 kubelet[8795]: Flag --resolv-conf has been deprecated, This parameter should be set via the config file specified by the Kubelet&amp;#39;s --
Nov 04 23:28:42 mini1 kubelet[8795]: Flag --cgroup-driver has been deprecated, This parameter should be set via the config file specified by the Kubelet&amp;#39;s
Nov 04 23:28:42 mini1 kubelet[8795]: Flag --resolv-conf has been deprecated, This parameter should be set via the config file specified by the Kubelet&amp;#39;s --
Nov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.907863 8795 server.go:410] Version: v1.16.1
Nov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.908251 8795 plugins.go:100] No cloud provider specified.
Nov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.908283 8795 server.go:773] Client rotation is on, will bootstrap in background
Nov 04 23:28:42 mini1 kubelet[8795]: I1104 23:28:42.917653 8795 certificate_store.go:129] Loading cert/key pair from &amp;#34;/var/lib/kubelet/pki/kubelet-clien
Nov 04 23:28:43 mini1 kubelet[8795]: I1104 23:28:43.073234 8795 server.go:644] --cgroups-per-qos enabled, but --cgroup-root was not specified. defaulti
Nov 04 23:28:43 mini1 kubelet[8795]: F1104 23:28:43.073886 8795 server.go:271] failed to run Kubelet: running with swap on is not supported, please disa
Nov 04 23:28:43 mini1 systemd[1]: kubelet.service: Main process exited, code=exited, status=255/n/a
Nov 04 23:28:43 mini1 systemd[1]: kubelet.service: Failed with result &amp;#39;exit-code&amp;#39;.
lines 1947-1986/1986 (END)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;찾아보니 &lt;code&gt;docker&lt;/code&gt;가 정상적으로 실행 중인지 확인해 보라고.&lt;/p&gt;</description></item><item><title>Enable SCTP in kubernetes</title><link>https://cychong47.github.io/post/2019/enable-sctp-in-kubernetes/</link><pubDate>Mon, 07 Oct 2019 15:39:35 +0900</pubDate><guid>https://cychong47.github.io/post/2019/enable-sctp-in-kubernetes/</guid><description>&lt;h2 id="check-if-sctp-is-supported-by-creating-sctp-service"&gt;Check if SCTP is supported by creating SCTP service&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://blog.aweimeow.tw/enable-sctp-in-kubernetes-cluster/"&gt;https://blog.aweimeow.tw/enable-sctp-in-kubernetes-cluster/&lt;/a&gt;&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~/work/sctp$ cat service.yaml
apiVersion: v1
kind: Service
metadata:
 name: sctp
spec:
 selector:
 app: sctp
 ports:
 - protocol: SCTP
 port: 9999
 targetPort: 30001
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@mini1:~/work/sctp$ kubectl create -f service.yaml
The Service &amp;#34;sctp&amp;#34; is invalid: spec.ports[0].protocol: Unsupported value: &amp;#34;SCTP&amp;#34;: supported values: &amp;#34;TCP&amp;#34;, &amp;#34;UDP&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="enable-sctp-in-running-kubernetes-cluster"&gt;Enable SCTP in running kubernetes cluster&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://stackoverflow.com/questions/55909512/how-to-configure-already-running-cluster-in-kubernetes"&gt;https://stackoverflow.com/questions/55909512/how-to-configure-already-running-cluster-in-kubernetes&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Basically you must pass this flag to kube-apiserver. How you can do that depends on how you set up the cluster. If you used kubeadm or kubespray then you should edit file &lt;code&gt;/etc/kubernetes/manifests/kube-apiserver.yaml&lt;/code&gt; and add this flag somewhere under &amp;ldquo;command&amp;rdquo; field (somewhere between other flags). After that kube-apiserver pod should be restarted automatically. If not - you can kill it by hand.&lt;/p&gt;</description></item><item><title>Convention on impose core requirements</title><link>https://cychong47.github.io/post/2019/convention-on-impose-core-requirements/</link><pubDate>Sun, 29 Sep 2019 14:35:21 +0900</pubDate><guid>https://cychong47.github.io/post/2019/convention-on-impose-core-requirements/</guid><description>&lt;p&gt;하나의 Helm chart를 이용하여 여러 개의 pod를 설치 하는 nested chart 인 경우 각각의 pod에 대한 CPU requirement는 각 subchart의 values.yaml에 resources 항목에 기술하면 된다.&lt;/p&gt;
&lt;p&gt;아래는 ONAP중 closed loop control에서 Data collection을 담당하는 &lt;a href="https://wiki.onap.org/pages/viewpage.action?pageId=1015831"&gt;DCAE&lt;/a&gt;의 SW들을 kubernets에 배포하기 위해 만들어진 차트들이다. 다음과 같이 8개의 chart들로 구성되어 있고,&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;$ tree -d oom/kubernetes/dcaegen2/charts/ -L 1
oom/kubernetes/dcaegen2/charts/
├── dcae-bootstrap
├── dcae-cloudify-manager
├── dcae-config-binding-service
├── dcae-deployment-handler
├── dcae-healthcheck
├── dcae-policy-handler
├── dcae-redis
└── dcae-servicechange-handler

8 directories
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;각각의 subchart는 각자의 values.yaml 파일을 가지고 있다.&lt;/p&gt;</description></item><item><title>Install VM with multipass on OS X</title><link>https://cychong47.github.io/post/2019/install-vm-with-multipass/</link><pubDate>Sat, 28 Sep 2019 15:17:26 +0900</pubDate><guid>https://cychong47.github.io/post/2019/install-vm-with-multipass/</guid><description>&lt;h2 id="multipass"&gt;multipass?&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Multipass is a lightweight VM manager for Linux, Windows and macOS. It&amp;rsquo;s designed for developers who want a fresh Ubuntu environment with a single command. It uses KVM on Linux, Hyper-V on Windows and HyperKit on macOS to run the VM with minimal overhead. It can also use VirtualBox on Windows and macOS. Multipass will fetch images for you and keep them up to date.&lt;/p&gt;
&lt;p&gt;Since it supports metadata for cloud-init, you can simulate a small cloud deployment on your laptop or workstation.&lt;/p&gt;</description></item><item><title>Ghost Season 5 - Helm</title><link>https://cychong47.github.io/post/2019/ghost-season-5-helm/</link><pubDate>Sun, 22 Sep 2019 13:14:16 +0900</pubDate><guid>https://cychong47.github.io/post/2019/ghost-season-5-helm/</guid><description>&lt;p&gt;ghost를 설치한 지 몇 년이 지났는데 그 동안 여러 가지 방법으로 &lt;a href="http://sosa0sa.com:2368/ghost-deployment-season-4/"&gt;Ghost 운용 환경을 구축&lt;/a&gt;해왔다.&lt;/p&gt;
&lt;p&gt;Host 환경, Docker, Ansible, kubernetes 에 이어 이번은 5번째 시즌인데 &lt;a href="https://helm.sh"&gt;Helm Chart&lt;/a&gt; 를 시용해서 설치해 보는 것이다. 처음 시작은 helm repository에 있는 공식(?) 공개된 helm chart를 이용하여 values.yaml 파일만 내 환경에 맞게 변경해서 사용하려던 것이었는데 아쉽게 아직은 그렇게 하기 힘든 것으로 보여 직접 helm chart를 만들어서 사용하고 있다. 이 문서는 그 과정을 기술한 것으로 향후 공식 helm chart를 활용할 수 있는 때가 오면 시즌 6에 해당하는 글을 또 쓸 듯 하다.&lt;/p&gt;</description></item><item><title>Wifi 2.5GHz bluetooth coexist</title><link>https://cychong47.github.io/post/2019/wifi-5ghz-bluetooth-coexistence/</link><pubDate>Mon, 26 Aug 2019 15:46:19 +0900</pubDate><guid>https://cychong47.github.io/post/2019/wifi-5ghz-bluetooth-coexistence/</guid><description>&lt;p&gt;간혹 아니 자주 블루투스로 연결한 마우스가 너무 반응이 느리다.
맥이 이상한 가 싶어 트랙패드를 만져보면 전혀 반응 속도에 이상이 없다.&lt;br&gt;
인터넷을 뒤져보니 Wifi 2.5GHz와 블루투스가 간섭을 일으켜서 그런다고.
가장 간단한 해결책은 2.5GHz인데, 설명서에 있는 대로 2.5GHz에 대해 &lt;code&gt;Radio Enable&lt;/code&gt; 를 꺼도 여전히 AP list에 나온다.
그러다 우연히 본 옵션이 &amp;ldquo;Bluetooth coexistence&amp;rdquo;. 5GHz에 대해서는 이 옵션이 없는 걸 보니 뭔가 영향을 줄 것 같다.
일단 옵션을 Enable로 변경.&lt;/p&gt;
&lt;p&gt;Let&amp;rsquo;s see what happens.
&lt;img src="https://cychong47.github.io/images/2019/08/enable_bluetooth_coexist.png" alt="enable_bluetooth_coexist"&gt;&lt;/p&gt;</description></item><item><title>Calico CNI (draft)</title><link>https://cychong47.github.io/post/2019/calico-cni-1/</link><pubDate>Sun, 18 Aug 2019 15:20:01 +0900</pubDate><guid>https://cychong47.github.io/post/2019/calico-cni-1/</guid><description>&lt;h2 id="getting-started-with-calico-on-kubernetes"&gt;&lt;a href="https://www.dasblinkenlichten.com/getting-started-with-calico-on-kubernetes/"&gt;Getting started with Calico on Kubernetes&lt;/a&gt;&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Calico를 사용하는 경우 kubelet의 실행 옵션 중 &lt;code&gt;--network-plugin=cni&lt;/code&gt;와 같이 변경된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;kube-controller-manager의 실행 옵션 중 &lt;code&gt;--allocate-node-cidrs=false&lt;/code&gt; 로 역시 변경된다. 이는 CNI(여기서는 Calico의 IPAM)에서 IP 주소를 할당하기 때문&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pod 내 route table에서는 host의 link local address를 default route로 사용한다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pod가 갖는 eth0 interface는 root(혹은 default) namespace에 존재하는 &amp;lsquo;cali&amp;rsquo;로 시작하는 interface와 veh pair 관계를 갖는다.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;veth pairs는 아래 설명과 같이 서로 연결된 두 개의 interface를 의미하는데 한쪽으로 들어가면 연결된 다른 인터페이스로 나온다. 즉 pod의 eth0 interface를 통해 패킷을 전송하면 host의 cali interface로 나와 커널의 라우팅 혹은 iptable 처리를 받는다.&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.fir3net.com/Networking/Terms-and-Concepts/virtual-networking-devices-tun-tap-and-veth-pairs-explained.html"&gt;https://www.fir3net.com/Networking/Terms-and-Concepts/virtual-networking-devices-tun-tap-and-veth-pairs-explained.html&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;What goes in one end will come out the other.&lt;/p&gt;</description></item><item><title>Boundary Clock</title><link>https://cychong47.github.io/post/2019/boundary-clock/</link><pubDate>Thu, 18 Jul 2019 14:19:02 +0900</pubDate><guid>https://cychong47.github.io/post/2019/boundary-clock/</guid><description>&lt;p&gt;&lt;a href="http://community.cambiumnetworks.com/t5/PTP-FAQ/IEEE-1588-What-s-the-difference-between-a-Boundary-Clock-and/td-p/50392"&gt;IEEE 1588: What’s the difference between a Boundary Clock and Transparent Clock?&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="ieee-1588-2002"&gt;IEEE 1588 2002&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Original standard&lt;/li&gt;
&lt;li&gt;Ordinary Clock : GrandMaster of Slave. Always a single port&lt;/li&gt;
&lt;li&gt;Boundary Clock
&lt;ul&gt;
&lt;li&gt;clock node that has two or more ports (router or switch)&lt;/li&gt;
&lt;li&gt;One port as a slave clock,&lt;/li&gt;
&lt;li&gt;The remaining ports are master clock for other nodes.&lt;/li&gt;
&lt;li&gt;BC recovers the time of day within the slave clock and relays it as a reference to the mater clock function&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="1pps"&gt;1PPS&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Pulse-Per-Second&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.iqdfrequencyproducts.com/media/pg/1589/1495630251/gps-do.pdf"&gt;https://www.iqdfrequencyproducts.com/media/pg/1589/1495630251/gps-do.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="holdover-time"&gt;Holdover time&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Time to maintain the accuracy during the GPS is not locked&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="oxco-vs-tcxo"&gt;OXCO vs. TCXO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Oven Controlled Oscillator
&lt;ul&gt;
&lt;li&gt;ensure 8 microseconds of holdover from 8 to 24 hours,&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.eetimes.com/document.asp?doc_id=1278627#"&gt;https://www.eetimes.com/document.asp?doc_id=1278627#&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;TCXO(Temperature-Compensated Crystal Oscillator)&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Setup Ghost in microk8s</title><link>https://cychong47.github.io/post/2019/setup-ghost-in-microk8s-2/</link><pubDate>Mon, 20 May 2019 16:00:56 +0900</pubDate><guid>https://cychong47.github.io/post/2019/setup-ghost-in-microk8s-2/</guid><description>&lt;h1 id="install-microk8s"&gt;Install microk8s&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://microk8s.io/"&gt;MicroK8s - Fast, Light, Upstream Developer Kubernetes&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;설치는 위 링크에 있는 공식 홈페이지에 있는 대로 &lt;code&gt;snap&lt;/code&gt; 명령어 하나로 간단하게 설치할 수 있다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cychong@mini1:~$ sudo snap install microk8s --classic
2019-05-18T09:43:53+09:00 INFO Waiting for restart...
microk8s v1.14.1 from Canonical✓ installed
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;설치된 &lt;code&gt;microk8s&lt;/code&gt;의 정보를 확인하려면 &lt;code&gt;snap info microk8s&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;cychong@mini1:~$ sudo snap info microk8s
name: microk8s
summary: Kubernetes for workstations and appliances
publisher: Canonical✓
contact: &amp;lt;https://github.com/ubuntu/microk8s&amp;gt;
license: unset
description: |
 MicroK8s is a small, fast, secure, single node Kubernetes that installs on just about any Linux
 box. Use it for offline development, prototyping, testing, or use it on a VM as a small, cheap,
 reliable k8s for CI/CD. It's also a great k8s for appliances - develop your IoT apps for k8s and
 deploy them to MicroK8s on your boxes.
commands:
 - microk8s.config
 - microk8s.ctr
 - microk8s.disable
 - microk8s.enable
 - microk8s.inspect
 - microk8s.istioctl
 - microk8s.kubectl
 - microk8s.reset
 - microk8s.start
 - microk8s.status
 - microk8s.stop
services:
 microk8s.daemon-apiserver: simple, enabled, active
 microk8s.daemon-apiserver-kicker: simple, enabled, active
 microk8s.daemon-containerd: simple, enabled, active
 microk8s.daemon-controller-manager: simple, enabled, active
 microk8s.daemon-etcd: simple, enabled, active
 microk8s.daemon-kubelet: simple, enabled, active
 microk8s.daemon-proxy: simple, enabled, active
 microk8s.daemon-scheduler: simple, enabled, active
snap-id: EaXqgt1lyCaxKaQCU349mlodBkDCXRcg
tracking: stable
refresh-date: today at 09:44 KST
channels:
 stable: v1.14.1 2019-04-18 (522) 214MB classic
 candidate: v1.14.1 2019-04-15 (522) 214MB classic
 beta: v1.14.1 2019-04-15 (522) 214MB classic
 edge: v1.14.2 2019-05-17 (604) 217MB classic
 1.15/stable: –
 1.15/candidate: –
 1.15/beta: –
 1.15/edge: v1.15.0-alpha.3 2019-05-08 (578) 215MB classic
 1.14/stable: v1.14.1 2019-04-18 (521) 214MB classic
 1.14/candidate: v1.14.1 2019-04-15 (521) 214MB classic
 1.14/beta: v1.14.1 2019-04-15 (521) 214MB classic
 1.14/edge: v1.14.2 2019-05-17 (603) 217MB classic
 1.13/stable: v1.13.5 2019-04-22 (526) 237MB classic
 1.13/candidate: v1.13.6 2019-05-09 (581) 237MB classic
 1.13/beta: v1.13.6 2019-05-09 (581) 237MB classic
 1.13/edge: v1.13.6 2019-05-08 (581) 237MB classic
 1.12/stable: v1.12.8 2019-05-02 (547) 259MB classic
 1.12/candidate: v1.12.8 2019-05-01 (547) 259MB classic
 1.12/beta: v1.12.8 2019-05-01 (547) 259MB classic
 1.12/edge: v1.12.8 2019-04-24 (547) 259MB classic
 1.11/stable: v1.11.10 2019-05-10 (557) 258MB classic
 1.11/candidate: v1.11.10 2019-05-02 (557) 258MB classic
 1.11/beta: v1.11.10 2019-05-02 (557) 258MB classic
 1.11/edge: v1.11.10 2019-05-01 (557) 258MB classic
 1.10/stable: v1.10.13 2019-04-22 (546) 222MB classic
 1.10/candidate: v1.10.13 2019-04-22 (546) 222MB classic
 1.10/beta: v1.10.13 2019-04-22 (546) 222MB classic
 1.10/edge: v1.10.13 2019-04-22 (546) 222MB classic
installed: v1.14.1 (522) 214MB classic
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="enable-servicesmicrok8s"&gt;Enable services(microk8s)&lt;/h2&gt;
&lt;pre&gt;&lt;code&gt;cychong@mini1:~$ sudo microk8s.enable dashboard registry dns
Enabling dashboard
secret/kubernetes-dashboard-certs created
serviceaccount/kubernetes-dashboard created
deployment.apps/kubernetes-dashboard created
service/kubernetes-dashboard created
service/monitoring-grafana created
service/monitoring-influxdb created
service/heapster created
deployment.extensions/monitoring-influxdb-grafana-v4 created
serviceaccount/heapster created
configmap/heapster-config created
configmap/eventer-config created
deployment.extensions/heapster-v1.5.2 created
dashboard enabled
Enabling the private registry
Enabling default storage class
deployment.extensions/hostpath-provisioner created
storageclass.storage.k8s.io/microk8s-hostpath created
Storage will be available soon
Applying registry manifest
namespace/container-registry created
persistentvolumeclaim/registry-claim created
deployment.extensions/registry created
service/registry created
The registry is enabled
Enabling DNS
Applying manifest
service/kube-dns created
serviceaccount/kube-dns created
configmap/kube-dns created
deployment.extensions/kube-dns created
Restarting kubelet
DNS is enabled
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;서비스 상태는 &lt;code&gt;microk8s.status&lt;/code&gt;로 확인 가능&lt;/p&gt;</description></item><item><title>ghost deployment season 4</title><link>https://cychong47.github.io/post/2019/ghost-deployment-season-4/</link><pubDate>Sun, 19 May 2019 12:45:58 +0900</pubDate><guid>https://cychong47.github.io/post/2019/ghost-deployment-season-4/</guid><description>&lt;p&gt;ghost blog를 구성해서 사용한 게 벌써 2014년 이다. 당시 0.x 버전 이었던 초반에는 얼마 못 가고 사라지지 않을까 걱정했는데 한참을 1.0버전을 발표하지 않더니 벌써 2.x 버전이다.&lt;/p&gt;
&lt;p&gt;그동안 내가 ghost 블로그를 운용하는 방식도 몇 번의 변화를 가졌다.&lt;/p&gt;
&lt;h3 id="시즌-1---brew--tar-ball"&gt;시즌 1 - brew &amp;amp; tar-ball&lt;/h3&gt;
&lt;p&gt;처음에는 매뉴얼 대로 직접 Node.js와 ghost 소스를 이용해서 직접 OS X에 설치해서 운용했다.&lt;/p&gt;
&lt;h3 id="시즌-2---docker"&gt;시즌 2 - Docker&lt;/h3&gt;
&lt;p&gt;그러다 Node.js 버전이 꼬이는 것도 그렇고, docker를 쓰면 ghost 버전이 새로 나왔을 때 편할 듯 해서 &lt;a href="http://sosa0sa.com:2368/move-to-docker/"&gt;docker를 쓰는 방식으로 변경했다&lt;/a&gt;. 이 시점에 docker의 stateless 속성을 이용하고, 데이터의 백업도 고려해서 ghost content는 Dropbox에 두고, docker 실행할 때 volume으로 마운트 하는 방식을 사용했다.
그 당시 ghost보다 먼저 운용하고 있던 &lt;a href="http://sosa0sa.com:2368/install-wordpress-with-docker/"&gt;wordpress도 함께 docker로 실행 환경을 바꿨다&lt;/a&gt;. wordpess는 ghost와 달리 MySql을 필요로 해서 docker-compose를 이용해서 두 개의 container를 연동해서 실행했다.&lt;/p&gt;</description></item><item><title>Kubernetes Networks</title><link>https://cychong47.github.io/post/2019/kubernetes-networks/</link><pubDate>Thu, 16 May 2019 14:07:53 +0900</pubDate><guid>https://cychong47.github.io/post/2019/kubernetes-networks/</guid><description>&lt;p&gt;&lt;a href="https://docs.google.com/spreadsheets/d/1qCOlor16Wp5mHd6MQxB5gUEQILnijyDLIExEpqmee2k/edit?fbclid=IwAR0tlnpZ694c674Tmri3N3vgpaq4jH4zzPSA-RgFz1o4C49NgurHCezPDGo#gid=0"&gt;Kubernetes Networks in google docs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;이거 보면 IPv6를 사용해야 하는 경우 선택할 수 있는 CNI는 Calico, Cillium, Contiv, Tungsten Fabric 정도로 좁혀지네&lt;/p&gt;</description></item><item><title>(펌글) 아마존 3년 출근기</title><link>https://cychong47.github.io/post/2019/amazon-daily-work/</link><pubDate>Thu, 16 May 2019 11:54:25 +0900</pubDate><guid>https://cychong47.github.io/post/2019/amazon-daily-work/</guid><description>&lt;p&gt;&lt;a href="https://zaverome.wordpress.com/2019/01/09/%EC%95%84%EB%A7%88%EC%A1%B4-3%EB%85%84-%EC%B6%9C%EA%B7%BC%EA%B8%B0-1-%ED%95%98%EB%A3%A8-%EC%9D%BC%EA%B3%BC-%EB%B0%8F-%EC%9A%94%EC%95%BD/"&gt;https://zaverome.wordpress.com/2019/01/09/%EC%95%84%EB%A7%88%EC%A1%B4-3%EB%85%84-%EC%B6%9C%EA%B7%BC%EA%B8%B0-1-%ED%95%98%EB%A3%A8-%EC%9D%BC%EA%B3%BC-%EB%B0%8F-%EC%9A%94%EC%95%BD/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;인상적인 내용들&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;매일 하는 스탠드업 미팅(데일리 스크럼)은 오후 4시입니다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;오후 4시에 하는 데일리 미팅이라. &lt;strong&gt;신기&lt;/strong&gt;하다. 보통 오늘 할 일과, 이슈 등을 이야기하는 것이 잘 알려진 daily meeting의 practice인데 오후에 한다니. 아래 내용을 보면 &lt;strong&gt;야근&lt;/strong&gt;도 안 한다는데. 흠.. 신기하네&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;아마존에서 일한 이래 일이 많아서 사무실에 늦게까지 남아 야근을 한 일은 한 번도 없습니다. 일년에 두 세번 정도 일이 좀 남아서 퇴근 후에 집에서 한 두시간 정도 일을 한 적은 있습니다.&lt;/p&gt;</description></item><item><title>Install Ubuntu 18.04.1 in Mac mini 2009</title><link>https://cychong47.github.io/post/2019/install-ubuntu-18-04-1-in-mac-mini-2009/</link><pubDate>Sun, 10 Feb 2019 14:42:07 +0900</pubDate><guid>https://cychong47.github.io/post/2019/install-ubuntu-18-04-1-in-mac-mini-2009/</guid><description>&lt;h2 id="최고령-mac은-아니고-세-번째-고령"&gt;최고령 Mac은 아니고 세 번째 고령&lt;/h2&gt;
&lt;p&gt;가장 오래된 Mac은 2005년에 구입한 Powerbook. PowerPc processor를 사용한 마지막 Apple의 laptop. 그 다음 오래된 것은 iMac 2007. 하지만 이 두 녀석들은 현재 꺼진 상태로 방치되고 있어, 현역은 Mac mini 2009라는. 당시에 리퍼를 구입했던 걸로 기억하는데 10년이 지난 2019년에도 유용하게 사용하고 있다는 게 너무 신기하다.&lt;/p&gt;
&lt;h2 id="한글-글꼴"&gt;한글 글꼴&lt;/h2&gt;
&lt;p&gt;Firefox 등에서 한글 글꼴이 없어 한글 페이지가 깨져서 나눔고딕을 설치
이것 저것 찾아보다 &lt;a href="https://blog.inidog.com/p/20170131169"&gt;https://blog.inidog.com/p/20170131169&lt;/a&gt; 참고해서 한번에 해결했다.마지막 명령어 &lt;code&gt;fc-cache -r&lt;/code&gt; 을 수행하는 도중 firefox의 한글 페이지에서 깨진 한글 글꼴이 예쁜 나눔고딕으로 변하는 모습은 감동(?)이었다&amp;hellip;&lt;/p&gt;</description></item><item><title>DPDK 18.11</title><link>https://cychong47.github.io/post/2019/dpdk-18-11/</link><pubDate>Mon, 07 Jan 2019 14:57:59 +0900</pubDate><guid>https://cychong47.github.io/post/2019/dpdk-18-11/</guid><description>&lt;p&gt;&lt;a href="https://doc.dpdk.org/guides-18.11/rel_notes/release_18_11.html"&gt;https://doc.dpdk.org/guides-18.11/rel_notes/release_18_11.html&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="new-features"&gt;New Features&lt;/h2&gt;
&lt;h4 id="updated-the-c11-memory-model-version-of-the-ring-library"&gt;Updated the C11 memory model version of the ring library.&lt;/h4&gt;
&lt;p&gt;Added changes to decrease latency for architectures using the C11 memory model version of the ring library.&lt;/p&gt;
&lt;p&gt;On Cavium ThunderX2 platform, the changes decreased latency by 27-29% and 3-15% for MPMC and SPSC cases respectively (with 2 lcores). The real improvements may vary with the number of contending lcores and the size of the ring.&lt;/p&gt;
&lt;h4 id="added-support-for-device-multi-process-hotplug"&gt;Added support for device multi-process hotplug.&lt;/h4&gt;
&lt;p&gt;Added support for hotplug and hot-unplug in a multiprocessing scenario. Any ethdev devices created in the primary process will be regarded as shared and will be available for all DPDK processes. Synchronization between processes will be done using DPDK IPC.&lt;/p&gt;</description></item><item><title>Get the latest jetpack plugin</title><link>https://cychong47.github.io/post/2018/get-the-latest-jetpack-plugin/</link><pubDate>Sun, 16 Dec 2018 06:55:44 +0900</pubDate><guid>https://cychong47.github.io/post/2018/get-the-latest-jetpack-plugin/</guid><description>&lt;p&gt;&lt;a href="http://sosa0sa.com:2368/use-jetpack-for-wordpress-5-0/"&gt;http://sosa0sa.com:2368/use-jetpack-for-wordpress-5-0/&lt;/a&gt; 의 연장선. Jetpack plugin의 최신 버전을 알아내서 자동으로 해당 바이너리 파일을 다운로드 받아 보자.&lt;/p&gt;
&lt;p&gt;몇 가지 module 을 사용하는데 필요한 module은 &lt;a href="https://realpython.com/python-web-scraping-practical-introduction/"&gt;https://realpython.com/python-web-scraping-practical-introduction/&lt;/a&gt; 을 참고해서 설치&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;$ python3 -m venv venv
$ . ./venv/bin/activate
$ pip3 install requests BeautifulSoup4
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="webscrappy"&gt;webscrap.py&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;from requests import get
from requests.exceptions import RequestException
from contextlib import closing
from bs4 import BeautifulSoup
from urllib.request import *

&amp;#39;&amp;#39;&amp;#39;
https://realpython.com/python-web-scraping-practical-introduction/
&amp;#39;&amp;#39;&amp;#39;

def simple_get(url):
 &amp;#34;&amp;#34;&amp;#34;
 Attempts to get the content at `url` by making an HTTP GET request.
 If the content-type of response is some kind of HTML/XML, return the
 text content, otherwise return None.
 &amp;#34;&amp;#34;&amp;#34;
 try:
 with closing(get(url, stream=True)) as resp:
 if is_good_response(resp):
 return resp.content
 else:
 return None

 except RequestException as e:
 log_error(&amp;#39;Error during requests to {0} : {1}&amp;#39;.format(url, str(e)))
 return None


def is_good_response(resp):
 &amp;#34;&amp;#34;&amp;#34;
 Returns True if the response seems to be HTML, False otherwise.
 &amp;#34;&amp;#34;&amp;#34;
 content_type = resp.headers[&amp;#39;Content-Type&amp;#39;].lower()
 return (resp.status_code == 200
 and content_type is not None
 and content_type.find(&amp;#39;html&amp;#39;) &amp;gt; -1)


def log_error(e):
 &amp;#34;&amp;#34;&amp;#34;
 It is always a good idea to log errors.
 This function just prints them, but you can
 make it do anything.
 &amp;#34;&amp;#34;&amp;#34;
 print(e)

def download_file(base_url, filename):
	file_url = &amp;#39;%s/%s&amp;#39; %(base_url, filename)

	print(&amp;#34;Download %s&amp;#34; %(file_url))
 
	try:
		from tqdm import tqdm
	except:
		urlretrieve(file_url, filename)
		return

	# use tqdm to display the progress but too slow
	file_response = get(file_url, stream=True)
	with open(filename, &amp;#39;wb&amp;#39;) as handle:
		for data in tqdm(file_response.iter_content()):
			handle.write(data)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Jetpack plugin 페이지에 있는 버전 정보를 이용해서 플러그인 다운로드 하기
tqdm은 progress를 보여주는 모듈인데 그냥 사용하면 속도가 너무 너무 느리다. 몇 초면 다운 받을 수 있는 파일을 1분에 걸쳐 받는&amp;hellip;&lt;/p&gt;</description></item><item><title>Use jetpack for wordpress 5.0</title><link>https://cychong47.github.io/post/2018/use-jetpack-for-wordpress-5-0/</link><pubDate>Mon, 10 Dec 2018 15:04:29 +0900</pubDate><guid>https://cychong47.github.io/post/2018/use-jetpack-for-wordpress-5-0/</guid><description>&lt;p&gt;Wordpress 5.0부터 기본 editor가 ghost와 같이 block editor 로 변경됨. Markdown을 사용하려면 이전과 동일하게 Jetpack을 사용해야 하는데 docker에서 wordpress를 돌리고 있는 내 경우 ftp를 통한 plugin 설치가 안되다는&amp;hellip;&lt;/p&gt;
&lt;p&gt;직접 설치는 안되므로 해결 방안은 Jetpack을 따로 받아 설치한 후 docker volume으로 jetpack 디렉토리를 plugins 디렉토리 밑에 마운트 시키는 방법.&lt;/p&gt;
&lt;p&gt;이번 기회에 최신 버전을 받는 방법을 포함해서 정리 해 보자.&lt;/p&gt;
&lt;h2 id="jetpack의-최신-버전-확인-방법"&gt;Jetpack의 최신 버전 확인 방법&lt;/h2&gt;
&lt;p&gt;&lt;a href="https://wordpress.org/plugins/jetpack/"&gt;https://wordpress.org/plugins/jetpack/&lt;/a&gt; 을 방문하면 오른쪽 plugin 정보란에서 다음과 같이 최신 버전 정보를 확인할 수 있다.&lt;/p&gt;</description></item><item><title>How NASA uses a wiki to reduce email</title><link>https://cychong47.github.io/post/2018/how-nasa-uses-a-wiki-to-reduce-email/</link><pubDate>Fri, 23 Nov 2018 11:37:27 +0900</pubDate><guid>https://cychong47.github.io/post/2018/how-nasa-uses-a-wiki-to-reduce-email/</guid><description>&lt;p&gt;Really good wiki adoption case in NASA&lt;/p&gt;
&lt;p&gt;&lt;a href="http://enterprisemediawiki.github.io/slides/MeetingMinutes/#/"&gt;http://enterprisemediawiki.github.io/slides/MeetingMinutes/#/&lt;/a&gt;&lt;/p&gt;</description></item><item><title>없어졌으면 하는 말</title><link>https://cychong47.github.io/post/2018/untitled-3/</link><pubDate>Thu, 18 Oct 2018 03:00:13 +0900</pubDate><guid>https://cychong47.github.io/post/2018/untitled-3/</guid><description>&lt;p&gt;자료 &amp;ldquo;등록&amp;rdquo;&lt;/p&gt;
&lt;p&gt;미팅 노트건 어떤 주제에 대한 정리 노트건 &amp;ldquo;등록&amp;quot;이란 단어를 만나면 &amp;ldquo;공식적&amp;quot;이고, &amp;ldquo;뭔가 부담스러운&amp;rdquo; 자료가 되는 것 같다.&lt;/p&gt;
&lt;p&gt;그래서 자료(라고 쓰고 그냥 &amp;lsquo;정보&amp;rsquo;라고 부른다) 공유가 안되는 것이 아닌가 싶다.&lt;/p&gt;
&lt;p&gt;누군가 눈을 부릅뜨고 있는 단상에 자료를 올리는 작업은 부담스럽다. 그런 문화/상황/환경/분위기부터 없어지면 좀 더 편하게 자료를 공유하지 않을까?&lt;/p&gt;
&lt;p&gt;Googler 들은 많은 자료를 자사 협업 툴인 Google docs등에서 작업할 듯 하다. 우리와는 다른 &amp;ldquo;일하는 환경&amp;quot;과 &amp;ldquo;사람들의 생각&amp;quot;이 그런 정보의 공유를 가능케 하는 게 아닐까 싶다.&lt;/p&gt;</description></item><item><title>Recover WordPress container</title><link>https://cychong47.github.io/post/2018/recovery-failed-wordpress-container/</link><pubDate>Wed, 05 Sep 2018 14:10:39 +0900</pubDate><guid>https://cychong47.github.io/post/2018/recovery-failed-wordpress-container/</guid><description>&lt;h2 id="one-day"&gt;One day&lt;/h2&gt;
&lt;p&gt;The Wordpress container does not work at all. &lt;code&gt;docker ps&lt;/code&gt;로 확인하면 1분 주기로 restart를 반복하고 있다. 경험상 이건 wordpress 앱이 초기화 과정에서 문제가 있는 거라는 걸로 짐작된다. 로그를 확인해 보니 아래와 같은 에러만 출력.&lt;/p&gt;
&lt;p&gt;뭐가 문제일까 멀쩡히 잘 돌던 녀석들인데.&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mini2:html cychong$ docker logs -f f12c3b3a57ef
...

Warning: mysqli::__construct(): Unexpected server respose while doing caching_sha2 auth: 109 in Standard input code on line 22

MySQL Connection Error: (2006) MySQL server has gone away

Warning: mysqli::__construct(): MySQL server has gone away in Standard input code on line 22

Warning: mysqli::__construct(): (HY000/2006): MySQL server has gone away in Standard input code on line 22

Warning: mysqli::__construct(): Unexpected server respose while doing caching_sha2 auth: 109 in Standard input code on line 22

Warning: mysqli::__construct(): MySQL server has gone away in Standard input code on line 22

Warning: mysqli::__construct(): (HY000/2006): MySQL server has gone away in Standard input code on line 22

MySQL Connection Error: (2006) MySQL server has gone away

Warning: mysqli::__construct(): Unexpected server respose while doing caching_sha2 auth: 109 in Standard input code on line 22

MySQL Connection Error: (2006) MySQL server has gone away

Warning: mysqli::__construct(): MySQL server has gone away in Standard input code on line 22

Warning: mysqli::__construct(): (HY000/2006): MySQL server has gone away in Standard input code on line 22
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="lets-debug"&gt;Let’s debug&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;하지만 뭔가 달라진 게 있으니 갑자기 문제가 발생했겠지.&lt;/p&gt;</description></item><item><title>2nd patch submit to DPDK</title><link>https://cychong47.github.io/post/2018/submit-patch-to-dpdk-with-git/</link><pubDate>Sat, 21 Jul 2018 15:02:14 +0900</pubDate><guid>https://cychong47.github.io/post/2018/submit-patch-to-dpdk-with-git/</guid><description>&lt;p&gt;AVX2가 지원되지 않는 머신에서 쓸데없이 ACL library 빌드할 때 AVX2를 이용해서 빌드하려는 문제를 확인했다. 지금까지 아무도 고치지 않은 게 이상하긴 한데 그래도 내가 생각한 수정 방법이 제대로 동작하는 듯 해서 패치를 한번 보내보기로 했다.&lt;/p&gt;
&lt;p&gt;수정사항은 비교적 간단하다.
ACL 라이브러리 빌드할 때 AVX2를 이용해서 빌드해야 하는 경우인지를 검사하는 코드가 &lt;code&gt;lib/librte_acl/Makefile&lt;/code&gt;에 정의되어 있는데 여기서 항상 &lt;code&gt;-march=core-avx2&lt;/code&gt; 옵션을 사용해서 AVX2가 지원되지 않는 머신에서도 AVX2를 사용해서 gcc가 빌드하도록 하는 걸로 보였다. 다른 코드 빌드할 때는 문제가 없는데 유독 ACL library에서만 이런 문제가 나서 보다 보니 아무래도 Makefile이 잘못된 듯 하다.&lt;/p&gt;</description></item><item><title>Astri vRAN</title><link>https://cychong47.github.io/post/2018/astri-vran/</link><pubDate>Sun, 15 Jul 2018 12:03:00 +0900</pubDate><guid>https://cychong47.github.io/post/2018/astri-vran/</guid><description>&lt;p&gt;&lt;a href="https://builders.intel.com/docs/networkbuilders/towards_5g_ran_virtualization_enabled_by_intel_and_astri.pdf"&gt;Toward 5G RAN virtualization by Intel and Astri&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://astri.oeg"&gt;http://astri.oeg&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="flexible-architecture"&gt;Flexible architecture&lt;/h2&gt;
&lt;h3 id="modular-phy-processing-architectures"&gt;Modular PHY processing architectures&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;PDCP Split&lt;/li&gt;
&lt;li&gt;MAC/PHY Split - HARQ processing in RRU(How???)&lt;/li&gt;
&lt;li&gt;Lower PHY Split - High FB overhead but smallest packet latency.
&lt;ul&gt;
&lt;li&gt;Good for JT and JR for COMP&lt;/li&gt;
&lt;li&gt;Good for Massive MIMO and Ultra low-latency communication(Why?)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;FAPI based MAC/PHY communication
&lt;ul&gt;
&lt;li&gt;L1 adaptation layer for MAC/PHY split (and Lower PHY Split?)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2018/07/Screenshot-2018-07-15-20.51.59.png" alt="Screenshot-2018-07-15-20.51.59"&gt;&lt;/p&gt;
&lt;h3 id="macphy-split-in-one-cpu"&gt;MAC/PHY split in one CPU&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;MAC/PHY split in one machine but netrwork based MAC/PHY communication over OVS
&lt;img src="https://cychong47.github.io/images/2018/07/Screenshot-2018-07-15-20.56.12.png" alt="Screenshot-2018-07-15-20.56.12"&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="virtual-cell"&gt;Virtual Cell&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;A group of physical cells form a &lt;code&gt;Virtual Cell&lt;/code&gt; which does not require HO between the physical cells.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="technical-specification"&gt;Technical Specification&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Commercial L1 reference design
&lt;img src="https://cychong47.github.io/images/2018/07/Screenshot-2018-07-15-21.02.00.png" alt="Screenshot-2018-07-15-21.02.00"&gt;&lt;/p&gt;</description></item><item><title>생각 정리의 기술</title><link>https://cychong47.github.io/post/2018/mindmap/</link><pubDate>Wed, 20 Jun 2018 14:00:06 +0900</pubDate><guid>https://cychong47.github.io/post/2018/mindmap/</guid><description>&lt;p&gt;오늘 회사에서 점심 시간에 배운 mindmap 활용법&lt;/p&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2018/06/mindmap.png" alt="mindmap"&gt;&lt;/p&gt;
&lt;p&gt;iThoughtX를 OS X, iOS용으로 모두 구입할 만큼 마인드맵에 관심이 있긴 한데 생각을 풀어낼 때 다양한 framework을 활용할 수 있다는 건 몰랐다. 관련된 책을 한번 읽어보면 좋겠네.&lt;/p&gt;
&lt;p&gt;오늘 강의해준 신 분은 무려 자기 이름을 걸로 책을 낸 저자 동종성 님&lt;br&gt;
&lt;img src="https://cychong47.github.io/images/2018/06/8982500995_1-1.jpg" alt="8982500995_1-1"&gt;&lt;/p&gt;</description></item><item><title>Update ansible-playbook for wordpress</title><link>https://cychong47.github.io/post/2018/update-ansible-playbook-for-wordpress/</link><pubDate>Thu, 14 Jun 2018 15:13:52 +0900</pubDate><guid>https://cychong47.github.io/post/2018/update-ansible-playbook-for-wordpress/</guid><description>&lt;p&gt;이상하게 wordpress 버전이 올라가면 docker용 wordpress 버전도 함께 올라갈 텐데 아무리 최신 docker image를 받아 container를 만들어도 wordpress admin 계정에 들어가면 wordpress를 업데이트 해야 한다고 한다.
docket store(&lt;a href="http://store.docker.com"&gt;http://store.docker.com&lt;/a&gt;)에 가면 분명히 wordpress 최신 버전으로 패키징되어 있는 데&amp;hellip;&lt;/p&gt;
&lt;p&gt;혹시나 하고 ansible-playbook을 보니 &lt;code&gt;/var/www/html&lt;/code&gt;에 마운트되는 위치에 이전 버전의 wordpress 파일들이 존재하고 있었다.&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt; volumes:
 - &amp;#34;/Users/cychong/Documents/wordpress/html:/var/www/html&amp;#34;
 - &amp;#34;/Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads&amp;#34;
 - &amp;#34;/Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini&amp;#34;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;바로 첫번째 줄이 문제를 유발하고 있는 곳&amp;hellip;
내가 왜 굳이 저렇게 했을까 생각해 보니 저 디렉토리에 바로 &lt;code&gt;wp-content&lt;/code&gt;가 있고, 그 아래 &lt;code&gt;themes&lt;/code&gt;와 &lt;code&gt;plugins&lt;/code&gt;가 있다. 처음 docker로 wordpress를 띄울 때 이미 설치한 theme이나 plugin이 wordpress docker 버전이 올라가서 새로 container를 만들 때마다 다시 설치해야 하는 번거로움을 피하려고 저렇게 한 듯 하다. 지금 생각하면 참 바보같은&amp;hellip;&lt;/p&gt;</description></item><item><title>wordpress admin 계정 복구</title><link>https://cychong47.github.io/post/2018/wordpress-admin-login-fail/</link><pubDate>Thu, 14 Jun 2018 14:21:13 +0900</pubDate><guid>https://cychong47.github.io/post/2018/wordpress-admin-login-fail/</guid><description>&lt;h2 id="문제"&gt;문제&lt;/h2&gt;
&lt;p&gt;블로그 보는 거 자체는 문제가 없는데 admin 계정으로 로그인 시도하면 반복해서 로그인 페이지로 redirect됨&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;http://sosa0sa.com/wp-login.php?redirect_to=http://sosa0sa.com/wp-admin/&amp;amp;reauth=1
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;구글링을 하니 대부분 쿠키를 초기화하고, theme, plugin등을 초기화하라는 의견이 대부분. 모두 따라해 봤으니 제대로 동작하지 않는다&amp;hellip; &lt;code&gt;-_-&lt;/code&gt;;;;&lt;/p&gt;
&lt;p&gt;마지막으로 wp_usermeta table에서 session_token 값을 초기화하라는 말이 있어 이것도 해 보기로. &lt;code&gt;phpmyadmin&lt;/code&gt;을 설치해서 table의 값을 변경하라고 해서 &lt;code&gt;phpmyadmin&lt;/code&gt;을 역시 docker로 설치해 보기로&lt;/p&gt;
&lt;p&gt;&lt;a href="https://wordpress.org/support/topic/possible-fix-for-sudden-redirect-loop-at-wp-login-with-reauth1/"&gt;https://wordpress.org/support/topic/possible-fix-for-sudden-redirect-loop-at-wp-login-with-reauth1/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="phpmyadmin-docker-설치"&gt;Phpmyadmin docker 설치&lt;/h2&gt;
&lt;p&gt;Wordpress ansible-playbook 에 다음과 같이 추가&lt;/p&gt;
&lt;p&gt;links를 통해 mysql container와 연결하고 PMA_HOST를 해당 mysql container의 name으로 지정하는 것이 중요한 내용임.
처음에는 PMA_HOST를 “localhost”나 “127.0.0.1”로 지정하니 정상적으로 mysql에 로그인이 되지 않음&lt;/p&gt;</description></item><item><title>Grafana, influxDB and python</title><link>https://cychong47.github.io/post/2018/grafana-influxdb-and-python/</link><pubDate>Wed, 06 Jun 2018 04:33:06 +0900</pubDate><guid>https://cychong47.github.io/post/2018/grafana-influxdb-and-python/</guid><description>&lt;p&gt;Time-series data를 python을 이용해서 influxDB에 저장하고, Grafana로 그래프를 보여주는 예제&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/cychong47/influxdb_example.git"&gt;https://github.com/cychong47/influxdb_example.git&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="install-grafana-and-influxdb"&gt;Install Grafana and influxDB&lt;/h1&gt;
&lt;h2 id="install-grafana"&gt;Install Grafana&lt;/h2&gt;
&lt;p&gt;직접 호스트에 설치할 수도 있지만, 세상 편하게 만들어준 docker를 이용해서 grafana, influxdb등을 설치하자.&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:~ cychong$ docker pull grafana/grafana 
Using default tag: latest
latest: Pulling from grafana/grafana
f2aa67a397c4: Pull complete 
89573effc7c8: Pull complete 
b55c103da375: Pull complete 
Digest: sha256:364bec4a39ecbec744ea4270aae35f6554eb6f2047b3ee08f7b5f1134857c32c
Status: Downloaded newer image for grafana/grafana:latest
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Start &lt;code&gt;grafana&lt;/code&gt;&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:~ cychong$ docker run -d -p 3000:3000 —name grafana grafana/grafana 
148894d7009259b02b04e1a98467f549400be91f9b055f8686557d69b9339e4b
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="install-influxdb"&gt;Install influxDB&lt;/h2&gt;
&lt;p&gt;influxdb도 docker 명령어 하나로 설치&lt;/p&gt;</description></item><item><title>Elastic stack and Metricbeat</title><link>https://cychong47.github.io/post/2018/install_elasticstack_and_metricbeat/</link><pubDate>Thu, 31 May 2018 21:58:51 +0900</pubDate><guid>https://cychong47.github.io/post/2018/install_elasticstack_and_metricbeat/</guid><description>&lt;h2 id="install-elastic-stackelk-stack-with-docker"&gt;Install Elastic Stack(ELK stack) with docker&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:elk-wireshark cychong$ git clonehttps://github.com/deviantony/docker-elk.git
git: &amp;#39;clonehttps://github.com/deviantony/docker-elk.git&amp;#39; is not a git command. See &amp;#39;git --help&amp;#39;.
mbpr15:elk-wireshark cychong$ git clone https://github.com/deviantony/docker-elk.git
Cloning into &amp;#39;docker-elk&amp;#39;...
remote: Counting objects: 1235, done.
remote: Total 1235 (delta 0), reused 0 (delta 0), pack-reused 1235
Receiving objects: 100% (1235/1235), 259.29 KiB | 77.00 KiB/s, done.
Resolving deltas: 100% (470/470), done.
mbpr15:elk-wireshark cychong$ cd elk
mbpr15:elk-wireshark cychong$ cd docker-elk/
mbpr15:docker-elk cychong$ ls
LICENSE			elasticsearch		logstash
README.md		extensions
docker-compose.yml	kibana
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="install-elk-with-docker-compose"&gt;Install ELK with docker-compose&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:docker-elk cychong$ docker-compose up -d
Creating network &amp;#34;docker-elk_elk&amp;#34; with driver &amp;#34;bridge&amp;#34;
Building elasticsearch
Step 1/1 : FROM docker.elastic.co/elasticsearch/elasticsearch-oss:6.2.4
6.2.4: Pulling from elasticsearch/elasticsearch-oss
469cfcc7a4b3: Pull complete
8e27facfa9e0: Pull complete
cdd15392adc7: Pull complete
19ff08a29664: Pull complete
ddc4fd93fdcc: Pull complete
b723bede0878: Pull complete
Digest: sha256:2d9c774c536bd1f64abc4993ebc96a2344404d780cbeb81a8b3b4c3807550e57
Status: Downloaded newer image for docker.elastic.co/elasticsearch/elasticsearch-oss:6.2.4
 ---&amp;gt; 3822ba554fe9
Successfully built 3822ba554fe9
Successfully tagged docker-elk_elasticsearch:latest
WARNING: Image for service elasticsearch was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Building logstash
Step 1/1 : FROM docker.elastic.co/logstash/logstash-oss:6.2.4
6.2.4: Pulling from logstash/logstash-oss
469cfcc7a4b3: Already exists
b4cfa2eb1616: Pull complete
ec994fa6fa7f: Pull complete
ccf455902ac6: Pull complete
6d54f3767ae5: Pull complete
af0dd1a720da: Pull complete
457dbabd3f63: Pull complete
f2c481bd6da1: Pull complete
d04342e2b9a1: Pull complete
e8bca7e9b0d9: Pull complete
d0096563f301: Pull complete
Digest: sha256:28668a65f6b6a4f1e2abef7aa3fd3b9c8476a16aa5bebc1a9acf0f7de5b80eef
Status: Downloaded newer image for docker.elastic.co/logstash/logstash-oss:6.2.4
 ---&amp;gt; 0bade66b6bee
Successfully built 0bade66b6bee
Successfully tagged docker-elk_logstash:latest
WARNING: Image for service logstash was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Building kibana
Step 1/1 : FROM docker.elastic.co/kibana/kibana-oss:6.2.4
6.2.4: Pulling from kibana/kibana-oss
469cfcc7a4b3: Already exists
78e4c5fdc069: Pull complete
d9ecdaefa1b8: Pull complete
c8e48c8f74d7: Pull complete
1606c56cdbff: Pull complete
4e23ce1503d4: Pull complete
d36b703b3f90: Pull complete
da5da7625f92: Pull complete
Digest: sha256:1d1f9bac326bf276010df82a2b4593619f48a5207619e8817c8b20d5a1bb3547
Status: Downloaded newer image for docker.elastic.co/kibana/kibana-oss:6.2.4
 ---&amp;gt; 32510971af4e
Successfully built 32510971af4e
Successfully tagged docker-elk_kibana:latest
WARNING: Image for service kibana was built because it did not already exist. To rebuild this image you must use `docker-compose build` or `docker-compose up --build`.
Creating docker-elk_elasticsearch_1 ... done
Creating docker-elk_kibana_1 ... done
Creating docker-elk_logstash_1 ... done
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:docker-elk cychong$ docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
4fc052e81fae docker-elk_logstash “/usr/local/bin/dock…” 9 minutes ago Up 9 minutes 5044/tcp, 0.0.0.0:5000-&amp;gt;5000/tcp, 9600/tcp docker-elk_logstash_1
46f049297c7b docker-elk_kibana “/bin/bash /usr/loca…” 9 minutes ago Up 9 minutes 0.0.0.0:5601-&amp;gt;5601/tcp docker-elk_kibana_1
8ff911ebab03 docker-elk_elasticsearch “/usr/local/bin/dock…” 9 minutes ago Up 9 minutes 0.0.0.0:9200-&amp;gt;9200/tcp, 0.0.0.0:9300-&amp;gt;9300/tcp docker-elk_elasticsearch_1
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:docker-elk cychong$ curl http://localhost:9200
{
 “name” : “npNAiWg”,
 “cluster_name” : “docker-cluster”,
 “cluster_uuid” : “7nY4KVvNS4epY4Z80NCUZw”,
 “version” : {
 “number” : “6.2.4”,
 “build_hash” : “ccec39f”,
 “build_date” : “2018-04-12T20:37:28.497551Z”,
 “build_snapshot” : false,
 “lucene_version” : “7.2.1”,
 “minimum_wire_compatibility_version” : “5.6.0”,
 “minimum_index_compatibility_version” : “5.0.0”
 },
 “tagline” : “You Know, for Search”
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="open-httplocalhost5601-with-browser"&gt;Open http://localhost:5601 with browser&lt;/h2&gt;
&lt;h2 id="install-metricbeats-with-docker---check-the-latest-version-from-elasticco"&gt;install metricbeats with docker - check the latest version from elastic.co&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;docker pull docker.elastic.co/beats/metricbeat:6.2.4
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;metricbeat 는 시스템 통계 정보를 수집해서 elasticsearch로 보내는 역할을 함.
다양한 모듈들이 &lt;code&gt;modules.d&lt;/code&gt; 디렉토리 아래 위치하고, metricbeats.yml은 수집한 정보를 보낼 위치를 변경하는 정도면 기본적인 동작을 확인할 수 있음.&lt;/p&gt;</description></item><item><title>2018.01 home network</title><link>https://cychong47.github.io/post/2018/2018-01-home-network/</link><pubDate>Tue, 30 Jan 2018 15:44:01 +0900</pubDate><guid>https://cychong47.github.io/post/2018/2018-01-home-network/</guid><description>&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2018/01/Home-network-2018.png" alt="Home-network-2018"&gt;&lt;/p&gt;</description></item><item><title>Ansible - Install homebrew</title><link>https://cychong47.github.io/post/2017/ansible-homebrew/</link><pubDate>Sat, 30 Dec 2017 02:34:39 +0900</pubDate><guid>https://cychong47.github.io/post/2017/ansible-homebrew/</guid><description>&lt;h2 id="update-homebrew"&gt;update homebrew&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:mp3 cychong$ ansible all -m homebrew -a update_homebrew=yes
localhost | SUCCESS =&amp;gt; {
 &amp;#34;changed&amp;#34;: true,
 &amp;#34;msg&amp;#34;: &amp;#34;Homebrew updated successfully.&amp;#34;
}
mini2 | SUCCESS =&amp;gt; {
 &amp;#34;changed&amp;#34;: true,
 &amp;#34;msg&amp;#34;: &amp;#34;Homebrew updated successfully.&amp;#34;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="upgrade-all-packages"&gt;upgrade all packages&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:mp3 cychong$ ansible all -m homebrew -a update_homebrew=yes -a upgrade_all=yes
localhost | SUCCESS =&amp;gt; {
 &amp;#34;changed&amp;#34;: true,
 &amp;#34;msg&amp;#34;: &amp;#34;Homebrew upgraded.&amp;#34;
}
mini2 | SUCCESS =&amp;gt; {
 &amp;#34;changed&amp;#34;: true,
 &amp;#34;msg&amp;#34;: &amp;#34;Homebrew upgraded.&amp;#34;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="install-a-package"&gt;install a package&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:mp3 cychong$ ansible all -m homebrew -a name=neovim -a state=present
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:~ cychong$ cat install_brew_neovim.yaml 
---
- hosts: all
 tasks:
 - name : install neovim in homebrew
 homebrew: 
 name: neovim
 state: present

mbpr15:~ cychong$ ansible-playbook install_brew_neovim.yaml 

PLAY [all] *****************************************************************************************************************************************************************

TASK [Gathering Facts] *****************************************************************************************************************************************************
ok: [localhost]
ok: [mini2]

TASK [install neovim in homebrew] ******************************************************************************************************************************************
changed: [localhost]
changed: [mini2]

PLAY RECAP *****************************************************************************************************************************************************************
localhost : ok=2 changed=1 unreachable=0 failed=0 
mini2 : ok=2 changed=1 unreachable=0 failed=0 

mbpr15:~ cychong$ which nvim
/usr/local/bin/nvim
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;삭제는 &lt;code&gt;state&lt;/code&gt;만 &lt;code&gt;absent&lt;/code&gt;로 변경하면 된다.&lt;/p&gt;</description></item><item><title>Ansible - recreate ghost container</title><link>https://cychong47.github.io/post/2017/recreate-ghost-container/</link><pubDate>Sat, 30 Dec 2017 02:31:41 +0900</pubDate><guid>https://cychong47.github.io/post/2017/recreate-ghost-container/</guid><description>&lt;h2 id="yaml-file"&gt;YAML file&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;state:absent&lt;/code&gt; 는 현재 존재하는 container를 중지시키고, 삭제한다.
단순히 stop만 시키려면 &lt;code&gt;state:stopped&lt;/code&gt;로 지정하면 된다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;pull: yes&lt;/code&gt; 옵션을 사용하면 항상 최신 image를 pull한다고 한다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;recreate
Use with present and started states to force the re-creation of an existing container.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:ansible cychong$ cat recreate_container_ghost.yaml 
---
- hosts: mini2
 tasks:

 - name: Stop and remove contianer
 docker_container:
 name: ghost
 state: absent

 - name: Create ghost Container
 docker_container:
 name: ghost
 image: ghost
 # always pull the latest image
 pull: yes
 state: started
 recreate: yes
 volumes:
 - &amp;#34;/Users/cychong/Dropbox/Apps/ghost/content/:/var/lib/ghost/content&amp;#34; 
 - &amp;#34;/Users/cychong/Dropbox/Apps/ghost/config.production.json:/var/lib/ghost/config.production.json&amp;#34;
 ports:
 - &amp;#34;2368:2368&amp;#34;
 env:
 NODE_ENV: production
&lt;/code&gt;&lt;/pre&gt;&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:ansible cychong$ ansible-playbook recreate_container_ghost.yaml 

PLAY [mini2] ***************************************************************************************************************************************************************

TASK [Gathering Facts] *****************************************************************************************************************************************************
ok: [mini2]

TASK [Stop and remove contianer] *******************************************************************************************************************************************
changed: [mini2]

TASK [Create ghost Container] **********************************************************************************************************************************************
changed: [mini2]

PLAY RECAP *****************************************************************************************************************************************************************
mini2 : ok=3 changed=2 unreachable=0 failed=0 
&lt;/code&gt;&lt;/pre&gt;</description></item><item><title>Ansible - basics of ansible-playbook</title><link>https://cychong47.github.io/post/2017/ansible-playbook/</link><pubDate>Fri, 29 Dec 2017 13:43:14 +0900</pubDate><guid>https://cychong47.github.io/post/2017/ansible-playbook/</guid><description>&lt;h2 id="play"&gt;&lt;code&gt;play&lt;/code&gt;&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;The goal of a play is to map a group of hosts to some well defined roles, represented by things ansible calls tasks. At a basic level, a task is nothing more than a call to an ansible module&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;play는 명령을 수행할 대상과 수행할 명령을 모두 포함하고 있다.&lt;/p&gt;
&lt;h2 id="playbook"&gt;&lt;code&gt;playbook&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;playbook은 하나 혹은 이상의 play들의 집합으로 정의한다.&lt;/p&gt;
&lt;h3 id="conventional-template-of-playbook"&gt;Conventional template of playbook&lt;/h3&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;---
- hosts: XXX
 optoins....
 
 tasks:
 -name: YYY
 MODULE_NAME : MODULE_ARGS
 -name : ZZZ
 MODULE_NAME: MODULE_ARGS
 ...
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;하나의 play는 “하나 혹은 이상의 목적지 그룹에 대해 수행되는 task들의 매핑”으로 정의된다. 즉 하나의 &lt;code&gt;hosts&lt;/code&gt; 와 해당 hosts에서 수행할 &lt;code&gt;tasks&lt;/code&gt;들 간의 매핑을 하나의 play로 정의한다.
&lt;code&gt;hosts&lt;/code&gt; 에는 접속 및 로그인에 관련된 옵션 들이 추가될 수 있다.&lt;/p&gt;</description></item><item><title>Ansible - ad-hoc or basic</title><link>https://cychong47.github.io/post/2017/ansible-exercise-1/</link><pubDate>Wed, 27 Dec 2017 14:32:51 +0900</pubDate><guid>https://cychong47.github.io/post/2017/ansible-exercise-1/</guid><description>&lt;h2 id="create-inventoryansible-hosts-file"&gt;Create inventory(Ansible hosts) file&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:Homebrew cychong$ cat /etc/ansible/hosts
mini1 ansible_host=x.y.z.a ansible_ssh_user=cychong ansible_ssh_port=22
mini2 ansible_host=x.y.z.b ansible_ssh_user=cychong ansible_ssh_port=22
localhost ansible_connection=local
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="ping"&gt;ping&lt;/h2&gt;
&lt;p&gt;ping 명령도 ansible이 제공하는 &lt;code&gt;ping&lt;/code&gt; module을 이용하므로 &lt;code&gt;-m&lt;/code&gt; 옵션을 사용한다.&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:Homebrew cychong$ ansible all -m ping -k
SSH password: 
localhost | SUCCESS =&amp;gt; {
 &amp;#34;changed&amp;#34;: false,
 &amp;#34;ping&amp;#34;: &amp;#34;pong&amp;#34;
}
mini2 | SUCCESS =&amp;gt; {
 &amp;#34;changed&amp;#34;: false,
 &amp;#34;ping&amp;#34;: &amp;#34;pong&amp;#34;
}
mini1 | UNREACHABLE! =&amp;gt; {
 &amp;#34;changed&amp;#34;: false,
 &amp;#34;msg&amp;#34;: &amp;#34;timed out&amp;#34;,
 &amp;#34;unreachable&amp;#34;: true
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;ssh의 로그인 ID는 /etc/ansible/hosts에 기술하거나 명령어 옵션 &lt;code&gt;—user=cychong&lt;/code&gt;으로 지정할 수 있다.&lt;/p&gt;</description></item><item><title>Install Wordpress with docker</title><link>https://cychong47.github.io/post/2017/install-wordpress-with-docker/</link><pubDate>Tue, 19 Dec 2017 22:20:06 +0900</pubDate><guid>https://cychong47.github.io/post/2017/install-wordpress-with-docker/</guid><description>&lt;h2 id="summary"&gt;Summary&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;docker run --restart=always -e MYSQL_ROOT_PASSWORD=aqwe123 -e MYSQL_USER=wpuser -e MYSQL_PASSWORD=wpuser@ -e MYSQL_DATABASE=wordpress_db -v /Users/cychong/Dropbox/Apps/wordpress/database:/var/lib/mysql --name mysql -d mysql

docker run --restart=always -e WORDPRESS_DB_USER=wpuser -e WORDPRESS_DB_PASSWORD=wpuser@ -e WORDPRESS_DB_NAME=wordpress_db -p 80:80 -v /Users/cychong/Documents/wordpress/html:/var/www/html -v /Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads -v /Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini --link mysql:mysql --name wpcontainer -d wordpress
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If required, import database to mysql
(Once wordpress data is imported into mysql, upgrading mysql does not requires re-import ingof wordpress data)&lt;/p&gt;
&lt;h2 id="mysql"&gt;mysql&lt;/h2&gt;
&lt;h3 id="install-container"&gt;install container&lt;/h3&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong:~ cychong$ docker run --restart=always -e MYSQL_ROOT_PASSWORD=aqwe123 -e MYSQL_USER=wpuser -e MYSQL_PASSWORD=wpuser@ -e MYSQL_DATABASE=wordpress_db -v /Users/cychong/Dropbox/Apps/wordpress/database:/var/lib/mysql --name mysql -d mysql
Unable to find image &amp;#39;mysql:latest&amp;#39; locally
latest: Pulling from library/mysql
aa18ad1a0d33: Pull complete 
a5745c3b8bcc: Pull complete 
76375fcd129c: Pull complete 
4f72cfb004cf: Pull complete 
1d6a01e515fb: Pull complete 
a71e1163fa7e: Pull complete 
8c1a568fa442: Pull complete 
e7a69cecc173: Pull complete 
9759a0f979a1: Pull complete 
3f71dac6110f: Pull complete 
58f37de54392: Pull complete 
Digest: sha256:790b7b18b832822ef400e44ad9fac885a746db1a7028ec52325730cf9b831753
Status: Downloaded newer image for mysql:latest
b1f54c680120898fc7ff16751048fe18ae461399d5d7f10308c156c68d40577b
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id="check-container-is-started"&gt;check container is started&lt;/h3&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong:~ cychong$ docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
b1f54c680120 mysql &amp;#34;docker-entrypoint...&amp;#34; 13 seconds ago Up 10 seconds 3306/tcp mysql
dea965b550e6 ghost:latest &amp;#34;docker-entrypoint...&amp;#34; 8 days ago Up 8 days 0.0.0.0:2368-&amp;gt;2368/tcp ghost
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id="check-files-are-located-where-volume-is-mounted"&gt;check files are located where volume is mounted&lt;/h3&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong:~/Dropbox/Apps/wordpress/database cychong$ ls
auto.cnf		ib_buffer_pool		mysql			server-key.pem
ca-key.pem		ib_logfile0		performance_schema	sys
ca.pem			ib_logfile1		private_key.pem		wordpress_db
client-cert.pem		ibdata1			public_key.pem
client-key.pem		ibtmp1			server-cert.pem
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="wordpress"&gt;wordpress&lt;/h2&gt;
&lt;h2 id="install-container-1"&gt;install container&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong:~ cychong$ docker run --restart=always -e WORDPRESS_DB_USER=wpuser -e WORDPRESS_DB_PASSWORD=wpuser@ -e WORDPRESS_DB_NAME=wordpress_db -p 80:80 -v /Users/cychong/Documents/wordpress/html:/var/www/html -v /Users/cychong/Documents/wordpress/uploads:/var/www/html/wp-content/uploads -v /Users/cychong/Documents/wordpress/conf/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini --link mysql:mysql --name wpcontainer -d wordpress
525ba1e4fff2caccc020960908e4f538be9512c2541e62a94c5a36a341e7ff3c

cychong:~ cychong$ docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
525ba1e4fff2 wordpress &amp;#34;docker-entrypoint...&amp;#34; 44 seconds ago Up 42 seconds 0.0.0.0:80-&amp;gt;80/tcp wpcontainer
b1f54c680120 mysql &amp;#34;docker-entrypoint...&amp;#34; 11 minutes ago Up 11 minutes 3306/tcp mysql
dea965b550e6 ghost:latest &amp;#34;docker-entrypoint...&amp;#34; 8 days ago Up 8 days 0.0.0.0:2368-&amp;gt;2368/tcp ghost
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id="check-containers"&gt;check containers&lt;/h3&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong:~ cychong$ docker ps
CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES
8ea2303518ad wordpress &amp;#34;docker-entrypoint...&amp;#34; About a minute ago Up About a minute 0.0.0.0:80-&amp;gt;80/tcp wpcontainer
b1f54c680120 mysql &amp;#34;docker-entrypoint...&amp;#34; 3 minutes ago Up 3 minutes 3306/tcp mysql
dea965b550e6 ghost:latest &amp;#34;docker-entrypoint...&amp;#34; 8 days ago Up 8 days 0.0.0.0:2368-&amp;gt;2368/tcp ghost
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id="check-files"&gt;check files&lt;/h3&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong:~ cychong$ ls Documents/wordpress/html/
index.php		wp-admin		wp-config.php		wp-links-opml.php	wp-settings.php
license.txt		wp-blog-header.php	wp-content		wp-load.php		wp-signup.php
readme.html		wp-comments-post.php	wp-cron.php		wp-login.php		wp-trackback.php
wp-activate.php		wp-config-sample.php	wp-includes		wp-mail.php		xmlrpc.php
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id="mysql-dump-data-is-not-imported"&gt;mysql dump data is not imported.&lt;/h3&gt;
&lt;p&gt;copy mysql dump file to mounted volume directory&lt;/p&gt;</description></item><item><title>clienBBS</title><link>https://cychong47.github.io/post/2017/clienbbs/</link><pubDate>Thu, 14 Dec 2017 09:42:15 +0900</pubDate><guid>https://cychong47.github.io/post/2017/clienbbs/</guid><description>&lt;p&gt;pip3로는 설치가 안되네&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:~ cychong$ pip3 install clientBBS
Collecting clientBBS
 Could not find a version that satisfies the requirement clientBBS (from versions: )
No matching distribution found for clientBBS
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;그래서 그냥 github 링크에서 클론해서 실행&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:working cychong$ git clone https://github.com/liza183/clienBBS.git
Cloning into &amp;#39;clienBBS&amp;#39;...
remote: Counting objects: 219, done.
remote: Compressing objects: 100% (25/25), done.
remote: Total 219 (delta 20), reused 23 (delta 9), pack-reused 185
Receiving objects: 100% (219/219), 33.96 MiB | 3.84 MiB/s, done.
Resolving deltas: 100% (122/122), done.
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;실행해 보자&lt;/p&gt;</description></item><item><title>mac mini 에 windows 10 설치</title><link>https://cychong47.github.io/post/2017/mac-mini-e-windows-10-seolci/</link><pubDate>Tue, 12 Dec 2017 15:18:05 +0900</pubDate><guid>https://cychong47.github.io/post/2017/mac-mini-e-windows-10-seolci/</guid><description>&lt;p&gt;mac mini 2009에 windows 10을 무사히 설치.&lt;/p&gt;
&lt;p&gt;몇 가지 삽질을 적어보면&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;mac mini는 windows 7까지만 지원하고, optic drive를 이용한 설치만 지원하기 때문에 그냥(?) 해서는 windows 10을 설치할 수 없음. 이를 해결하려면 Applications/Utilities에 있는 Boot camp assistant 앱을 복사해서 Contents 디렉토리에 있는 Info.plist 파일 내용을 수정해야 함. 대충 보면 Win7OnlyModels 하는 부분이랑 USBBootSupportedModels 부분을 아예 삭제하면 된다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Boot camp를 실행시켜 windows partition을 나누려고 했는데 이상하게 3조각으로 나뉘어지면서 윈도10용 설치 파티션을 만들 수 없다고 해서 결국 엘케피탄 설치 파일을 이용해서 다시 설치. 이 과정에서 이미 app store에서 숨겨진 El capitan 용 설치 SW 받기 위해 mas-cli라는 유틸리티를 알게 되서 활용(백투더맥 쵝오!)&lt;/p&gt;</description></item><item><title>Vagrant</title><link>https://cychong47.github.io/post/2017/vagrant-2/</link><pubDate>Tue, 21 Nov 2017 15:04:19 +0900</pubDate><guid>https://cychong47.github.io/post/2017/vagrant-2/</guid><description>&lt;h1 id="vagrant"&gt;Vagrant&lt;/h1&gt;
&lt;h2 id="what-is-a-vagrant"&gt;What is a Vagrant?&lt;/h2&gt;
&lt;p&gt;Backend에 virtualbox를 사용(변경 가능) 하고, virtualbox를 이용해 VM을 생성하여 그 VM 내 원하는 환경(특정 OS부터 특정 library까지) 을 구성함.&lt;/p&gt;
&lt;p&gt;예전에 fd.io에서 빌드하는 vpp 개발 환경이 vagrant로 되어 있었는데 왜 그런가 싶었는데 이제 생각해 보니 vpp 동작에 필요한 OS, kernel module, DPDK SDK 와 패치 들 그리고 vpp code 까지 모든 걸 제어할 수 있도록 VagrantFile을 만들어서 개발 환경을 표준화하려는 것 이었다는.&lt;/p&gt;
&lt;p&gt;Container와 달리 독립된 OS환경을 가질 수 있으므로 OS버전이 다르거나 , 커널 모듈 수정 등을 필요로 한 경우에 유용할 듯&lt;/p&gt;</description></item><item><title>Amdocs Preps 'Carrier-Grade' Version of ONAP</title><link>https://cychong47.github.io/post/2017/amdocs-preps-carrier-grade-version-of-onap/</link><pubDate>Tue, 21 Nov 2017 14:51:25 +0900</pubDate><guid>https://cychong47.github.io/post/2017/amdocs-preps-carrier-grade-version-of-onap/</guid><description>&lt;p&gt;From Amdocs Preps &amp;lsquo;Carrier-Grade&amp;rsquo; Version of ONAP | Light Reading(&lt;a href="http://www.lightreading.com/mobile/mec-(mobile-edge-computing)/amdocs-preps-carrier-grade-version-of-onap/d/d-id/738315"&gt;http://www.lightreading.com/mobile/mec-(mobile-edge-computing)/amdocs-preps-carrier-grade-version-of-onap/d/d-id/738315&lt;/a&gt;)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&amp;ldquo;We&amp;rsquo;re just about to make a big carrier [and] enterprise grade release of ONAP,&amp;rdquo; Angela Logothetis, VP and CTO of Amdocs Open Network, told Light Reading&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;Logothetis says that Amdocs is working with Intel Corp. (Nasdaq: INTC) on edge computing proofs-of-concept. This involves understanding what content and data needs to cached and where exactly that should happen on the network.&lt;/p&gt;</description></item><item><title>ONAP Takes Flak as Telcos Prep for Release 1 | Light Reading</title><link>https://cychong47.github.io/post/2017/onap-takes-flak-as-telcos-prep-for-release-1-light-reading/</link><pubDate>Tue, 14 Nov 2017 22:31:57 +0900</pubDate><guid>https://cychong47.github.io/post/2017/onap-takes-flak-as-telcos-prep-for-release-1-light-reading/</guid><description>&lt;h3 id="1st-release"&gt;1st release&lt;/h3&gt;
&lt;p&gt;Amsterdam release which is due to November 16&lt;/p&gt;
&lt;h3 id="critics"&gt;Critics&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;It will not be stable enough to be used for product&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id="misunderstanding"&gt;misunderstanding&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;That release will focus on providing support for three network functions or services &amp;ndash; a virtual firewall (vFW), virtual customer premises equipment (vCPE) and a voice-over-LTE service running on a virtual evolved packet core (vEPC)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I think this is a misunderstanding. These are just an use case not the ONAP supports them only. Maybe that can be interpreted ONAP is verified for this cases. But still it does not mean ONAP supports only them&lt;/p&gt;</description></item><item><title>Lead Follow or Get Out of the Way</title><link>https://cychong47.github.io/post/2017/lead-or-step-aside/</link><pubDate>Sun, 29 Oct 2017 01:38:23 +0900</pubDate><guid>https://cychong47.github.io/post/2017/lead-or-step-aside/</guid><description>&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2017/10/IMG_4262.JPG" alt="IMG_4262"&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.amazon.com/Lead-Follow-Get-Out-Way/dp/0812910044"&gt;book from Amazon&lt;/a&gt;&lt;/p&gt;</description></item><item><title>관리자는 '관리'업무를 하는 동료이다.</title><link>https://cychong47.github.io/post/2017/what-is-good-manager/</link><pubDate>Sat, 28 Oct 2017 15:34:55 +0900</pubDate><guid>https://cychong47.github.io/post/2017/what-is-good-manager/</guid><description>&lt;p&gt;구글이 연구한 &amp;lsquo;좋은 관리자가 가져야 할 8가지 덕목&amp;rsquo;.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;좋은 코치(coaches)다.&lt;/li&gt;
&lt;li&gt;팀에게 권한을 양도하며 마이크로매니지를 하지 않는다.&lt;/li&gt;
&lt;li&gt;팀원의 성공에 관심을 표명하며 개인적 삶에도 관심을 기울인다.&lt;/li&gt;
&lt;li&gt;생산적이며 결과를 중심으로 사고한다.&lt;/li&gt;
&lt;li&gt;훌륭한 커뮤니케이션 능력을 가지고 있다.&lt;/li&gt;
&lt;li&gt;팀원들이 경력을 키워나가도록 도움을 준다.&lt;/li&gt;
&lt;li&gt;팀을 위한 명확한 비전을 가지고 있다.&lt;/li&gt;
&lt;li&gt;팀에게 조언을 해주기에 충분한 기술적인 능력을 갖추고 있다.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;하나 하나 절대 쉬운 일이 없다.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://m.news.naver.com/read.nhn?mode=LSD&amp;amp;sid1=001&amp;amp;oid=092&amp;amp;aid=0002112310"&gt;구글이 제시한 &amp;lsquo;관리자의 자격&amp;rsquo; &lt;/a&gt;.&lt;/p&gt;</description></item><item><title>Record CBS Music Radio in every day</title><link>https://cychong47.github.io/post/2017/record-cbs-fm-cinema-music/</link><pubDate>Mon, 09 Oct 2017 16:22:15 +0900</pubDate><guid>https://cychong47.github.io/post/2017/record-cbs-fm-cinema-music/</guid><description>&lt;h1 id="purpose"&gt;Purpose&lt;/h1&gt;
&lt;p&gt;매일 낮 11시 부터 1시간 동안 CBS 뮤직 FM에서 진행되는 &lt;code&gt;신영음&lt;/code&gt;을 듣고 싶다. 아주 오래 전 가장 좋아했던 라디어 프로가 정은임씨가 진행하던 영화음악 이었는데 한참 후에 알게된 &lt;code&gt;신영음&lt;/code&gt;을 통해 내가 좋아하는 영화음악을 다시 들을 수 있게 되었다.
문제는 라디오 방송 시간. 어디서든 CBS FM 라디오를 들을 수 있는 공식 &lt;code&gt;레인보우&lt;/code&gt;앱 이나 &lt;code&gt;myTuner Pro&lt;/code&gt; 같은 앱을 쓰면 들을 수 있지만, 근무시간에 라디오를 듣기도 그렇고, 결정적으로 11시 30분에서 12시 사이에 점심 시간이 시작되어 제대로 듣기가 힘들었다.&lt;/p&gt;</description></item><item><title>사진 백업 2017 버전</title><link>https://cychong47.github.io/post/2017/sajin-baegeob-2017-beojeon/</link><pubDate>Mon, 09 Oct 2017 15:41:52 +0900</pubDate><guid>https://cychong47.github.io/post/2017/sajin-baegeob-2017-beojeon/</guid><description>&lt;p&gt;최적화(?) 중.&lt;/p&gt;
&lt;h2 id="lightroom으로-사진-관리"&gt;Lightroom으로 사진 관리&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Apple Photos 앱이 아닌 Adobe Lightroom으로 사진 관리.&lt;/li&gt;
&lt;li&gt;사진 파일은 DB에 포함시키지 않고, meta data만 DB에 저장하도록 import 방식을 사용.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:Lightroom cychong$ pwd
/Users/cychong/Pictures/Lightroom
mbpr15:Lightroom cychong$ ls -al
total 55288
drwxr-xr-x 7 cychong staff 224 Oct 9 23:36 .
drwx------+ 5 cychong staff 160 Oct 8 10:55 ..
-rw-r--r--@ 1 cychong staff 6148 Oct 9 22:47 .DS_Store
drwxr-xr-x 20 cychong staff 640 Oct 9 23:43 Lightroom Catalog Previews.lrdata
-rw-r--r--@ 1 cychong staff 26193920 Oct 9 23:41 Lightroom Catalog.lrcat
-rw-r--r-- 1 cychong staff 1687256 Oct 9 23:41 Lightroom Catalog.lrcat-journal
-rw-r--r-- 1 cychong staff 55 Oct 9 18:58 Lightroom Catalog.lrcat.lock
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="1차-작업-공간은-500g-ssd"&gt;1차 작업 공간은 500G SSD&lt;/h2&gt;
&lt;h2 id="백업"&gt;백업&lt;/h2&gt;
&lt;h3 id="1차-백업---mac-mini-2011-1tb-내장-하드에-백업"&gt;1차 백업 - Mac mini 2011 1TB 내장 하드에 백업&lt;/h3&gt;
&lt;p&gt;일단은 ditto app으로 일괄 복사.(incremental backup solution 찾아 적용 필요)&lt;/p&gt;</description></item><item><title>Error in using homebrew module in ansible</title><link>https://cychong47.github.io/post/2017/untitled-2/</link><pubDate>Sun, 08 Oct 2017 17:25:43 +0900</pubDate><guid>https://cychong47.github.io/post/2017/untitled-2/</guid><description>&lt;p&gt;When I call the homebrew modules for three hosts including the localhost, one host reports error.&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:~ cychong$ ansible-playbook install_brew_ack.yaml --verbose
No config file found; using defaults

PLAY [all] **************************************************************************************************

TASK [Gathering Facts] **************************************************************************************
ok: [localhost]
ok: [mini2]
ok: [mini1]

TASK [install ack in homebrew] ******************************************************************************
ok: [localhost] =&amp;gt; {&amp;#34;changed&amp;#34;: false, &amp;#34;failed&amp;#34;: false, &amp;#34;msg&amp;#34;: &amp;#34;Package already installed: ack&amp;#34;}
ok: [mini1] =&amp;gt; {&amp;#34;changed&amp;#34;: false, &amp;#34;failed&amp;#34;: false, &amp;#34;msg&amp;#34;: &amp;#34;Package already installed: ack&amp;#34;}
fatal: [mini2]: FAILED! =&amp;gt; {&amp;#34;changed&amp;#34;: false, &amp;#34;failed&amp;#34;: true, &amp;#34;msg&amp;#34;: &amp;#34;Warning: git 2.14.2 is already installed\nError: Git must be installed and in your PATH!\nxcrun: error: invalid active developer path (/Library/Developer/CommandLineTools), missing xcrun at: /Library/Developer/CommandLineTools/usr/bin/xcrun\nError: ack cannot be built with any available compilers.\nInstall GNU&amp;#39;s GCC\n brew install gcc&amp;#34;}
	to retry, use: --limit @/Users/cychong/install_brew_ack.retry

PLAY RECAP **************************************************************************************************
localhost : ok=2 changed=0 unreachable=0 failed=0 
mini1 : ok=2 changed=0 unreachable=0 failed=0 
mini2 : ok=1 changed=0 unreachable=0 failed=1 
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;This requires xcrun is not installed. (The following command will have a pop-up window to install command line tool).&lt;/p&gt;</description></item><item><title>FTP server is gone from High Siera OSX Server</title><link>https://cychong47.github.io/post/2017/ftp-server-is-gone-from-high-siera-osx-server/</link><pubDate>Sat, 07 Oct 2017 00:19:27 +0900</pubDate><guid>https://cychong47.github.io/post/2017/ftp-server-is-gone-from-high-siera-osx-server/</guid><description>&lt;p&gt;It is gone finally&amp;hellip;
[macOS Server 5.4 changes in High Sierra you need to know about!])https://www.imore.com/changes-macos-server-54-high-sierra)&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;File Transfer Protocol (FTP): A longtime a security risk, for example for sending password information in clear text, FTP support will be removed from macOS server if you upgrade.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As my xeros printer/scanner suppors only ftp or samba(which is much much slower than the ftp) I have to run my own ftp server in my mac mini.&lt;/p&gt;</description></item><item><title>WP video plugin</title><link>https://cychong47.github.io/post/2017/wp-video-plugin/</link><pubDate>Fri, 06 Oct 2017 01:55:04 +0900</pubDate><guid>https://cychong47.github.io/post/2017/wp-video-plugin/</guid><description>&lt;p&gt;Install &lt;a href="https://ko.wordpress.org/plugins/easy-video-player/"&gt;Easy Video Player&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Others &lt;a href="https://wpdean.com/wordpress-video-player-plugins/"&gt;7 Free WordPress Video Player Plugins of 2017&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Play with Ansible</title><link>https://cychong47.github.io/post/2017/ansible/</link><pubDate>Wed, 04 Oct 2017 00:22:48 +0900</pubDate><guid>https://cychong47.github.io/post/2017/ansible/</guid><description>&lt;h1 id="configuration"&gt;Configuration&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;ansible client A&lt;/li&gt;
&lt;li&gt;ansible target B, C&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="in-client"&gt;In client&lt;/h2&gt;
&lt;p&gt;Ansible targets(B,C) should be listed in the following file. If required additional parameters can be specified such as login account, ssh port and etc&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# /etc/ansible/hosts
&lt;/code&gt;&lt;/pre&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;192.168.1.100 ansible_ssh_user=cychong ansible_ssh_port=22
192.168.1.200 ansible_ssh_user=cychong ansible_ssh_port=22
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="in-ansible-targets"&gt;In ansible targets&lt;/h2&gt;
&lt;p&gt;A should be found on the following file&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# grep A .ssh/authorized_keys
&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id="test-run-from-a"&gt;Test run from A&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;# ansible all -m ping
192.168.1.200 | SUCCESS =&amp;gt; {
 &amp;#34;changed&amp;#34;: false, 
 &amp;#34;failed&amp;#34;: false, 
 &amp;#34;ping&amp;#34;: &amp;#34;pong&amp;#34;
}
192.168.1.100 | SUCCESS =&amp;gt; {
 &amp;#34;changed&amp;#34;: false, 
 &amp;#34;failed&amp;#34;: false, 
 &amp;#34;ping&amp;#34;: &amp;#34;pong&amp;#34;
}
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="test-run-from-a-2"&gt;Test run from A #2&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:~ cychong$ ansible all -a &amp;#34;/usr/bin/du -hs Downloads&amp;#34;
192.168.1.100 | SUCCESS | rc=0 &amp;gt;&amp;gt;
 20G	Downloads

192.168.1.200 | SUCCESS | rc=0 &amp;gt;&amp;gt;
 11G	Downloads
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="test-run-from-a-3"&gt;Test run from A #3&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:~ cychong$ ansible all -a &amp;#34;/bin/df -h .&amp;#34;
192.168.1.200 | SUCCESS | rc=0 &amp;gt;&amp;gt;
Filesystem Size Used Avail Capacity iused ifree %iused Mounted on
/dev/disk2s1 119Gi 103Gi 12Gi 90% 1178609 9223372036853597198 0% /

192.168.1.100 | SUCCESS | rc=0 &amp;gt;&amp;gt;
Filesystem Size Used Avail Capacity iused ifree %iused Mounted on
/dev/disk0s2 115Gi 58Gi 57Gi 51% 15210230 14862623 51% /
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id="how-ansible-works"&gt;How ansible works&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Playbooks contain plays&lt;/li&gt;
&lt;li&gt;Play contain taks&lt;/li&gt;
&lt;li&gt;Task call modules&lt;/li&gt;
&lt;li&gt;Taks run sequentially&lt;/li&gt;
&lt;li&gt;Handlers are triggered by task, and run once at the end of play&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="playbooks"&gt;Playbooks&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;YAML files describes the desired state of something&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="modules"&gt;Modules&lt;/h2&gt;
&lt;h3 id="list-up-all-modules"&gt;list up all modules&lt;/h3&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;$ ansible-doc -l 
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id="show-man-page-of-a-specific-module"&gt;Show man-page of a specific module&lt;/h3&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;$ ansible-doc MODULE_NAME
$ ansible-doc homebrew 
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="inventories"&gt;Inventories&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Statc lines of servers&lt;/li&gt;
&lt;li&gt;ranges&lt;/li&gt;
&lt;li&gt;dynamic list of servers : AWS, Azure, GCP&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;code&gt;/etc/ansible/hosts&lt;/code&gt;&lt;/p&gt;</description></item><item><title>(Series</title><link>https://cychong47.github.io/post/2017/series-4-10-lessons-from-telemetry/</link><pubDate>Tue, 03 Oct 2017 16:24:37 +0900</pubDate><guid>https://cychong47.github.io/post/2017/series-4-10-lessons-from-telemetry/</guid><description>&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=tIN8BjHwpNs"&gt;https://www.youtube.com/watch?v=tIN8BjHwpNs&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Other similar videos
&lt;a href="https://www.youtube.com/watch?v=NVYqgc9RK2s"&gt;Architecture for fine-grain, high-resolution Telemetry for network elements. Jun 4 2015, Juniper Networks, Presented in NANOG&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=9El0PCtNxtg"&gt;Visualizing Cisco Telemetry Data using Elasticsearch, Logstash and Kibana&lt;/a&gt;&lt;/p&gt;</description></item><item><title>(Series</title><link>https://cychong47.github.io/post/2017/cisco-ios-xr-and-signalfx-demo/</link><pubDate>Tue, 03 Oct 2017 13:47:55 +0900</pubDate><guid>https://cychong47.github.io/post/2017/cisco-ios-xr-and-signalfx-demo/</guid><description>&lt;p&gt;출처 : &lt;a href="https://www.sdxcentral.com/resources/sdn-demofriday/cisco-ios-xr-signalfx-demo-monitoring-your-modern-network/"&gt;sdxcentral, Feb 5, 2016&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2017/10/Screenshot-2017-10-03-22.24.45.png" alt="Screenshot-2017-10-03-22.24.45"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2017/10/Screenshot-2017-10-03-22.24.34.png" alt="Screenshot-2017-10-03-22.24.34"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2017/10/Screenshot-2017-10-03-22.24.18.png" alt="Screenshot-2017-10-03-22.24.18"&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2017/10/Screenshot-2017-10-03-22.38.49.png" alt="Screenshot-2017-10-03-22.38.49"&gt;&lt;/p&gt;
&lt;h2 id="tools-presented-in-the-video"&gt;tools presented in the video&lt;/h2&gt;
&lt;h2 id="reference"&gt;reference&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://player.vimeo.com/video/154632747"&gt;video&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.sdxcentral.com/wp-content/uploads/2016/02/cisco-signalfx-sdn-nfv-iosxr6-demo-slides.pdf"&gt;ppt&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>(Series</title><link>https://cychong47.github.io/post/2017/streaming-telemetry-with-google-protocol-buffers/</link><pubDate>Sun, 01 Oct 2017 21:38:04 +0900</pubDate><guid>https://cychong47.github.io/post/2017/streaming-telemetry-with-google-protocol-buffers/</guid><description>&lt;p&gt;출처 : &lt;a href="https://blogs.cisco.com/sp/streaming-telemetry-with-google-protocol-buffers"&gt;https://blogs.cisco.com/sp/streaming-telemetry-with-google-protocol-buffers&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="summary"&gt;Summary&lt;/h2&gt;
&lt;p&gt;JSON, &amp;ldquo;compact&amp;rdquo; GPB and &amp;ldquo;Key-Value&amp;rdquo; GPB&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;ldquo;Compact&amp;rdquo; GPB data on wire can be decoded without the &lt;code&gt;decoder ring&lt;/code&gt; while &amp;ldquo;Key-Value&amp;rdquo; GPB data is Self-Describing.&lt;/li&gt;
&lt;li&gt;Compact GPB can be used with UDP(default) and TCP(optionally)&lt;/li&gt;
&lt;li&gt;&amp;ldquo;Key-value&amp;rdquo; GPB is only for TCP&lt;/li&gt;
&lt;li&gt;833 bytes of compact GPB while more than 4000 bytes for Key-value GPB&lt;/li&gt;
&lt;li&gt;Compressed JSON(?)&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>CISCO Yang data model</title><link>https://cychong47.github.io/post/2017/cisco-yang-data-model/</link><pubDate>Sun, 01 Oct 2017 21:33:27 +0900</pubDate><guid>https://cychong47.github.io/post/2017/cisco-yang-data-model/</guid><description>&lt;p&gt;Seems that configuration and operation data are defined in a different yang file though it is not clear they are module or submodule&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The models are in the .yang format. A model with:
-oper in the model name indicates an operational model. For example, Cisco-IOS-XR-cdp-oper.yang is an operational model for Cisco Discovery Protocol (CDP).
-cfg indicates a configuration model. For example, Cisco-IOS-XR-cdp-cfg.yang is a configuration model for CDP.
-act indicates a NETCONF actions model. For example, Cisco-IOS-XR-ipv4-ospf-act.yang is an action model for OSPF.&lt;/p&gt;</description></item><item><title>(Series</title><link>https://cychong47.github.io/post/2017/model-driven-telemetry/</link><pubDate>Sun, 01 Oct 2017 14:06:46 +0900</pubDate><guid>https://cychong47.github.io/post/2017/model-driven-telemetry/</guid><description>&lt;p&gt;&lt;a href="http://blogs.cisco.com/sp/why-you-should-care-about-model-driven-telemetry"&gt;Why You Should Care About Model-Driven Telemetry&lt;/a&gt; from CISCO blog&lt;/p&gt;
&lt;h2 id="summary"&gt;Summary&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Periodic polling -&amp;gt; Pushing(Streaming)&lt;/li&gt;
&lt;li&gt;Model based data with YANG&lt;/li&gt;
&lt;li&gt;Use standard encoding such as JSON, Google Protocol Buffers&lt;/li&gt;
&lt;li&gt;Easy to manipulate, connect to analytic solutions&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="1-min-poll-is-too-slow"&gt;1-min poll is too slow&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;For the last 25 years, network operators have heavily relied on SNMP polling and CLI screen-scraping to extract operational data from the network. But the new and automated demands of today’s networks have pushed these mechanisms to the breaking point.&lt;/p&gt;</description></item><item><title>brew install python</title><link>https://cychong47.github.io/post/2017/brew-install-python/</link><pubDate>Sun, 01 Oct 2017 13:44:47 +0900</pubDate><guid>https://cychong47.github.io/post/2017/brew-install-python/</guid><description>&lt;p&gt;Just for the record as some environments are mentioned&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;mbpr15:working cychong$ brew install python
==&amp;gt; Installing dependencies for python: readline, sqlite, gdbm, openssl
==&amp;gt; Installing python dependency: readline
==&amp;gt; Downloading https://homebrew.bintray.com/bottles/readline-7.0.3_1.high_sierra.bottle.tar.gz
######################################################################## 100.0%
==&amp;gt; Pouring readline-7.0.3_1.high_sierra.bottle.tar.gz
==&amp;gt; Caveats
This formula is keg-only, which means it was not symlinked into /usr/local,
because macOS provides the BSD libedit library, which shadows libreadline.
In order to prevent conflicts when programs look for libreadline we are
defaulting this GNU Readline installation to keg-only..

For compilers to find this software you may need to set:
 LDFLAGS: -L/usr/local/opt/readline/lib
 CPPFLAGS: -I/usr/local/opt/readline/include

==&amp;gt; Summary
🍺 /usr/local/Cellar/readline/7.0.3_1: 46 files, 1.5MB
==&amp;gt; Installing python dependency: sqlite
==&amp;gt; Downloading https://homebrew.bintray.com/bottles/sqlite-3.20.1.high_sierra.bottle.tar.gz
######################################################################## 100.0%
==&amp;gt; Pouring sqlite-3.20.1.high_sierra.bottle.tar.gz
==&amp;gt; Caveats
This formula is keg-only, which means it was not symlinked into /usr/local,
because macOS provides an older sqlite3.

If you need to have this software first in your PATH run:
 echo &amp;#39;export PATH=&amp;#34;/usr/local/opt/sqlite/bin:$PATH&amp;#34;&amp;#39; &amp;gt;&amp;gt; ~/.bash_profile

For compilers to find this software you may need to set:
 LDFLAGS: -L/usr/local/opt/sqlite/lib
 CPPFLAGS: -I/usr/local/opt/sqlite/include

==&amp;gt; Summary
🍺 /usr/local/Cellar/sqlite/3.20.1: 11 files, 2.9MB
==&amp;gt; Installing python dependency: gdbm
==&amp;gt; Downloading https://homebrew.bintray.com/bottles/gdbm-1.13.high_sierra.bottle.tar.gz
######################################################################## 100.0%
==&amp;gt; Pouring gdbm-1.13.high_sierra.bottle.tar.gz
🍺 /usr/local/Cellar/gdbm/1.13: 19 files, 553.9KB
==&amp;gt; Installing python dependency: openssl
==&amp;gt; Downloading https://homebrew.bintray.com/bottles/openssl-1.0.2l.high_sierra.bottle.tar.gz
######################################################################## 100.0%
==&amp;gt; Pouring openssl-1.0.2l.high_sierra.bottle.tar.gz
==&amp;gt; Caveats
A CA file has been bootstrapped using certificates from the SystemRoots
keychain. To add additional certificates (e.g. the certificates added in
the System keychain), place .pem files in
 /usr/local/etc/openssl/certs

and run
 /usr/local/opt/openssl/bin/c_rehash

This formula is keg-only, which means it was not symlinked into /usr/local,
because Apple has deprecated use of OpenSSL in favor of its own TLS and crypto libraries.

If you need to have this software first in your PATH run:
 echo &amp;#39;export PATH=&amp;#34;/usr/local/opt/openssl/bin:$PATH&amp;#34;&amp;#39; &amp;gt;&amp;gt; ~/.bash_profile

For compilers to find this software you may need to set:
 LDFLAGS: -L/usr/local/opt/openssl/lib
 CPPFLAGS: -I/usr/local/opt/openssl/include

==&amp;gt; Summary
🍺 /usr/local/Cellar/openssl/1.0.2l: 1,709 files, 12.3MB
==&amp;gt; Installing python
==&amp;gt; Downloading https://homebrew.bintray.com/bottles/python-2.7.14.high_sierra.bottle.tar.gz
######################################################################## 100.0%
==&amp;gt; Pouring python-2.7.14.high_sierra.bottle.tar.gz
==&amp;gt; /usr/local/Cellar/python/2.7.14/bin/python2 -s setup.py --no-user-cfg install --force --verbose --single-v
==&amp;gt; /usr/local/Cellar/python/2.7.14/bin/python2 -s setup.py --no-user-cfg install --force --verbose --single-v
==&amp;gt; /usr/local/Cellar/python/2.7.14/bin/python2 -s setup.py --no-user-cfg install --force --verbose --single-v
==&amp;gt; Caveats
This formula installs a python2 executable to /usr/local/bin.
If you wish to have this formula&amp;#39;s python executable in your PATH then add
the following to ~/.bash_profile:
 export PATH=&amp;#34;/usr/local/opt/python/libexec/bin:$PATH&amp;#34;

Pip and setuptools have been installed. To update them
 pip2 install --upgrade pip setuptools

You can install Python packages with
 pip2 install &amp;lt;package&amp;gt;

They will install into the site-package directory
 /usr/local/lib/python2.7/site-packages

See: https://docs.brew.sh/Homebrew-and-Python.html
==&amp;gt; Summary
🍺 /usr/local/Cellar/python/2.7.14: 3,517 files, 48.4MB
&lt;/code&gt;&lt;/pre&gt;</description></item><item><title>Parsing http header with scary</title><link>https://cychong47.github.io/post/2017/parsing-http-header-with-scary/</link><pubDate>Sun, 01 Oct 2017 09:36:35 +0900</pubDate><guid>https://cychong47.github.io/post/2017/parsing-http-header-with-scary/</guid><description>&lt;h3 id="정규식으로-http-분석"&gt;정규식으로 http 분석&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;def processHTTP(data):

 str_method = &amp;quot;&amp;quot;
 str_uri = &amp;quot;&amp;quot;
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="정규표현식을-통해-넘어온-데이터에서-method-uri-http-버전-정보등으로-구분함"&gt;정규표현식을 통해 넘어온 데이터에서 METHOD, URI, HTTP 버전 정보등으로 구분함&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;h = re.search(&amp;quot;(?P&amp;lt;method&amp;gt;(^GET|^POST|^PUT|^DELETE)) (?P&amp;lt;uri&amp;gt;.+) (?P&amp;lt;version&amp;gt;.+)&amp;quot;, data)
if not h: return &amp;quot;Error&amp;quot; # 정규표현식에 해당하는 데이터가 없는 경우 Error 를 리턴해줌

# method 로 정의된 부준은 str_method 에 저장
if h.group(&amp;quot;method&amp;quot;): str_method = h.group(&amp;quot;method&amp;quot;)
# URI 데이터는 str_uri 에 저장
if h.group(&amp;quot;uri&amp;quot;): str_uri = h.group(&amp;quot;uri&amp;quot;)

return str_method,str_uri # method 와 uri 를 리턴해 줌
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;출처 : &lt;a href="http://www.packetinside.com/2010/11/scapy-"&gt;http://www.packetinside.com/2010/11/scapy-&lt;/a&gt;로-패킷-핸들링하는-프로그램-만들기-세번째.html?showComment=1423994884595&lt;/p&gt;</description></item><item><title>Google's Load Balancer</title><link>https://cychong47.github.io/post/2017/googles-load-balancer/</link><pubDate>Sun, 01 Oct 2017 08:34:30 +0900</pubDate><guid>https://cychong47.github.io/post/2017/googles-load-balancer/</guid><description>&lt;h1 id="maglev"&gt;Maglev&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Google( &lt;a href="https://research.google.com/pubs/pub44824.html"&gt;https://research.google.com/pubs/pub44824.html&lt;/a&gt; )&lt;/li&gt;
&lt;li&gt;Used in Google Cloud since 2008&lt;/li&gt;
&lt;li&gt;Scalable load balancer
&lt;ul&gt;
&lt;li&gt;Consistent hashing&lt;/li&gt;
&lt;li&gt;Connection Tracking&lt;/li&gt;
&lt;li&gt;Scale-out model backed by router&amp;rsquo;s ECMP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bypass kernel space for performance.&lt;/li&gt;
&lt;li&gt;Support connection persistence&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="network-architecture"&gt;Network Architecture&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;DNS - Routers - Maglevs - Service EndPoints.&lt;/li&gt;
&lt;li&gt;One service is served by one or more VIPs
&lt;ul&gt;
&lt;li&gt;DNS returns VIP considering geolocation and load of location&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;One VIP is served by multiple Maglevs
&lt;ul&gt;
&lt;li&gt;Router use ECMP to select one Maglev&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;One VIP is mapped to multiple Service EndPoints
&lt;ul&gt;
&lt;li&gt;Maglev select Service EndPoint by seletion algorithm and connection tracking table&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Maglev use GRE to send incoming packet to Service EndPoint or another Maglev
&lt;ul&gt;
&lt;li&gt;Send to IP fragment to another special Maglev servers&lt;/li&gt;
&lt;li&gt;Use only 3-tuple for IP fragment&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Each Service EndPoint use Direct Server Return(DSR)&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="maglev-1"&gt;Maglev&lt;/h1&gt;
&lt;h2 id="controller"&gt;Controller&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Responsible for VIP announcement with BGP&lt;/li&gt;
&lt;li&gt;Check health status of forwarder&lt;/li&gt;
&lt;li&gt;If forwarder is not headthy, withdraw all VIP announcements&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="forwarder"&gt;Forwarder&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Each VIP has one or multiple backend pools(BP)&lt;/li&gt;
&lt;li&gt;BP contain physical IP address of the Service EndPoint&lt;/li&gt;
&lt;li&gt;Each BP has specific health checking methods - depends on the service requirement(just reachability or more)&lt;/li&gt;
&lt;li&gt;Config Manager parse and update configuration of forwarder&amp;rsquo;s behavior based on the &lt;strong&gt;Config Objects&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Sharding
&lt;ul&gt;
&lt;li&gt;Sharding of Maglev enables service isolation - new service or QoS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="backend-selection"&gt;Backend Selection&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Consistent Hashing distribute loads&lt;/li&gt;
&lt;li&gt;Record selection in &lt;strong&gt;LOCAL connection tracking table&lt;/strong&gt;
&lt;ul&gt;
&lt;li&gt;Connection tracking table is &lt;strong&gt;not shared&lt;/strong&gt; with another Maglev&lt;/li&gt;
&lt;li&gt;Does not guarantee consistency on Maglev or Service EndPoint Changes(add/delete)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;For different traffic type
&lt;ul&gt;
&lt;li&gt;TCP SYN : select Backend and record it in connection tracking table&lt;/li&gt;
&lt;li&gt;TCP non-SYN : lookup connection tracking table&lt;/li&gt;
&lt;li&gt;5-tuple : (maybe) lookup connection tracking table and select backend if not found&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="consistent-hashing"&gt;Consistent Hashing&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;If Maglev is added or removed, router select different Maglev for the exsiting session - ECMP is changed&lt;/li&gt;
&lt;li&gt;If one Maglev&amp;rsquo;s local connection tracking table is overflowed, it will lose previous selection&lt;/li&gt;
&lt;li&gt;To resolve this issues,
&lt;ul&gt;
&lt;li&gt;Synchronize local connection tracking table between Maglevs -&amp;gt; overhead, overhead, overhead&lt;/li&gt;
&lt;li&gt;Consistent hashing for minimize disruption in member changes&lt;/li&gt;
&lt;li&gt;Maglev hashing - load balancing and minimal disruption on member changes&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="reference"&gt;reference&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://blog.acolyer.org/2016/03/21/maglev-a-fast-and-reliable-software-network-load-balancer/"&gt;Maglev: A Fast and Reliable Software Network Load Balancer&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blog.carlosgaldino.com/consistent-hashing.html"&gt;Consistent Hashing&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://dzone.com/articles/simple-magic-consistent"&gt;The Simple Magic of Consistent Hashing&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>OPNFV Asia Meeting</title><link>https://cychong47.github.io/post/2017/opnfv-asia-meeting/</link><pubDate>Sun, 01 Oct 2017 08:28:34 +0900</pubDate><guid>https://cychong47.github.io/post/2017/opnfv-asia-meeting/</guid><description>&lt;h2 id="zte-pharos-lab"&gt;ZTE Pharos Lab&lt;/h2&gt;
&lt;p&gt;Pharos : OPNFV를 시험하는 worldwide lab
외부에서 접속하는 것이 필요하므로 ssh를 열어줄 수는 없어서 openVPN을 제공하고, 망을 분리하는 등의 이슈 해결을 위해 노력한 듯&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.opnfv.org/developers/pharos"&gt;https://www.opnfv.org/developers/pharos&lt;/a&gt;
Pharos는 시험 환경을 구축해서 community에 공개해서 사용할 수 있는 환경을 제공하는 듯
Provide developers with substantial resources for early testing within realistic NFV environments via an open, consistent, repeatable test domain&lt;/p&gt;
&lt;h3 id="why-donate-pharos-environment"&gt;Why donate Pharos environment&lt;/h3&gt;
&lt;p&gt;NFV 환경에 사용할 HW를 직접 제조하는 업체들에게는 제품 호환성에 대한 시험을 유도할 수 있는 장점을 가짐.&lt;/p&gt;</description></item><item><title>Integrating VES to OPNFV</title><link>https://cychong47.github.io/post/2017/ves-to-opnfv/</link><pubDate>Mon, 25 Sep 2017 15:44:11 +0900</pubDate><guid>https://cychong47.github.io/post/2017/ves-to-opnfv/</guid><description>&lt;h1 id="ves-project"&gt;VES project&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://wiki.opnfv.org/display/ves/VES+Home"&gt;VNF Event Stream Project&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="demo"&gt;Demo&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://wiki.opnfv.org/display/ves/vHello_VES+Demo"&gt;vHello VES Demo in OpenStack Barcelona 2016&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=Zoxcj4mwUwU"&gt;VES ONAP demo from OPNFV Summit 2017&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="from-vf-event-streaming-ves-project-proposal"&gt;From VF Event Streaming (VES) Project Proposal&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Alok Gupta 13 Jun, 2016&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.opnfv.org/download/attachments/6819329/OPNVF%20VES.pptx?version=4&amp;amp;modificationDate=1466395653000&amp;amp;api=v2"&gt;OPNFV VES.pptx&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.opnfv.org/display/PROJ/VNF+Event+Stream"&gt;VNF Event Stream&lt;/a&gt; Prpoposal&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OPNFV projects that potentially benefit from the VES project&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Fault Management ([Doctor] (&lt;a href="https://wiki.opnfv.org/display/doctor"&gt;https://wiki.opnfv.org/display/doctor&lt;/a&gt;)) ***&lt;/li&gt;
&lt;li&gt;Virtualized Infrastructure Deployment Policies (&lt;a href="https://wiki.opnfv.org/display/copper"&gt;Copper&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;High Availability for OPNFV (&lt;a href="https://wiki.opnfv.org/display/availability"&gt;Availability&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Data Collection for Failure Prediction (&lt;a href="https://wiki.opnfv.org/display/prediction"&gt;Prediction&lt;/a&gt;) ***&lt;/li&gt;
&lt;li&gt;Audit (&lt;a href="https://wiki.opnfv.org/display/inspector"&gt;Inspector&lt;/a&gt;)&lt;/li&gt;
&lt;li&gt;Fault localization (RCA, &lt;a href="https://wiki.opnfv.org/display/pinpoint/"&gt;Pinpoint&lt;/a&gt; ) ***&lt;/li&gt;
&lt;li&gt;Service Function Chaining (sfc)&lt;/li&gt;
&lt;li&gt;Moon Security Management &lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;OpenStack projects that potentially benefit from the VES project&lt;/p&gt;</description></item><item><title>OPNFV Barometer and VES</title><link>https://cychong47.github.io/post/2017/opnfv-barometer/</link><pubDate>Mon, 25 Sep 2017 15:05:40 +0900</pubDate><guid>https://cychong47.github.io/post/2017/opnfv-barometer/</guid><description>&lt;h1 id="summary"&gt;Summary&lt;/h1&gt;
&lt;p&gt;The VES can be supported with the help of Kafka broker with the collectd in OPNFV Barometer project which is aim to collect telemetrics from the NFVI.&lt;/p&gt;
&lt;h1 id="barometer-project"&gt;Barometer Project&lt;/h1&gt;
&lt;p&gt;&lt;a href="https://wiki.opnfv.org/display/fastpath/Barometer+Home"&gt;The purpose of this project&lt;/a&gt; is providing metrics can be used to decide quality of NFVI. For this, the followings are reported&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;NIC statistics&lt;/li&gt;
&lt;li&gt;Resources such as CPU, Memory, load, cache, themals, fan speeds, voltages and machine check exceptions.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This means the output of this project will be used in the host itself as well as inside of VM.&lt;/p&gt;</description></item><item><title>(Summary) AT&amp;T Container Strategy</title><link>https://cychong47.github.io/post/2017/summary-at-t-container-strategy/</link><pubDate>Thu, 21 Sep 2017 15:21:45 +0900</pubDate><guid>https://cychong47.github.io/post/2017/summary-at-t-container-strategy/</guid><description>&lt;p&gt;From &lt;a href="https://www.youtube.com/watch?v=rYRiH3HZFN4&amp;amp;t=3s"&gt;https://www.youtube.com/watch?v=rYRiH3HZFN4&amp;amp;t=3s&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Presented in OpenStack Summit 2017 Boston&lt;/p&gt;
&lt;h2 id="container-will-be-used-for-workload-processing-after-2019"&gt;Container will be used for workload processing after 2019&lt;/h2&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2017/09/Openstack-Summit-2017---ATT-Container-Strategy-03-1.png" alt="Openstack-Summit-2017&amp;mdash;ATT-Container-Strategy-03-1"&gt;&lt;/p&gt;
&lt;p&gt;VNF is differ from Enterprise IT worklaod(4:19)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VNF is not a simple VM&lt;/li&gt;
&lt;li&gt;Maintain a state&lt;/li&gt;
&lt;li&gt;Complex network configuration&lt;/li&gt;
&lt;li&gt;Sophisticated Storage Connectivity&lt;/li&gt;
&lt;li&gt;HA is important&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;2018-2019 vendor and open source project especially openstack should do something to meet the requirements.&lt;/p&gt;
&lt;p&gt;Even it takes some time for container to replace VM for workload perspective, running the Openstack service as a container is possible today.&lt;/p&gt;</description></item><item><title>(News) Amdocs Brings an NFV Software Package Based on ONAP</title><link>https://cychong47.github.io/post/2017/new-amdocs-brings-an-nfv-software-package-based-on-onap/</link><pubDate>Wed, 20 Sep 2017 15:30:44 +0900</pubDate><guid>https://cychong47.github.io/post/2017/new-amdocs-brings-an-nfv-software-package-based-on-onap/</guid><description>&lt;p&gt;September 12, 2017&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.sdxcentral.com/articles/news/amdocs-brings-nfv-software-package-based-onap/2017/09/"&gt;https://www.sdxcentral.com/articles/news/amdocs-brings-nfv-software-package-based-onap/2017/09/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Amdocs announced its new &lt;strong&gt;NFV Powered by ONAP portfolio&lt;/strong&gt; &lt;strong&gt;–&lt;/strong&gt; a portfolio featuring modular capabilities that accelerate service design, virtualization and operating capabilities on demand.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Service providers using technologies developed in ONAP and its ecosystem of capabilities can provide enterprises the ability to design their own networks as part of a richer set of service features.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;from : &lt;a href="https://www.amdocs.com/media-room/amdocs-nfv-powered-onap-worlds-first-software-and-services-portfolio-carriers-based-open"&gt;https://www.amdocs.com/media-room/amdocs-nfv-powered-onap-worlds-first-software-and-services-portfolio-carriers-based-open&lt;/a&gt;&lt;/p&gt;
&lt;h4 id="amdoc"&gt;Amdoc?&lt;/h4&gt;
&lt;p&gt;&lt;a href="https://www.sdxcentral.com/articles/news/amdocs-will-integrator-att-ecomp-platform/2016/07/"&gt;Amdocs was initially involved&lt;/a&gt; with AT&amp;amp;T’s home-grown ECOMP platform as an integrator.(2016/07)&lt;/p&gt;</description></item><item><title>Prometheus</title><link>https://cychong47.github.io/post/2017/prometheus/</link><pubDate>Mon, 18 Sep 2017 13:59:00 +0900</pubDate><guid>https://cychong47.github.io/post/2017/prometheus/</guid><description>&lt;p&gt;Cloud Native Computing Foundation(&lt;a href="http://cncf.io"&gt;http://cncf.io&lt;/a&gt;)에 포함된 Container monitoring tool.&lt;/p&gt;
&lt;p&gt;집 맥미니에서 돌리고 있는 3개 container들을 관리하는데 사용할 수 있나 싶어(실은 관리할 것도 없지만 그냥 재미로 container monitor 기능을 보고 싶어서) 설치 해 봤다&lt;/p&gt;
&lt;h3 id="install"&gt;Install&lt;/h3&gt;
&lt;p&gt;cncf.io의 많은 툴이 그렇지만 golang으로 작성되어 있어 golang부터 설치했다&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;brew install go
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;OSX에서 brew는 사용할 때마다 감탄을 금치 못하게 한다. 물론 우분투에도 apt가 있지만 apt보다 brew가 훨씬 편한 것 같다.&lt;/p&gt;
&lt;p&gt;그 다음에는 그냥 docker hub에 있는 prometheus docker 가져다 설치&lt;/p&gt;</description></item><item><title>NGNIX for service mesh</title><link>https://cychong47.github.io/post/2017/ngnix-for-service-mesh/</link><pubDate>Fri, 15 Sep 2017 14:39:11 +0900</pubDate><guid>https://cychong47.github.io/post/2017/ngnix-for-service-mesh/</guid><description>&lt;p&gt;&lt;a href="https://www.infoq.com/news/2017/09/nginx-platform-service-mesh?utm_source=facebook&amp;amp;utm_medium=link&amp;amp;utm_campaign=calendar"&gt;NGINX Releases Microservices Platform, OpenShift Ingress Controller, and Service Mesh Preview&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;NGNIX also join for service mesh bandwagon?&lt;/p&gt;
&lt;h3 id="ngnix-application-platform"&gt;NGNIX Application Platform&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;NGINX Plus, the commercial variant of the popular open source NGINX web server.&lt;/li&gt;
&lt;li&gt;NGINX Web Application Firewall (WAF)&lt;/li&gt;
&lt;li&gt;NGINX Unit, a new open source application server that can run PHP, Python and Go&lt;/li&gt;
&lt;li&gt;NGINX Controller, a centralised control plane for monitoring and management of NGINX Plus&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="additional-release"&gt;Additional release&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;a Kubernetes Ingress Controller solution for load balancing on the Red Hat OpenShift Container Platform&lt;/li&gt;
&lt;li&gt;an implementation of NGINX as a service proxy for the Istio service mesh control plane.&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;NGINX has also released nginmesh, an open source preview version of NGINX as a service proxy for Layer 7 load balancing and proxying within the Istio service mesh platform. It aims to provide key capabilities and integration with Istio when deployed as a sidecar container, and will facilitate communication between services in a &amp;ldquo;standard, reliable, and secure manner&amp;rdquo;. Additionally, NGINX will collaborate as part of the Istio community by joining the Istio networking special interest group.&lt;/p&gt;</description></item><item><title>Wordpress with docker-compose</title><link>https://cychong47.github.io/post/2017/wordpress-with-docker-compose-failing/</link><pubDate>Sun, 03 Sep 2017 15:00:57 +0900</pubDate><guid>https://cychong47.github.io/post/2017/wordpress-with-docker-compose-failing/</guid><description>&lt;p&gt;Under construction!!&lt;/p&gt;
&lt;h3 id="error"&gt;Error&lt;/h3&gt;
&lt;p&gt;&lt;a href="https://docs.docker.com/compose/wordpress/#define-the-project"&gt;https://docs.docker.com/compose/wordpress/#define-the-project&lt;/a&gt; 에 있는 에제대로 docker-compose.yaml 파일을 만든 후 도전~~&lt;/p&gt;
&lt;p&gt;근데 실패&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong:~/work/my_wordpress cychong$ docker-compose up -d
Pulling db (mysql:5.7)...
Traceback (most recent call last):
 File &amp;#34;docker-compose&amp;#34;, line 3, in &amp;lt;module&amp;gt;
 File &amp;#34;compose/cli/main.py&amp;#34;, line 68, in main
 File &amp;#34;compose/cli/main.py&amp;#34;, line 118, in perform_command
 File &amp;#34;compose/cli/main.py&amp;#34;, line 928, in up
 File &amp;#34;compose/project.py&amp;#34;, line 427, in up
 File &amp;#34;compose/service.py&amp;#34;, line 311, in ensure_image_exists
 File &amp;#34;compose/service.py&amp;#34;, line 1016, in pull
 File &amp;#34;site-packages/docker/api/image.py&amp;#34;, line 358, in pull
 File &amp;#34;site-packages/docker/auth.py&amp;#34;, line 50, in get_config_header
 File &amp;#34;site-packages/docker/auth.py&amp;#34;, line 97, in resolve_authconfig
 File &amp;#34;site-packages/docker/auth.py&amp;#34;, line 142, in _resolve_authconfig_credstore
docker.errors.DockerException: Credentials store error: StoreError(&amp;#39;Credentials store docker-credential-osxkeychain exited with &amp;#34;User interaction is not allowed.&amp;#34;.&amp;#39;,)
Failed to execute script docker-compose
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;저 에러가 뭘까 하고 Googling을 해 보니 &lt;code&gt;&amp;quot;Credentials store docker-credential-osxkeychain exited with &amp;quot;User interaction is not allowed&amp;quot;&lt;/code&gt; 이런 해결책이 나왔다.&lt;/p&gt;</description></item><item><title>ghost container with docker-compose</title><link>https://cychong47.github.io/post/2017/ghost-container-with-docker-compose/</link><pubDate>Sun, 03 Sep 2017 01:26:28 +0900</pubDate><guid>https://cychong47.github.io/post/2017/ghost-container-with-docker-compose/</guid><description>&lt;p&gt;얼마전에 구성한 ghost container는 ghost가 1.x로 업데이트가 되면서 설정 정보의 위치가 변경되었는데 그걸 미처 몰라 블로그 주소가 기본값인 localhost로 설정되는 문제가 있었다.
기존 ghost container에 접근해서 확인해 보니 `/var/lib/ghost/config.production.json&amp;rsquo; 파일에 주소가 설정되어 있는 걸 보고 이 파일도 따로 지정해 주도록 변경했다.
그러면서 docker-compose를 한번 써 보기로&lt;/p&gt;
&lt;p&gt;일단 기존 ghost를 정리하고&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong:~ cychong$ docker stop ghost
ghost
cychong:~ cychong$ docker rm ghost
ghost
cychong:~ cychong$ docker rmi ghost
Untagged: ghost:latest
Untagged: ghost@sha256:a1f70641d35755395eb16827de4e67861e01bffe18bac8e54ab5c68cd170a2ea
Deleted: sha256:e6ba3dd3c2491c6086d570fa9769a9f60d7c004129ff9ae7ff9fa0bad16a993b
Deleted: sha256:c1ee9d43624bb4a1922c15d7a9175a80d1952cb71464d6d9d900fe21948227af
Deleted: sha256:f8f95cdbafce4ecd226cdd690e6f909203a0f83d3507c53a71d4e59826ea881b
Deleted: sha256:935d8847555992b702173b83b0d210f2728a24b5287467396dc8d5c68907691f
Deleted: sha256:f4766b72a49d4cd2e897da0efcec94c33a0d24a95cb8426a790e1c45e6e39fae
Deleted: sha256:0c0dbaebe17c6f585eb596e705ed5acba668097698a7780844c12597bb99b34a
Deleted: sha256:c807796bea7a34c0b73eae853b728f2bbcd7a4fecc19d049455b322120f95ce7
Deleted: sha256:15f9f4e44e22d3287b6caf9555110383d3ff2e88ee9cc03823b1ba5a01b75eac
Deleted: sha256:77809f11069f2abfb571cba07ee3d696ec32823df0f5d0587042ffdb27a80add
Deleted: sha256:5d6bba18f7b25c9b93d3cc0d93a4cff54eb88b0ba22ed867633a21fc3ded5f57
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;하는 김에 최신 버전의 ghost받아오고&lt;/p&gt;</description></item><item><title>Try to restore Wordpress container</title><link>https://cychong47.github.io/post/2017/try-to-restore-wordpress-docker/</link><pubDate>Sun, 03 Sep 2017 00:36:25 +0900</pubDate><guid>https://cychong47.github.io/post/2017/try-to-restore-wordpress-docker/</guid><description>&lt;p&gt;docker 버전이 업데이트되고, 몇 가지 변경사항이 있은 후 ghost, wordpress/mysql 조합의 container들이 접속이 되질 않는다.
한참을 두고 보다 ghost는 새 버전(1.x)이 나온 걸 계기로 새로 설치를 했는데(당연히 이전 설치에서 데이터를 container 내부가 아니라 local machine에 두도록 해서 데이터는 그대로 보존) wordpress는 그러질 못했다.&lt;/p&gt;
&lt;p&gt;이것 역시 참다참다 못해 &lt;a href="https://docs.docker.com/compose/wordpress/#define-the-project"&gt;https://docs.docker.com/compose/wordpress/#define-the-project&lt;/a&gt; 에 나와있는 docker swarm을 이용해서 복구해 보려고 삽을 들었다.&lt;/p&gt;
&lt;p&gt;위 페이지에 있는 대로 설정 파일을 만들고&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;version: &amp;#39;3&amp;#39;

services:
 db:
 image: mysql:5.7
 volumes:
 - /Users/cychong/Dropbox/Apps/wordpress/:/var/lib/mysql
 restart: always
 environment:
 MYSQL_ROOT_PASSWORD: xxx
 MYSQL_DATABASE: xxx
 MYSQL_USER: xxx
 MYSQL_PASSWORD: xxx

 wordpress:
 depends_on:
 - db
 image: wordpress:latest
 volumes:
 - /Users/cychong/Documents/wordpress/:/var/www/html
 - /Users/cychong/Documents/wordpress/php_uploads.ini:/usr/local/etc/php/conf.d/uploads.ini
 ports:
 - &amp;#34;8000:80&amp;#34;
 restart: always
 environment:
 WORDPRESS_DB_HOST: db:3306
 WORDPRESS_DB_USER: xxx
 WORDPRESS_DB_PASSWORD: xxx
volumes:
 db_data:
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;문서에 있는 대로 docker compose 명령을 실행했는데&lt;/p&gt;</description></item><item><title>Tesla 폄하에 대한 나의 생각</title><link>https://cychong47.github.io/post/2017/tesla-pyeomhae-daehan-nayi-saenggag/</link><pubDate>Tue, 22 Aug 2017 22:11:57 +0900</pubDate><guid>https://cychong47.github.io/post/2017/tesla-pyeomhae-daehan-nayi-saenggag/</guid><description>&lt;p&gt;난 반대로 기존 상용차업체들이 몇 년간 테슬라를 보면서도 고작(?) 전기차 라는 키워드에만 집중해서 분석한 듯한 모습이 더 실망스러운데. 여전히 테슬라를 전기동력을 이용한 차를 만드는 회사로 인지하는 건 아닌지.&lt;/p&gt;
&lt;p&gt;다른 분야와 마찬가지로 자동차부문에 SW라는 개념을 넣은 것도 전기차 못지 않은 혁신이라고 생각. 도대체 서비스센터 갈때마다 뭔 소프트웨어 업데이트를 했다고 하지만 사용자인 내가 느낄 수 있는 건 단 한번도 없었는데(이건 내 제한된 경험때문에 V사만 그런 것일지도 모르지만)&lt;/p&gt;
&lt;p&gt;한번 차를 팔면 땡(그나마 하드웨어에 대한 유지보수망)이라는 생각을 가지고 있는 회사와 끊임없이 SW를 통해 부가가치를 만들어 제공하려는 회사는 하늘과 땅 차이가 아닐까 싶다. 내가 테슬라를 산다면(일단 한숨부터 쉬고&amp;hellip; 가격이 ㅎㄷㄷ) 그건 전기차여서라기 보다는 SW를 통한 기능 혁신 때문일 듯&lt;/p&gt;</description></item><item><title>Useful quicklooks</title><link>https://cychong47.github.io/post/2017/useful-quicklooks/</link><pubDate>Wed, 26 Jul 2017 14:36:10 +0900</pubDate><guid>https://cychong47.github.io/post/2017/useful-quicklooks/</guid><description>&lt;pre tabindex="0"&gt;&lt;code&gt;brew cask install qlmarkdown
brew cask install quicklook-json
brew cask install qlprettypatch
brew cask install quicklook-csv
&lt;/code&gt;&lt;/pre&gt;</description></item><item><title>Naver Labs 12 commandments</title><link>https://cychong47.github.io/post/2017/naver-labs-12-commandments/</link><pubDate>Thu, 08 Jun 2017 22:06:37 +0900</pubDate><guid>https://cychong47.github.io/post/2017/naver-labs-12-commandments/</guid><description>&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2017/06/10322716_312737782251024_4003636941493260411_n.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2017/06/10730858_312737868917682_2073320376500002461_n.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2017/06/10177447_312737902251012_2276001140975349740_n.jpg" alt=""&gt;&lt;/p&gt;</description></item><item><title>(요약) How to ship production-grade Go</title><link>https://cychong47.github.io/post/2017/how-to-ship-production-grade-go/</link><pubDate>Thu, 04 May 2017 12:24:27 +0900</pubDate><guid>https://cychong47.github.io/post/2017/how-to-ship-production-grade-go/</guid><description>&lt;p&gt;출처 : &lt;a href="https://www.oreilly.com/ideas/how-to-ship-production-grade-go?utm_medium=social&amp;amp;utm_source=twitter.com&amp;amp;utm_campaign=saeu17&amp;amp;utm_content=live+training+joshi+jj&amp;amp;cmp=tw-prog-trainreg-article-saeu17_training_go_joshi_ormt_jj"&gt;O&amp;rsquo;reilly radar&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;현장에서 발생하는 문제 몇 번 겪어본 사람이면 대부분 동의할 문제긴 한데 structured log 사용이나 application metric 측정 등은 오래&lt;/p&gt;
&lt;h2 id="wrap-errors"&gt;Wrap errors&lt;/h2&gt;
&lt;p&gt;Error handler wrapper function을 이용해서 error code(annotation 포함) 등을 잘 출력해서 분석이 쉽게 하자&lt;/p&gt;
&lt;h2 id="report-panics"&gt;Report panics&lt;/h2&gt;
&lt;p&gt;Panic을 내야 하는 경우에는 해당 사실을 어딘가 기록(하거나 전송해서 남기고) 패닉 처리하자.&lt;/p&gt;
&lt;h2 id="use-structured-logs"&gt;Use structured logs&lt;/h2&gt;
&lt;p&gt;일반 text보다는 덜 human-readable하지만 SW를 이용해서 분석하기 쉬운 structured log를 남기자. ELK를 이용해 로그 분석하기도 용이하다.&lt;br&gt;
Go stdlib이 제공하는 &lt;code&gt;lib&lt;/code&gt;은 unstructured log만 지원하므로 &lt;code&gt;logrus&lt;/code&gt;(&lt;a href="http://github.com/Sirupsen/logrus"&gt;http://github.com/Sirupsen/logrus&lt;/a&gt;)와 같은 3rd party package를 활용한다.&lt;/p&gt;</description></item><item><title>Slack이 기능 중 하나 - 방해금지</title><link>https://cychong47.github.io/post/2017/slack-do-not-disturb/</link><pubDate>Sun, 16 Apr 2017 05:51:11 +0900</pubDate><guid>https://cychong47.github.io/post/2017/slack-do-not-disturb/</guid><description>&lt;p&gt;Slack에서 제공하는 여러 가지 기능 중 하나로 &amp;ldquo;Do not disturb&amp;quot;가 있다.
아래는 그 기능을 설명한 블로그 글( &lt;a href="http://www.popit.kr/slack-tip/"&gt;Slack으로 막일을 줄여요 ~ 막일을 줄이기 위한 유용한 팁 2&lt;/a&gt; )&lt;/p&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2017/04/slack-do-not-disturb.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Slack 툴을 만든 회사 Slack에서의 문화를 따라 나온 기능이라고 하는데 직원들이 퇴근 후에도 회사 일에 연결되어 있다는 부담감을 없애주고 싶었단다.&lt;/p&gt;
&lt;p&gt;이 기능을 활용하면 사람들간에 저녁이나 주말에 나누고 싶은 정보가 있을 때, 각자의 설정에 따라 바로 알림을 받거나, 혹은 나중에 알 수도 있을 거다. 정보를 보내는 사람 관점에서는 보다 부담없이 나누고 싶은 이야기를 할 수 있지 않을까 싶은데.&lt;/p&gt;</description></item><item><title>윤식당에서 배우는 agile</title><link>https://cychong47.github.io/post/2017/younkitchen-agile/</link><pubDate>Sun, 16 Apr 2017 05:40:05 +0900</pubDate><guid>https://cychong47.github.io/post/2017/younkitchen-agile/</guid><description>&lt;p&gt;요즘 재밌게 보고 있는 JTBC 윤식당. 이서진을 포함한 몇 명의 연기자가 해외에 식당을 내고 운영한다. 그나마 얼굴이 덜 알려진 해외에서 요리를 남에게 파는 행위를 해봤을 것 같지 않은 사람들이 모여 식당을 운영하는 걸 잔잔(?)한 톤으로 보여준다.&lt;/p&gt;
&lt;p&gt;그런데 우연히 읽은 글에서 &amp;lsquo;윤식당&amp;rsquo;과 스타트업을 연결한 걸 봤다.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://madedesignbyme.com/archives/1387"&gt;http://madedesignbyme.com/archives/1387&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;하지만 윤식당이란 타이틀처럼 식당장사를 하게되는데 그들은 이걸 처음 해보게 됩니다. 이들은 처음하는 식당을 어떻게하면 좋은 결과를 만들어 낼수 있는지 저녁을 먹으며 연구하고 그 다음날 아침, 전날의 피드백을 반영하기위해 식재료를 사러가는 것으로 그날의 하루를 시작합니다.&lt;/p&gt;</description></item><item><title>Slack + Ghost</title><link>https://cychong47.github.io/post/2017/slack-ghost/</link><pubDate>Wed, 12 Apr 2017 15:37:39 +0900</pubDate><guid>https://cychong47.github.io/post/2017/slack-ghost/</guid><description>&lt;p&gt;Slack에 개인 채널(?)을 만들었다.
이런 저런 내가 수집(?)하는 정보들을 한 군데서 모아서 히스토리를 만들면 어떨까 하는 생각에&lt;/p&gt;
&lt;p&gt;누구는 slack과 빌드 상황도 연동해서 사용한다고 하는데 그건 좀 공부가 필요해 보이고, 일단 제일 쉬워 보이는 ghost와 연동을 시도해 봤다.&lt;/p&gt;
&lt;p&gt;Ghost의 admin 화면에서 Apps를 선택하면 이런 화면이 나온다.&lt;/p&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2017/04/ghost_apps_menu.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;여기서 Slack항목의 Active를 선택하면 slack와 연동할 수 있는 URL을 입력하라고 나온다. 아래는 이미 연동이 된 상태로 처음 선택한 경우에는 URL 아래에 있는 &amp;ldquo;Set up a new incoming webhook here&amp;quot;의 here를 선택한다.&lt;/p&gt;</description></item><item><title>Feature Flag Driven Development</title><link>https://cychong47.github.io/post/2017/feature-flag-driven-development/</link><pubDate>Wed, 12 Apr 2017 15:29:09 +0900</pubDate><guid>https://cychong47.github.io/post/2017/feature-flag-driven-development/</guid><description>&lt;p&gt;From Ericsson &amp;ldquo;Fueling 5G with DevOps&amp;rdquo;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Maintaining one track in software development, using &lt;strong&gt;feature flag-driven development&lt;/strong&gt;, and establishing version-controlled repositories for application code and application and system configuration data enables teams to create a complete environment that is ready for consistent “build and deploy”.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2 id="what-is-feature-flag-driven-development"&gt;What is &lt;code&gt;feature flag-driven development&lt;/code&gt;?&lt;/h2&gt;
&lt;p&gt;특정 feature에 대해 일부 고객(예를 들면 전체 고객 중 1%)에 대해서만 먼저 적용한 후 feedback에 따라 확대 적용할 지 rollback할 지를 결정하는 방식&lt;br&gt;
문제가 발생하여 기능을 Rollback을 해야 하는 경우라도 일부 고객에만 영향을 주므로 부담이 적다는&lt;br&gt;
&lt;img src="http://blog.launchdarkly.com/wp-content/uploads/2015/10/ld_overview2.png" alt=""&gt;&lt;/p&gt;</description></item><item><title>Espresso - Google's peering edge architecture</title><link>https://cychong47.github.io/post/2017/espresso-googles-peering-edge-architecture/</link><pubDate>Wed, 12 Apr 2017 00:32:57 +0900</pubDate><guid>https://cychong47.github.io/post/2017/espresso-googles-peering-edge-architecture/</guid><description>&lt;p&gt;Google Fellow Amin Vahdat,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Early on, we realized that the network we needed to support our services did not exist and could not be bought,”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://blog.google/topics/google-cloud/making-google-cloud-faster-more-available-and-cost-effective-extending-sdn-public-internet-espresso/"&gt;Espresso makes Google cloud faster, more available and cost effective by extending SDN to the public internet&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;network should be treated as a large-scale distributed system&lt;/li&gt;
&lt;li&gt;leveraging the same control infrastructure we developed for Google’s compute and storage systems&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/nespresso-2.width-566.png" alt="nespresso-1"&gt;&lt;/p&gt;
&lt;h2 id="four-pillars-on-googles-sdn-strategy"&gt;Four pillars on Google&amp;rsquo;s SDN strategy&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Jupiter&lt;/strong&gt;: Google employed SDN principles to build Jupiter, a data center interconnect capable of supporting more than 100,000 servers. As of 2013 it supports more than 1 Pb/s of total bandwidth to host its services.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;B4 WAN interconnect&lt;/strong&gt;: Google constructed B4 to connect its data centers to one another to replicate data in real-time between individual campuses. “It’s built on white boxes with our software controlling it,” said Vahdat at today’s session. “Our goal was to build a copy network. As it’s grown it’s become mission critical. B4 grows faster than our public network.”&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Andromeda&lt;/strong&gt;: Google’s Andromeda is a &lt;a href="https://www.sdxcentral.com/nfv/"&gt;&lt;strong&gt;network functions virtualization (NFV)&lt;/strong&gt;&lt;/a&gt; stack that allows it to deliver the same capabilities available to its native applications all the way to &lt;a href="https://www.sdxcentral.com/cloud/containers/"&gt;containers&lt;/a&gt; and &lt;a href="https://www.sdxcentral.com/cloud/containers/definitions/what-is-a-linux-container/"&gt;virtual machines&lt;/a&gt; running on the Google Cloud Platform.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Espresso&lt;/strong&gt; : Google&amp;rsquo;s peering edge architecture. Select the optimal internal server and route based on the real-time information&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="background"&gt;Background&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;For example, consider real-time voice search. Answering the question “What’s the latest news?” with &lt;a href="https://assistant.google.com/"&gt;Google Assistant&lt;/a&gt; requires a fast, low-latency connection from a user’s device to the edge of Google’s network, and from the edge of our network to one of our data centers. Once inside a data center, hundreds—or even thousands—of individual servers must consult vast amounts of data to score the mapping of an audio recording to possible phrases in one of many languages and dialects. The resulting phrase is then passed to another cluster to perform a web search, consulting a real-time index of internet content. The results are then gathered, scored and returned to the edge of Google’s network back to the end user.&lt;/p&gt;</description></item><item><title>Why message queue used for microservice?</title><link>https://cychong47.github.io/post/2017/why-message-queue-used-for-microservice/</link><pubDate>Sun, 09 Apr 2017 15:41:23 +0900</pubDate><guid>https://cychong47.github.io/post/2017/why-message-queue-used-for-microservice/</guid><description/></item><item><title>P4</title><link>https://cychong47.github.io/post/2017/p4/</link><pubDate>Sun, 09 Apr 2017 08:58:50 +0900</pubDate><guid>https://cychong47.github.io/post/2017/p4/</guid><description>&lt;p&gt;Open source language for &amp;ldquo;Programming Protocol-independent Packet Processor&amp;rdquo;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://p4.org"&gt;http://p4.org&lt;/a&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Barefoot network - Tofino - PISA(Protocol Independent Switch Architecture) switch&lt;/li&gt;
&lt;li&gt;Netronome - smart NIC&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.ericsson.com/research-blog/5g/5g-flexibility-or-high-performance-both/"&gt;5G: flexibility or high performance? Both - Ericsson Research Blog&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;POF/PIF and P4 initiatives all point in a direction where programmable packet processing will not depend on standardized OpenFlow action sets anymore&lt;/p&gt;
&lt;p&gt;POF : Protocol Oblivious Forwarding
PIF : Protocol Independent Forwarding&lt;/p&gt;
&lt;/blockquote&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.opennetworking.org/protocol-independent-forwarding/174-certification"&gt;OF-PI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://en.wikipedia.org/wiki/P4_(programming_language)"&gt;P4 in wikipedia&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://onrc.stanford.edu/p4.html"&gt;p4 in ONRC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.newelectronics.co.uk/electronics-technology/revolutionising-networking-technology/152737/"&gt;Revolutionising networking technology from newelectronics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.datacenterdynamics.com/content-tracks/core-edge/p4-driving-innovation-in-server-based-networking/97544.fullarticle"&gt;P4: driving innovation in server-based networking (Jan 4 2017)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.researchgate.net/publication/310595166_Extern_Objects_in_P4_an_ROHC_Compression_Case_Study"&gt;Extern objects in P4:an ROHC Compression Case study&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>Table or dish</title><link>https://cychong47.github.io/post/2017/table-or-dish/</link><pubDate>Thu, 06 Apr 2017 00:40:05 +0900</pubDate><guid>https://cychong47.github.io/post/2017/table-or-dish/</guid><description>&lt;blockquote&gt;
&lt;p&gt;They are going to have to make a choice here - do you want to be at the table or on the plate?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;먹을래 먹힐래?&lt;/p&gt;</description></item><item><title>Move to docker</title><link>https://cychong47.github.io/post/2017/move-to-docker/</link><pubDate>Tue, 04 Apr 2017 13:51:03 +0900</pubDate><guid>https://cychong47.github.io/post/2017/move-to-docker/</guid><description>&lt;p&gt;지금 집에 있는 두 대의 mac mini를 이용해서 각각 wordpress와 ghost를 돌리고 있다.&lt;br&gt;
wordpress의 경우 2013년부터 시작한 블로그를 운영하는데 사용하고 있는데, 웹호스팅 회사 몇 군데를 전전하다 몇 년 전부터 집에 있는 mac mini 2009에 &lt;a href="https://www.mamp.info/"&gt;MAMP&lt;/a&gt;를 이용해서 자체 서버를 이용하고 있었다.&lt;/p&gt;
&lt;p&gt;Ghost는 내가 좋아하는 markdown을 기본으로 사용하는 블로그 툴을 찾다 만났는데 지금은 사라졌지만 초기 홈페이지에 있던 멋진 dashboard에 낚여 설치했다. Open source 답지 않고 느린 개발 속도가 이해되지는 않지만, 여전히 markdwon을 제대로 지원하는 흔치 않은 설치형 블로그 툴이라 아직 희망을 버리지 않고 사용하고 있다. 현재는 0.11.2 버전이 공식 stable 버전이고 올해 나올 걸로 예상되는 1.0의 alpha 버전이 개발중이다.&lt;/p&gt;</description></item><item><title>fossilization</title><link>https://cychong47.github.io/post/2016/fossilization/</link><pubDate>Thu, 12 May 2016 03:41:20 +0900</pubDate><guid>https://cychong47.github.io/post/2016/fossilization/</guid><description>&lt;blockquote&gt;
&lt;p&gt;fossilize also -lise&lt;/p&gt;
&lt;p&gt;(usually passive) if people, ideas, systems etc fossilize or are fossilized, they never change or develop, even when there are good reasons why they should change&lt;/p&gt;
&lt;p&gt; Most couples, however fossilized their relationship, have some interests in common.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;간혹 팟캐스트에 공룡에 대한 이야기가 나온다. 공룡에 대한 연구가 상대적으로 오래되지 않고, 현존하지 않은 생명체에 대한 거라 발굴된 화석에 의존해서 복원해야 해서 그 복원 결과가 시간에 따라 달라진다고 한다. 새로운 증거나 보다 논리적인 설명이 나오면 그걸로 기존의 가설의 결과가 달라진다고. 예를 들면 티라노사우르스가 빠르게 달리는 것처럼 알려졌지만, 요즈음은 티라노사우르스는 뛰지 못했다는 게 정설이다. 몸무게 덕에 뛰었다간 무릎이 다 망가진다고.&lt;/p&gt;</description></item><item><title>상식과 다른 결과를 보면</title><link>https://cychong47.github.io/post/2016/too-early-confident/</link><pubDate>Wed, 11 May 2016 10:01:53 +0900</pubDate><guid>https://cychong47.github.io/post/2016/too-early-confident/</guid><description>&lt;p&gt;먼저 주변을 의심해 보자.&lt;/p&gt;
&lt;p&gt;상식적인 혹은 알려진 것과 다른 결과가 나왔다면 내가 한 시험 방법을 다시 한번 의심해 보자. 제발&lt;/p&gt;</description></item><item><title>빨리 해봐야 소용없다</title><link>https://cychong47.github.io/post/2016/no-need-to-rush/</link><pubDate>Wed, 11 May 2016 09:59:23 +0900</pubDate><guid>https://cychong47.github.io/post/2016/no-need-to-rush/</guid><description>&lt;p&gt;개발자의 품을 가벼이 여기는 조직에서 일 할때는 일정보다 일을 빨리하면 안된다. 기껏 한 일이 아무 소용없을 때가 많다.&lt;/p&gt;</description></item><item><title>Ghost 본문 다 보이기</title><link>https://cychong47.github.io/post/2016/display-post-by-default-ghost/</link><pubDate>Mon, 09 May 2016 15:23:57 +0900</pubDate><guid>https://cychong47.github.io/post/2016/display-post-by-default-ghost/</guid><description>&lt;p&gt;theme을 수정해서 ghost blog 화면에서 글 본문이 다 나오도록 할 수 있다.&lt;/p&gt;
&lt;p&gt;대신 theme마다 조금씩 적용 방법이 다른데 기본적으로 변경해야 할 내용은 동일&lt;/p&gt;
&lt;h1 id="casper-theme"&gt;casper theme&lt;/h1&gt;
&lt;p&gt;casper는 &lt;code&gt;index.hbs&lt;/code&gt; 파일에서 &lt;code&gt;loop.hbs&lt;/code&gt;라는 별도 파일을 통해 본문을 보이게 하고 있다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;index.hbs&lt;/code&gt;&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt; 21 {{! The main content area on the homepage }}
 22 &amp;lt;main id=&amp;#34;content&amp;#34; class=&amp;#34;content&amp;#34; role=&amp;#34;main&amp;#34;&amp;gt;
 23
 24 {{! The tag below includes the post loop - partials/loop.hbs }}
 25 {{&amp;gt; &amp;#34;loop&amp;#34;}}
 26
 27 &amp;lt;/main&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;위 코드에서 가리키는 partials/loop.hbs 코드에서 exceprt인 부분을 찾아서 다음과 같이 변경한다. 아래에서 13라인부터 15라인이 원본으로 각 post의 일부만 보이게 하고, 더 읽으려면 &lt;code&gt;&amp;gt;&amp;gt;&lt;/code&gt;등을 클릭하게 한다. 이 부분을 막고 post 전체를 표시하는 17라인에서 19라인까지의 내용을 추가한다.&lt;/p&gt;</description></item><item><title>Frag &amp; Reassembly Test</title><link>https://cychong47.github.io/post/2016/frag-reassembly-test/</link><pubDate>Sun, 01 May 2016 15:35:28 +0900</pubDate><guid>https://cychong47.github.io/post/2016/frag-reassembly-test/</guid><description>&lt;h2 id="set-environment"&gt;set environment&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;export RTE_ARCH=x86_64
export RTE_SDK=/home/cychong/Work/dpdk-2.1.0
export RTE_TARGET=x86_64-native-linuxapp-gcc
export RTE_OUTPUT=$RTE_SDK/$RTE_TARGET
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="run"&gt;run&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;sudo ./build/ip_reassembly -c 0x1 -n 4 -m 1000M --no-huge --no-pci --no-hpet -- --display_pps 1 --tx_pps 10
&lt;/code&gt;&lt;/pre&gt;</description></item><item><title>DPDK IPv4 reassembly</title><link>https://cychong47.github.io/post/2016/dpdk-ipv4-reassembly/</link><pubDate>Thu, 24 Mar 2016 15:03:55 +0900</pubDate><guid>https://cychong47.github.io/post/2016/dpdk-ipv4-reassembly/</guid><description>&lt;p&gt;&lt;code&gt;rte_ipv4_frag_reassemble_packet()&lt;/code&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ip_frag_find()&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;기존에 존재하는 flow면 해당 flow를 저장한 entry 정보를(&lt;code&gt;ip_frag_pkt *pkg&lt;/code&gt;)&lt;/li&gt;
&lt;li&gt;신규 flow인 경우 해당 신규 flow를 저장할 신규 혹은 재사용된 entry를 return함&lt;/li&gt;
&lt;li&gt;추가할 수 있는 통계
&lt;ul&gt;
&lt;li&gt;신규 flow?&lt;/li&gt;
&lt;li&gt;기존 flow에 정상 추가&lt;/li&gt;
&lt;li&gt;기존 flow에 비정상 추가(기존 flow가 timeouted)&lt;/li&gt;
&lt;li&gt;이도 저도 아닌 상황(할당 실패)&lt;/li&gt;
&lt;li&gt;LRU entry free&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tbl-&amp;gt;max_entries&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tbl-&amp;gt;use_entries&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;return
&lt;ul&gt;
&lt;li&gt;기존 존재하는 flow, 신규 할당한 flow entry 혹은 NULL&lt;/li&gt;
&lt;li&gt;만일 NULL을 return하면 현재 수신한 mbuf를 death row에 추가한다. 불쌍한&amp;hellip;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ip_frag_lookup()&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;if matched entry is exist
&lt;ul&gt;
&lt;li&gt;return flow entry&lt;/li&gt;
&lt;li&gt;return &lt;code&gt;&amp;amp;stale&lt;/code&gt; if time-outed entry is exist&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;if new entry
&lt;ul&gt;
&lt;li&gt;return NULL&lt;/li&gt;
&lt;li&gt;return free for new empty entry&lt;/li&gt;
&lt;li&gt;return &lt;code&gt;&amp;amp;stale&lt;/code&gt; if time-outed entry is exist&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ip_frag_key_cmp()&lt;/code&gt; return 0 if key matched&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;if &lt;code&gt;ip_frag_lookup()&lt;/code&gt; returns NULL
&lt;ul&gt;
&lt;li&gt;if stale entry is not NULL, remove it with &lt;code&gt;ip_frag_tbl_del()&lt;/code&gt; and save to free for reuse&lt;/li&gt;
&lt;li&gt;even if free is not NULL, check if &lt;code&gt;tbl-&amp;gt;use_entries&lt;/code&gt; does not exceed &lt;code&gt;tbl-&amp;gt;max_entries&lt;/code&gt;. If so, check if the LRU entry is timeouted, then free the LRU entry. Otherwise, fail to add new entry to the tbl&lt;/li&gt;
&lt;li&gt;tbl에서 할당하는 것고 &lt;code&gt;max_entries&lt;/code&gt;, &lt;code&gt;use_entries&lt;/code&gt;간의 차이점은??&lt;/li&gt;
&lt;li&gt;If free is not NULL, add new flow to this free entry&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;if &lt;code&gt;ip_frag_lookup()&lt;/code&gt; returns non-NULL
&lt;ul&gt;
&lt;li&gt;if timeouted, reuse it for the received flow&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;tbl-&amp;gt;use_entries—; del_num++&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ip_frag_process()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rte_ip_frag_free_death_row()&lt;/code&gt; 주기적으로 호출해줘야 함&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>DPDK new mbuf 사용 주의사항</title><link>https://cychong47.github.io/post/2016/header-length-in-mbuf/</link><pubDate>Sun, 06 Mar 2016 08:22:24 +0900</pubDate><guid>https://cychong47.github.io/post/2016/header-length-in-mbuf/</guid><description>&lt;p&gt;&lt;code&gt;l2_len&lt;/code&gt;, &lt;code&gt;l3_len&lt;/code&gt;, &lt;code&gt;l4_len&lt;/code&gt; 등을 사용하는 라이브러리가 존재함&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;reassembly&lt;/li&gt;
&lt;li&gt;Tx checksum offload&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="reassembly"&gt;Reassembly&lt;/h3&gt;
&lt;p&gt;&lt;code&gt;rte_ipv6_frag_reassemble_packet()&lt;/code&gt;, &lt;code&gt;rte_ipv4_frag_reassemble_packet()&lt;/code&gt;
Incoming mbuf should have its &lt;code&gt;l2_len&lt;/code&gt; and &lt;code&gt;l3_len&lt;/code&gt; fields setup correctly.&lt;/p&gt;
&lt;h3 id="l4-checksum-hw-offloading"&gt;L4 checksum HW offloading&lt;/h3&gt;
&lt;p&gt;To use hardware L4 checksum offload, the user needs to&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;fill &lt;code&gt;l2_len&lt;/code&gt; and &lt;code&gt;l3_len&lt;/code&gt; in mbuf&lt;/li&gt;
&lt;li&gt;set the flags &lt;code&gt;PKT_TX_TCP_CKSUM&lt;/code&gt;, &lt;code&gt;PKT_TX_SCTP_CKSUM&lt;/code&gt; or &lt;code&gt;PKT_TX_UDP_CKSUM&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;set the flag &lt;code&gt;PKT_TX_IPV4&lt;/code&gt; or &lt;code&gt;PKT_TX_IPV6&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;calculate the pseudo header checksum and set it in the L4 header (only for TCP or UDP). See &lt;code&gt;rte_ipv4_phdr_cksum()&lt;/code&gt; and &lt;code&gt;rte_ipv6_phdr_cksum()&lt;/code&gt;. For SCTP, set the crc field to 0.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="l3-checksum-hw-offloading"&gt;L3 checksum HW offloading&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;set the flag &lt;code&gt;PKT_TX_IPV4&lt;/code&gt; (IP checksum은 IPv4에만 존재)&lt;/li&gt;
&lt;li&gt;set the IP checksum field in the packet to 0&lt;/li&gt;
&lt;li&gt;fill the mbuf offload information: &lt;code&gt;l2_len&lt;/code&gt;, &lt;code&gt;l3_len&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PKT_TX_IP_CKSUM&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="ip-checksum-offloading"&gt;IP checksum offloading&lt;/h3&gt;
&lt;p&gt;example from &lt;code&gt;prog_guide/mbuf_lib.rst&lt;/code&gt;&lt;/p&gt;</description></item><item><title>KNI가 buffer를 free 하는 방법</title><link>https://cychong47.github.io/post/2016/how_kni_free_mbuf/</link><pubDate>Sun, 06 Mar 2016 08:17:58 +0900</pubDate><guid>https://cychong47.github.io/post/2016/how_kni_free_mbuf/</guid><description>&lt;h1 id="dpdk-to-kni-rx"&gt;DPDK to KNI RX&lt;/h1&gt;
&lt;p&gt;KNI는 &lt;code&gt;rx_q&lt;/code&gt;로부터 mbuf를 수신한 후 &lt;code&gt;data_len&lt;/code&gt; 크기의 skb를 할당하여 데이터를 복사한 후 &lt;code&gt;netif_rx&lt;/code&gt;를 호출한다.
그러므로 mbuf는 KNI kernel module까지만 사용되고, 커널 networking stack에서는 사용되지는 않는다.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;kni_net.c&lt;/code&gt;의 &lt;code&gt;kni_net_rx_normal()&lt;/code&gt; 함수가 DPDK application으로부터 mbuf를 받아 커널에 전달하는 함수인데 실제 함수는 batch processing을 위해 한번에 여러 개의 패킷을 &lt;code&gt;rx_q&lt;/code&gt;로부터 읽어 처리하도록 구현되어 있다.&lt;/p&gt;
&lt;p&gt;아래는 하나의 패킷에 대해 수행되는 코드를 간략화 한 것이다(예외 처리 부분도 제외)&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;num_rx = kni_fifo_get(kni-&amp;gt;rx_q, (void **)va, num_rx);

kva = (void *)va[i] - kni-&amp;gt;mbuf_va + kni-&amp;gt;mbuf_kva;
len = kva-&amp;gt;data_len;
data_kva = kva-&amp;gt;buf_addr + kva-&amp;gt;data_off - kni-&amp;gt;mbuf_va + kni-&amp;gt;mbuf_kva;

skb = dev_alloc_skb(len + 2);

/* Align IP on 16B boundary */
skb_reserve(skb, 2);
memcpy(skb_put(skb, len), data_kva, len);
skb-&amp;gt;dev = dev;
skb-&amp;gt;protocol = eth_type_trans(skb, dev);
skb-&amp;gt;ip_summed = CHECKSUM_UNNECESSARY;

/* Call netif interface */
netif_rx(skb);

/* Update statistics */
kni-&amp;gt;stats.rx_bytes += len;
kni-&amp;gt;stats.rx_packets++;

/* Burst enqueue mbufs into free_q */
ret = kni_fifo_put(kni-&amp;gt;free_q, (void **)va, num_rx);
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;In case DPDK application restarted&lt;/p&gt;</description></item><item><title>(Scapy) Suppress Scapy warning message</title><link>https://cychong47.github.io/post/2016/scapy-suppress-scapy-warning-message/</link><pubDate>Thu, 03 Mar 2016 14:50:24 +0900</pubDate><guid>https://cychong47.github.io/post/2016/scapy-suppress-scapy-warning-message/</guid><description>&lt;h1 id="without-suppressing-scapy-ipv6-warning"&gt;Without Suppressing Scapy IPv6 warning&lt;/h1&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@ubuntu:~$ python
Python 2.7.6 (default, Jun 22 2015, 17:58:13)
[GCC 4.8.2] on linux2
Type &amp;#34;help&amp;#34;, &amp;#34;copyright&amp;#34;, &amp;#34;credits&amp;#34; or &amp;#34;license&amp;#34; for more information.
&amp;gt;&amp;gt;&amp;gt; from scapy.all import *
WARNING: No route found for IPv6 destination :: (no default route?)
&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;h1 id="suppress-scapy-ipv6-warning"&gt;Suppress scapy IPv6 warning&lt;/h1&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;cychong@ubuntu:~$ python
Python 2.7.6 (default, Jun 22 2015, 17:58:13)
[GCC 4.8.2] on linux2
Type &amp;#34;help&amp;#34;, &amp;#34;copyright&amp;#34;, &amp;#34;credits&amp;#34; or &amp;#34;license&amp;#34; for more information.
&amp;gt;&amp;gt;&amp;gt; import logging
&amp;gt;&amp;gt;&amp;gt; logging.getLogger(&amp;#34;scapy.runtime&amp;#34;).setLevel(logging.ERROR)
&amp;gt;&amp;gt;&amp;gt; from scapy.all import *
&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;</description></item><item><title>how to build IPsec packet with scapy</title><link>https://cychong47.github.io/post/2016/how-to-use-snapy-for-ipsec/</link><pubDate>Sun, 14 Feb 2016 14:59:42 +0900</pubDate><guid>https://cychong47.github.io/post/2016/how-to-use-snapy-for-ipsec/</guid><description>&lt;h2 id="import-modules"&gt;import modules&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;$ python
&amp;gt;&amp;gt;&amp;gt; from scapy.all import *
&amp;gt;&amp;gt;&amp;gt; from scapy.layers.ipsec import *
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="build-plaintext-packet"&gt;build plaintext packet&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; p = IP(src=&amp;#39;1.1.1.1&amp;#39;, dst=&amp;#39;2.2.2.2&amp;#39;) / TCP(sport=45012, dport=80) / Raw(&amp;#39;testdata&amp;#39;) 
&amp;gt;&amp;gt;&amp;gt; p = IP(str(p))
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="setup-sa"&gt;setup SA&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; sa = SecurityAssociation(ESP, spi=0xdeadbeef, crypt_algo=&amp;#39;AES-CBC&amp;#39;,crypt_key=&amp;#39;sixteenbytes key&amp;#39;)
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="encrypt-wo-iv"&gt;Encrypt w/o IV&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; e = sa.encrypt(p, 5)
&amp;gt;&amp;gt;&amp;gt; e
&amp;lt;IP version=4L ihl=5L tos=0x0 len=76 id=1 flags= frag=0L ttl=64 proto=esp chksum=0x747a src=1.1.1.1 dst=2.2.2.2 |&amp;lt;ESP spi=0xdeadbeef seq=5 data=&amp;#39;uD\x7fdj19\xe7\xc4\xff8\x10\xcdQ\xf0\xa6\x1e!\x84\xc3&amp;gt;!\x18\xa6\xf6\xb8\x93\xc6it\x9a\xfc\x1c\xee\xe5C\xcd\xf0\x7fD\xca\x8d\xadKh\xa8\xe5x&amp;#39; |&amp;gt;&amp;gt;
&amp;gt;&amp;gt;&amp;gt; e.show()
###[ IP ]###
 version = 4L
 ihl = 5L
 tos = 0x0
 len = 76
 id = 1
 flags = 
 frag = 0L
 ttl = 64
 proto = esp
 chksum = 0x747a
 src = 1.1.1.1
 dst = 2.2.2.2
 \options \
###[ ESP ]###
 spi = 0xdeadbeef
 seq = 5
 data = &amp;#39;uD\x7fdj19\xe7\xc4\xff8\x10\xcdQ\xf0\xa6\x1e!\x84\xc3&amp;gt;!\x18\xa6\xf6\xb8\x93\xc6it\x9a\xfc\x1c\xee\xe5C\xcd\xf0\x7fD\xca\x8d\xadKh\xa8\xe5x&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id="encrypt-w-iv"&gt;Encrypt w/ IV&lt;/h2&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;&amp;gt;&amp;gt;&amp;gt; e = sa.encrypt(p, 5, &amp;#34;1234567890123456&amp;#34;)
&amp;gt;&amp;gt;&amp;gt; e
&amp;lt;IP version=4L ihl=5L tos=0x0 len=76 id=1 flags= frag=0L ttl=64 proto=esp chksum=0x747a src=1.1.1.1 dst=2.2.2.2 |&amp;lt;ESP spi=0xdeadbeef seq=5 data=&amp;#39;1234567890123456\xa4\x0b\xebZ\xa7\xc8\xb6\x95\xfb\x13\x07\xc5TD\xa2\xe7DP\xfcP\xa5y\xc4\x06W\xe8\xf5\xf0\x86\xe1\x0c\xfd&amp;#39; |&amp;gt;&amp;gt;
&amp;gt;&amp;gt;&amp;gt; e.show()
###[ IP ]###
 version = 4L
 ihl = 5L
 tos = 0x0
 len = 76
 id = 1
 flags = 
 frag = 0L
 ttl = 64
 proto = esp
 chksum = 0x747a
 src = 1.1.1.1
 dst = 2.2.2.2
 \options \
###[ ESP ]###
 spi = 0xdeadbeef
 seq = 5
 data = &amp;#39;1234567890123456\xa4\x0b\xebZ\xa7\xc8\xb6\x95\xfb\x13\x07\xc5TD\xa2\xe7DP\xfcP\xa5y\xc4\x06W\xe8\xf5\xf0\x86\xe1\x0c\xfd&amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;data 의 시작 부분에 IV값 &amp;lsquo;1234567890123456&amp;rsquo;이 있음을 알 수 있다.
ESP는 SPI(4B), SEQ(4B), IV(16B) , Encrypted Data 형태로 구성된다.&lt;/p&gt;</description></item><item><title>fragment missing test with scapy</title><link>https://cychong47.github.io/post/2016/fragment-missing-test-with-scapy/</link><pubDate>Sun, 14 Feb 2016 13:57:41 +0900</pubDate><guid>https://cychong47.github.io/post/2016/fragment-missing-test-with-scapy/</guid><description>&lt;p&gt;다음과 같이 scapy를 이용해서 fragment를 쉽게 만들 수 있다.&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;from scapy.all import *

dip=&amp;#34;10.0.0.1&amp;#34;
payload=&amp;#34; &amp;#34;*1000

packet=IP(dst=dip)/UDP(dport=0x1234)/payload
 
frag_list=fragment(packet,fragsize=500)
 
counter=1
for fragment in frag_list:
 print &amp;#34;Packet no%d&amp;#34; %counter
 print 

 fragment.show()
 counter+=1
 send(fragment)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;frag_list에서 counter 변수를 확인해서 전송하지 않으면 간단하게 fragment가 수신되지 않은 경우에 시험할 수 있음.&lt;/p&gt;
&lt;p&gt;필요하면 frag_list의 순서를 뒤집는 것도 가능하고, 각 fragment의 offset값을 조정하거나 패킷 크기를 변경하면 다른 비정상 경우도 쉽게 시험할 수 있다.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.secdev.org/projects/scapy/doc/usage.html#interactive-tutorial"&gt;scapy interactive tutorial&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Vagrant</title><link>https://cychong47.github.io/post/2016/vagrant/</link><pubDate>Sun, 14 Feb 2016 07:52:01 +0900</pubDate><guid>https://cychong47.github.io/post/2016/vagrant/</guid><description>&lt;p&gt;Vagrant&lt;/p&gt;
&lt;p&gt;fd.io의 개발 환경 구성하는 문서를 보니 vagrant를 사용한다. 그런데 또 virtualbox니 vmware 이야기를 한다.
이전에도 vagrant라는 단어를 들어본적이 있었는데 이번 기회에 좀 알아보기로&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.vagrantup.com/docs/why-vagrant/"&gt;Why Vagrant&lt;/a&gt;를 보면 다음과 같이 설명하고 있다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Vagrant provides easy to configure, reproducible, and portable work environments built on top of industry-standard technology and controlled by a single consistent workflow to help maximize the productivity and flexibility of you and your team.&lt;/p&gt;
&lt;p&gt;To achieve its magic, Vagrant stands on the shoulders of giants. Machines are provisioned on top of VirtualBox, VMware, AWS, or any other provider. Then, industry-standard provisioning tools such as shell scripts, Chef, or Puppet, can be used to automatically install and configure software on the machine.&lt;/p&gt;</description></item><item><title>fd.io</title><link>https://cychong47.github.io/post/2016/fd-io-tree/</link><pubDate>Sat, 13 Feb 2016 05:51:52 +0900</pubDate><guid>https://cychong47.github.io/post/2016/fd-io-tree/</guid><description>&lt;pre tabindex="0"&gt;&lt;code&gt;├── build-data
│   ├── packages
│   └── platforms
├── build-root
│   ├── deb
│   │   └── debian
│   │   └── source
│   ├── emacs-lisp
│   ├── packages
│   ├── rpm
│   ├── scripts
│   └── vagrant
├── dpdk
│   ├── dkms
│   ├── dpdk-2.1.0_patches
│   └── dpdk-2.2.0_patches
├── g2
├── gmod
│   └── gmod
├── perftool
├── sample-plugin
│   └── sample
├── svm
├── test
│   ├── resources
│   │   ├── libraries
│   │   │   ├── bash
│   │   │   ├── python
│   │   │   └── robot
│   │   │   └── vat
│   │   └── templates
│   │   └── vat
│   └── tests
│   └── suites
│   ├── bridge_domain
│   └── vhost_user_dummy
├── vlib
│   ├── example
│   └── vlib
│   └── unix
├── vlib-api
│   ├── vlibapi
│   ├── vlibmemory
│   └── vlibsocket
├── vnet
│   ├── etc
│   │   └── scripts
│   │   ├── dhcp
│   │   ├── ludd-cluster-1
│   │   ├── ludd-cluster-3
│   │   ├── mpls-o-ethernet
│   │   ├── mpls-o-gre
│   │   ├── sr
│   │   └── virl
│   └── vnet
│   ├── cdp
│   ├── classify
│   ├── devices
│   │   ├── dpdk
│   │   ├── ssvm
│   │   └── virtio
│   ├── dhcp
│   ├── dhcpv6
│   ├── ethernet
│   ├── flow
│   ├── gre
│   ├── hdlc
│   ├── ip
│   ├── ipsec
│   ├── l2
│   ├── l2tp
│   ├── lawful-intercept
│   ├── lisp-gpe
│   ├── llc
│   ├── map
│   │   └── examples
│   ├── mcast
│   ├── mpls-gre
│   ├── nsh-gre
│   ├── nsh-vxlan-gpe
│   ├── osi
│   ├── pg
│   ├── plugin
│   ├── policer
│   ├── ppp
│   ├── snap
│   ├── sr
│   ├── srp
│   ├── unix
│   ├── vcgn
│   └── vxlan
├── vpp
│   ├── api
│   ├── app
│   ├── conf
│   ├── oam
│   ├── stats
│   └── vnet
├── vpp-api-test
│   ├── scripts
│   └── vat
├── vpp-japi
│   ├── japi
│   │   ├── org
│   │   │   └── openvpp
│   │   │   └── vppjapi
│   │   └── test
│   └── m4
├── vppapigen
└── vppinfra
 ├── config
 ├── tools
 └── vppinfra
&lt;/code&gt;&lt;/pre&gt;</description></item><item><title>fd.io</title><link>https://cychong47.github.io/post/2016/fd-io/</link><pubDate>Sat, 13 Feb 2016 01:29:43 +0900</pubDate><guid>https://cychong47.github.io/post/2016/fd-io/</guid><description>&lt;p&gt;2016년 2월 11일 공개된 CISCO 주도의 프로젝트.
무려 2002년부터 개발한 것으로 현재 버전은 3번째 revision이라고 한다.&lt;br&gt;
간만에 dpdk.org mailing list에 들어갔다 가장 최근에 올라온 글 제목이 눈에 띄었다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[dpdk-dev] [dpdk-announce] new project using DPDK - FD.io Vincent JARDIN&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&amp;ldquo;new project&amp;rdquo;?&lt;/p&gt;
&lt;p&gt;그래서 내용을 봤더니 이게 다 였다는&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;A new project using DPDK is available,
 http://FD.io
said
 FiDo

You can clone it from:
 http://gerrit.fd.io/

Best regards,
 Vincent
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;그래도 첫 번째 링크를 따라가 보니 화려하다. CISCO, Ericsson, Intel이 platinum member네. 어딜가나 있는 여러 회사 이름도 보이고. Cavium도 있네. ODP를 밀고 있는데 잘 안되나? 물론 내용을 보면 조금 다르긴 하지만.&lt;br&gt;
거기에 6wind도 있다. 역시 직접적인 경쟁회사라고 볼 수도 있을 텐데. E, H사가 보이는데 N사는 아직 없다. OFP에 집중하려는 걸까&lt;/p&gt;</description></item><item><title>왜 공부해야 하는가에 대한 간단하지만 명확한 답</title><link>https://cychong47.github.io/post/2016/why_have_to_keep_studying/</link><pubDate>Wed, 10 Feb 2016 04:23:12 +0900</pubDate><guid>https://cychong47.github.io/post/2016/why_have_to_keep_studying/</guid><description>&lt;blockquote&gt;
&lt;p&gt;왜 공부해야 하는가&lt;br&gt;
사회의 변화속도는 우리의 변화속도를 압도하기 때문입니다.&lt;br&gt;
&amp;lt;누가 내 치즈를 옮겼을까&amp;gt;에 잘 묘사되어 있지요.&lt;br&gt;
따라잡지 않으면 뒤쳐지기 때문에 우리는 늘 공부해야 합니다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;a href="https://brunch.co.kr/@choihs0228/4"&gt;https://brunch.co.kr/@choihs0228/4&lt;/a&gt;&lt;/p&gt;</description></item><item><title>DPDK NIC 초기화</title><link>https://cychong47.github.io/post/2016/dpdk_nic_init/</link><pubDate>Tue, 09 Feb 2016 14:54:21 +0900</pubDate><guid>https://cychong47.github.io/post/2016/dpdk_nic_init/</guid><description>&lt;h3 id="constructor-attribute"&gt;constructor attribute&lt;/h3&gt;
&lt;p&gt;&lt;a href="http://phoxis.org/2011/04/27/c-language-constructors-and-destructors-with-gcc/"&gt;http://phoxis.org/2011/04/27/c-language-constructors-and-destructors-with-gcc/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;constructor attribute을 가진 함수는 main 함수를 실행하기 전에 호출한다.&lt;/p&gt;
&lt;p&gt;예제 (&lt;a href="http://phoxis.org/2011/04/27/c-language-constructors-and-destructors-with-gcc/"&gt;출처&lt;/a&gt;)&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;#include &amp;lt;stdio.h&amp;gt;
 
void begin (void) __attribute__((constructor));
void end (void) __attribute__((destructor));
 
int main (void)
{
 printf (&amp;#34;\nInside main ()&amp;#34;);
}
 
void begin (void)
{
 printf (&amp;#34;\nIn begin ()&amp;#34;);
}
 
void end (void)
{
 printf (&amp;#34;\nIn end ()\n&amp;#34;);
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;실행하면&lt;/p&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;In begin ()
Inside main ()
In end ()
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id="dpdk"&gt;DPDK&lt;/h3&gt;
&lt;p&gt;DPDK의 경우 device driver들을 모두 constructor attirbute을 사용해서 main 함수 전에 호출되록 한다.&lt;/p&gt;</description></item><item><title>Introducing Python</title><link>https://cychong47.github.io/post/2016/introducing-python/</link><pubDate>Mon, 08 Feb 2016 13:25:34 +0900</pubDate><guid>https://cychong47.github.io/post/2016/introducing-python/</guid><description>&lt;p&gt;Introducing Python 을 판교어린이도서관에서 짧게 보고 적은 아이템들&lt;/p&gt;
&lt;p&gt;python3 based&lt;/p&gt;
&lt;p&gt;Decorator는 공부가 필요한 내용&lt;/p&gt;
&lt;p&gt;sys.path : module 검색 경로
&lt;code&gt;__init__.py&lt;/code&gt; 파일이 있으면 그 디렉토리를 PKG로 간주함&lt;br&gt;
defaultdic()&lt;br&gt;
Counters()&lt;br&gt;
dicionary는 key의 순서를 보장하지 않음. OrderedDict()로 사전을 정의하면 가능 &lt;br&gt;
deque = stack + queue
pprint()는 print보다 깔끔하게 출력한다고.&lt;br&gt;
&lt;code&gt;'\uXXX'&lt;/code&gt; 유니코드&lt;br&gt;
&lt;code&gt;%10.4s&lt;/code&gt; : 10칸의 공간. 문자열 중 4개만 출력&lt;br&gt;
struct &lt;code&gt;'&amp;gt;LL'&lt;/code&gt; : &lt;code&gt;'&amp;gt;'&lt;/code&gt; Big endian, &lt;code&gt;L&lt;/code&gt; : uint32_t&lt;/p&gt;
&lt;p&gt;list comprehension : for loop보다 빠름. 어떻게 사용하는 지 구체적으로 좀 더 알아봐야 함.&lt;/p&gt;</description></item><item><title>SR-IOV and DPDK</title><link>https://cychong47.github.io/post/2016/sriov-and-dpdk/</link><pubDate>Sun, 07 Feb 2016 23:40:26 +0900</pubDate><guid>https://cychong47.github.io/post/2016/sriov-and-dpdk/</guid><description>&lt;p&gt;SR-IOV and DPDK&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.metaswitch.com/the-switch/accelerating-the-nfv-data-plane"&gt;Accelerating the NFV Data Plane : SR-IOV and DPDK… in my own words&lt;/a&gt; 를 읽고 요약&lt;/p&gt;
&lt;h2 id="before-hw-assisted-virtualisation"&gt;Before HW assisted Virtualisation&lt;/h2&gt;
&lt;p&gt;SR-IOV 전까지는 VMM이 패킷 송수신에 매번 개입해야 했음.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;1st interrupt from NIC to VMM&lt;/li&gt;
&lt;li&gt;2nd interrupt from VMM to VM&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="intel-vmdq"&gt;Intel VMDq&lt;/h2&gt;
&lt;p&gt;Only one interrupt from NIC to VM as each VM has its own Rx queue.&lt;/p&gt;
&lt;h2 id="sr-iov"&gt;SR-IOV&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;SR-IOV : Standard IO memory Memory Management Unit from Intel(VT-d) and AMD(IOV)&lt;/li&gt;
&lt;li&gt;Virtual Function - Limited, lightweight, PCIe resource and a dedicated Tx/Rx packet queue&lt;/li&gt;
&lt;li&gt;Interrupt 부담이 없다고 하는데 왜??? 마지막 결론에서는 SR-IOV를 사용하면 interrupt를 두 개 다 없앨 수 있다고 하는데 이 부분은 잘 이해가 안된다.
HW 기반&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="sr-iov-and-vswitch"&gt;SR-IOV and vSwitch&lt;/h2&gt;
&lt;p&gt;SR-IOV는 VMM의 부담을 덜어주는 장점을 가지고 있지만, 반대로 vSwitch가 제공할 수 있는 네트웍 기능들 - portability, flexibility, QoS, complex traffic steering 등을 이용할 수 없게 되었다는. 문제는 이런 기능들이 NFV환경에서 필요하고(할 거고). vSwitch의 기능을 사용할 수 없으면 service chaining 같은 건 고민할 것도 없고, 위 기능들을 모두 각 VNF에서 구현해야 하는데. 물론 기존 PNF가 그랬던 것 처럼 못할 것도 없지만, 한 곳에 모아놓은 VNF사이에 구현해야 하는 공통 기능이면 가능하면 NFVI에서 구현할 수 있으면 좋겠지&lt;/p&gt;</description></item><item><title>DPDK 2.2 crypto dev API</title><link>https://cychong47.github.io/post/2016/dpdk-2-2-crypto-dev-api/</link><pubDate>Sun, 24 Jan 2016 15:08:11 +0900</pubDate><guid>https://cychong47.github.io/post/2016/dpdk-2-2-crypto-dev-api/</guid><description>&lt;h3 id="pktmbuf_offload"&gt;pktmbuf_offload&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;pool은 &lt;code&gt;rte_pktmbuf_offload_pool_create()&lt;/code&gt;를 사용하여 생성&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;l2fwd_mbuf_ol_pool = rte_pktmbuf_offload_pool_create(
 &amp;#34;mbuf_offload_pool&amp;#34;, NB_MBUF, 128, 0, rte_socket_id());
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;할당은 &lt;code&gt;rte_pktmbuf_offload_alloc()&lt;/code&gt;를 이용.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;rte_pktmbuf_offload_alloc(l2fwd_mbuf_ol_pool, RTE_PKTMBUF_OL_CRYPTO);
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;mbuf 마다 하나씩 할당해서 crypto 연산에 사용&lt;/li&gt;
&lt;li&gt;crypto 연산에 필요한 추가 옵션 등을 설정함.&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;/* Append space for digest to end of packet */
ol-&amp;gt;op.crypto.digest.data = (uint8_t *)rte_pktmbuf_append(m,
		cparams-&amp;gt;digest_length);
ol-&amp;gt;op.crypto.digest.phys_addr = rte_pktmbuf_mtophys_offset(m,
		rte_pktmbuf_pkt_len(m) - cparams-&amp;gt;digest_length);
ol-&amp;gt;op.crypto.digest.length = cparams-&amp;gt;digest_length;

ol-&amp;gt;op.crypto.iv.data = cparams-&amp;gt;iv_key.data;
ol-&amp;gt;op.crypto.iv.phys_addr = cparams-&amp;gt;iv_key.phys_addr;
ol-&amp;gt;op.crypto.iv.length = cparams-&amp;gt;iv_key.length;

ol-&amp;gt;op.crypto.data.to_cipher.offset = ipdata_offset;
ol-&amp;gt;op.crypto.data.to_cipher.length = data_len;

ol-&amp;gt;op.crypto.data.to_hash.offset = ipdata_offset;
ol-&amp;gt;op.crypto.data.to_hash.length = data_len;
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id="l2fwd_simple_crypto_enqueue"&gt;&lt;code&gt;l2fwd_simple_crypto_enqueue()&lt;/code&gt;&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;crypto operation에 맞게 data align에 맞게 padding&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rte_crypto_op_attach_session()&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;ol-&amp;gt;op&lt;/code&gt;에 crypto 연산에 필요한 정보를 설정
&lt;ul&gt;
&lt;li&gt;crypto 대상 위치, 길이 등&lt;/li&gt;
&lt;li&gt;session 개념이 있는데 정확히 뭔지는 모르겠음…&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;code&gt;rte_crypto_op_attach_session()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;op-&amp;gt;session = sess;
op-&amp;gt;type = RTE_CRYPTO_OP_WITH_SESSION;
&lt;/code&gt;&lt;/pre&gt;&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rte_pktmbuf_offload_attach()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id="l2fwd_crypto_enqueue"&gt;&lt;code&gt;l2fwd_crypto_enqueue()&lt;/code&gt;&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;l2fwd_crypto_send_burst()&lt;/code&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;rte_cryptodev_enqueue_burst()&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="struct-rte_mbuf_offload"&gt;&lt;code&gt;struct rte_mbuf_offload&lt;/code&gt;&lt;/h3&gt;
&lt;pre tabindex="0"&gt;&lt;code&gt;/**
 * Generic packet mbuf offload
 * This is used to specify a offload operation to be performed on a rte_mbuf.
 * Multiple offload operations can be chained to the same mbuf, but only a
 * single offload operation of a particular type can be in the chain
 */
struct rte_mbuf_offload {
 struct rte_mbuf_offload *next; /**&amp;lt; next offload in chain */
 struct rte_mbuf *m; /**&amp;lt; mbuf offload is attached to */
 struct rte_mempool *mp; /**&amp;lt; mempool offload allocated from */

 enum rte_mbuf_ol_op_type type; /**&amp;lt; offload type */
 union {
 struct rte_crypto_op crypto; /**&amp;lt; Crypto operation */
 } op;
};
&lt;/code&gt;&lt;/pre&gt;</description></item><item><title>DPDK based applications</title><link>https://cychong47.github.io/post/2016/dpdk_based_apps/</link><pubDate>Sun, 24 Jan 2016 14:59:18 +0900</pubDate><guid>https://cychong47.github.io/post/2016/dpdk_based_apps/</guid><description>&lt;p&gt;2016.02.10 기준&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="https://github.com/marty90/DPDK-Dump"&gt;DPDK-dump&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://trex-tgn.cisco.com"&gt;TRex - Realistic traffic generator&lt;/a&gt;&lt;br&gt;
&lt;a href="https://github.com/cisco-system-traffic-generator"&gt;git-hub&lt;/a&gt; - &lt;a href="https://github.com/cisco-system-traffic-generator/trex-core"&gt;trex-core&lt;/a&gt;, &lt;a href="https://github.com/cisco-system-traffic-generator/trex-doc"&gt;trex-doc&lt;/a&gt;, &lt;a href="https://github.com/cisco-system-traffic-generator/trex-profiles"&gt;trex-profiles&lt;/a&gt;, &lt;a href="https://github.com/cisco-system-traffic-generator/trex-qt-gui"&gt;trex-qt-gui&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.gandi.net/news/en/2015-12-16/6308-packet-journey_a_free_software_router_for_linux_based_on_dpdk/"&gt;Packet-journey&lt;/a&gt;
&lt;a href="https://github.com/Gandi/packet-journey"&gt;git-hub&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://fd.io"&gt;FD.io&lt;/a&gt; Fast Data Path&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/opendp/dpdk-nginx"&gt;DPDK-nginx&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://dpdk.org/browse/apps/pktgen-dpdk/refs/"&gt;DPDK-pktgen&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://github.com/opendp/dpdk-odp"&gt;DPDK-ODP&lt;/a&gt; TCP/IP stack for DPDK&lt;/li&gt;
&lt;/ol&gt;</description></item><item><title>2년전에 느꼈던 답답함이 여전하네</title><link>https://cychong47.github.io/post/2016/two-years-back/</link><pubDate>Mon, 04 Jan 2016 15:19:11 +0900</pubDate><guid>https://cychong47.github.io/post/2016/two-years-back/</guid><description>&lt;p&gt;우연히 tumblr를 보니 2013년에 적었던 답답한 현실이 지금도 똑같다는 사실에 놀랐다. 들으려고 하는 사람은 없고, 쓸데없는 일에 시간을 보내는 건 지금도 전혀 바뀐게 없어 보인다.&lt;/p&gt;
&lt;p&gt;여전히 사용하라는 툴에서 제공하는 정보와 취합해 달라고 하는 정보가 다르다. 그럼 어떻게 하라는 건지? 툴을 고치던가, 툴의 정보를 원하는 정보로 바꾸는 기준을 제시해줘야 하는 거 아닌가?
내용은 관심없고, 그냥 결과만 달라고 하는. 자기가 그런 변환 작업을 한 적이 없으니 얼마나 귀찮은지 모르는 거다. 그리고 사람마다 다른 기준으로 정보를 취합해도 별 문제가 없다는 건 결국 별로 중요하지 않는 내용이라는 거다. 그런 걸 사람들이 못 느낄까? 다 안다. 결국 정보를 제공해야 하는 사람도 대충 대충 하게 된다. 악순환.&lt;/p&gt;</description></item><item><title>Googlegeist vs. SCI</title><link>https://cychong47.github.io/post/2016/googlegeist_vs_sci/</link><pubDate>Sat, 02 Jan 2016 02:44:51 +0900</pubDate><guid>https://cychong47.github.io/post/2016/googlegeist_vs_sci/</guid><description>&lt;p&gt;SCI 결과를 개선하기 위해 실질적으로 이뤄지는 노력이 안 보인다는 것. 노력한다해도 그건 관리자와 비관리자가 함께 노력해야 하는 일일텐데(관리자나 회사에 대한 불만이므로 그 불만 개선이 노력이 맞는 방향인지는 당연히 비관리지에게도 한께 논의되어야 한다) 그런 건 보기 어렵다.&lt;/p&gt;
&lt;p&gt;문제 제기는 니들이 하지만 문제 해결은 나만 할 수 있다고 착각은 버려야 한다. 직원들이 불만에 대해 공감도 못하는데 어떻게 그 불만을 해결하기 위해 노력할 수 있겠나. 아니 공감을 하지 못하면 이해하기 위해 혹은 설득하기 위해 함께 이야기해야 하는데 그런 노력은 대부분 알아서 하란다. 잘 될 턱이 있나.&lt;/p&gt;</description></item><item><title>(글) 왜 “애자일”, 특히 스크럼이 끔찍한가.</title><link>https://cychong47.github.io/post/2016/anti-agile/</link><pubDate>Fri, 01 Jan 2016 15:25:13 +0900</pubDate><guid>https://cychong47.github.io/post/2016/anti-agile/</guid><description>&lt;p&gt;출처 : &lt;a href="http://wonnyz.tumblr.com/post/136256619316/%EC%99%9C-%EC%95%A0%EC%9E%90%EC%9D%BC-%ED%8A%B9%ED%9E%88-%EC%8A%A4%ED%81%AC%EB%9F%BC%EC%9D%B4-%EB%81%94%EC%B0%8D%ED%95%9C%EA%B0%80"&gt;왜 “애자일”, 특히 스크럼이 끔찍한가&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;스크럼 팀에 실제 시니어 엔지니어의 역할은 없는데, 문제는 스크럼을 도입한 많은 회사에서 보통 전사적으로 시행한다는 것이다. 관리직으로 넘어가는 것 말고는, “스크럼 마스터”가 되어 이것을 말단에 도입하는 책임을 지는 선택지가 있다. 권한이 없는, 헛소리에 불과한 가짜 관리직 말이다. 스크럼 팀을 떠나서 해로운 마이크로매니지먼트를 받으면서 살지 않으려면 괴물 안으로 깊숙히 파고들어서 다른 사람에게 유해한 마이크로매니지먼트를 강요하는 수 밖에 없다. “애자일”과 스크럼이 나에게 말하는 것은 시니어 프로그래머는 반드시 필요하지 않다고 여겨지므로, 무시해도 좋으며, 마치 프로그래밍이란 35세 이전에 접어야 하는 유치한 것이라고 하는 것 같았다&lt;/p&gt;</description></item><item><title>click - python option 처리 모듈</title><link>https://cychong47.github.io/post/2016/click-python-module/</link><pubDate>Fri, 01 Jan 2016 13:45:58 +0900</pubDate><guid>https://cychong47.github.io/post/2016/click-python-module/</guid><description>&lt;p&gt;&lt;a href="http://click.pocoo.org/5/"&gt;http://click.pocoo.org/5/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;C로 프로그램을 짤 때 사용할 표준 포맷도 이렇게 해야겠다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;$ python hello.py --help
Usage: hello.py [OPTIONS]

 Simple program that greets NAME for a total of COUNT times.

Options:
 --count INTEGER Number of greetings.
 --name TEXT The person to greet.
 --help Show this message and exit.
&lt;/code&gt;&lt;/pre&gt;</description></item><item><title>DPDK QAT example 빌드하기</title><link>https://cychong47.github.io/post/2016/build_dpdk_qat/</link><pubDate>Fri, 01 Jan 2016 10:57:39 +0900</pubDate><guid>https://cychong47.github.io/post/2016/build_dpdk_qat/</guid><description>&lt;h3 id="download-dpdk-220targz"&gt;Download dpdk-2.2.0.tar.gz&lt;/h3&gt;
&lt;p&gt;Refer &lt;a href="http://dpdk.org/download"&gt;http://dpdk.org/download&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wget http://dpdk.org/browse/dpdk/snapshot/dpdk-2.2.0.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="download-qat_mux"&gt;Download qat_mux&lt;/h3&gt;
&lt;p&gt;Refer &lt;a href="https://01.org/packet-processing/intel"&gt;https://01.org/packet-processing/intel&lt;/a&gt;®-quickassist-technology-drivers-and-patches&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wget https://01.org/sites/default/files/page/qatmux.l.2.5.0-80.tgz 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Getting Started Guide 문서도 받아 둔다.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wget https://01.org/sites/default/files/page/330750-004_qat_gsg.pdf 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="configure-dpdk"&gt;Configure DPDK&lt;/h3&gt;
&lt;pre&gt;&lt;code&gt;export RTE_SDK=/home/cychong/work/dpdk-2.2.0 
export RTE_TARGET=x86_64-native-linuxapp-gcc
make config T=$RTE_TARGET O=$RTE_TARGET
make 
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="configure-qat"&gt;Configure QAT&lt;/h3&gt;
&lt;p&gt;Ubuntu (14.04) 기준으로 몇 개 패키지를 설치해야 QAT를 빌드할 수 있는데 나름 기본적인 패키지들이라 그냥 설치해 놓으면 좋을 듯.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install zlib1g-dev
sudo apt-get install libssl-dev
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;적당한 위치에 풀면 되는데 &lt;code&gt;~/work/qat&lt;/code&gt;에 압축을 푼 경우를 기준으로 정리&lt;/p&gt;</description></item><item><title>Designing a RESTful API with Python and Flask</title><link>https://cychong47.github.io/post/2015/designing-a-restful-api-with-python-and-flask/</link><pubDate>Thu, 24 Dec 2015 14:11:59 +0900</pubDate><guid>https://cychong47.github.io/post/2015/designing-a-restful-api-with-python-and-flask/</guid><description>&lt;p&gt;&lt;a href="http://blog.miguelgrinberg.com/post/designing-a-restful-api-with-python-and-flask"&gt;Designing a RESTful API with Python and Flask&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;RESTful API는 URI에 필요한 인자를 다 넘기는 형태라 사용자가 직접 주소를 입력하는 것이 아니라 다른 SW에서 해당 URI를 입력하는 형태로 사용하는 게 자연스러운 거네.&lt;/p&gt;</description></item><item><title>virtualenv 사용</title><link>https://cychong47.github.io/post/2015/virtualenv/</link><pubDate>Mon, 21 Dec 2015 14:59:29 +0900</pubDate><guid>https://cychong47.github.io/post/2015/virtualenv/</guid><description>&lt;p&gt;virtualenv 설치&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mini-2:~ cychong$ sudo easy_install pip
mini-2:~ cychong$ sudo pip install virtualenv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;virtualenv로 project directory 생성&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mini-2:work cychong$ mkdir click
mini-2:work cychong$ cd click/
mini-2:click cychong$ ls
mini-2:click cychong$ virtualenv venv
New python executable in venv/bin/python
Installing setuptools, pip, wheel...done.
mini-2:click cychong$ ls
venv
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;virtualenv 환경으로 들어가기&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;mini-2:click cychong$ . venv/bin/activate
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;원하는 패키지 설치&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;(venv)mini-2:click cychong$ pip install Click
Collecting Click
 Downloading click-6.2-py2.py3-none-any.whl (70kB)
 100% |████████████████████████████████| 73kB 270kB/s
Installing collected packages: Click
Successfully installed Click-6.2
&lt;/code&gt;&lt;/pre&gt;</description></item><item><title>Culture should be setup first</title><link>https://cychong47.github.io/post/2015/culture/</link><pubDate>Sun, 13 Dec 2015 13:44:24 +0900</pubDate><guid>https://cychong47.github.io/post/2015/culture/</guid><description>&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2015/12/based_on_culture_from_workrules-net.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;from Google Work Rules&lt;/p&gt;
&lt;p&gt;2006년에 구글에 입사.
72년 생&lt;/p&gt;
&lt;p&gt;구글 임직원 나이 평균에 비하면 많지만, 그래도 비슷한 덩치의 국내 기업의 인사 담당자와 비교하면. 하긴 구글을 국내 (대)기업과 비교하는 것 자체가 의미없는 일이지만&lt;/p&gt;
&lt;p&gt;과연 현실은 그렇다해도 저런 생각을 가진 사람을 주변에서 볼 수 있을까?&lt;/p&gt;
&lt;p&gt;그러기에 현실은 너무 지난하다.&lt;/p&gt;</description></item><item><title>OpenFastPath</title><link>https://cychong47.github.io/post/2015/openfastpath/</link><pubDate>Fri, 11 Dec 2015 14:40:23 +0900</pubDate><guid>https://cychong47.github.io/post/2015/openfastpath/</guid><description>&lt;p&gt;Another Open source project.&lt;/p&gt;
&lt;p&gt;User-land protocol stack.
Incorporate with ODP&lt;br&gt;
To use with DPDK, ODP and ODP-DPDK should be used.&lt;/p&gt;
&lt;p&gt;From the &lt;a href="http://www.openfastpath.org/index.php/faq/"&gt;FAQ&lt;/a&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Q: Does the OFP IP stack mimic Linux stack config inside the fastpath, meaning does it intercept Linux ipconfig/ip commands and automatically create similar entities inside the fastpath stack?

A: Yes. Uses Netlink to sync with ifconfig commands and also with routes.
Q: Does the OFP IP stack have full IPv4/IPv6 fragmentation/re-assembly support?
A: IPv4 only. Fragmentation and reassembly on IPv4. 

Q: Does the OFP IP stack have a replacement/equivalent of DPDK KNI (Kernel Network Interface) to allow forwarding packets between Linux/Fastpath?

A: OFP uses a generic solution called TAP, not intended for performance. Fastpath can relay packets to Linux(slowpath). The use case to relay packets from Linux to Fastpath is not implemented. Linux will send packets straight to NIC/wire.
&lt;/code&gt;&lt;/pre&gt;</description></item><item><title>Hugepage</title><link>https://cychong47.github.io/post/2015/hugepage/</link><pubDate>Fri, 11 Dec 2015 14:30:56 +0900</pubDate><guid>https://cychong47.github.io/post/2015/hugepage/</guid><description>&lt;p&gt;Linux에서 사용하는 기본 page size는 4KB. 이 대신 2MB 혹은 1GB의 큰 크기를 hugepage라고 한다. Hugepage는 연속된 physical memory에 할당되어야 한다는 제약 조건이 있지만, 대신 swap out되지 않아 성능 개선 효과가 있다.&lt;/p&gt;
&lt;p&gt;아래 링크에서는 Oracle DB를 사용하는데 page swapping때문에 CPU 부하가 간헐적으로 크게 증가하는 현상을 hugepage를 사용해서 해결한 경우.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.pythian.com/blog/performance-tuning-hugepages-in-linux/"&gt;Performance tuning : hugepages in Linux&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.ibm.com/developerworks/community/wikis/home?lang=en#!/wiki/W51a7ffcf4dfd_4b40_9d82_446ebc23c550/page/Enabling+huge+pages+for+shared+memory"&gt;Enabling huge pages for shared memory&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;기왕 hugepage를 사용한다면 shared memory도 hugepage에 할당하는 것이 유리할 듯.&lt;/p&gt;</description></item><item><title>Single tasking</title><link>https://cychong47.github.io/post/2015/single-tasking/</link><pubDate>Fri, 11 Dec 2015 14:08:11 +0900</pubDate><guid>https://cychong47.github.io/post/2015/single-tasking/</guid><description>&lt;p&gt;난 특히 멀티태스킹이 안된다.&lt;br&gt;
하나에도 제대로 집중하기 힘들다.
11월은 아무 쓸데없는 TF 2개에 참여하느라 제대로 일을 못했다. 정말&amp;hellip;&lt;/p&gt;</description></item><item><title>19 hard things you need to do to be successful</title><link>https://cychong47.github.io/post/2015/19-hard-things-you-need-to-do-to-be-successful/</link><pubDate>Thu, 10 Dec 2015 14:58:06 +0900</pubDate><guid>https://cychong47.github.io/post/2015/19-hard-things-you-need-to-do-to-be-successful/</guid><description>&lt;p&gt;Last login: Thu Dec 10 00:38:48 on ttys000
Chae-yongs-MacBook-Pro:~ cychong$
Chae-yongs-MacBook-Pro:~ cychong$ vi hard.txt
Chae-yongs-MacBook-Pro:~ cychong$ ack &amp;ldquo;You have to&amp;rdquo; hard.txt | sort | uniq &amp;gt; a
Chae-yongs-MacBook-Pro:~ cychong$ vi a
Chae-yongs-MacBook-Pro:~ cychong$ ack &amp;ldquo;You have to&amp;rdquo; hard.txt | uniq &amp;gt; a
Chae-yongs-MacBook-Pro:~ cychong$ vi a&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;You have to do the hard things.&lt;/li&gt;
&lt;li&gt;You have to make the call you’re afraid to make.&lt;/li&gt;
&lt;li&gt;You have to get up earlier than you want to get up.&lt;/li&gt;
&lt;li&gt;You have to give more than you get in return right away.&lt;/li&gt;
&lt;li&gt;You have to care more about others than they care about you.&lt;/li&gt;
&lt;li&gt;You have to fight when you are already injured, bloody, and sore.&lt;/li&gt;
&lt;li&gt;You have to feel unsure and insecure when playing it safe seems smarter.&lt;/li&gt;
&lt;li&gt;You have to lead when no one else is following you yet.&lt;/li&gt;
&lt;li&gt;You have to invest in yourself even though no one else is.&lt;/li&gt;
&lt;li&gt;You have to look like a fool while you’re looking for answers you don’t have.&lt;/li&gt;
&lt;li&gt;You have to grind out the details when it’s easier to shrug them off.&lt;/li&gt;
&lt;li&gt;You have to deliver results when making excuses is an option.&lt;/li&gt;
&lt;li&gt;You have to search for your own explanations even when you’re told to accept the “facts.”&lt;/li&gt;
&lt;li&gt;You have to make mistakes and look like an idiot.&lt;/li&gt;
&lt;li&gt;You have to try and fail and try again.&lt;/li&gt;
&lt;li&gt;You have to run faster even though you’re out of breath.&lt;/li&gt;
&lt;li&gt;You have to be kind to people who have been cruel to you.&lt;/li&gt;
&lt;li&gt;You have to meet deadlines that are unreasonable and deliver results that are unparalleled.&lt;/li&gt;
&lt;li&gt;You have to be accountable for your actions even when things go wrong.&lt;/li&gt;
&lt;li&gt;You have to keep moving towards where you want to be no matter what’s in front of you.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;출처 : &lt;a href="http://www.businessinsider.com/hard-things-you-need-to-do-to-be-successful-2015-12?amp"&gt;http://www.businessinsider.com/hard-things-you-need-to-do-to-be-successful-2015-12?amp&lt;/a&gt;
20 substitutions on 20 lines&lt;/p&gt;</description></item><item><title>Code 량이 늘면 버그도 함께 들어나기 마련</title><link>https://cychong47.github.io/post/2015/errors_from_more_code/</link><pubDate>Mon, 07 Dec 2015 14:00:58 +0900</pubDate><guid>https://cychong47.github.io/post/2015/errors_from_more_code/</guid><description>&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2015/12/12313677_10153195940702321_1604212637607630351_n.jpg" alt=""&gt;&lt;/p&gt;
&lt;p&gt;부정하기 어렵다. 하지만 코드가 늘어나는 것은 피할 수 없으니 불필요한 기능/코드는 삭제하는 노력을 끊임없이 해야 한다. 그렇지 않으면 technical debt만 늘어날 뿐이다. 개발할 때는 제대로 이해하고 만들어서 technical debt가 아니었더라도 시간이 지나 동작하지 않는 코드가 되면 불필요한 짐만 된다.&lt;/p&gt;</description></item><item><title>역량 평가를 없앤 회사에서 일어난 일</title><link>https://cychong47.github.io/post/2015/what_happens_if_performance_rating_is_omitted/</link><pubDate>Sat, 05 Dec 2015 13:14:53 +0900</pubDate><guid>https://cychong47.github.io/post/2015/what_happens_if_performance_rating_is_omitted/</guid><description>&lt;p&gt;출처 : &lt;a href="https://hbr.org/2015/11/what-really-happens-when-companies-nix-performance-ratings"&gt;Harvard Businee Review&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;최소 52개 대형 회사가 기존 년 단위의 고과 평과 제도를 없앰. 이 중 33개 업체를 집중 분석하여 해당 업체에서 일어난 변화를 정리&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;manager-employee간 대화가 극적으로 증가.
33개 미국 기반의 업체 중 76%는 기존에 1년 단위의 역량 대화를 나눴으나, 이젠 68%가 최소 분기별 대화를 권장하고 있다고 함.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;관리 부담이 크게 줄어듬
33개 업체의 2/3에서 역량 평가를 위한 관리자의 문서 작성 요구가 공식적으로 줄어듬. 다른 30% 업체는 문서 작성을 아예 없앰.&lt;br&gt;
HBR에서 확인한 바로는 65,000이상의 고용인을 리뷰하기 위해 매년 2백만 시간이 필요했음. 실제 통상적인 고과 면담이 업무 역량을 높이는 데 도움이 되지 않는 것을 생각하면 이 시간은 낭비임.&lt;/p&gt;</description></item><item><title>OpenStack이 Python으로 만들어졌다니</title><link>https://cychong47.github.io/post/2015/openstacki-pythoneuro-mandeuleojyeossdani/</link><pubDate>Wed, 25 Nov 2015 11:36:43 +0900</pubDate><guid>https://cychong47.github.io/post/2015/openstacki-pythoneuro-mandeuleojyeossdani/</guid><description>&lt;p&gt;&lt;a href="https://github.com/openstack/neutron"&gt;Neuron&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Python project 체계를 잡는데 도움이 될 듯 하다.
아래는 pylink를 이용해서 syntax 검사하는 script&lt;/p&gt;
&lt;p&gt;&lt;a href="https://github.com/openstack/neutron/blob/master/tools/coding-checks.sh"&gt;https://github.com/openstack/neutron/blob/master/tools/coding-checks.sh&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Cisco Cloud Services Router 1000V</title><link>https://cychong47.github.io/post/2015/cisco-cloud-services-router-1000v/</link><pubDate>Mon, 23 Nov 2015 14:50:31 +0900</pubDate><guid>https://cychong47.github.io/post/2015/cisco-cloud-services-router-1000v/</guid><description>&lt;p&gt;&lt;a href="http://www.cisco.com/c/en/us/products/collateral/routers/cloud-services-router-1000v-series/datasheet-c78-733443.html"&gt;http://www.cisco.com/c/en/us/products/collateral/routers/cloud-services-router-1000v-series/datasheet-c78-733443.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;How many vCPUs are required for processing.&lt;/p&gt;</description></item><item><title>CISCO Cloud Service Platform 2100</title><link>https://cychong47.github.io/post/2015/cisco-cloud-service-platform-2100/</link><pubDate>Mon, 23 Nov 2015 14:24:35 +0900</pubDate><guid>https://cychong47.github.io/post/2015/cisco-cloud-service-platform-2100/</guid><description>&lt;p&gt;&lt;a href="http://www.cisco.com/c/en/us/products/collateral/switches/cloud-services-platform-2100/datasheet-c78-735317.html"&gt;Data sheet&lt;/a&gt; (&lt;a href="http://www.cisco.com/c/en/us/products/collateral/switches/cloud-services-platform-2100/datasheet-c78-735317.pdf"&gt;PDF&lt;/a&gt;)&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Some Cisco virtual network services that use the DPDK include Cisco Cloud Services Router (CSR) 1000V, Cisco Virtual Mobile Packet Core software, and Cisco IOS® XR 9000v virtual router.&lt;/li&gt;
&lt;li&gt;Supporte CISCO appliances
&lt;ul&gt;
&lt;li&gt;Cisco Cloud Services Router (CSR) 1000V virtual router&lt;/li&gt;
&lt;li&gt;Cisco Virtual Adaptive Security Appliance (ASAv)&lt;/li&gt;
&lt;li&gt;Cisco Prime™ Data Center Network Manager (DCNM)&lt;/li&gt;
&lt;li&gt;Cisco Virtual Network Analysis Module (vNAM)&lt;/li&gt;
&lt;li&gt;Cisco Virtual Security Gateway (VSG) for Cisco Nexus® 1000V Switch deployments&lt;/li&gt;
&lt;li&gt;Cisco Virtual Supervisor Module (VSM) for Cisco Nexus 1000V Switch deployments&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;1U&lt;/li&gt;
&lt;li&gt;2 CPU, each has 8 core Ivy Bridge(E5-2630 v3)&lt;/li&gt;
&lt;li&gt;REST API&lt;/li&gt;
&lt;li&gt;It uses REST API and NETCONF protocol for north-bound management and orchestration (MANO) tools.&lt;/li&gt;
&lt;li&gt;Network services could be abstracted to a pool of high-availability resources among several hosts.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;a href="http://www.cisco.com/c/dam/en/us/solutions/collateral/service-provider/network-functions-virtualization-nfv/nfv-partnership.pdf"&gt;Cisco Systems and Intel Corporation NFV Partnership&lt;/a&gt;&lt;/p&gt;</description></item><item><title>제대로 만들려면 제품의 성격부터 정의해야</title><link>https://cychong47.github.io/post/2015/what_is_the_target_product/</link><pubDate>Sun, 22 Nov 2015 14:35:23 +0900</pubDate><guid>https://cychong47.github.io/post/2015/what_is_the_target_product/</guid><description>&lt;p&gt;철학의 부재. 중심의 부재. 대화의 부재&lt;/p&gt;
&lt;p&gt;제품을 만드는데 철학이 없다는 건 정말 큰 문제다. 누군가 대충 스케치만 그린 그림을 가지고 차를 만든다고 생각하면 끔찍하다. 각 부분 부분별로 , 기능 별로 어떻게 만들 것인지 고민없이 그냥 각 부서별로 자기가 맡은 걸 만든다면 그 차가 굴러가기만 해도 기적이지만, 제대로 굴러가는 커녕 일정 내 만들어질 리가 없다.&lt;/p&gt;
&lt;p&gt;처음부터 끝까지 혹은 적어도 그걸 만드는 사람들이 충분히 제품의 철학(성격 등)을 공감할 때까지 끊임없이 대화해서 그나마 비슷한 생각을 가진 후에야 각 기능별 부분별 설계가 이뤄져야 한다.&lt;/p&gt;</description></item><item><title>개인의 잘못으로만 돌리는 이유</title><link>https://cychong47.github.io/post/2015/why_blame_personals/</link><pubDate>Thu, 19 Nov 2015 22:22:07 +0900</pubDate><guid>https://cychong47.github.io/post/2015/why_blame_personals/</guid><description>&lt;p&gt;잘못된(?) 진단은 잘못된 처방을 낳는다.&lt;/p&gt;
&lt;p&gt;모든 걸 개인의 잘못으로 돌리려는 의도는 의외로 단순. 잘못을 저지른 개인은 개선시키면 된다는 단순한 해법을 제시할 수 있으므로. 개인을 구박하거나 심지어는 그 조직에서 제외시키면 문제가 해결(?)되는 것처럼 보이니까.&lt;/p&gt;
&lt;p&gt;하지만 그 뒤에 숨어있는 실은 개인의 잘못으로 돌려진 관리의 문제, 시스템의 문제는 아무도 건드리지 않는다. 문제의 원인이 너무 커서, 문제의 원인이 너무 근본적이라, 문제의 원인이 권력자에게 있는 터라.
그렇게 문제는 반복된다. 비난의 대상이 되는 &amp;lsquo;개인&amp;rsquo;만 바뀔 뿐.
병든 조직은 서서히 그렇게 스러진다&amp;hellip;&lt;/p&gt;</description></item><item><title>개발자를 위해 한 일이 뭐가 있지?</title><link>https://cychong47.github.io/post/2015/what_for_the_developer/</link><pubDate>Wed, 18 Nov 2015 14:43:51 +0900</pubDate><guid>https://cychong47.github.io/post/2015/what_for_the_developer/</guid><description>&lt;p&gt;관리자들이 개발자들을 위해 한 일이 뭐가 있나?&lt;/p&gt;
&lt;p&gt;아무리 생각해도 잘 모르겠다.&lt;/p&gt;
&lt;p&gt;그럼 개발자를 위한 사람이나 제도는 없다는 건데&lt;/p&gt;
&lt;p&gt;그러면서 개발자가 잘 하기 기대하는 건 도둑놈 심보가 아닌가?&lt;/p&gt;
&lt;p&gt;자꾸만 벗어나길 원하는 &amp;lsquo;개발&amp;rsquo;업무를 만든 게 누구인지? 왜 그렇게 된 건지?&lt;/p&gt;
&lt;p&gt;이런 근본적인 질문에 대한 고민과 해결 없이 SW품질을 논한다는 건 어불성설이다.&lt;/p&gt;</description></item><item><title>규제를 풀기 어려운 이유는</title><link>https://cychong47.github.io/post/2015/gyujereul-pulgi-eoryeoun-iyuneun/</link><pubDate>Wed, 18 Nov 2015 14:41:55 +0900</pubDate><guid>https://cychong47.github.io/post/2015/gyujereul-pulgi-eoryeoun-iyuneun/</guid><description>&lt;p&gt;규제를 풀기 어려운 이유는 그 규제를 풀어도 문제가 없는 지 자신이 없기 때문이다. 증명하기 어려운 경우가 대부분. 하지만 머리를 맞대고 함께 이야기해봐야 한다. 정말 필요한 절차인지 고민해야 한다. 가능하면 절차는 줄이고 또 줄여야 한다고 생각.&lt;/p&gt;
&lt;p&gt;이런 고민조차 어려운 이유는 대부분 한 쪽이 들으려 하지 않기 때문. 기존에 하던 (불필요해보이는) 절차를 없애는 경우 발생할 수 있는 위험요소를 감수할 의지가 없으므로. 혹시 이렇게 생각하고 있는 건 아닌지&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;그런 번거로운 절차는 내가 하는 게 아니라 니들이 하는 거니까&lt;/p&gt;</description></item><item><title>DPDK IP reassembly example</title><link>https://cychong47.github.io/post/2015/dpdk-ip-reassembly-example/</link><pubDate>Tue, 17 Nov 2015 13:49:57 +0900</pubDate><guid>https://cychong47.github.io/post/2015/dpdk-ip-reassembly-example/</guid><description>&lt;pre&gt;&lt;code&gt;TAILQ_HEAD(ip_pkt_list, ip_frag_pkt); /**&amp;lt; @internal fragments tailq */
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id="자료-구조체"&gt;자료 구조체&lt;/h3&gt;
&lt;h5 id="fragment-관리용-table"&gt;Fragment 관리용 table&lt;/h5&gt;
&lt;pre&gt;&lt;code&gt;struct rte_ip_frag_tbl *frag_tbl; 
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;locking 없이 IP reassembly를 수행할 단위(통상 core)로 한 개씩 만든다. 즉 하나의 core가 여러 rx queue를 처리하더라도 하나의 &lt;code&gt;frag_tbl&lt;/code&gt;만 가지면 된다.&lt;br&gt;
아래 &lt;code&gt;rte_ip_frag_table_create()&lt;/code&gt;함수를 이용해서 생성한다.&lt;/p&gt;
&lt;h5 id="struct-rte_ip_frag_death_row-death_row"&gt;&lt;code&gt;struct rte_ip_frag_death_row death_row&lt;/code&gt;&lt;/h5&gt;
&lt;p&gt;core별로 갖는 death_row. IP reassembly를 호출한 후 해당 함수내에서 free할 mbuf를 이 리스트에 담아줌.&lt;br&gt;
main loop에서 reassembly작업 후 &lt;code&gt;rte_ip_frag_free_death_row()&lt;/code&gt;함수를 호출해 reassembly에 실패한 mbuf를 free함&lt;/p&gt;
&lt;p&gt;&lt;code&gt;IP_MAX_FRAG_NUM&lt;/code&gt; defines the maximum fragments of one reassembly. Defined same as &lt;code&gt;RTE_LIBRTE_IP_FRAG_MAX_FRAG&lt;/code&gt; aka 4.&lt;/p&gt;</description></item><item><title>또 하나의 코미디</title><link>https://cychong47.github.io/post/2015/do_you_know_agile/</link><pubDate>Fri, 06 Nov 2015 16:47:18 +0900</pubDate><guid>https://cychong47.github.io/post/2015/do_you_know_agile/</guid><description>&lt;blockquote&gt;
&lt;p&gt;자네는 Agile이 뭔지, Scrum Master가 어떤 일을 해야 하는 지 모르겠지만, 앞으로 자네를 &amp;lsquo;Scrum Master&amp;rsquo;라고 부르겠네.&lt;/p&gt;
&lt;p&gt;이제 우리는 Scrum Master를 가졌으니, Agile을 하는 걸쎄&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;글쎄요&amp;hellip;&lt;/p&gt;
&lt;p&gt;저도 Agile을 잘 모르지만, 동의할 수가 없네요.&lt;/p&gt;
&lt;p&gt;국정교과서의 필요성에 대해 이야기하는 이상한 나라의 사람들 만큼이나 이해하기 어렵네요.&lt;/p&gt;</description></item><item><title>Software developer의 생산성을 측정할 수 있을까?</title><link>https://cychong47.github.io/post/2015/software-developeryi-saengsanseongeul-ceugjeonghal-su-isseulgga/</link><pubDate>Sun, 01 Nov 2015 15:02:04 +0900</pubDate><guid>https://cychong47.github.io/post/2015/software-developeryi-saengsanseongeul-ceugjeonghal-su-isseulgga/</guid><description>&lt;p&gt;&lt;a href="http://swreflections.blogspot.kr/2015/01/we-cant-measure-programmer-productivity.html?m=1"&gt;We can’t measure Programmer Productivity… or can we?&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="loc"&gt;LOC&lt;/h2&gt;
&lt;p&gt;The more fundamental problem is that measuring productivity by lines (or Function Points or other derivatives) typed doesn’t make any sense. A lot of important work in software development, the most important work, involves thinking and learning – not typing.&lt;/p&gt;
&lt;p&gt;The best programmers spend a lot of time understanding and solving hard problems, or helping other people understand and solve hard problems, instead of typing. They find ways to simplify code and eliminate duplication. And a lot of the code that they do write won’t count anyways, as they iterate through experiments and build prototypes and throw all of it away in order to get to an optimal solution.&lt;/p&gt;</description></item><item><title>분야별 노하우 공유가 필요한데</title><link>https://cychong47.github.io/post/2015/bunyabyeol-nohau-gongyuga-pilyohande/</link><pubDate>Sun, 01 Nov 2015 13:26:06 +0900</pubDate><guid>https://cychong47.github.io/post/2015/bunyabyeol-nohau-gongyuga-pilyohande/</guid><description>&lt;p&gt;예 ipsec on asf/se/&amp;hellip;&lt;/p&gt;
&lt;p&gt;불럭별 특징이 아니라 프로토콜별 호환성이나 주의사항에 대한 취합 필요&lt;/p&gt;
&lt;p&gt;보통 postmortem하면 그 블럭의 특징이라고 보는 경향이 강한데 그것과 무관하게 프로토콜 특성에 대한 내용은 블럭 설계와 별개로 모아놔야 하지 않을까?&lt;/p&gt;
&lt;p&gt;StackOverflow 처럼 분야별로&amp;hellip;&lt;/p&gt;</description></item><item><title>Running DPDK on VMware Fusion</title><link>https://cychong47.github.io/post/2015/running-dpdk-on-vmware-fusion/</link><pubDate>Tue, 20 Oct 2015 14:19:05 +0900</pubDate><guid>https://cychong47.github.io/post/2015/running-dpdk-on-vmware-fusion/</guid><description>&lt;p&gt;VirtualBox supports emulated e1000 NIC for VM while VMware fusion does not. &lt;strong&gt;VMware Fusion&amp;rsquo;s VM setting does not support configuring of NIC HW type&lt;/strong&gt;. The NIC HW is PCnet32 which is not supported by DPDK.&lt;/p&gt;
&lt;p&gt;However, we can change NIC HW type by editing VM configuration file directly.&lt;/p&gt;
&lt;p&gt;Refer : &lt;a href="http://thesolutionsarchitect.net/how-to-emulate-10-gbps-nic-in-a-vmware-fusion-vm/"&gt;How to emulate 10 Gbps NIC in a VMware Fusion VM&lt;/a&gt;&lt;/p&gt;
&lt;h5 id="edit-vmx-file-to"&gt;Edit vmx file to&lt;/h5&gt;
&lt;p&gt;VMX file is in where vmware image located&lt;/p&gt;</description></item><item><title>TRex - DPDK based traffic generator</title><link>https://cychong47.github.io/post/2015/trex-dpdk-based-traffic-generator/</link><pubDate>Mon, 12 Oct 2015 13:11:14 +0900</pubDate><guid>https://cychong47.github.io/post/2015/trex-dpdk-based-traffic-generator/</guid><description>&lt;p&gt;DPDK Userspace in Dublin 2015에서 발표&lt;/p&gt;
&lt;p&gt;Stageful traffic generator&lt;/p&gt;
&lt;h5 id="특징"&gt;특징&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;Generate traffic based on templates of real, captured flows&lt;/li&gt;
&lt;li&gt;No TCP/IP stack&lt;/li&gt;
&lt;li&gt;Up to 200Gbps with standard server hardware&lt;/li&gt;
&lt;li&gt;Low cost 1RU (C220M UCS-1RU)&lt;/li&gt;
&lt;li&gt;Cisco internal&lt;/li&gt;
&lt;li&gt;DPDK, ZMQ, Python libs&lt;/li&gt;
&lt;li&gt;Virtualization(vmxnet3/e1000)&lt;/li&gt;
&lt;li&gt;~20Gbps per core&lt;/li&gt;
&lt;li&gt;Generate flow templates&lt;/li&gt;
&lt;li&gt;Support 1K templates&lt;/li&gt;
&lt;li&gt;Yaml based traffic profile&lt;/li&gt;
&lt;/ul&gt;
&lt;h5 id="gui"&gt;GUI&lt;/h5&gt;
&lt;p&gt;GUI which monitors real-time properties of TRex - min/max/average latency, jitter&lt;/p&gt;
&lt;h5 id="python-연동"&gt;Python 연동&lt;/h5&gt;
&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2015/10/TRex_realistic_traffic_generator.png" alt=""&gt;&lt;/p&gt;
&lt;h5 id="code"&gt;Code&lt;/h5&gt;
&lt;p&gt;&lt;a href="https://github.com/cisco-system-traffic-generator/trex-core"&gt;https://github.com/cisco-system-traffic-generator/trex-core&lt;/a&gt;&lt;/p&gt;</description></item><item><title>What makes a good engineering culture?</title><link>https://cychong47.github.io/post/2015/what-makes-a-good-engineering-culture/</link><pubDate>Wed, 30 Sep 2015 13:41:57 +0900</pubDate><guid>https://cychong47.github.io/post/2015/what-makes-a-good-engineering-culture/</guid><description>&lt;p&gt;From &lt;a href="http://www.theeffectiveengineer.com/blog/what-makes-a-good-engineering-culture"&gt;http://www.theeffectiveengineer.com/blog/what-makes-a-good-engineering-culture&lt;/a&gt;&lt;/p&gt;
&lt;h3 id="1-optimize-for-iteration-speed"&gt;1. Optimize for iteration speed&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Continous deployment to support rapid validation&lt;/li&gt;
&lt;li&gt;High test coverage to reduce build and site breakages&lt;/li&gt;
&lt;li&gt;Fast unit tests to encourage people to run them&lt;/li&gt;
&lt;li&gt;Fast and incremental compiles and reloads to reduce development time&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Bill Walsh, 49ers to 3 Super bowls,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Commit, Explode, Recover&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A team crippled with indecisiveness will just cause individual efforts to flounders&lt;/p&gt;
&lt;h3 id="2-push-relentlessly-toward-automation"&gt;2. Push relentlessly toward automation&lt;/h3&gt;
&lt;p&gt;Consider operational burden per engineer&lt;/p&gt;</description></item><item><title>부서간 협력이 안 되니 대책으로</title><link>https://cychong47.github.io/post/2015/buseogan-hyeobryeogi-an-doeni-daecaegeuro/</link><pubDate>Sun, 20 Sep 2015 01:31:36 +0900</pubDate><guid>https://cychong47.github.io/post/2015/buseogan-hyeobryeogi-an-doeni-daecaegeuro/</guid><description>&lt;p&gt;부서간 협력이 잘 안되는 듯 하니 대책으로 &amp;lsquo;부서간 협력지수&amp;rsquo;를 수치화해서 평가하겠다. 그럼 협력이 잘 될까 궁금하네&lt;/p&gt;</description></item><item><title>Leading Lights 2015 Finalists - Most Innovative NFV Product Strategy (Vendor)</title><link>https://cychong47.github.io/post/2015/leading-lights-2015-finalists-most-innovative-nfv-product-strategy-vendor/</link><pubDate>Sat, 19 Sep 2015 13:11:50 +0900</pubDate><guid>https://cychong47.github.io/post/2015/leading-lights-2015-finalists-most-innovative-nfv-product-strategy-vendor/</guid><description>&lt;p&gt;HP, Intel, Cisco/Juniper, WindRiver 외에 Orchestrator 관련 회사도 다수 존재.&lt;/p&gt;
&lt;p&gt;개인적으로는 역시 Nokia가 가장 관심이 가는데&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Telco Cloud portfolio - virtualizing radio functions - &lt;strong&gt;LTE eNB L2/L3 processing&lt;/strong&gt;, MME and GW functionality, Wi-Fi controllers and virtual RNCs and vBSCs&lt;/li&gt;
&lt;li&gt;Multi-layer architecture - pioneers the use of Ethernet fronthaul and any combination of distributed and centralized deployments&lt;/li&gt;
&lt;li&gt;Processing capacity is allocated from almost anywhere in the network, such as an adjacent cell or a centralized data center, to where it is needed most for coordination and capacity.&lt;/li&gt;
&lt;li&gt;The multi-layer approach supports distributed and centralized deployments, or a combination of both, using multiple fronthaul types, including &lt;strong&gt;Ethernet&lt;/strong&gt;.&lt;/li&gt;
&lt;li&gt;Ready for the upcoming demands of &lt;strong&gt;5G&lt;/strong&gt; core and radio demands&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;출처 : &lt;a href="http://www.lightreading.com/nfv/nfv-strategies/leading-lights-2015-finalists-most-innovative-nfv-product-strategy-(vendor)/d/d-id/716166"&gt;Leading Lights 2015 Finalists: Most Innovative NFV Product Strategy (Vendor)&lt;/a&gt;&lt;/p&gt;</description></item><item><title>SW 품질 강화 노력</title><link>https://cychong47.github.io/post/2015/sw_quality/</link><pubDate>Sun, 13 Sep 2015 05:23:38 +0900</pubDate><guid>https://cychong47.github.io/post/2015/sw_quality/</guid><description>&lt;p&gt;어딘가 보고 정리한 글인데 출처를 기억하지 못하겠다&amp;hellip;.&lt;/p&gt;
&lt;h5 id="sw-품질-개선-노력의-대상"&gt;SW 품질 개선 노력의 대상&lt;/h5&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;SW 품질을 높이는데 Tool, System, People 그리고 Management중에 어떤 면을 개선하는 경우 효과가 높을까?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tool : 2 배&lt;/li&gt;
&lt;li&gt;System : 10배&lt;/li&gt;
&lt;li&gt;People : 30배&lt;/li&gt;
&lt;li&gt;Management : 60배 이상&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;그렇지만 대개의 관리자는 개선효과를 반대로 알고 있다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;사람은 변화해야 할 때 변화한다(더 이상 저항하지 못할 때) 그러나 위기는 갑자기 오지 않는다. 다만 위기에 대한 인지를 갑자기 할 뿐이다.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;변화는 성능 저하를 유발한다. 그 성능 저하를 감수하고, 계속 변화해가야 변화가 주는 효과를 얻을 수 있다.&lt;/p&gt;</description></item><item><title>경쟁을 통한 성과 추구는 마약과 같다</title><link>https://cychong47.github.io/post/2015/competetion_is_like_drug/</link><pubDate>Sat, 12 Sep 2015 10:28:31 +0900</pubDate><guid>https://cychong47.github.io/post/2015/competetion_is_like_drug/</guid><description>&lt;p&gt;경쟁을 부추켜서 조직의 성과를 얻으려는 관리자는 아무런 노력도 하지 않고 결과만 날로 먹으려는 것과 같다. 아무 고민없이 할 수 있는 제일 쉬운 방법이니까.&lt;/p&gt;
&lt;p&gt;조직원들에게 동기부여를 줄지, 조직의 협동심을 아떻게하면 높일 수 있을 지 고민할 필요가 없이 결과만 취하면 되니까. 그런 관리자는 조직에 해를 끼치는 존재다.&lt;/p&gt;
&lt;p&gt;할 수 있는 게 없는 건지,해도 안되는 건지. 여러가지 방법을 써도 안된다면 조직원과 함께 고민하면 안될까. 함께 속해 있는 &amp;lsquo;조직&amp;rsquo;의 성과를 위한 거니까&lt;/p&gt;
&lt;p&gt;@유정식의 &amp;lsquo;착각하는 CEO&amp;rsquo;를 읽는 중 프랑스/베트남/쥐 박멸/쥐 사육 부분을 읽고&lt;/p&gt;</description></item><item><title>(펌) 스포카, "성장 배경? '리모트'와 '블로그 문화' 덕분이죠"</title><link>https://cychong47.github.io/post/2015/peom-seupoka-seongjang-baegyeong-rimoteuwa-beulrogeu-munhwa-deogbunijyo/</link><pubDate>Tue, 28 Jul 2015 12:26:14 +0900</pubDate><guid>https://cychong47.github.io/post/2015/peom-seupoka-seongjang-baegyeong-rimoteuwa-beulrogeu-munhwa-deogbunijyo/</guid><description>&lt;p&gt;Link : &lt;a href="http://www.bloter.net/archives/233978"&gt;http://www.bloter.net/archives/233978&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;스포카는 측정 가능한 업무 시스템을 위해 깃허브, 슬랙, 지라 같은 협업 도구를 이용했다. 직원들은 협업 도구들로 기록을 철저히 하면서 업무상황을 공유하고 있다. 기록 내용은 아주 자세한 내용을 담는다. 예를 들어 ‘○○에게 e메일을 보냈다’, ‘A에게 답변을 받았다’, ‘개발을 위한 자료 조사 중’ 같은 식이다. 이 내용은 직원별로 볼 수 있다. e메일 내용이 어떤 것이었는지, 자료 조사는 어떤 것을 했는지도 상세히 기록되고 있다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;김재석 CTO는 “처음에는 기록을 습관화하는 데 시간이 조금 더 걸렸다”라며 “기록을 편하게 할 수 있도록 기존 협업도구를 스포카 환경에 맞게 재개발하기도 했다”라고 설명했다. 예를 들어 스포카는 채팅도구에 일본어 번역기를 붙여 일본어와 한국어를 모르는 직원들이 서로 정보를 공유할 수 있게 돕고 있다.&lt;/p&gt;</description></item><item><title>The Power of Ten-Rules for Developing Safety Critical Code</title><link>https://cychong47.github.io/post/2015/the-power-of-ten-rules-for-developing-safety-critical-code/</link><pubDate>Mon, 27 Jul 2015 22:50:35 +0900</pubDate><guid>https://cychong47.github.io/post/2015/the-power-of-ten-rules-for-developing-safety-critical-code/</guid><description>&lt;p&gt;from NASA/JPL(Jet Propulsion Laboratory)&lt;/p&gt;
&lt;p&gt;The result is that most existing guidelines contain well over a hundred rules, sometimes with questionable justification. Some rules especially those that try to stipulate the use of white-space in programs, may have been introduced by personal preference; others are meants to prevent very specific and unlikely types of error from eariler coding efforts within the same organization.&lt;/p&gt;
&lt;p&gt;효율적인 가이드라인이 되려면, rule의 개수는 적어야 하고, 쉽게 이해되고, 기억될 수 있을 만큼 명확해야 한다.&lt;br&gt;
규칙은 기계적으로 검사할 수 있을 만큼 구체적이어야 한다.&lt;/p&gt;</description></item><item><title>관리자 들도 공부 좀 합시다</title><link>https://cychong47.github.io/post/2015/gwanrija-deuldo-gongbu-jom-habsida/</link><pubDate>Sat, 04 Jul 2015 13:56:36 +0900</pubDate><guid>https://cychong47.github.io/post/2015/gwanrija-deuldo-gongbu-jom-habsida/</guid><description>&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2015/07/2569BC445582D18F35DDF5.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;출처 : &lt;a href="http://bcho.tistory.com/1034"&gt;관리의 기본 (Fundamental of management) #2 - 관리자/리더에게 필요한 역량&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;가장 중요한 것은 Communication 역량으로, 팀내 또는 팀간의 조율을 위해서는 반드시 필요한 능력이라고 생각한다. 두말할 필요가 없는 부분인데, 효과적인 커뮤니케이션 스킬을 가지기 위해서는 상호 존중이 바탕이 되어야 한다. 존중의 바탕이 없이는 명령이되고, 명령은 팀을 Push하는 모델을 만들지, 팀이 스스로 높은 성과를 낼 수 있도록 Pull (당기는 형태)의 리더쉽을 만들어내기는 어렵다.&lt;/p&gt;
&lt;p&gt;관리자로써 전체적인 계획을 만들고 이를 실행하려면, 팀원들을 코칭할 필요가 있다. 이것이 Coaching skill이고.&lt;/p&gt;</description></item><item><title>열심히 비교한 결론이 고작 그건가?</title><link>https://cychong47.github.io/post/2015/yeolsimhi-bigyohan-gyeolroni-gojag-geugeonga/</link><pubDate>Wed, 24 Jun 2015 15:20:57 +0900</pubDate><guid>https://cychong47.github.io/post/2015/yeolsimhi-bigyohan-gyeolroni-gojag-geugeonga/</guid><description>&lt;p&gt;그냥 누구나 생각하는 바람직한 방법과 목표 그리고 절차를 따라야 한다는 게 고작 결론인가? 그런 누구나 할 수 있는 이야기잖아. 저런 이야기를 돈을 내고 들어야 한다는 건가? 이해가 안된다.&lt;/p&gt;
&lt;p&gt;현재 불편한, 잘못된, 쓸데없는 일을 하게 만드는 절차를 감당해야 하는 사람들에게 솔직한 의견을 구하는 것이 더 나은 방법 아닐까?&lt;/p&gt;
&lt;p&gt;아무리 다른 곳의 일하는 체계나 조직을 분석해도 소용없다. 그 비교자료에는 없는 내용이 핵심이니까. 조직을 운영하는 사람들의 능력과 그 조직을 구성하는 사람들의 능력. 그리고 생각들. 그건 아무리 해도 표현할 수가 없다. 알 수도 없다. 그런데 그게 핵심이다. 아무리 좋은 툴을 갖다 줘도, 아무리 선진 일처리 방식을 가져와도 사람을 빼놓고 일해서는 소용없다.&lt;/p&gt;</description></item><item><title>Divide &amp; Conquer</title><link>https://cychong47.github.io/post/2015/divide-conquer/</link><pubDate>Sun, 21 Jun 2015 08:24:05 +0900</pubDate><guid>https://cychong47.github.io/post/2015/divide-conquer/</guid><description>&lt;p&gt;출처 : &lt;a href="http://m.news.naver.com/read.nhn?mode=LSD&amp;amp;sid1=001&amp;amp;oid=008&amp;amp;aid=0003492855"&gt;http://m.news.naver.com/read.nhn?mode=LSD&amp;amp;sid1=001&amp;amp;oid=008&amp;amp;aid=0003492855&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;4.어려운 문제에 무턱대고 덤비지 마라&lt;br&gt;
어렵고 힘든 문제에 부딪히면 지레 겁을 먹기 쉽다. 아니면 무대포로 앞뒤 재지 않고 그냥 밀어붙인다. 그러나 구글과 페북에서 근무하며 얻은 지혜는 어렵고 덩치 큰 문제를 만나면 작게 쪼개서 각 부분별로 해결책을 찾는다는 것이다. 이렇게 부분별로 찾아진 해결책이 모아지면 원래의 덩치 큰 어려운 문제는 자연스럽게 풀리게 된다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;문제가 어려우면 어려울 수록 잘게 쪼개자. 잘게 쪼갠 문제를 해결하다 보면 전체 문제가 풀릴 수도 있다. 하지만 동시에 문제의 전체적인 모습을 보는 것도 게을리하면 안된다. 모순같지만 세상사 모든 게 그렇다. 절대적으로 맞는 말은 없다.&lt;/p&gt;</description></item><item><title>의도된 마감효과?</title><link>https://cychong47.github.io/post/2015/magamhyogwareul-norineun-geonga/</link><pubDate>Thu, 18 Jun 2015 00:00:45 +0900</pubDate><guid>https://cychong47.github.io/post/2015/magamhyogwareul-norineun-geonga/</guid><description>&lt;p&gt;(예를 들어) 분명 물리적으로 10개월이 필요한 일이 있다. 일정이 급하다고 6개월내 해 내라고 한다. 열심히 하지만 결국 6개월 기한은 넘어가고 겨우겨우 (담당자들이 개고생해서) 8개월 혹은 9개월내 일을 마친다.&lt;/p&gt;
&lt;p&gt;그리곤 말한다. (6개월을 요구했던 이들은) 처음에 6개월을 여구했으니까 8개월내 해낸거라고. 처음부터 10개월을 이야기했으면 못했을 거라고.&lt;/p&gt;
&lt;p&gt;하지만 경험상 저런 경우 8개월내 끝나기 보다 12개월이 걸리는 경우가 많다. 무리한 일정은 부실한 설계와 엉성한 구현을 만들어내고 버그로 인한 재작업을 유도한다. 이때 책임은 누가 져야 할까?&lt;/p&gt;</description></item><item><title>착각과 자만</title><link>https://cychong47.github.io/post/2015/cagga/</link><pubDate>Thu, 28 May 2015 14:14:28 +0900</pubDate><guid>https://cychong47.github.io/post/2015/cagga/</guid><description>&lt;p&gt;스스로 잘한다고 공공연하게 말하는 친구의 말은 믿을 수가 없다. 자기가 잘하는 단 하나만 생각해서 잘한다고 말하지만, 그게 SW 개발자가 가져야 할 모든 건 아닌데. 그것도 깨닫지 못하는 걸 보면 잘한다고 자만하는 건 스스로의 착각.&lt;/p&gt;
&lt;p&gt;남들의 인정을 받는 지 의문.&lt;/p&gt;
&lt;p&gt;혹은 남들이 자신과 함께 일하고 싶어 하는 지 한번이라도 생각해 봤으면.&lt;/p&gt;
&lt;p&gt;또 저런 친구들의 착각은 남들이 자기랑 함께 일하기 싫어하는 이유를 자신이 너무 잘나서 라고 생각한다는&amp;hellip;&lt;/p&gt;</description></item><item><title>Coding Style의 중요성</title><link>https://cychong47.github.io/post/2015/coding-styleyi-jungyoseong/</link><pubDate>Mon, 25 May 2015 12:44:28 +0900</pubDate><guid>https://cychong47.github.io/post/2015/coding-styleyi-jungyoseong/</guid><description>&lt;blockquote&gt;
&lt;p&gt;대부분의 개발자는 현업에서 선배 개발자들이 작성한 코드를 유지보수하면서 코드 작성 방법을 배우게 됩니다. 회사에 따라 다르긴 하겠지만, 이렇게 접한 대부분의 코드는 겨우 겨우 동작만 하지, 코드의 가독성이나 유지보수를 거의 생각하지 않고 작성된 코드일 확률이 높습니다. 이런 코드를 읽고, 어떻게든 돌아가게 수정하는 훈련만 하다 보면 애시당초 코드를 잘 짠다는 게 무엇인지 알기가 어렵게 됩니다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;출처 : &lt;a href="http://wp.me/p66O1q-3j"&gt;http://wp.me/p66O1q-3j&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;평소 내가 가진 생각과 비슷하다. 코드는 작성하는 게 1이면 읽는 게 9라고 한다. 그 만큼 기계가 아닌 사람이 읽는 것의 대상이 되는 경우가 많으므로 읽는 작업에 도움이 되도록 coding style의 정리가 반드시 필요하다고 생각한다. 하지만 이걸 무시하는 경우가 너무 많다는.&lt;/p&gt;</description></item><item><title>DPDK Coding style</title><link>https://cychong47.github.io/post/2015/dpdk-coding-style/</link><pubDate>Thu, 21 May 2015 14:51:37 +0900</pubDate><guid>https://cychong47.github.io/post/2015/dpdk-coding-style/</guid><description>&lt;p&gt;출처 : &lt;a href="http://dpdk.org/ml/archives/dev/2015-May/017666.html"&gt;DPDK mailing list&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="coding-style"&gt;Coding Style&lt;/h1&gt;
&lt;h2 id="description"&gt;Description&lt;/h2&gt;
&lt;p&gt;This document specifies the preferred style for source files in the DPDK
source tree. It is based on the Linux Kernel coding guidelines and the
FreeBSD 7.2 Kernel Developer&amp;rsquo;s Manual (see man style(9)), but was
heavily modified for the needs of the DPDK.&lt;/p&gt;
&lt;h2 id="general-guidelines"&gt;General Guidelines&lt;/h2&gt;
&lt;p&gt;The rules and guidelines given in this document cannot cover every
situation, so the following general guidelines should be used as a
fallback:&lt;/p&gt;</description></item><item><title>Docker for dummies 정리</title><link>https://cychong47.github.io/post/2015/docker-for-dummies-jeongri/</link><pubDate>Wed, 20 May 2015 14:18:04 +0900</pubDate><guid>https://cychong47.github.io/post/2015/docker-for-dummies-jeongri/</guid><description>&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2015/05/Docker_for_dummies.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;출처 : Docker 무작정 따라하기&lt;/p&gt;
&lt;p&gt;참고 : &lt;a href="http://www.pyrasis.com/docker.html"&gt;가장 빨리 배우는 Docker&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Designing for Service Agility</title><link>https://cychong47.github.io/post/2015/wp-designing-for-service-agility/</link><pubDate>Thu, 08 Jan 2015 15:33:34 +0900</pubDate><guid>https://cychong47.github.io/post/2015/wp-designing-for-service-agility/</guid><description>&lt;p&gt;Heavy Reading 2014 December&lt;/p&gt;
&lt;p&gt;&lt;a href="http://contextream.com/media/docs/HR-ConteXtream-Fit-VNF-WP-12-8.pdf"&gt;http://contextream.com/media/docs/HR-ConteXtream-Fit-VNF-WP-12-8.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The important Factors Driving NFV deployment is Service Agility &amp;amp; Flexibility&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In a virtual environment, where applications are extracted from hardware, VNF de- signers face different challenges and opportunities. If operators are to achieve a step change in service agility, it should be possible to provision VNFs on a quasi-on- demand basis. Fit VNFs can be dedicated to a single function and then connected together using traffic steering (or &amp;ldquo;chaining&amp;rdquo;) mechanisms to create services.&lt;/p&gt;</description></item><item><title>Intel Embedded Tech Forum 2014</title><link>https://cychong47.github.io/post/2014/intel-embedded-tech-forum-2014/</link><pubDate>Tue, 09 Dec 2014 10:38:08 +0900</pubDate><guid>https://cychong47.github.io/post/2014/intel-embedded-tech-forum-2014/</guid><description>&lt;h1 id="small-cell"&gt;Small Cell&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Big Cell&lt;/li&gt;
&lt;li&gt;256 user 이하를 small cell로 정의&lt;/li&gt;
&lt;li&gt;mini-CRAN&lt;/li&gt;
&lt;li&gt;Paris Hill SOC을 이용하는 경우 RRH에서 LTE/3G DSP+DFE 까지 처리하고 Ethernet으로 IA core로 전달. Altiostar 구조와 유사한 듯
&lt;ul&gt;
&lt;li&gt;Wifi 와 3G/4G까지 지원하는 차세대 SOC&lt;/li&gt;
&lt;li&gt;2/4/8 core까지 지원&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Aricent와 협업하여 L1/L2/L3 Protocol stack 개발&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="onp"&gt;ONP&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Red Rock Canyon
&lt;ul&gt;
&lt;li&gt;Las Vegas에서 30분 가량 걸리는 거리&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Switch와 NIC 통합&lt;/li&gt;
&lt;li&gt;PCI-e를 지원해서 NIC없이 Xeon을 직접 연결할 수 있음.&lt;/li&gt;
&lt;li&gt;150page 가량의 report&lt;/li&gt;
&lt;li&gt;ONP 1.1 버전. 1.2 버전은 각 OSS 버전을 업데이트할 계획
&lt;ul&gt;
&lt;li&gt;OpenStack Juno&lt;/li&gt;
&lt;li&gt;OpenDayLight Helium&lt;/li&gt;
&lt;li&gt;DPDK v1.8&lt;/li&gt;
&lt;li&gt;Haswell 2600 v3&lt;/li&gt;
&lt;li&gt;Ethernet Controller Fortvillle XL710&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;NTT lagopus SDN Controller
&lt;ul&gt;
&lt;li&gt;OpenFlow 1.3&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lagopus.github.io"&gt;http://lagopus.github.io&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2 RX, 4 Processing, 2 Tx cores&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Juniper Virtual NX - DPDK based router
&lt;ul&gt;
&lt;li&gt;vMX can run in the most popular hypervisors, including: KVM, VMware, and Xen. The vMX can even run in Docker containers and on bare metal.&lt;/li&gt;
&lt;li&gt;Buyers will be able to buy either license in increments based on capacity, for example in 100M, 1G, or 10G sizes, or any combination thereof.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.juniper.net/us/en/products-services/routing/mx-series/vmx/"&gt;http://www.juniper.net/us/en/products-services/routing/mx-series/vmx/&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="windriver"&gt;WindRiver&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;CIE(Contents Inspection Engine)
&lt;ul&gt;
&lt;li&gt;Intel Hyperscan 사용&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.intel.com/content/dam/www/public/us/en/documents/presentation/wind-river-intelligent-network-platform-presentation.pdf"&gt;http://www.intel.com/content/dam/www/public/us/en/documents/presentation/wind-river-intelligent-network-platform-presentation.pdf&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Titanium Server
&lt;ul&gt;
&lt;li&gt;OPNFV 와 유사하게 OSS들의 조합으로 구성 Carrier Grade 요구에 맞게 hardening
&lt;ul&gt;
&lt;li&gt;Carrier Grade Linux&lt;/li&gt;
&lt;li&gt;Carrier grade high-performance Kernel-based Virtual Machine (KVM) virtualization&lt;/li&gt;
&lt;li&gt;Carrier grade accelerated vSwitch - 20Gbps on 2 cores&lt;/li&gt;
&lt;li&gt;Carrier grade OpenStack&lt;/li&gt;
&lt;li&gt;Carrier grade middleware&lt;/li&gt;
&lt;li&gt;Lifecycle development tools&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.windriver.com/products/titanium-server/"&gt;http://www.windriver.com/products/titanium-server/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;1초내 VM 복구 등&lt;/li&gt;
&lt;li&gt;Live migration in 200ms&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="communication-infrastructure-platform"&gt;Communication Infrastructure Platform&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Broadwell-DE
&lt;ul&gt;
&lt;li&gt;10G 2개 포함&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h1 id="intel-software-platform-solution"&gt;Intel Software Platform Solution&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Intel System Studio&lt;/li&gt;
&lt;li&gt;3Ghz CPU에서 10Gbps를 지원하려면 201cycle. Spin lock에 60-90 cycle, task switch에 300 cycle&lt;/li&gt;
&lt;li&gt;Haswell은 20 core/CPU 지원. HT 켜고 QPI 연결하면 80개 logical core&lt;/li&gt;
&lt;li&gt;OVS 2.4에서 공식적으로 DPDK 지원 포함&lt;/li&gt;
&lt;li&gt;Linux UIO is replaced by VFIO
&lt;ul&gt;
&lt;li&gt;DPDK 1.7.0부터 VFIO 지원&lt;/li&gt;
&lt;li&gt;&lt;a href="http://lwn.net/Articles/474088/"&gt;Safe device assignment with VFIO&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.linux-kvm.org/wiki/images/d/d1/2011-forum-VFIO.pdf"&gt;VFIO PCI device assignment breaks free of KVM&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.mjmwired.net/kernel/Documentation/vfio.txt"&gt;Documentation / vfio.txt&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.linux-kvm.org/wiki/images/b/b4/2012-forum-VFIO.pdf"&gt;VFIO : A User&amp;rsquo;s perspective&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>R.I.P OVDK</title><link>https://cychong47.github.io/post/2014/r-i-p-ovdk/</link><pubDate>Thu, 27 Nov 2014 14:47:38 +0900</pubDate><guid>https://cychong47.github.io/post/2014/r-i-p-ovdk/</guid><description>&lt;p&gt;며칠 밖에 보지 않았지만, 그래도 내용을 분석해 보려고 했던 OVDK인데, 오늘 기사를 보니 Intel에서 공식적으로 OVDK의 개발 중단을 발표했단다.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.sdncentral.com/news/intel-dead-ends-fork-open-vswitch/2014/11/"&gt;Intel Dead-Ends Its Fork of Open vSwitch&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Data path(Fast path)를 커널 모듈에서 처리하는 OVS를 fork해서 DPDK를 이용해서 user space에 Fast Path를 만들려고 했는데 그러다 보니 역시 계속해서 발전하는 OVS의 기능을 수용하기 부담스러웠나 보다. 더군다나 OVS에서도 experimental feature이긴 하지만 DPDK를 이용하는 코드도 있다고 하니.&lt;/p&gt;
&lt;p&gt;내년 초에 나올 다음 버전 OVS에 공식 기능으로 들어가길 기대한다고.&lt;/p&gt;</description></item><item><title>ODP</title><link>https://cychong47.github.io/post/2014/odp/</link><pubDate>Wed, 19 Nov 2014 14:02:19 +0900</pubDate><guid>https://cychong47.github.io/post/2014/odp/</guid><description>&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=tUwE1-IRdIQ#t=28"&gt;Cavium Demonstrates Multiple OpenDataPlane Applications at Linaro Connect USA 2014&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=zmnjZUQPq5U&amp;amp;spfreload=10"&gt;Cavium ThunderX 48 Core 2.5Ghz ARM Server SoC&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;blockquote&gt;
&lt;p&gt;Cavium ThunderX 48 Core 2.5Ghz ARM Server SoC Cavium ThunderX is the world&amp;rsquo;s fastest ARM Processor, featuring 48 ARMv8 64bit cores at 2.5Ghz each, with two SoC&amp;rsquo;s possible per motherboard, this means 240Ghz of compuete power per Server Board. Providing extremely high performance at much lower power, much lower cost, much more optimized than any x86 server system. Cavium is shipping samples of their Server product by the end of this year with mass production scheduled for next year. &lt;a href="http://armdevices.net/2014/06/06/cavium-thunderx-48-core-2-5ghz-arm-server-soc/"&gt;http://armdevices.net/2014/06/06/cavium-thunderx-48-core-2-5ghz-arm-server-soc/&lt;/a&gt;&lt;/p&gt;</description></item><item><title>DPDK Summit 2014 Videos</title><link>https://cychong47.github.io/post/2014/dpdk-summit-2014-videos/</link><pubDate>Wed, 19 Nov 2014 13:59:07 +0900</pubDate><guid>https://cychong47.github.io/post/2014/dpdk-summit-2014-videos/</guid><description>&lt;ul&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=qpfwDySweUA"&gt;Application Performance Tuning and Future Optimizations in DPDK&lt;/a&gt; by Venky Venkatesan&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=EgjX0chfIcI&amp;amp;spfreload=10"&gt;DPDK in a Virtual World&lt;/a&gt; by Bhavesh Davda Rashmin Patel&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=mv8dB2GiaIw&amp;amp;spfreload=10"&gt;High Performance Networking Leveraging the DPDK and the Growing Community&lt;/a&gt; by Thomas Monj alon&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=907VShi799k&amp;amp;spfreload=10"&gt;Multi Socket Ferrari for NFV&lt;/a&gt; by Laszlo Vadkerti Andras Kovacs&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=KaXfDjIhn0U&amp;amp;spfreload=10"&gt;Lightning Fast IO with PacketDirect&lt;/a&gt; by Gabriel Silva&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=PSVHVDqGjcg&amp;amp;spfreload=10"&gt;A High Performance vSwitch of the User by the User for the User&lt;/a&gt; by Yoshihiro Nakajima&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=jZYPtYPXYuU&amp;amp;spfreload=10"&gt;Is It Time to Revisit the IP Stack in the Linux Kernel and KVM&lt;/a&gt; by Jun Xu&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.youtube.com/watch?v=r-JA5NBybrs&amp;amp;spfreload=10"&gt;Closing Remarks&lt;/a&gt; by Tim ODriscoll&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>(펌) 부실한 공유문화를 지배하는 개발자의 심리</title><link>https://cychong47.github.io/post/2014/peom-busilhan-gongyumunhwareul-jibaehaneun-gaebaljayi-simri/</link><pubDate>Mon, 17 Nov 2014 13:35:16 +0900</pubDate><guid>https://cychong47.github.io/post/2014/peom-busilhan-gongyumunhwareul-jibaehaneun-gaebaljayi-simri/</guid><description>&lt;p&gt;정말 하나같이 핵심적인 내용인데 정작 이걸 알아야 하는 사람은 이런 데 관심이 없겠지.&lt;/p&gt;
&lt;p&gt;출처 : &lt;a href="http://www.cnet.co.kr/view/25939"&gt;부실한 공유문화를 지배하는 개발자의 심리&lt;/a&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;전반적으로 공유문화가 부실하게 된 것은 현재 개발자들의 책임은 아니다. 원래 문화라는게 우리의 선조, 선배들이 만들어 놓은 것을 따르면서 아주 약간씩 바뀌는 것이다. 개발문화도 그렇다. 지금까지 선배들이 그런 환경에서 그렇게 일해 왔기 때문에 그런 문화가 형성되었고 우리도 거기에 적응해서 일하고 있는 것이다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;문화가 바뀌기 어려운 이유는 나 혼자 노력해서는 안되기 때문이다. 다른 사람들은 공유를 위해서 노력하지 않고 나 혼자 애를 쓰면 나만 두배로 손해를 본다. 이는 ‘죄수 딜레마’와 비슷하다.&lt;/p&gt;</description></item><item><title>Cuckoo Switch</title><link>https://cychong47.github.io/post/2014/cuckoo-switch/</link><pubDate>Sun, 09 Nov 2014 08:48:38 +0900</pubDate><guid>https://cychong47.github.io/post/2014/cuckoo-switch/</guid><description>&lt;p&gt;Cuckoo 알고리즘을 사용하여 Flow lookup과 flow update 성능을 높힌 것과 DPDK를 이용하여 패킷 처리 성능을 높힌 것&lt;/p&gt;
&lt;p&gt;출처 : &lt;a href="https://www.cs.cmu.edu/~binfan/papers/conext13_cuckooswitch.pdf"&gt;Scalable, High Performance Ethernet Forwarding with CuckooSwitch&lt;/a&gt;&lt;/p&gt;
&lt;h2 id="dpdk"&gt;DPDK&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;DPDK를 이용한 IO 성능 개선한 것 외에 특이한 것은 없음.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="cuckoo-hashing"&gt;Cuckoo hashing&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;대개 FIB update를 위해 RCU(Read Copy Update)를 사용함. 이 경우 완전한 정보를 갖는 additional entry가 필요&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;수정된 cuckoo algorithm을 기반으로 한 flow table 사용&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Basic Cuckoo hashing&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;ensures 50% table space utilization&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;4-way associative hash table has 95% utilization&lt;/p&gt;</description></item><item><title>내게 권한이 있다면</title><link>https://cychong47.github.io/post/2014/naege-gweonhani-issdamyeon/</link><pubDate>Tue, 14 Oct 2014 14:47:49 +0900</pubDate><guid>https://cychong47.github.io/post/2014/naege-gweonhani-issdamyeon/</guid><description>&lt;ol&gt;
&lt;li&gt;우선 할 것은 모든 과제의 진행상황을 투명하게 볼 수 있는 시스템만들기&lt;/li&gt;
&lt;li&gt;엑셀로 관리하고 있는 정보에 대해 최적의 대안을 찾아 엑셀 사용을 최소화 하기&lt;/li&gt;
&lt;li&gt;파일 서버에 단순히 모으고 있는 자료를 DB화. 적어도 하나의 과제에 관련된 문서를 한눈에 볼 수 있게 하고, 검색이 가능하도록 변경&lt;/li&gt;
&lt;li&gt;File based DB 시스템 대체 방안. 필요하다면 기존 요구사항만 기존 담당자들로부터 받고, 새로운 생각을 가진 사람들에게 대안을 제안하도록&lt;/li&gt;
&lt;li&gt;Code Coverage 100% 같은 비효율적인 업무 없애기&lt;/li&gt;
&lt;li&gt;Inventory 정보 투명화. 어떤 실험 자산을 어떻게 사용하고 있는지, 부서간 공유.&lt;/li&gt;
&lt;li&gt;분야별 정보 공유할 수 있는 공간 만들고, 정보 공유 독려. 무슨무슨 TF니 WG를 만들기 보다 스스로 정보를 공유하도록 만들기(보다 구체적인 방안 필요)&lt;/li&gt;
&lt;li&gt;메일을 통한 정보 공유 최소화. 메일과 같은 휘발성 매체가 아닌(적어도 사내에서는 휘발성이 높음) CMS에 기록해서 이력 관리가 쉽도록&lt;/li&gt;
&lt;li&gt;모든 공유 정보는 CMS에 기록(위키 등)&lt;/li&gt;
&lt;li&gt;Unit Test 강화. 불필요한 코드 삭제 유도&lt;/li&gt;
&lt;li&gt;비현실적이고, 불합리한 무리한 패키지 개발 계획 조정. 1년에 최대 2개만 개발&lt;/li&gt;
&lt;li&gt;SIT단계 이후 진행되는 pre-SIT 같은 바보같은 업무 없앰&lt;/li&gt;
&lt;li&gt;TC 개수 관리 같은 의미없는 숫자기반 관리 지양&lt;/li&gt;
&lt;li&gt;아침 8시 회의 같은 어이없는 회의 금지&lt;/li&gt;
&lt;li&gt;SE Lab 강화.&lt;/li&gt;
&lt;li&gt;모 부서와의 전쟁. 미개하고, 무례하고, 개념없는 놈들.&lt;/li&gt;
&lt;li&gt;비효율적인 문서 작성 기반의 업무 보고 대안 강구.&lt;/li&gt;
&lt;li&gt;부서 혹은 부문 별 wish list 관리. 각 부서는 제기된 요청사항에 대해 검토 후 선정된 결과에 대해 기능 구현/개선. 단 선정 내용에 대해 필히 공유(그렇지 않으면 의미 있는 것보다는 쉬운 것을 선정할 수 있으므로)&lt;/li&gt;
&lt;/ol&gt;</description></item><item><title>나영석 PD</title><link>https://cychong47.github.io/post/2014/nayeongseog-pd/</link><pubDate>Tue, 07 Oct 2014 15:30:34 +0900</pubDate><guid>https://cychong47.github.io/post/2014/nayeongseog-pd/</guid><description>&lt;blockquote&gt;
&lt;p&gt;창의적인 아이디어를 만들기가 쉽지 않을 텐데, 나름의 노하우가 있다면?
후배들에게 ‘아이디어를 좀 내봐, 너 좋은 아이디어 없냐?’ 하는 회의는 의미 없다. 아이디어가 있으면 이미 이야기했을 것이다. 내가 중요하게 생각하는 것은 회의에 참석한 캐릭터의 특성을 파악하는 것이다. ‘저 친구는 어떤 성향인지, 뭘 좋아하고 싫어하는지, 편견이 심한지 그렇지 않은지, 판단은 믿을 만한지’ 등등. 스태프들의 캐릭터를 파악하고 있어야 한다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;멋진데. 이런 게 진정한 관리자의 덕목이 아닐까&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;PD로 일하는 데 도움이 되었던 경험이 있다면?
아무래도 대학 다닐 때 연극했던 경험이 제일 소중하다. 마음 맞는 사람들이 모여서 공통의 목표를 향해 진짜 미친 듯이, 자기의 모든 것을 포기하면서 비등점을 향해 달려 나간다. 그리고 공연이 딱 끝나고 나면 모두 운다. 수십명이 함께. 그 일이 진짜 짜릿하다. ‘내가 하고 싶은 일이 이런 일이구나’라는 걸 그때 처음 느꼈고, 이 비슷한 일이면 아무거나 상관없다는 생각이 들었다. 그래서 시트콤 작가 모집 광고를 보고 지원하기도 했고, 영화사에 조연출로 들어가기도 했다.&lt;/p&gt;</description></item><item><title>Intel SDN/NFV Forum Korea 2014</title><link>https://cychong47.github.io/post/2014/intel-sdnnfv-forum-korea-2014/</link><pubDate>Sun, 28 Sep 2014 14:09:56 +0900</pubDate><guid>https://cychong47.github.io/post/2014/intel-sdnnfv-forum-korea-2014/</guid><description>&lt;p&gt;근태를 처리하지 못해 하루 최소 근무시간인 4시간을 채우고 포럼 장소인 리츠칼튼 호텔로 달려(버스타고) 감. 다행히 오후 세션 시작 시간인 1시 10분 전에 도착했지만 덕분에 점심도 못 먹고 끝날 때까지 있어야 했다. 먹은 거라곤 사탕 몇 개.&lt;/p&gt;
&lt;p&gt;트랙 2개인데, 다른 쪽 트랙에서도 듣고 싶은 게 있었지만 트랙 1을 끝까지 들었다.&lt;/p&gt;
&lt;h2 id="quanta"&gt;Quanta&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Taiwan Company&lt;/li&gt;
&lt;li&gt;CPU와 switch 를 상호 선택할 수 있도록 함.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="상용-스위치-칩-사용"&gt;상용 스위치 칩 사용&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Intel Alta and RRC(w/ Aricent OS)
&lt;ul&gt;
&lt;li&gt;Intel ONS&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Broadcom Trident and Tomahawk&lt;/li&gt;
&lt;li&gt;Cavium Xpliant&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="다양한--cpu-사용-가능"&gt;다양한 CPU 사용 가능&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Intel, Freescale, Cavium, Broadcom(XLP)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="oce-onieopen-network-install-environment"&gt;OCE, ONIE(Open Network Install Environment)&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Fetch Network OS from the booter(boot loader -&amp;gt; ONIE -&amp;gt; fetch network OS)&lt;/li&gt;
&lt;li&gt;Similar to loadable OS&lt;/li&gt;
&lt;li&gt;표준 I/F가 있다고 하네.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://opencompute.org"&gt;http://opencompute.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://opencomputeproject.github.io/onie/docs/overview/index.html"&gt;ONIE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/natmorris/onie-open-network-install-environment-osdc-2014-netways-berlin"&gt;Slideshare&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="open-network-linux"&gt;Open Network Linux&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Linux distribution for &amp;ldquo;bare metal&amp;rdquo; switches&lt;/li&gt;
&lt;li&gt;Quanta Ubuntu&lt;/li&gt;
&lt;li&gt;ONL is sponsored by BigSwitch&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.opennetlinux.org"&gt;homepage&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="north-bound-if"&gt;North Bound I/F&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;OpenFlow&lt;/li&gt;
&lt;li&gt;RestFul&lt;/li&gt;
&lt;li&gt;OpEN API ???&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="restful-api-in-switch"&gt;Restful API in switch&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Switch provide RestFul API directly.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.returninfinity.com/baremetal.html"&gt;Baremetal OS&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;64-bit OS for x86-64 based computers&lt;/li&gt;
&lt;li&gt;Written in Assembly&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Puppet, Chef
&lt;ul&gt;
&lt;li&gt;Puppet is a tool designed to manage the configuration of Unix-like and MS systems. The user describe system resources and their state, either using Puppet&amp;rsquo;s declarative language or a Ruby DSL.&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.puppetlabs.com"&gt;Puppet&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://wiki.openstack.org/wiki/Puppet-openstack"&gt;Puppet-openstack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://www.getchef.com/check"&gt;Chef&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.slideshare.net/mattray/openstack-deployment-with-chef"&gt;Chef-openstack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.getchef.com/openstack.html"&gt;Chef for OpenStack&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Chef is a systems and clouds infrastructure automation framework that makes it easy servers and applications to any physical, virtual, or cloud location, no matter the size of the infrastructure.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;MLAG(Multi-Chassis Link Aggregation)
&lt;ul&gt;
&lt;li&gt;Extension of LAG up to node-level.&lt;/li&gt;
&lt;li&gt;Not covered by IEEE 802.1AX-2008&lt;/li&gt;
&lt;li&gt;Vendor-specific implementation&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Support OF 1.3&lt;/li&gt;
&lt;li&gt;One customer build their hypersclae datacenter with qunata&amp;rsquo;s h/W and their inhouse OS, but still use ONIE&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="advantech"&gt;Advantech&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;For Enterprise and Telecom market&lt;/li&gt;
&lt;li&gt;All QuickAssist Accelerator support&lt;/li&gt;
&lt;li&gt;Netronome as I/O processor
&lt;ul&gt;
&lt;li&gt;FlowNIC acceleration card&lt;/li&gt;
&lt;li&gt;Flow Processor as Accelerated switch&lt;/li&gt;
&lt;li&gt;NFP-6840 for high-end&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Use 6wind solution&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="nec-nfv-commercial-ready-solution"&gt;NEC NFV Commercial Ready solution&lt;/h2&gt;
&lt;h3 id="nec"&gt;NEC&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;R&amp;amp;D on Virtualization from 2009&lt;/li&gt;
&lt;li&gt;National POC&lt;/li&gt;
&lt;li&gt;500K Subscribers POC(VoLTE)&lt;/li&gt;
&lt;li&gt;투자 비용은 mobile network이 가장 크게 증가함.&lt;/li&gt;
&lt;li&gt;동시에 data revenue의 증가도 가장 큼.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="how-to-reduce-tco"&gt;How to reduce TCO&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;virtualization based resource utilization&lt;/li&gt;
&lt;li&gt;Programmable scalable reliable network&lt;/li&gt;
&lt;li&gt;Flexible automated configuration&lt;/li&gt;
&lt;li&gt;centralized control &amp;amp; management&lt;/li&gt;
&lt;li&gt;Average 39%(CAPEX + OPEX)
&lt;ul&gt;
&lt;li&gt;CAPEX 28% - New feature&lt;/li&gt;
&lt;li&gt;OPEX System Upgrade 89% reduction&lt;/li&gt;
&lt;li&gt;OPEX Floor Site rental 66%&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id="component"&gt;Component&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Redhat or HP for OS and hypervisor&lt;/li&gt;
&lt;li&gt;HP or Dell&lt;/li&gt;
&lt;li&gt;Intel DPDK, NIC&lt;/li&gt;
&lt;li&gt;OpenStack&lt;/li&gt;
&lt;li&gt;Shift from ATCA NF to COTS NF&lt;/li&gt;
&lt;li&gt;M2M Service Platform over NFV
&lt;ul&gt;
&lt;li&gt;CONNEXIVE Platofrm(virtualized platform) for M2M Services&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="pluribus"&gt;Pluribus&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://pluribusnetworks.com"&gt;http://pluribusnetworks.com&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Startup from 2010&lt;/li&gt;
&lt;li&gt;Pretty interesting&lt;/li&gt;
&lt;li&gt;Netvisor and Server-switch architecture&lt;/li&gt;
&lt;li&gt;H/W is from advantech for some product&lt;/li&gt;
&lt;li&gt;Utilize many open-sources
&lt;ul&gt;
&lt;li&gt;ISC Internet Switch consortium&lt;/li&gt;
&lt;li&gt;Quagga&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Convert legacy designed switch to server based based design
&lt;ul&gt;
&lt;li&gt;Legacy switch use proprietary chip and small control processor&lt;/li&gt;
&lt;li&gt;Server use powerful CPU for control processor and commercial NIC&lt;/li&gt;
&lt;li&gt;Switch chip is used to replace NIC&lt;/li&gt;
&lt;li&gt;Switch chip을 PCIe를 통해 CPU에 직접 연결. DMA를 통해 직접 스위치 내부 테이블을 제어.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Netvisor cover multiple boxes -&lt;/li&gt;
&lt;li&gt;illumos container???
&lt;ul&gt;
&lt;li&gt;illumos is a free and open-source Unix OS derived from the OpenSolaris&lt;/li&gt;
&lt;li&gt;&lt;a href="http://illumos.org"&gt;http://illumos.org&lt;/a&gt; or wiki.illumos.org&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bhyve hypervisor - 30x faster than KVM?
&lt;ul&gt;
&lt;li&gt;BSD hypervisor&lt;/li&gt;
&lt;li&gt;&lt;a href="http://hbyve.org"&gt;http://hbyve.org&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Runs FreeBSD 9+, OpenBSD and Linux guests&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Fabric Cluster - build standard based ethernet fabric as &lt;strong&gt;ONE logical switch&lt;/strong&gt;&lt;/li&gt;
&lt;li&gt;Time Machine analytics
&lt;ul&gt;
&lt;li&gt;Can track of flows on a specific time period in the past&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Netvisor Fabric-Connect&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="brocade"&gt;Brocade&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Last night(14/9/23), announce brocade controller&lt;/li&gt;
&lt;li&gt;AWS 계정을 이용하면 demo를 직접 사용해 볼 수 있다고&lt;/li&gt;
&lt;li&gt;Linear performance as the number of cores are increased while other&amp;rsquo;s performance is saturated&lt;/li&gt;
&lt;li&gt;Yahoo Japan use Brocade VCS fabric for hadoop environment.&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>DPDK on VirtualBox</title><link>https://cychong47.github.io/post/2014/dpdk-on-virtualbox/</link><pubDate>Tue, 23 Sep 2014 15:37:21 +0900</pubDate><guid>https://cychong47.github.io/post/2014/dpdk-on-virtualbox/</guid><description>&lt;h1 id="virtualbox에-dpdk-설치하기"&gt;VirtualBox에 DPDK 설치하기&lt;/h1&gt;
&lt;p&gt;&lt;a href="http://plvision.eu/blog/deploying-intel-dpdk-in-oracle-virtualbox/#"&gt;참고&lt;/a&gt;&lt;/p&gt;
&lt;h1 id="virtualbox-설치하기"&gt;VirtualBox 설치하기&lt;/h1&gt;
&lt;p&gt;통상적인 절차대로 VirtualBox를 설치하고, Ubuntu 14.04 LTS 설치한다. DPDK는 32bit와 64bit를 모두 지원하지만 64비트를 사용하는 것이 좋다. Application에 따라 많은 양의 Memory를 사용할 수도 있으므로.&lt;/p&gt;
&lt;h2 id="nic-카드-추가"&gt;NIC 카드 추가&lt;/h2&gt;
&lt;p&gt;VirtualBox가 지원하는 NIC에 Intel 82540EM과 82545EM이 있다. 둘 다 DPDK에서 지원하는 1G NIC이다. 이 중에서 82545EM 카드를 2개 추가한다.&lt;/p&gt;
&lt;p&gt;VirtualBox의 Guest OS를 종료시킨 상태에서 환경 설정에서 &lt;code&gt;Network &amp;gt; Adapter&lt;/code&gt; 항목에서 Adapter 2, Adapter 3를 활성화시킨다.&lt;/p&gt;
&lt;p&gt;그 결과 총 3개의 NIC이 설치되었다.&lt;/p&gt;</description></item><item><title>(펌) 머리속 정리법 10가지</title><link>https://cychong47.github.io/post/2014/peom-meorisog-jeongribeob-10gaji/</link><pubDate>Wed, 10 Sep 2014 14:55:07 +0900</pubDate><guid>https://cychong47.github.io/post/2014/peom-meorisog-jeongribeob-10gaji/</guid><description>&lt;ol&gt;
&lt;li&gt;휴식을 취하라&lt;/li&gt;
&lt;li&gt;다양한 활동에 대해 각각의 컴퓨터 모니터를 설치하라.&lt;/li&gt;
&lt;li&gt;종이로 된 할 일 목록을 사용하라&lt;/li&gt;
&lt;li&gt;한 이메일을 복수의 카테고리로 분류하라.&lt;/li&gt;
&lt;li&gt;필요할 때는 통째로 없애라.&lt;/li&gt;
&lt;li&gt;간단한 업무와 장기 프로젝트를 위한 시간을 따로 지정하라.&lt;/li&gt;
&lt;li&gt;결정을 내릴 때 그 가치보다 더 많은 시간을 들이지 말라&lt;/li&gt;
&lt;li&gt;잠을 자라. 직장에서 낮잠을 자라.&lt;/li&gt;
&lt;li&gt;지나치게 정리하지 말라&lt;/li&gt;
&lt;li&gt;일은 직장에 두고 와라.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;출처 : &lt;a href="http://kr.wsj.com/posts/2014/08/22/%EC%A0%95%EB%B3%B4-%EA%B3%BC%EB%8B%A4%EC%9D%98-%EC%8B%9C%EB%8C%80-%EB%A8%B8%EB%A6%BF%EC%86%8D-%EC%A0%95%EB%A6%AC%EB%B2%95-10%EA%B0%80%EC%A7%80/"&gt;정보 과다의 시대, 머릿속 정리법 10가지&lt;/a&gt;&lt;/p&gt;</description></item><item><title>Time Machine backup</title><link>https://cychong47.github.io/post/2014/time-machine-backup/</link><pubDate>Wed, 10 Sep 2014 13:40:43 +0900</pubDate><guid>https://cychong47.github.io/post/2014/time-machine-backup/</guid><description>&lt;p&gt;&lt;img src="https://cychong47.github.io/images/2014/Sep/TimeMachine-Backup-20140910.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;추가 해야 할 내용&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;MovingCastle에 대한 추가 백업?&lt;/li&gt;
&lt;li&gt;혹은 Mini 2011을 이중 백업.&lt;/li&gt;
&lt;li&gt;Wordpress Blog 내용만 추가로 백업 필요.&lt;/li&gt;
&lt;li&gt;Ghost Blog 추가 백업&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>초보적인 실수를 반복한다고 구박하지만</title><link>https://cychong47.github.io/post/2014/cobojeogin-silsureul-banboghandago-gubaghajiman/</link><pubDate>Mon, 08 Sep 2014 09:12:34 +0900</pubDate><guid>https://cychong47.github.io/post/2014/cobojeogin-silsureul-banboghandago-gubaghajiman/</guid><description>&lt;p&gt;초보적인 실수를 반복한다고 구박하지만,&lt;br&gt;
자기들은 기본적인 패키지 운영도 못하면서 누굴 구박하는지. 조직간 알력 해결도 못하면서. 같은 일을 서로 더 힘들게 하는 문화를 만들어 놓고서.&lt;br&gt;
매일 같이 비상이다 위기다 라고 협박만 하면서.&lt;br&gt;
잘못된 일정 따위는 사과하지 않으면서.&lt;br&gt;
특정 부서의 오기로 만들어진 과제 일정 차질에 대해서는 아무 말도 안하면서.&lt;br&gt;
뭐가 잘났다고.&lt;/p&gt;</description></item><item><title>The Pragmatic Programmer</title><link>https://cychong47.github.io/post/2014/the-pragmatic-programmer/</link><pubDate>Mon, 08 Sep 2014 08:48:49 +0900</pubDate><guid>https://cychong47.github.io/post/2014/the-pragmatic-programmer/</guid><description>&lt;h3 id="tpp-3-provide-options-dont-make-lame-excuses"&gt;TPP 3. Provide Options, Don&amp;rsquo;t make Lame excuses&lt;/h3&gt;
&lt;p&gt;검토 결과 부정적일 때, 그냥 안된다고 하지말고 대안을 같이 제시하자. &amp;ldquo;이거 해 봤어?&amp;rdquo; &amp;ldquo;이거 고려했어&amp;rdquo; 같이 나올 수 있는 질문에 대해 미리 고민하고 대응할 것. 여기서 대응이란 질문에 대한 답을 제시할 수 있도록 미리 준비하라는 것. 실제로 고려해 보고, 실제로 시도해보고 나서 할 수 있으면 최고.&lt;/p&gt;
&lt;p&gt;무조건 안된다고 하지 말고, 대안을 제시하자. 안된다고 말하기 보다는 그 문제를 해결하기 위해 뭘 할 수 있는 지 제시하자.&lt;/p&gt;</description></item><item><title>Synology + Webdav + Devonthink</title><link>https://cychong47.github.io/post/2014/synology-webdav-devonthink/</link><pubDate>Sat, 06 Sep 2014 15:39:33 +0900</pubDate><guid>https://cychong47.github.io/post/2014/synology-webdav-devonthink/</guid><description>&lt;p&gt;우선 Synology NAS에서 webdav를 켜는 건 기본이고&lt;br&gt;
&lt;img src="https://cychong47.github.io/images/2014/Sep/Synology_webdav.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;Devonthink의 Sync tab에서 타입을 webdav로 하면 아래와 같은 입력 창이 나오는데 여기에 서버 주소 등 필요한 정보를 적으면 된다. 이때 path는 user name으로 로그인했을 때 기준으로 하면 됨. 즉 Full path를 적으면 되는데 처음 입력할 때는 &lt;code&gt;/home/Documents/Devonthink&lt;/code&gt;로 입력했는데 나중에 다시 보면 저렇게 바뀌어 있다.&lt;br&gt;
&lt;img src="https://cychong47.github.io/images/2014/Sep/Devonthink_webdav.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;이제 두 대의 맥을 이렇게 운영하련다.&lt;br&gt;
&lt;img src="https://cychong47.github.io/images/2014/Sep/Devonthink-sync.png" alt=""&gt;&lt;/p&gt;
&lt;p&gt;동기화 관련 참고자료&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://jmjeong.com/use-devonthink-at-home-and-work/"&gt;Dropbox를 사용할 때 동시에 여러 Mac에서 동기화된 DB를 열지 않도록 하는 applescript&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://binnyon.tistory.com/78"&gt;Devonthink DB가 깨졌을 때 복구하는 방법&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://namsieon.com/1473"&gt;웹페이지 일부만 스크랩하는 방법&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>(펌) 삶의 목적</title><link>https://cychong47.github.io/post/2014/peom-salmyi-mogjeog/</link><pubDate>Wed, 03 Sep 2014 04:21:54 +0900</pubDate><guid>https://cychong47.github.io/post/2014/peom-salmyi-mogjeog/</guid><description>&lt;blockquote&gt;
&lt;p&gt;&amp;lt;인생의 목적&amp;gt;&lt;/p&gt;
&lt;p&gt;우리는 살기 위해, 그리고 경험하기 위해 태어났습니다.&lt;/p&gt;
&lt;p&gt;바쁜 일정 속에서도 스스로에게 되뇌이곤 합니다.&lt;/p&gt;
&lt;p&gt;인간은 일하기 위해 태어난 것이 아니라, 인생이라는 선물을 즐기기 위해 태어났다고. 우리는 일하기 위해 존재하는 것이 아니라, 조금 더 세상을 나아지게 하기 위해 여기 있다고.&lt;/p&gt;
&lt;p&gt;당신이 당신의 인생을 일에 올인하고 있다면, 분명 후회의 순간이 찾아옵니다.&lt;/p&gt;
&lt;p&gt;당신이 직장에서 성공하고 있다면 더더욱 항상 기억해야합니다. 우리는 삶을 위해 삽니다. 그리고 일은 절대 삶보다 중요할 수 없습니다.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;인생의 목적은 삶을 사는 것이지 일하는 게 아니다. 일도 삶의 일부로 해석해야지, 일이 목적이 되어서는 안된다는&lt;/p&gt;</description></item><item><title>(펌) 20 Life Lessons Everyone Can Master By The Age 40</title><link>https://cychong47.github.io/post/2014/peom-20-life-lessons-everyone-can-master-by-the-age-40/</link><pubDate>Sun, 24 Aug 2014 12:17:51 +0900</pubDate><guid>https://cychong47.github.io/post/2014/peom-20-life-lessons-everyone-can-master-by-the-age-40/</guid><description>&lt;p&gt;출처 : &lt;a href="http://www.lifehack.org/articles/communication/20-life-lessons-everyone-can-master-the-age-40.html?ref=tp&amp;amp;n=2"&gt;20 Life Lessons Everyone Can Master By The Age 40&lt;/a&gt;&lt;/p&gt;
&lt;h4 id="1-everything-will-be-okay-and-if-its-not-its-certainly-not-the-end-of-the-world"&gt;1. Everything will be okay, and if it’s not, it’s certainly not the end of the world.&lt;/h4&gt;
&lt;p&gt;내가 포기할 때 실패한 끝난 거다.&lt;/p&gt;
&lt;h4 id="2-find-what-you-love-and-own-it"&gt;2. Find what you love and own it!&lt;/h4&gt;
&lt;h4 id="3-dont-fear-mistakes"&gt;3. Don’t fear mistakes.&lt;/h4&gt;
&lt;h4 id="4-you-deserve-respect"&gt;4. You deserve respect.&lt;/h4&gt;
&lt;h4 id="5-romance-is-not-the-same-as-love"&gt;5. Romance is NOT the same as love.&lt;/h4&gt;
&lt;h4 id="6-its-never-too-late-to-live-a-life-that-makes-you-proud"&gt;6. It’s never too late to live a life that makes you proud.&lt;/h4&gt;
&lt;h4 id="7-remain-calm-in-all-situations"&gt;7. Remain calm in all situations.&lt;/h4&gt;
&lt;h4 id="8-you-win-some-you-lose-some"&gt;8. You win some, you lose some.&lt;/h4&gt;
&lt;h4 id="9-the-term-overnight-success-really-means-2-to-10-years"&gt;9. The term ‘Overnight Success’ really means 2 to 10 years.&lt;/h4&gt;
&lt;blockquote&gt;
&lt;p&gt;Everything takes time and the best things in life are earned through consistency and patience. This doesn’t necessarily mean that if you just work hard, you’ll have everything you ever wanted. There’s definitely such a thing as working smarter. In order to discover ways to work ‘smarter’ it takes years of experience.&lt;/p&gt;</description></item><item><title>(펌) 어떻게 하면 더 나은 소프트웨어를 만들 수 있을까?</title><link>https://cychong47.github.io/post/2014/peom-eoddeohge-hamyeon-deo-naeun-sopeuteuweeoreul-mandeul-su-isseulgga/</link><pubDate>Sun, 24 Aug 2014 10:55:06 +0900</pubDate><guid>https://cychong47.github.io/post/2014/peom-eoddeohge-hamyeon-deo-naeun-sopeuteuweeoreul-mandeul-su-isseulgga/</guid><description>&lt;p&gt;어떻게 하면 더 나은 소프트웨어를 만들 수 있을까? – 인터뷰 시리즈 part 1, Fernando Jimenez Moreno와 함께&lt;/p&gt;
&lt;p&gt;출처 : &lt;a href="http://hacks.mozilla.or.kr/2014/08/how-can-we-write-better-software-interview-series-part-1/"&gt;http://hacks.mozilla.or.kr/2014/08/how-can-we-write-better-software-interview-series-part-1/&lt;/a&gt;&lt;br&gt;
영문 원본 : &lt;a href="https://hacks.mozilla.org/2014/07/how-can-we-write-better-software-interview-series-part-1/"&gt;https://hacks.mozilla.org/2014/07/how-can-we-write-better-software-interview-series-part-1/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Telefonica에서 근무하고 있으면서 MozillaOS 개발에 참여하고 있는 사람의 인터뷰 기사&lt;br&gt;
Code Reviewer 업무를 함에 있어 참고할 만한 좋은 내용이 많아 옮겨 본다.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;우리가 모질라와 함께 일한 것은 2011년으로 거슬러 올라갑니다. 두 회사 모두에게 잘 맞는 공통된 작업 절차를 찾기까지 꽤 많은 시간이 걸렸습니다. 제말은, 우리는 텔코(telco) 문화에서 일하던 사람입니다. 텔코 문화에서는 대부분의 작업들이 폐쇄적이고 비밀입니다. 이것은 모질라의 공개적이고 투명한 문화와는 반대죠.&lt;/p&gt;</description></item><item><title>SDN expert group 세미나 - Play with DPDK</title><link>https://cychong47.github.io/post/2014/sdn-expert-group-semina-play-with-dpdk/</link><pubDate>Thu, 21 Aug 2014 12:11:18 +0900</pubDate><guid>https://cychong47.github.io/post/2014/sdn-expert-group-semina-play-with-dpdk/</guid><description>&lt;h1 id="세미나-내용"&gt;세미나 내용&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Controller &amp;ndash;(OpenFlow)&amp;ndash; ovs-switchd &amp;ndash;(netlink)&amp;ndash; Datapath&lt;/li&gt;
&lt;li&gt;Datapath is in the kernel space&lt;/li&gt;
&lt;li&gt;OVDK move the kernel based OVS to user space.
&lt;ul&gt;
&lt;li&gt;ovs-switched talk to OVDK with UDP&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;기존 OVDK는 port별 task handler(각각 별도의 core에서 동작)
&lt;ul&gt;
&lt;li&gt;그 결과 많은 core 필요&lt;/li&gt;
&lt;li&gt;WR 이야기처럼 VM간 혹은 VM과 외부와의 통신을 담당하는 OVS용으로 많은 core를 사용하면 실제로 VM이 사용할 수 있는 core 개수가 줄어들어 문제&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;virtIO 사용시 VM에서 동작하는 application이 kernel stack의 필요한 경우 결국 OVDK와 VM내 커널 space간 copy가 필요함
&lt;ul&gt;
&lt;li&gt;최신 버전에서는 VM에서도 KNI based virtIO를 이용하도록 개선함. 확인 필요&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Rainbow platform
&lt;ul&gt;
&lt;li&gt;DPDK의 log library를 이용해서 외부 log server로 실시간으로 메시지 보냄. sFlow나 netFlow는 실시간이 아니라고. 음..&lt;/li&gt;
&lt;li&gt;log library에 대한 확인 필요. 쓸만하면 log library를 별도로 만들지 말고 이걸 사용하는 것도 좋을 듯.&lt;/li&gt;
&lt;li&gt;log server는 NoSQL을 이용한 분석 서버라고&lt;/li&gt;
&lt;li&gt;분석 서버에서 실시간 분석해서 의심되는 패킷을 받으면 OVS들에 명령을 내려 별도 DPI 서버로 경유하도록 해서 쉽게 Service Chaining 을 구현할 수 있다.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;DPDK를 접한 지는 오래 되었지만 초반에 한번 플랫폼이 정리된 후 크게 개선하지 못했다. 딱히 요구사항이 없어서 나름 안정된 걸 건드릴 이유를 찾지 못한 것이 표면적인 이유지만, 실은 기능 혹은 성능 개선을 해서 얻는 실질적인 장점이 별로 없어서.&lt;/p&gt;</description></item><item><title>차라리 혼자 생각할 시간 가져라</title><link>https://cychong47.github.io/post/2014/carari-honja-saenggaghal-sigan-gajyeora/</link><pubDate>Wed, 20 Aug 2014 14:43:09 +0900</pubDate><guid>https://cychong47.github.io/post/2014/carari-honja-saenggaghal-sigan-gajyeora/</guid><description>&lt;blockquote&gt;
&lt;p&gt;그러나 생각하기 위한 시간을 내는 것으로는 부족해 보인다. 자신의 믿음에 부합되는 정보만을 찾는 편향이 인간에게는 있다고 했다. 혼자 생각한다고 그런 편향에서 벗어날 수 있을 것 같지는 않다.&lt;br&gt;
▶그렇다. 아파트 가격이 오를 것이라고 믿으면 그에 부합되는 증거만을 보려고 한다. 반대되는 증거는 보려 하지 않는다. 그렇기 때문에 우리는 우리 곁에 &amp;lsquo;최고 이의 제기자(chief challenger officer)&amp;lsquo;를 둬야 한다. 내 의견에 이의를 제기하는 사람 말이다. 리더일수록 더욱 그래야 한다.&lt;br&gt;
에릭 슈밋 구글 회장의 회의 진행 방식도 좋다. 그는 회의에서 미심쩍은 얼굴을 하고 있는 사람을 찾는다. 그리고는 “당신의 견해는 무엇이냐”고 묻는다. 이는 자신과 다른 의견을 청취하기 위해서다.&lt;/p&gt;</description></item><item><title>종교의 차별된 사랑</title><link>https://cychong47.github.io/post/2014/jonggyoyi-cabyeoldoen-sarang/</link><pubDate>Sat, 16 Aug 2014 14:30:53 +0900</pubDate><guid>https://cychong47.github.io/post/2014/jonggyoyi-cabyeoldoen-sarang/</guid><description>&lt;p&gt;회사라고 치자. 계열사에 회장이 떴다. 회장이 계열사 직원들로부터 소원수리를 받았다. 심각한 문제다. 그런데 사장들이 뻔히 문제점을 알고 있으면서 무시하고 아무 일도 안하고 있는 거다. 그러면 어떻게 될까?&lt;/p&gt;
&lt;p&gt;당장 질책이 떨어지고, 문제의 경중의 따라 사장이 짤릴 수도 있다.&lt;/p&gt;
&lt;p&gt;지금 교황이 방한한 일을 그렇게 보면 과대해석일까?&lt;/p&gt;
&lt;p&gt;교황은 와서 세월호 등을 포함해 대한민국에서 소외되고 있는 많은 사람들을 만난다. 바쁜 그 며칠간의 일정이 그렇다. 하지만 일년 내내 대한민국에 있는 추기경이라는 사람은 뭐가 그리 바쁜 지 힘없고 고통받는 이들을 외면해 왔다. 도대체 뭐에 써먹는 추기경인지. 자기가 챙겨야 할 고통받는 사람들은 최소한 재산이 넉넉하거나 권력이 있어야 하나보다.&lt;/p&gt;</description></item><item><title>SDN의 진정한 가치</title><link>https://cychong47.github.io/post/2014/sdnyi-jinjeonghan-gaci/</link><pubDate>Fri, 15 Aug 2014 13:04:09 +0900</pubDate><guid>https://cychong47.github.io/post/2014/sdnyi-jinjeonghan-gaci/</guid><description>&lt;p&gt;SDN이 주로 operator 입장에서 비용 절감, 관리 용이, 혁신 용이, 자동화(programmable)의 장점을 이야기하는데 NTT DOCOMO는 실제로 이런 방법을 통해 사용자에게 제공할 수 있는 가치(end-user value)에 대해 이야기한다.&lt;/p&gt;
&lt;p&gt;조금 과장하면 앞 선 장점 나열은 비-애플인 듯하고, 후자는 애플의 발표인 듯. 단순히 Operator에게 비용뿐만 아니라 인지도를 올릴 수 있는 방법을 제시한다는 면에서 참 느낌이 다르다.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.6windblog.com/sdn-helping-real-people-in-a-real-crisis/"&gt;SDN: Helping Real People in a Real Crisis | 6WIND Blog&lt;/a&gt;&lt;/p&gt;</description></item><item><title>DPI &amp; Traffic analysis in networks based on NFV and SDN</title><link>https://cychong47.github.io/post/2014/dpi-traffic-analysis-in-networks-based-on-nfv-and-sdn/</link><pubDate>Tue, 12 Aug 2014 15:10:23 +0900</pubDate><guid>https://cychong47.github.io/post/2014/dpi-traffic-analysis-in-networks-based-on-nfv-and-sdn/</guid><description>&lt;h2 id="출처"&gt;출처&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.qosmos.com/wp-content/uploads/2014/01/Heavy-Reading_Qosmos_DPI-SDN-NFV_White-Paper_Jan2014.pdf"&gt;Heavy-ReadingQosmosDPI-SDN-NFVWhite-PaperJan2014.pdf&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;2014년 1월&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="전반적인-내용"&gt;전반적인 내용&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The largest use case (by number of vendors citing it) is service assurance for QoS/QoE; the second largest is policy control (PCEF), which we believe is the largest use case by volume&lt;/li&gt;
&lt;li&gt;Half of respondents said that encryption of protocols is reducing the effectiveness of DPI . Packet metric analysis (heuristics) was identified as the main remedy - packet size, spacing, frequency&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="dpi-용도"&gt;DPI 용도&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Service Awarence (QoS, QoE)가 가장 높음(60%)&lt;/li&gt;
&lt;li&gt;Policy Control(PCEF)도 비슷&lt;/li&gt;
&lt;li&gt;3GPP TDF 기능. 표준 내용 확인 필요&lt;/li&gt;
&lt;li&gt;Service Analystics system도 높은 관심
&lt;ul&gt;
&lt;li&gt;가입자 수준에서 분석하려는 의도가 많아짐.&lt;/li&gt;
&lt;li&gt;Customer prefrences and load/characteristics&lt;/li&gt;
&lt;li&gt;Real-time analytics&lt;/li&gt;
&lt;li&gt;Real-time subscriber data analysis and RAN congenstion control at cell level&lt;/li&gt;
&lt;li&gt;Pose hard challenge to engineers.&lt;/li&gt;
&lt;li&gt;Accurate real-time detection of application and protocols is essential.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;대부분의 대형 벤더가 자체 DPI 솔류션 확보. 작은 업체일 수록 third-party solution 사용
&lt;ul&gt;
&lt;li&gt;대략 응답자의 30%가 third-party solution 사용하나, 대형 벤더의 응답율이 높아 실제 사용률은 더 높을 듯&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;암호화된 패킷 때문에 Packet Metric analysis(size, spacing, frequency) 등 DPI 이상의 기술로 해결해 가야 함.&lt;/li&gt;
&lt;li&gt;NFV는 새로운 제품 개발의 H/W 및 S/W 설계에 영향을 줄거라는 의견이 92%로 지배적.
&lt;ul&gt;
&lt;li&gt;그렇지만, 가상화 할때 고려하는 H/W platform으로는 COTS만큼 자체 H/W를 고려하고 있음&lt;/li&gt;
&lt;li&gt;아직 어떤 것이 H/W platform인지 맞는 것인지 확신이 없기 때문에 그만큼 보수적으로 자체 플랫폼을 고려하는 것으로 분석됨.&lt;/li&gt;
&lt;li&gt;그렇지만 appliance-selling(H/W) 모델에서 usage-selling(Software license) 모델로 이동할 거라는 예상&lt;/li&gt;
&lt;li&gt;NFV와 표준화된 third-party component의 출현은 점점 outsouring 비율을 높일 거라는 예상.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="nfvsdn을-고려한-dpi"&gt;NFV/SDN을 고려한 DPI&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;DPI는 Switch node의 Hypervisor(OVS), VM 내(DPI VNFC-Virtual Network Function) 그리고 Controller에 위치할 것으로 보임
&lt;ul&gt;
&lt;li&gt;VM내 DPI(DPI VNFC)는 ETSI ISG(July 2013)에서 정리한 공식 use case중 하나.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</description></item><item><title>OpenDataPlane</title><link>https://cychong47.github.io/post/2014/opendataplane/</link><pubDate>Sat, 24 May 2014 14:15:25 +0900</pubDate><guid>https://cychong47.github.io/post/2014/opendataplane/</guid><description>&lt;p&gt;Network 장비를 만드는 방법 중 가장 흔한 방법이 Networking에 최적화된 processor를 제공하는 업체로부터 processor를 구입하고, 그 processor와 함께 제공되는 SDK를 사용하는 것이다. 그러다보니 특정 업체의 processor를 위해 만든 S/W를 다른 processor로 포팅하는 경우 많은 부분을 수정해야 하는 경우가 많다.&lt;/p&gt;
&lt;p&gt;당연한 이야기지만, 특정 processor에 종속적인 부분은 해당 processor가 제공하는 H/W accelerator 를 이용하는 코드나 해당 processor의 특성에 맞게 설계된 구조 등이다. 다른 processor로 포팅하는 경우 전자의 경우는 새로운 processor에서 대응되는 API등이 제공되면 비교적 쉽게 변경할 수 있다. 후자의 경우는 좀 더 근본적인 문제라 다른 차원의 문제가 되지만. 예를 들어 특정 업체는 processor 차원에서 packet ordering을 제공하는 경우가 있다. 그러므로 이 경우 multi-core 환경에서 여러 core들은 서로 다른 core가 같은 flow(순서가 보장되어야 하는 패킷들의 흐름)에 속하는 패킷을 처리하는 지 신경 쓸 필요없이 패킷을 처리하고, 패킷을 최종적으로 전송할 때만 순서를 맞추는 작업을 H/W 기능을 이용해서 수행하면 된다. 반면 이런 H/W 기능이 없는 경우 근본적으로 flow별로 서로 다른 core에게 전달되도록 하는 등의 고려가 필요할 수 있다.&lt;/p&gt;</description></item><item><title>Welcome to Ghost</title><link>https://cychong47.github.io/post/2014/welcome-to-ghost-2/</link><pubDate>Sat, 10 May 2014 03:45:21 +0900</pubDate><guid>https://cychong47.github.io/post/2014/welcome-to-ghost-2/</guid><description>&lt;p&gt;You&amp;rsquo;re live! Nice. We&amp;rsquo;ve put together a little post to introduce you to the Ghost editor and get you started. You can manage your content by signing in to the admin area at &lt;code&gt;&amp;lt;your blog URL&amp;gt;/ghost/&lt;/code&gt;. When you arrive, you can select this post from a list on the left and see a preview of it on the right. Click the little pencil icon at the top of the preview to edit this post and read the next section!&lt;/p&gt;</description></item></channel></rss>