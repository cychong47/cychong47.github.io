<!doctype html><html lang=en-us><head><meta http-equiv=X-Clacks-Overhead content="GNU Terry Pratchett"><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><title>Upgrade kubernetes to 1.16.1 | Keep calm and Write something</title><meta name=title content="Upgrade kubernetes to 1.16.1"><meta name=description content='cychong@mini1:~/work/ghost-with-helm-x$ sudo apt update
[sudo] password for cychong:
Ign:2 http://dl.google.com/linux/chrome/deb stable InRelease
Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease
Hit:4 https://download.docker.com/linux/ubuntu bionic InRelease
Hit:5 http://dl.google.com/linux/chrome/deb stable Release
Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]
Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease
Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]
Get:9 http://archive.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]
Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 DEP-11 Metadata [295 kB]
Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 48x48 Icons [73.8 kB]
Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 64x64 Icons [147 kB]
Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 DEP-11 Metadata [254 kB]
Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 48x48 Icons [197 kB]
Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 64x64 Icons [453 kB]
Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 DEP-11 Metadata [2468 B]
Get:17 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 DEP-11 Metadata [7916 B]
Get:18 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 Packages [526 kB]
Get:19 http://archive.ubuntu.com/ubuntu bionic-security/main Translation-en [176 kB]
Get:20 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 DEP-11 Metadata [38.5 kB]
Get:21 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 48x48 Icons [17.6 kB]
Get:22 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 64x64 Icons [41.5 kB]
Get:23 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [611 kB]
Get:24 http://archive.ubuntu.com/ubuntu bionic-security/universe Translation-en [203 kB]
Get:25 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 DEP-11 Metadata [42.2 kB]
Get:26 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 48x48 Icons [16.4 kB]
Get:27 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 64x64 Icons [111 kB]
Get:28 http://archive.ubuntu.com/ubuntu bionic-security/multiverse amd64 DEP-11 Metadata [2464 B]
Fetched 3467 kB in 27s (128 kB/s)
Reading package lists... Done
Building dependency tree
Reading state information... Done
41 packages can be upgraded. Run &#39;apt list --upgradable&#39; to see them.

cychong@mini1:~/work/ghost-with-helm-x$ sudo apt-cache policy kubeadm
kubeadm:
  Installed: 1.15.3-00
  Candidate: 1.16.1-00
cychong@mini1:~/work/ghost-with-helm-x$  sudo apt-get install -y kubeadm=1.16.1-00 && sudo apt-mark hold kubeadm
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following package was automatically installed and is no longer required:
  libllvm7
Use &#39;sudo apt autoremove&#39; to remove it.
The following packages will be upgraded:
  kubeadm
1 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.
Need to get 8764 kB of archives.
After this operation, 4062 kB of additional disk space will be used.
Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.16.1-00 [8764 kB]
Fetched 8764 kB in 6s (1489 kB/s)
(Reading database ... 237550 files and directories currently installed.)
Preparing to unpack .../kubeadm_1.16.1-00_amd64.deb ...
Unpacking kubeadm (1.16.1-00) over (1.15.3-00) ...
Setting up kubeadm (1.16.1-00) ...
kubeadm set on hold.

cychong@mini1:~/work/ghost-with-helm-x$ kubeadm version
kubeadm version: &amp;version.Info{Major:"1", Minor:"16", GitVersion:"v1.16.1", GitCommit:"d647ddbd755faf07169599a625faf302ffc34458", GitTreeState:"clean", BuildDate:"2019-10-02T16:58:27Z", GoVersion:"go1.12.10", Compiler:"gc", Platform:"linux/amd64"}

cychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade plan
[upgrade/config] Making sure the configuration is correct:
[upgrade/config] Reading configuration from the cluster...
[upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;
[preflight] Running pre-flight checks.
[upgrade] Making sure the cluster is healthy:
[upgrade] Fetching available versions to upgrade to
[upgrade/versions] Cluster version: v1.15.3
[upgrade/versions] kubeadm version: v1.16.1
[upgrade/versions] Latest stable version: v1.16.1
[upgrade/versions] Latest version in the v1.15 series: v1.15.4

Components that must be upgraded manually after you have upgraded the control plane with &#39;kubeadm upgrade apply&#39;:
COMPONENT   CURRENT       AVAILABLE
Kubelet     1 x v1.15.3   v1.15.4

Upgrade to the latest version in the v1.15 series:

COMPONENT            CURRENT   AVAILABLE
API Server           v1.15.3   v1.15.4
Controller Manager   v1.15.3   v1.15.4
Scheduler            v1.15.3   v1.15.4
Kube Proxy           v1.15.3   v1.15.4
CoreDNS              1.3.1     1.6.2
Etcd                 3.3.10    3.3.10

You can now apply the upgrade by executing the following command:

	kubeadm upgrade apply v1.15.4

_____________________________________________________________________

Components that must be upgraded manually after you have upgraded the control plane with &#39;kubeadm upgrade apply&#39;:
COMPONENT   CURRENT       AVAILABLE
Kubelet     1 x v1.15.3   v1.16.1

Upgrade to the latest stable version:

COMPONENT            CURRENT   AVAILABLE
API Server           v1.15.3   v1.16.1
Controller Manager   v1.15.3   v1.16.1
Scheduler            v1.15.3   v1.16.1
Kube Proxy           v1.15.3   v1.16.1
CoreDNS              1.3.1     1.6.2
Etcd                 3.3.10    3.3.15-0

You can now apply the upgrade by executing the following command:

	kubeadm upgrade apply v1.16.1

_____________________________________________________________________
failed
cychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade apply v1.16.1
[upgrade/config] Making sure the configuration is correct:
[upgrade/config] Reading configuration from the cluster...
[upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;
[preflight] Running pre-flight checks.
[upgrade] Making sure the cluster is healthy:
[upgrade/version] You have chosen to change the cluster version to "v1.16.1"
[upgrade/versions] Cluster version: v1.15.3
[upgrade/versions] kubeadm version: v1.16.1
[upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y
[upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd]
[upgrade/prepull] Prepulling image for component etcd.
[upgrade/prepull] Prepulling image for component kube-controller-manager.
[upgrade/prepull] Prepulling image for component kube-apiserver.
[upgrade/prepull] Prepulling image for component kube-scheduler.
[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler
[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver
[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager
[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver


[upgrade/prepull] Failed prepulled the images for the control plane components error: the prepull operation timed out
To see the stack trace of this error execute with --v=5 or higher
retry
cychong@mini1:~$ sudo kubeadm upgrade apply v1.16.1
[sudo] password for cychong:
[upgrade/config] Making sure the configuration is correct:
[upgrade/config] Reading configuration from the cluster...
[upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;
[preflight] Running pre-flight checks.
[upgrade] Making sure the cluster is healthy:
[upgrade/version] You have chosen to change the cluster version to "v1.16.1"
[upgrade/versions] Cluster version: v1.15.3
[upgrade/versions] kubeadm version: v1.16.1
[upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y
[upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd]
[upgrade/prepull] Prepulling image for component etcd.
[upgrade/prepull] Prepulling image for component kube-controller-manager.
[upgrade/prepull] Prepulling image for component kube-scheduler.
[upgrade/prepull] Prepulling image for component kube-apiserver.
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler
[upgrade/prepull] Prepulled image for component kube-apiserver.
[upgrade/prepull] Prepulled image for component etcd.
[upgrade/prepull] Prepulled image for component kube-controller-manager.
[upgrade/prepull] Prepulled image for component kube-scheduler.
[upgrade/prepull] Successfully prepulled the images for all the control plane components
[upgrade/apply] Upgrading your Static Pod-hosted control plane to version "v1.16.1"...
Static pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538
Static pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10
Static pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75
[upgrade/etcd] Upgrading to TLS for etcd
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
[upgrade/staticpods] Preparing for "etcd" upgrade
[upgrade/staticpods] Renewing etcd-server certificate
[upgrade/staticpods] Renewing etcd-peer certificate
[upgrade/staticpods] Renewing etcd-healthcheck-client certificate
[upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/etcd.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/etcd.yaml"
[upgrade/staticpods] Waiting for the kubelet to restart the component
[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: d96090bab45a5dababb3c3015960926b
[apiclient] Found 1 Pods for label selector component=etcd
[upgrade/staticpods] Component "etcd" upgraded successfully!
[upgrade/etcd] Waiting for etcd to become available
[upgrade/staticpods] Writing new Static Pod manifests to "/etc/kubernetes/tmp/kubeadm-upgraded-manifests306281752"
[upgrade/staticpods] Preparing for "kube-apiserver" upgrade
[upgrade/staticpods] Renewing apiserver certificate
[upgrade/staticpods] Renewing apiserver-kubelet-client certificate
[upgrade/staticpods] Renewing front-proxy-client certificate
[upgrade/staticpods] Renewing apiserver-etcd-client certificate
[upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-apiserver.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-apiserver.yaml"
[upgrade/staticpods] Waiting for the kubelet to restart the component
[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)
Static pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538
Static pod: kube-apiserver-mini1 hash: 01800dd11dfbda441372caf7cbf8aa39
[apiclient] Found 1 Pods for label selector component=kube-apiserver
[upgrade/staticpods] Component "kube-apiserver" upgraded successfully!
[upgrade/staticpods] Preparing for "kube-controller-manager" upgrade
[upgrade/staticpods] Renewing controller-manager.conf certificate
[upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-controller-manager.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-controller-manager.yaml"
[upgrade/staticpods] Waiting for the kubelet to restart the component
[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)
Static pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10
Static pod: kube-controller-manager-mini1 hash: e12d193633dcf11f6095d89ee58c45a9
[apiclient] Found 1 Pods for label selector component=kube-controller-manager
[upgrade/staticpods] Component "kube-controller-manager" upgraded successfully!
[upgrade/staticpods] Preparing for "kube-scheduler" upgrade
[upgrade/staticpods] Renewing scheduler.conf certificate
[upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-scheduler.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-scheduler.yaml"
[upgrade/staticpods] Waiting for the kubelet to restart the component
[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)
Static pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75
Static pod: kube-scheduler-mini1 hash: bf9014e67294b0df0bc373fd7024ced7
[apiclient] Found 1 Pods for label selector component=kube-scheduler
[upgrade/staticpods] Component "kube-scheduler" upgraded successfully!
[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
[kubelet] Creating a ConfigMap "kubelet-config-1.16" in namespace kube-system with the configuration for the kubelets in the cluster
[kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.16" ConfigMap in the kube-system namespace
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

[upgrade/successful] SUCCESS! Your cluster was upgraded to "v1.16.1". Enjoy!

[upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven&#39;t already done so.
Upgrade calico from v3.8 to v3.9
kubectl apply -f https://docs.projectcalico.org/v3.9/manifests/calico.yaml
configmap/calico-config unchanged
customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org unchanged
clusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchanged
clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchanged
clusterrole.rbac.authorization.k8s.io/calico-node configured
clusterrolebinding.rbac.authorization.k8s.io/calico-node unchanged
daemonset.apps/calico-node configured
serviceaccount/calico-node unchanged
deployment.apps/calico-kube-controllers configured
serviceaccount/calico-kube-controllers unchanged
앗. 서브넷 변경하는 걸 깜빡'><meta name=keywords content="kubernetes,"><meta property="og:url" content="https://cychong47.github.io/post/2019/upgrade-kubernetes/"><meta property="og:site_name" content="Keep calm and Write something"><meta property="og:title" content="Upgrade kubernetes to 1.16.1"><meta property="og:description" content='cychong@mini1:~/work/ghost-with-helm-x$ sudo apt update [sudo] password for cychong: Ign:2 http://dl.google.com/linux/chrome/deb stable InRelease Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:4 https://download.docker.com/linux/ubuntu bionic InRelease Hit:5 http://dl.google.com/linux/chrome/deb stable Release Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] Get:9 http://archive.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB] Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 DEP-11 Metadata [295 kB] Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 48x48 Icons [73.8 kB] Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 64x64 Icons [147 kB] Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 DEP-11 Metadata [254 kB] Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 48x48 Icons [197 kB] Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 64x64 Icons [453 kB] Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 DEP-11 Metadata [2468 B] Get:17 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 DEP-11 Metadata [7916 B] Get:18 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 Packages [526 kB] Get:19 http://archive.ubuntu.com/ubuntu bionic-security/main Translation-en [176 kB] Get:20 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 DEP-11 Metadata [38.5 kB] Get:21 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 48x48 Icons [17.6 kB] Get:22 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 64x64 Icons [41.5 kB] Get:23 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [611 kB] Get:24 http://archive.ubuntu.com/ubuntu bionic-security/universe Translation-en [203 kB] Get:25 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 DEP-11 Metadata [42.2 kB] Get:26 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 48x48 Icons [16.4 kB] Get:27 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 64x64 Icons [111 kB] Get:28 http://archive.ubuntu.com/ubuntu bionic-security/multiverse amd64 DEP-11 Metadata [2464 B] Fetched 3467 kB in 27s (128 kB/s) Reading package lists... Done Building dependency tree Reading state information... Done 41 packages can be upgraded. Run &#39;apt list --upgradable&#39; to see them. cychong@mini1:~/work/ghost-with-helm-x$ sudo apt-cache policy kubeadm kubeadm: Installed: 1.15.3-00 Candidate: 1.16.1-00 cychong@mini1:~/work/ghost-with-helm-x$ sudo apt-get install -y kubeadm=1.16.1-00 && sudo apt-mark hold kubeadm Reading package lists... Done Building dependency tree Reading state information... Done The following package was automatically installed and is no longer required: libllvm7 Use &#39;sudo apt autoremove&#39; to remove it. The following packages will be upgraded: kubeadm 1 upgraded, 0 newly installed, 0 to remove and 40 not upgraded. Need to get 8764 kB of archives. After this operation, 4062 kB of additional disk space will be used. Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.16.1-00 [8764 kB] Fetched 8764 kB in 6s (1489 kB/s) (Reading database ... 237550 files and directories currently installed.) Preparing to unpack .../kubeadm_1.16.1-00_amd64.deb ... Unpacking kubeadm (1.16.1-00) over (1.15.3-00) ... Setting up kubeadm (1.16.1-00) ... kubeadm set on hold. cychong@mini1:~/work/ghost-with-helm-x$ kubeadm version kubeadm version: &amp;version.Info{Major:"1", Minor:"16", GitVersion:"v1.16.1", GitCommit:"d647ddbd755faf07169599a625faf302ffc34458", GitTreeState:"clean", BuildDate:"2019-10-02T16:58:27Z", GoVersion:"go1.12.10", Compiler:"gc", Platform:"linux/amd64"} cychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade plan [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39; [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade] Fetching available versions to upgrade to [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/versions] Latest stable version: v1.16.1 [upgrade/versions] Latest version in the v1.15 series: v1.15.4 Components that must be upgraded manually after you have upgraded the control plane with &#39;kubeadm upgrade apply&#39;: COMPONENT CURRENT AVAILABLE Kubelet 1 x v1.15.3 v1.15.4 Upgrade to the latest version in the v1.15 series: COMPONENT CURRENT AVAILABLE API Server v1.15.3 v1.15.4 Controller Manager v1.15.3 v1.15.4 Scheduler v1.15.3 v1.15.4 Kube Proxy v1.15.3 v1.15.4 CoreDNS 1.3.1 1.6.2 Etcd 3.3.10 3.3.10 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.15.4 _____________________________________________________________________ Components that must be upgraded manually after you have upgraded the control plane with &#39;kubeadm upgrade apply&#39;: COMPONENT CURRENT AVAILABLE Kubelet 1 x v1.15.3 v1.16.1 Upgrade to the latest stable version: COMPONENT CURRENT AVAILABLE API Server v1.15.3 v1.16.1 Controller Manager v1.15.3 v1.16.1 Scheduler v1.15.3 v1.16.1 Kube Proxy v1.15.3 v1.16.1 CoreDNS 1.3.1 1.6.2 Etcd 3.3.10 3.3.15-0 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.16.1 _____________________________________________________________________ failed cychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade apply v1.16.1 [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39; [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade/version] You have chosen to change the cluster version to "v1.16.1" [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd] [upgrade/prepull] Prepulling image for component etcd. [upgrade/prepull] Prepulling image for component kube-controller-manager. [upgrade/prepull] Prepulling image for component kube-apiserver. [upgrade/prepull] Prepulling image for component kube-scheduler. [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [upgrade/prepull] Failed prepulled the images for the control plane components error: the prepull operation timed out To see the stack trace of this error execute with --v=5 or higher retry cychong@mini1:~$ sudo kubeadm upgrade apply v1.16.1 [sudo] password for cychong: [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39; [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade/version] You have chosen to change the cluster version to "v1.16.1" [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd] [upgrade/prepull] Prepulling image for component etcd. [upgrade/prepull] Prepulling image for component kube-controller-manager. [upgrade/prepull] Prepulling image for component kube-scheduler. [upgrade/prepull] Prepulling image for component kube-apiserver. [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [upgrade/prepull] Prepulled image for component kube-apiserver. [upgrade/prepull] Prepulled image for component etcd. [upgrade/prepull] Prepulled image for component kube-controller-manager. [upgrade/prepull] Prepulled image for component kube-scheduler. [upgrade/prepull] Successfully prepulled the images for all the control plane components [upgrade/apply] Upgrading your Static Pod-hosted control plane to version "v1.16.1"... Static pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538 Static pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10 Static pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75 [upgrade/etcd] Upgrading to TLS for etcd Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa [upgrade/staticpods] Preparing for "etcd" upgrade [upgrade/staticpods] Renewing etcd-server certificate [upgrade/staticpods] Renewing etcd-peer certificate [upgrade/staticpods] Renewing etcd-healthcheck-client certificate [upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/etcd.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/etcd.yaml" [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: d96090bab45a5dababb3c3015960926b [apiclient] Found 1 Pods for label selector component=etcd [upgrade/staticpods] Component "etcd" upgraded successfully! [upgrade/etcd] Waiting for etcd to become available [upgrade/staticpods] Writing new Static Pod manifests to "/etc/kubernetes/tmp/kubeadm-upgraded-manifests306281752" [upgrade/staticpods] Preparing for "kube-apiserver" upgrade [upgrade/staticpods] Renewing apiserver certificate [upgrade/staticpods] Renewing apiserver-kubelet-client certificate [upgrade/staticpods] Renewing front-proxy-client certificate [upgrade/staticpods] Renewing apiserver-etcd-client certificate [upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-apiserver.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-apiserver.yaml" [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538 Static pod: kube-apiserver-mini1 hash: 01800dd11dfbda441372caf7cbf8aa39 [apiclient] Found 1 Pods for label selector component=kube-apiserver [upgrade/staticpods] Component "kube-apiserver" upgraded successfully! [upgrade/staticpods] Preparing for "kube-controller-manager" upgrade [upgrade/staticpods] Renewing controller-manager.conf certificate [upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-controller-manager.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-controller-manager.yaml" [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10 Static pod: kube-controller-manager-mini1 hash: e12d193633dcf11f6095d89ee58c45a9 [apiclient] Found 1 Pods for label selector component=kube-controller-manager [upgrade/staticpods] Component "kube-controller-manager" upgraded successfully! [upgrade/staticpods] Preparing for "kube-scheduler" upgrade [upgrade/staticpods] Renewing scheduler.conf certificate [upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-scheduler.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-scheduler.yaml" [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75 Static pod: kube-scheduler-mini1 hash: bf9014e67294b0df0bc373fd7024ced7 [apiclient] Found 1 Pods for label selector component=kube-scheduler [upgrade/staticpods] Component "kube-scheduler" upgraded successfully! [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace [kubelet] Creating a ConfigMap "kubelet-config-1.16" in namespace kube-system with the configuration for the kubelets in the cluster [kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.16" ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml" [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy [upgrade/successful] SUCCESS! Your cluster was upgraded to "v1.16.1". Enjoy! [upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven&#39;t already done so. Upgrade calico from v3.8 to v3.9 kubectl apply -f https://docs.projectcalico.org/v3.9/manifests/calico.yaml configmap/calico-config unchanged customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org unchanged clusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrole.rbac.authorization.k8s.io/calico-node configured clusterrolebinding.rbac.authorization.k8s.io/calico-node unchanged daemonset.apps/calico-node configured serviceaccount/calico-node unchanged deployment.apps/calico-kube-controllers configured serviceaccount/calico-kube-controllers unchanged 앗. 서브넷 변경하는 걸 깜빡'><meta property="og:locale" content="en_us"><meta property="og:type" content="article"><meta property="article:section" content="post"><meta property="article:published_time" content="2019-10-07T15:37:14+09:00"><meta property="article:modified_time" content="2019-10-07T15:39:18+00:00"><meta property="article:tag" content="Kubernetes"><meta name=twitter:card content="summary"><meta name=twitter:title content="Upgrade kubernetes to 1.16.1"><meta name=twitter:description content='cychong@mini1:~/work/ghost-with-helm-x$ sudo apt update [sudo] password for cychong: Ign:2 http://dl.google.com/linux/chrome/deb stable InRelease Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:4 https://download.docker.com/linux/ubuntu bionic InRelease Hit:5 http://dl.google.com/linux/chrome/deb stable Release Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] Get:9 http://archive.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB] Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 DEP-11 Metadata [295 kB] Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 48x48 Icons [73.8 kB] Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 64x64 Icons [147 kB] Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 DEP-11 Metadata [254 kB] Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 48x48 Icons [197 kB] Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 64x64 Icons [453 kB] Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 DEP-11 Metadata [2468 B] Get:17 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 DEP-11 Metadata [7916 B] Get:18 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 Packages [526 kB] Get:19 http://archive.ubuntu.com/ubuntu bionic-security/main Translation-en [176 kB] Get:20 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 DEP-11 Metadata [38.5 kB] Get:21 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 48x48 Icons [17.6 kB] Get:22 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 64x64 Icons [41.5 kB] Get:23 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [611 kB] Get:24 http://archive.ubuntu.com/ubuntu bionic-security/universe Translation-en [203 kB] Get:25 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 DEP-11 Metadata [42.2 kB] Get:26 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 48x48 Icons [16.4 kB] Get:27 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 64x64 Icons [111 kB] Get:28 http://archive.ubuntu.com/ubuntu bionic-security/multiverse amd64 DEP-11 Metadata [2464 B] Fetched 3467 kB in 27s (128 kB/s) Reading package lists... Done Building dependency tree Reading state information... Done 41 packages can be upgraded. Run &#39;apt list --upgradable&#39; to see them. cychong@mini1:~/work/ghost-with-helm-x$ sudo apt-cache policy kubeadm kubeadm: Installed: 1.15.3-00 Candidate: 1.16.1-00 cychong@mini1:~/work/ghost-with-helm-x$ sudo apt-get install -y kubeadm=1.16.1-00 && sudo apt-mark hold kubeadm Reading package lists... Done Building dependency tree Reading state information... Done The following package was automatically installed and is no longer required: libllvm7 Use &#39;sudo apt autoremove&#39; to remove it. The following packages will be upgraded: kubeadm 1 upgraded, 0 newly installed, 0 to remove and 40 not upgraded. Need to get 8764 kB of archives. After this operation, 4062 kB of additional disk space will be used. Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.16.1-00 [8764 kB] Fetched 8764 kB in 6s (1489 kB/s) (Reading database ... 237550 files and directories currently installed.) Preparing to unpack .../kubeadm_1.16.1-00_amd64.deb ... Unpacking kubeadm (1.16.1-00) over (1.15.3-00) ... Setting up kubeadm (1.16.1-00) ... kubeadm set on hold. cychong@mini1:~/work/ghost-with-helm-x$ kubeadm version kubeadm version: &amp;version.Info{Major:"1", Minor:"16", GitVersion:"v1.16.1", GitCommit:"d647ddbd755faf07169599a625faf302ffc34458", GitTreeState:"clean", BuildDate:"2019-10-02T16:58:27Z", GoVersion:"go1.12.10", Compiler:"gc", Platform:"linux/amd64"} cychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade plan [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39; [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade] Fetching available versions to upgrade to [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/versions] Latest stable version: v1.16.1 [upgrade/versions] Latest version in the v1.15 series: v1.15.4 Components that must be upgraded manually after you have upgraded the control plane with &#39;kubeadm upgrade apply&#39;: COMPONENT CURRENT AVAILABLE Kubelet 1 x v1.15.3 v1.15.4 Upgrade to the latest version in the v1.15 series: COMPONENT CURRENT AVAILABLE API Server v1.15.3 v1.15.4 Controller Manager v1.15.3 v1.15.4 Scheduler v1.15.3 v1.15.4 Kube Proxy v1.15.3 v1.15.4 CoreDNS 1.3.1 1.6.2 Etcd 3.3.10 3.3.10 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.15.4 _____________________________________________________________________ Components that must be upgraded manually after you have upgraded the control plane with &#39;kubeadm upgrade apply&#39;: COMPONENT CURRENT AVAILABLE Kubelet 1 x v1.15.3 v1.16.1 Upgrade to the latest stable version: COMPONENT CURRENT AVAILABLE API Server v1.15.3 v1.16.1 Controller Manager v1.15.3 v1.16.1 Scheduler v1.15.3 v1.16.1 Kube Proxy v1.15.3 v1.16.1 CoreDNS 1.3.1 1.6.2 Etcd 3.3.10 3.3.15-0 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.16.1 _____________________________________________________________________ failed cychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade apply v1.16.1 [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39; [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade/version] You have chosen to change the cluster version to "v1.16.1" [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd] [upgrade/prepull] Prepulling image for component etcd. [upgrade/prepull] Prepulling image for component kube-controller-manager. [upgrade/prepull] Prepulling image for component kube-apiserver. [upgrade/prepull] Prepulling image for component kube-scheduler. [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [upgrade/prepull] Failed prepulled the images for the control plane components error: the prepull operation timed out To see the stack trace of this error execute with --v=5 or higher retry cychong@mini1:~$ sudo kubeadm upgrade apply v1.16.1 [sudo] password for cychong: [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39; [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade/version] You have chosen to change the cluster version to "v1.16.1" [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd] [upgrade/prepull] Prepulling image for component etcd. [upgrade/prepull] Prepulling image for component kube-controller-manager. [upgrade/prepull] Prepulling image for component kube-scheduler. [upgrade/prepull] Prepulling image for component kube-apiserver. [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [upgrade/prepull] Prepulled image for component kube-apiserver. [upgrade/prepull] Prepulled image for component etcd. [upgrade/prepull] Prepulled image for component kube-controller-manager. [upgrade/prepull] Prepulled image for component kube-scheduler. [upgrade/prepull] Successfully prepulled the images for all the control plane components [upgrade/apply] Upgrading your Static Pod-hosted control plane to version "v1.16.1"... Static pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538 Static pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10 Static pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75 [upgrade/etcd] Upgrading to TLS for etcd Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa [upgrade/staticpods] Preparing for "etcd" upgrade [upgrade/staticpods] Renewing etcd-server certificate [upgrade/staticpods] Renewing etcd-peer certificate [upgrade/staticpods] Renewing etcd-healthcheck-client certificate [upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/etcd.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/etcd.yaml" [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: d96090bab45a5dababb3c3015960926b [apiclient] Found 1 Pods for label selector component=etcd [upgrade/staticpods] Component "etcd" upgraded successfully! [upgrade/etcd] Waiting for etcd to become available [upgrade/staticpods] Writing new Static Pod manifests to "/etc/kubernetes/tmp/kubeadm-upgraded-manifests306281752" [upgrade/staticpods] Preparing for "kube-apiserver" upgrade [upgrade/staticpods] Renewing apiserver certificate [upgrade/staticpods] Renewing apiserver-kubelet-client certificate [upgrade/staticpods] Renewing front-proxy-client certificate [upgrade/staticpods] Renewing apiserver-etcd-client certificate [upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-apiserver.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-apiserver.yaml" [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538 Static pod: kube-apiserver-mini1 hash: 01800dd11dfbda441372caf7cbf8aa39 [apiclient] Found 1 Pods for label selector component=kube-apiserver [upgrade/staticpods] Component "kube-apiserver" upgraded successfully! [upgrade/staticpods] Preparing for "kube-controller-manager" upgrade [upgrade/staticpods] Renewing controller-manager.conf certificate [upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-controller-manager.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-controller-manager.yaml" [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10 Static pod: kube-controller-manager-mini1 hash: e12d193633dcf11f6095d89ee58c45a9 [apiclient] Found 1 Pods for label selector component=kube-controller-manager [upgrade/staticpods] Component "kube-controller-manager" upgraded successfully! [upgrade/staticpods] Preparing for "kube-scheduler" upgrade [upgrade/staticpods] Renewing scheduler.conf certificate [upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-scheduler.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-scheduler.yaml" [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75 Static pod: kube-scheduler-mini1 hash: bf9014e67294b0df0bc373fd7024ced7 [apiclient] Found 1 Pods for label selector component=kube-scheduler [upgrade/staticpods] Component "kube-scheduler" upgraded successfully! [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace [kubelet] Creating a ConfigMap "kubelet-config-1.16" in namespace kube-system with the configuration for the kubelets in the cluster [kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.16" ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml" [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy [upgrade/successful] SUCCESS! Your cluster was upgraded to "v1.16.1". Enjoy! [upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven&#39;t already done so. Upgrade calico from v3.8 to v3.9 kubectl apply -f https://docs.projectcalico.org/v3.9/manifests/calico.yaml configmap/calico-config unchanged customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org unchanged clusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrole.rbac.authorization.k8s.io/calico-node configured clusterrolebinding.rbac.authorization.k8s.io/calico-node unchanged daemonset.apps/calico-node configured serviceaccount/calico-node unchanged deployment.apps/calico-kube-controllers configured serviceaccount/calico-kube-controllers unchanged 앗. 서브넷 변경하는 걸 깜빡'><meta itemprop=name content="Upgrade kubernetes to 1.16.1"><meta itemprop=description content='cychong@mini1:~/work/ghost-with-helm-x$ sudo apt update [sudo] password for cychong: Ign:2 http://dl.google.com/linux/chrome/deb stable InRelease Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease Hit:4 https://download.docker.com/linux/ubuntu bionic InRelease Hit:5 http://dl.google.com/linux/chrome/deb stable Release Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB] Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB] Get:9 http://archive.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB] Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 DEP-11 Metadata [295 kB] Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 48x48 Icons [73.8 kB] Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 64x64 Icons [147 kB] Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 DEP-11 Metadata [254 kB] Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 48x48 Icons [197 kB] Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 64x64 Icons [453 kB] Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 DEP-11 Metadata [2468 B] Get:17 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 DEP-11 Metadata [7916 B] Get:18 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 Packages [526 kB] Get:19 http://archive.ubuntu.com/ubuntu bionic-security/main Translation-en [176 kB] Get:20 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 DEP-11 Metadata [38.5 kB] Get:21 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 48x48 Icons [17.6 kB] Get:22 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 64x64 Icons [41.5 kB] Get:23 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [611 kB] Get:24 http://archive.ubuntu.com/ubuntu bionic-security/universe Translation-en [203 kB] Get:25 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 DEP-11 Metadata [42.2 kB] Get:26 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 48x48 Icons [16.4 kB] Get:27 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 64x64 Icons [111 kB] Get:28 http://archive.ubuntu.com/ubuntu bionic-security/multiverse amd64 DEP-11 Metadata [2464 B] Fetched 3467 kB in 27s (128 kB/s) Reading package lists... Done Building dependency tree Reading state information... Done 41 packages can be upgraded. Run &#39;apt list --upgradable&#39; to see them. cychong@mini1:~/work/ghost-with-helm-x$ sudo apt-cache policy kubeadm kubeadm: Installed: 1.15.3-00 Candidate: 1.16.1-00 cychong@mini1:~/work/ghost-with-helm-x$ sudo apt-get install -y kubeadm=1.16.1-00 && sudo apt-mark hold kubeadm Reading package lists... Done Building dependency tree Reading state information... Done The following package was automatically installed and is no longer required: libllvm7 Use &#39;sudo apt autoremove&#39; to remove it. The following packages will be upgraded: kubeadm 1 upgraded, 0 newly installed, 0 to remove and 40 not upgraded. Need to get 8764 kB of archives. After this operation, 4062 kB of additional disk space will be used. Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.16.1-00 [8764 kB] Fetched 8764 kB in 6s (1489 kB/s) (Reading database ... 237550 files and directories currently installed.) Preparing to unpack .../kubeadm_1.16.1-00_amd64.deb ... Unpacking kubeadm (1.16.1-00) over (1.15.3-00) ... Setting up kubeadm (1.16.1-00) ... kubeadm set on hold. cychong@mini1:~/work/ghost-with-helm-x$ kubeadm version kubeadm version: &amp;version.Info{Major:"1", Minor:"16", GitVersion:"v1.16.1", GitCommit:"d647ddbd755faf07169599a625faf302ffc34458", GitTreeState:"clean", BuildDate:"2019-10-02T16:58:27Z", GoVersion:"go1.12.10", Compiler:"gc", Platform:"linux/amd64"} cychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade plan [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39; [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade] Fetching available versions to upgrade to [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/versions] Latest stable version: v1.16.1 [upgrade/versions] Latest version in the v1.15 series: v1.15.4 Components that must be upgraded manually after you have upgraded the control plane with &#39;kubeadm upgrade apply&#39;: COMPONENT CURRENT AVAILABLE Kubelet 1 x v1.15.3 v1.15.4 Upgrade to the latest version in the v1.15 series: COMPONENT CURRENT AVAILABLE API Server v1.15.3 v1.15.4 Controller Manager v1.15.3 v1.15.4 Scheduler v1.15.3 v1.15.4 Kube Proxy v1.15.3 v1.15.4 CoreDNS 1.3.1 1.6.2 Etcd 3.3.10 3.3.10 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.15.4 _____________________________________________________________________ Components that must be upgraded manually after you have upgraded the control plane with &#39;kubeadm upgrade apply&#39;: COMPONENT CURRENT AVAILABLE Kubelet 1 x v1.15.3 v1.16.1 Upgrade to the latest stable version: COMPONENT CURRENT AVAILABLE API Server v1.15.3 v1.16.1 Controller Manager v1.15.3 v1.16.1 Scheduler v1.15.3 v1.16.1 Kube Proxy v1.15.3 v1.16.1 CoreDNS 1.3.1 1.6.2 Etcd 3.3.10 3.3.15-0 You can now apply the upgrade by executing the following command: kubeadm upgrade apply v1.16.1 _____________________________________________________________________ failed cychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade apply v1.16.1 [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39; [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade/version] You have chosen to change the cluster version to "v1.16.1" [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd] [upgrade/prepull] Prepulling image for component etcd. [upgrade/prepull] Prepulling image for component kube-controller-manager. [upgrade/prepull] Prepulling image for component kube-apiserver. [upgrade/prepull] Prepulling image for component kube-scheduler. [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [upgrade/prepull] Failed prepulled the images for the control plane components error: the prepull operation timed out To see the stack trace of this error execute with --v=5 or higher retry cychong@mini1:~$ sudo kubeadm upgrade apply v1.16.1 [sudo] password for cychong: [upgrade/config] Making sure the configuration is correct: [upgrade/config] Reading configuration from the cluster... [upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39; [preflight] Running pre-flight checks. [upgrade] Making sure the cluster is healthy: [upgrade/version] You have chosen to change the cluster version to "v1.16.1" [upgrade/versions] Cluster version: v1.15.3 [upgrade/versions] kubeadm version: v1.16.1 [upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y [upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd] [upgrade/prepull] Prepulling image for component etcd. [upgrade/prepull] Prepulling image for component kube-controller-manager. [upgrade/prepull] Prepulling image for component kube-scheduler. [upgrade/prepull] Prepulling image for component kube-apiserver. [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager [apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler [upgrade/prepull] Prepulled image for component kube-apiserver. [upgrade/prepull] Prepulled image for component etcd. [upgrade/prepull] Prepulled image for component kube-controller-manager. [upgrade/prepull] Prepulled image for component kube-scheduler. [upgrade/prepull] Successfully prepulled the images for all the control plane components [upgrade/apply] Upgrading your Static Pod-hosted control plane to version "v1.16.1"... Static pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538 Static pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10 Static pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75 [upgrade/etcd] Upgrading to TLS for etcd Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa [upgrade/staticpods] Preparing for "etcd" upgrade [upgrade/staticpods] Renewing etcd-server certificate [upgrade/staticpods] Renewing etcd-peer certificate [upgrade/staticpods] Renewing etcd-healthcheck-client certificate [upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/etcd.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/etcd.yaml" [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa Static pod: etcd-mini1 hash: d96090bab45a5dababb3c3015960926b [apiclient] Found 1 Pods for label selector component=etcd [upgrade/staticpods] Component "etcd" upgraded successfully! [upgrade/etcd] Waiting for etcd to become available [upgrade/staticpods] Writing new Static Pod manifests to "/etc/kubernetes/tmp/kubeadm-upgraded-manifests306281752" [upgrade/staticpods] Preparing for "kube-apiserver" upgrade [upgrade/staticpods] Renewing apiserver certificate [upgrade/staticpods] Renewing apiserver-kubelet-client certificate [upgrade/staticpods] Renewing front-proxy-client certificate [upgrade/staticpods] Renewing apiserver-etcd-client certificate [upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-apiserver.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-apiserver.yaml" [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538 Static pod: kube-apiserver-mini1 hash: 01800dd11dfbda441372caf7cbf8aa39 [apiclient] Found 1 Pods for label selector component=kube-apiserver [upgrade/staticpods] Component "kube-apiserver" upgraded successfully! [upgrade/staticpods] Preparing for "kube-controller-manager" upgrade [upgrade/staticpods] Renewing controller-manager.conf certificate [upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-controller-manager.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-controller-manager.yaml" [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10 Static pod: kube-controller-manager-mini1 hash: e12d193633dcf11f6095d89ee58c45a9 [apiclient] Found 1 Pods for label selector component=kube-controller-manager [upgrade/staticpods] Component "kube-controller-manager" upgraded successfully! [upgrade/staticpods] Preparing for "kube-scheduler" upgrade [upgrade/staticpods] Renewing scheduler.conf certificate [upgrade/staticpods] Moved new manifest to "/etc/kubernetes/manifests/kube-scheduler.yaml" and backed up old manifest to "/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-scheduler.yaml" [upgrade/staticpods] Waiting for the kubelet to restart the component [upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s) Static pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75 Static pod: kube-scheduler-mini1 hash: bf9014e67294b0df0bc373fd7024ced7 [apiclient] Found 1 Pods for label selector component=kube-scheduler [upgrade/staticpods] Component "kube-scheduler" upgraded successfully! [upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace [kubelet] Creating a ConfigMap "kubelet-config-1.16" in namespace kube-system with the configuration for the kubelets in the cluster [kubelet-start] Downloading configuration for the kubelet from the "kubelet-config-1.16" ConfigMap in the kube-system namespace [kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml" [bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials [bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token [bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster [addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy [upgrade/successful] SUCCESS! Your cluster was upgraded to "v1.16.1". Enjoy! [upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven&#39;t already done so. Upgrade calico from v3.8 to v3.9 kubectl apply -f https://docs.projectcalico.org/v3.9/manifests/calico.yaml configmap/calico-config unchanged customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org unchanged customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org unchanged clusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchanged clusterrole.rbac.authorization.k8s.io/calico-node configured clusterrolebinding.rbac.authorization.k8s.io/calico-node unchanged daemonset.apps/calico-node configured serviceaccount/calico-node unchanged deployment.apps/calico-kube-controllers configured serviceaccount/calico-kube-controllers unchanged 앗. 서브넷 변경하는 걸 깜빡'><meta itemprop=datePublished content="2019-10-07T15:37:14+09:00"><meta itemprop=dateModified content="2019-10-07T15:39:18+00:00"><meta itemprop=wordCount content="1863"><meta itemprop=keywords content="Kubernetes"><meta name=referrer content="no-referrer-when-downgrade"><style>:root{--width:720px;--font-main:Verdana, sans-serif;--font-secondary:Verdana, sans-serif;--font-scale:1em;--background-color:#fafafa;--heading-color:#222;--text-color:#444;--link-color:#3273dc;--visited-color:#8b6fcb;--blockquote-color:#222}@media(prefers-color-scheme:dark){:root{--background-color:#fafafa;--heading-color:#222;--text-color:#444;--link-color:#3273dc;--visited-color:#8b6fcb;--blockquote-color:#222}}body{font-family:var(--font-secondary);font-size:var(--font-scale);margin:auto;padding:20px;max-width:var(--width);text-align:left;background-color:var(--background-color);word-wrap:break-word;overflow-wrap:break-word;line-height:1.5;color:var(--text-color)}h1,h2,h3,h4,h5,h6{font-family:var(--font-main);color:var(--heading-color)}a{color:var(--link-color);cursor:pointer;text-decoration:none}a:hover{text-decoration:underline}nav a{margin-right:8px}strong,b{color:var(--heading-color)}button{margin:0;cursor:pointer}time{font-family:monospace;font-style:normal;font-size:15px}main{line-height:1.6}table{width:100%}hr{border:0;border-top:1px dashed}img{max-width:100%}code{font-family:monospace;padding:2px;border-radius:3px}blockquote{border-left:1px solid #999;color:var(--blockquote-color);padding-left:20px;font-style:italic}footer{padding:25px 0;text-align:center}.title:hover{text-decoration:none}.title h1{font-size:1.5em}.inline{width:auto!important}.highlight,.code{border-radius:3px;margin-block-start:1em;margin-block-end:1em;overflow-x:auto}ul.blog-posts{list-style-type:none;padding:unset}ul.blog-posts li{display:flex}ul.blog-posts li span{flex:0 0 130px}ul.blog-posts li a:visited{color:var(--visited-color)}</style></head><body><header><a href=/ class=title><h2>Keep calm and Write something</h2></a><nav><a href=/post/>Post</a>
<a href=/page/>Page</a>
<a href=/series/>Series</a>
<a href=/tags/>Tag</a>
<a href=/archive/>Archive</a>
<a href=/search/>Search</a></nav></header><main><content><pre tabindex=0><code>cychong@mini1:~/work/ghost-with-helm-x$ sudo apt update
[sudo] password for cychong:
Ign:2 http://dl.google.com/linux/chrome/deb stable InRelease
Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease
Hit:4 https://download.docker.com/linux/ubuntu bionic InRelease
Hit:5 http://dl.google.com/linux/chrome/deb stable Release
Get:6 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]
Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease
Get:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]
Get:9 http://archive.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]
Get:10 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 DEP-11 Metadata [295 kB]
Get:11 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 48x48 Icons [73.8 kB]
Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/main DEP-11 64x64 Icons [147 kB]
Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 DEP-11 Metadata [254 kB]
Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 48x48 Icons [197 kB]
Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe DEP-11 64x64 Icons [453 kB]
Get:16 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 DEP-11 Metadata [2468 B]
Get:17 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 DEP-11 Metadata [7916 B]
Get:18 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 Packages [526 kB]
Get:19 http://archive.ubuntu.com/ubuntu bionic-security/main Translation-en [176 kB]
Get:20 http://archive.ubuntu.com/ubuntu bionic-security/main amd64 DEP-11 Metadata [38.5 kB]
Get:21 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 48x48 Icons [17.6 kB]
Get:22 http://archive.ubuntu.com/ubuntu bionic-security/main DEP-11 64x64 Icons [41.5 kB]
Get:23 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [611 kB]
Get:24 http://archive.ubuntu.com/ubuntu bionic-security/universe Translation-en [203 kB]
Get:25 http://archive.ubuntu.com/ubuntu bionic-security/universe amd64 DEP-11 Metadata [42.2 kB]
Get:26 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 48x48 Icons [16.4 kB]
Get:27 http://archive.ubuntu.com/ubuntu bionic-security/universe DEP-11 64x64 Icons [111 kB]
Get:28 http://archive.ubuntu.com/ubuntu bionic-security/multiverse amd64 DEP-11 Metadata [2464 B]
Fetched 3467 kB in 27s (128 kB/s)
Reading package lists... Done
Building dependency tree
Reading state information... Done
41 packages can be upgraded. Run &#39;apt list --upgradable&#39; to see them.

cychong@mini1:~/work/ghost-with-helm-x$ sudo apt-cache policy kubeadm
kubeadm:
  Installed: 1.15.3-00
  Candidate: 1.16.1-00
</code></pre><pre tabindex=0><code>cychong@mini1:~/work/ghost-with-helm-x$  sudo apt-get install -y kubeadm=1.16.1-00 &amp;&amp; sudo apt-mark hold kubeadm
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following package was automatically installed and is no longer required:
  libllvm7
Use &#39;sudo apt autoremove&#39; to remove it.
The following packages will be upgraded:
  kubeadm
1 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.
Need to get 8764 kB of archives.
After this operation, 4062 kB of additional disk space will be used.
Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubeadm amd64 1.16.1-00 [8764 kB]
Fetched 8764 kB in 6s (1489 kB/s)
(Reading database ... 237550 files and directories currently installed.)
Preparing to unpack .../kubeadm_1.16.1-00_amd64.deb ...
Unpacking kubeadm (1.16.1-00) over (1.15.3-00) ...
Setting up kubeadm (1.16.1-00) ...
kubeadm set on hold.

cychong@mini1:~/work/ghost-with-helm-x$ kubeadm version
kubeadm version: &amp;version.Info{Major:&#34;1&#34;, Minor:&#34;16&#34;, GitVersion:&#34;v1.16.1&#34;, GitCommit:&#34;d647ddbd755faf07169599a625faf302ffc34458&#34;, GitTreeState:&#34;clean&#34;, BuildDate:&#34;2019-10-02T16:58:27Z&#34;, GoVersion:&#34;go1.12.10&#34;, Compiler:&#34;gc&#34;, Platform:&#34;linux/amd64&#34;}

cychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade plan
[upgrade/config] Making sure the configuration is correct:
[upgrade/config] Reading configuration from the cluster...
[upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;
[preflight] Running pre-flight checks.
[upgrade] Making sure the cluster is healthy:
[upgrade] Fetching available versions to upgrade to
[upgrade/versions] Cluster version: v1.15.3
[upgrade/versions] kubeadm version: v1.16.1
[upgrade/versions] Latest stable version: v1.16.1
[upgrade/versions] Latest version in the v1.15 series: v1.15.4

Components that must be upgraded manually after you have upgraded the control plane with &#39;kubeadm upgrade apply&#39;:
COMPONENT   CURRENT       AVAILABLE
Kubelet     1 x v1.15.3   v1.15.4

Upgrade to the latest version in the v1.15 series:

COMPONENT            CURRENT   AVAILABLE
API Server           v1.15.3   v1.15.4
Controller Manager   v1.15.3   v1.15.4
Scheduler            v1.15.3   v1.15.4
Kube Proxy           v1.15.3   v1.15.4
CoreDNS              1.3.1     1.6.2
Etcd                 3.3.10    3.3.10

You can now apply the upgrade by executing the following command:

	kubeadm upgrade apply v1.15.4

_____________________________________________________________________

Components that must be upgraded manually after you have upgraded the control plane with &#39;kubeadm upgrade apply&#39;:
COMPONENT   CURRENT       AVAILABLE
Kubelet     1 x v1.15.3   v1.16.1

Upgrade to the latest stable version:

COMPONENT            CURRENT   AVAILABLE
API Server           v1.15.3   v1.16.1
Controller Manager   v1.15.3   v1.16.1
Scheduler            v1.15.3   v1.16.1
Kube Proxy           v1.15.3   v1.16.1
CoreDNS              1.3.1     1.6.2
Etcd                 3.3.10    3.3.15-0

You can now apply the upgrade by executing the following command:

	kubeadm upgrade apply v1.16.1

_____________________________________________________________________
</code></pre><h3 id=failed>failed</h3><pre tabindex=0><code>cychong@mini1:~/work/ghost-with-helm-x$ sudo kubeadm upgrade apply v1.16.1
[upgrade/config] Making sure the configuration is correct:
[upgrade/config] Reading configuration from the cluster...
[upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;
[preflight] Running pre-flight checks.
[upgrade] Making sure the cluster is healthy:
[upgrade/version] You have chosen to change the cluster version to &#34;v1.16.1&#34;
[upgrade/versions] Cluster version: v1.15.3
[upgrade/versions] kubeadm version: v1.16.1
[upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y
[upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd]
[upgrade/prepull] Prepulling image for component etcd.
[upgrade/prepull] Prepulling image for component kube-controller-manager.
[upgrade/prepull] Prepulling image for component kube-apiserver.
[upgrade/prepull] Prepulling image for component kube-scheduler.
[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler
[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver
[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager
[apiclient] Found 0 Pods for label selector k8s-app=upgrade-prepull-etcd
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver


[upgrade/prepull] Failed prepulled the images for the control plane components error: the prepull operation timed out
To see the stack trace of this error execute with --v=5 or higher
</code></pre><h3 id=retry>retry</h3><pre tabindex=0><code>cychong@mini1:~$ sudo kubeadm upgrade apply v1.16.1
[sudo] password for cychong:
[upgrade/config] Making sure the configuration is correct:
[upgrade/config] Reading configuration from the cluster...
[upgrade/config] FYI: You can look at this config file with &#39;kubectl -n kube-system get cm kubeadm-config -oyaml&#39;
[preflight] Running pre-flight checks.
[upgrade] Making sure the cluster is healthy:
[upgrade/version] You have chosen to change the cluster version to &#34;v1.16.1&#34;
[upgrade/versions] Cluster version: v1.15.3
[upgrade/versions] kubeadm version: v1.16.1
[upgrade/confirm] Are you sure you want to proceed with the upgrade? [y/N]: y
[upgrade/prepull] Will prepull images for components [kube-apiserver kube-controller-manager kube-scheduler etcd]
[upgrade/prepull] Prepulling image for component etcd.
[upgrade/prepull] Prepulling image for component kube-controller-manager.
[upgrade/prepull] Prepulling image for component kube-scheduler.
[upgrade/prepull] Prepulling image for component kube-apiserver.
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-apiserver
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-etcd
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-controller-manager
[apiclient] Found 1 Pods for label selector k8s-app=upgrade-prepull-kube-scheduler
[upgrade/prepull] Prepulled image for component kube-apiserver.
[upgrade/prepull] Prepulled image for component etcd.
[upgrade/prepull] Prepulled image for component kube-controller-manager.
[upgrade/prepull] Prepulled image for component kube-scheduler.
[upgrade/prepull] Successfully prepulled the images for all the control plane components
[upgrade/apply] Upgrading your Static Pod-hosted control plane to version &#34;v1.16.1&#34;...
Static pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538
Static pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10
Static pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75
[upgrade/etcd] Upgrading to TLS for etcd
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
[upgrade/staticpods] Preparing for &#34;etcd&#34; upgrade
[upgrade/staticpods] Renewing etcd-server certificate
[upgrade/staticpods] Renewing etcd-peer certificate
[upgrade/staticpods] Renewing etcd-healthcheck-client certificate
[upgrade/staticpods] Moved new manifest to &#34;/etc/kubernetes/manifests/etcd.yaml&#34; and backed up old manifest to &#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/etcd.yaml&#34;
[upgrade/staticpods] Waiting for the kubelet to restart the component
[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: 71542aaa2829652ef14b22098a4b46aa
Static pod: etcd-mini1 hash: d96090bab45a5dababb3c3015960926b
[apiclient] Found 1 Pods for label selector component=etcd
[upgrade/staticpods] Component &#34;etcd&#34; upgraded successfully!
[upgrade/etcd] Waiting for etcd to become available
[upgrade/staticpods] Writing new Static Pod manifests to &#34;/etc/kubernetes/tmp/kubeadm-upgraded-manifests306281752&#34;
[upgrade/staticpods] Preparing for &#34;kube-apiserver&#34; upgrade
[upgrade/staticpods] Renewing apiserver certificate
[upgrade/staticpods] Renewing apiserver-kubelet-client certificate
[upgrade/staticpods] Renewing front-proxy-client certificate
[upgrade/staticpods] Renewing apiserver-etcd-client certificate
[upgrade/staticpods] Moved new manifest to &#34;/etc/kubernetes/manifests/kube-apiserver.yaml&#34; and backed up old manifest to &#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-apiserver.yaml&#34;
[upgrade/staticpods] Waiting for the kubelet to restart the component
[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)
Static pod: kube-apiserver-mini1 hash: 868871559cc75dab75f106d4af342538
Static pod: kube-apiserver-mini1 hash: 01800dd11dfbda441372caf7cbf8aa39
[apiclient] Found 1 Pods for label selector component=kube-apiserver
[upgrade/staticpods] Component &#34;kube-apiserver&#34; upgraded successfully!
[upgrade/staticpods] Preparing for &#34;kube-controller-manager&#34; upgrade
[upgrade/staticpods] Renewing controller-manager.conf certificate
[upgrade/staticpods] Moved new manifest to &#34;/etc/kubernetes/manifests/kube-controller-manager.yaml&#34; and backed up old manifest to &#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-controller-manager.yaml&#34;
[upgrade/staticpods] Waiting for the kubelet to restart the component
[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)
Static pod: kube-controller-manager-mini1 hash: 44f6b9cce90e81a472520a3fb9751d10
Static pod: kube-controller-manager-mini1 hash: e12d193633dcf11f6095d89ee58c45a9
[apiclient] Found 1 Pods for label selector component=kube-controller-manager
[upgrade/staticpods] Component &#34;kube-controller-manager&#34; upgraded successfully!
[upgrade/staticpods] Preparing for &#34;kube-scheduler&#34; upgrade
[upgrade/staticpods] Renewing scheduler.conf certificate
[upgrade/staticpods] Moved new manifest to &#34;/etc/kubernetes/manifests/kube-scheduler.yaml&#34; and backed up old manifest to &#34;/etc/kubernetes/tmp/kubeadm-backup-manifests-2019-10-07-23-43-23/kube-scheduler.yaml&#34;
[upgrade/staticpods] Waiting for the kubelet to restart the component
[upgrade/staticpods] This might take a minute or longer depending on the component/version gap (timeout 5m0s)
Static pod: kube-scheduler-mini1 hash: 7d5d3c0a6786e517a8973fa06754cb75
Static pod: kube-scheduler-mini1 hash: bf9014e67294b0df0bc373fd7024ced7
[apiclient] Found 1 Pods for label selector component=kube-scheduler
[upgrade/staticpods] Component &#34;kube-scheduler&#34; upgraded successfully!
[upload-config] Storing the configuration used in ConfigMap &#34;kubeadm-config&#34; in the &#34;kube-system&#34; Namespace
[kubelet] Creating a ConfigMap &#34;kubelet-config-1.16&#34; in namespace kube-system with the configuration for the kubelets in the cluster
[kubelet-start] Downloading configuration for the kubelet from the &#34;kubelet-config-1.16&#34; ConfigMap in the kube-system namespace
[kubelet-start] Writing kubelet configuration to file &#34;/var/lib/kubelet/config.yaml&#34;
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

[upgrade/successful] SUCCESS! Your cluster was upgraded to &#34;v1.16.1&#34;. Enjoy!

[upgrade/kubelet] Now that your control plane is upgraded, please proceed with upgrading your kubelets if you haven&#39;t already done so.
</code></pre><h3 id=upgrade-calico-from-v38-to-v39>Upgrade calico from v3.8 to v3.9</h3><pre tabindex=0><code>kubectl apply -f https://docs.projectcalico.org/v3.9/manifests/calico.yaml
configmap/calico-config unchanged
customresourcedefinition.apiextensions.k8s.io/felixconfigurations.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/ipamblocks.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/blockaffinities.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/ipamhandles.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/ipamconfigs.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/bgppeers.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/bgpconfigurations.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/ippools.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/hostendpoints.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/clusterinformations.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/globalnetworkpolicies.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/globalnetworksets.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/networkpolicies.crd.projectcalico.org unchanged
customresourcedefinition.apiextensions.k8s.io/networksets.crd.projectcalico.org unchanged
clusterrole.rbac.authorization.k8s.io/calico-kube-controllers unchanged
clusterrolebinding.rbac.authorization.k8s.io/calico-kube-controllers unchanged
clusterrole.rbac.authorization.k8s.io/calico-node configured
clusterrolebinding.rbac.authorization.k8s.io/calico-node unchanged
daemonset.apps/calico-node configured
serviceaccount/calico-node unchanged
deployment.apps/calico-kube-controllers configured
serviceaccount/calico-kube-controllers unchanged
</code></pre><p>앗. 서브넷 변경하는 걸 깜빡</p><pre tabindex=0><code>cychong@mini1:~$ wget https://docs.projectcalico.org/v3.9/manifests/calico.yaml
--2019-10-07 23:49:13--  https://docs.projectcalico.org/v3.9/manifests/calico.yaml
Resolving docs.projectcalico.org (docs.projectcalico.org)... 104.248.78.23, 2604:a880:2:d0::21e9:b001
Connecting to docs.projectcalico.org (docs.projectcalico.org)|104.248.78.23|:443... connected.
HTTP request sent, awaiting response... v200 OK
Length: 20648 (20K) [application/x-yaml]
Saving to: ‘calico.yaml’

calico.yaml                          0%[                                                              ]       0  --.-KB/s               icalico.yaml                        100%[=============================================================&gt;]  20.16K   123KB/s    in 0.2s

c2019-10-07 23:49:14 (123 KB/s) - ‘calico.yaml’ saved [20648/20648]
</code></pre><p>Change <code>CALICO_IPV4POOL_CIDR</code></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>            - <span style=color:#f92672>name</span>: <span style=color:#ae81ff>CALICO_IPV4POOL_CIDR</span>
</span></span><span style=display:flex><span>              <span style=color:#f92672>value</span>: <span style=color:#e6db74>&#34;10.201.0.0/24&#34;</span>
</span></span></code></pre></div><h2 id=upgrade-kubelet-and-kubectl>Upgrade kubelet and kubectl</h2><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cychong@mini1:~$ sudo apt-mark unhold kubelet kubectl <span style=color:#f92672>&amp;&amp;</span> sudo apt-get update <span style=color:#f92672>&amp;&amp;</span> sudo apt-get install -y kubelet<span style=color:#f92672>=</span>1.16.1-00 kubectl<span style=color:#f92672>=</span>1.16.1-00 <span style=color:#f92672>&amp;&amp;</span> sudo apt-mark hold kubelet kubectl
</span></span><span style=display:flex><span>Canceled hold on kubelet.
</span></span><span style=display:flex><span>Canceled hold on kubectl.
</span></span><span style=display:flex><span>Ign:2 http://dl.google.com/linux/chrome/deb stable InRelease
</span></span><span style=display:flex><span>Hit:3 http://dl.google.com/linux/chrome/deb stable Release
</span></span><span style=display:flex><span>Hit:4 http://archive.ubuntu.com/ubuntu bionic InRelease
</span></span><span style=display:flex><span>Hit:5 https://download.docker.com/linux/ubuntu bionic InRelease
</span></span><span style=display:flex><span>Hit:7 http://archive.ubuntu.com/ubuntu bionic-updates InRelease
</span></span><span style=display:flex><span>Hit:1 https://packages.cloud.google.com/apt kubernetes-xenial InRelease
</span></span><span style=display:flex><span>Hit:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease
</span></span><span style=display:flex><span>Hit:9 http://archive.ubuntu.com/ubuntu bionic-security InRelease
</span></span><span style=display:flex><span>Reading package lists... Done
</span></span><span style=display:flex><span>Reading package lists... Done
</span></span><span style=display:flex><span>Building dependency tree
</span></span><span style=display:flex><span>Reading state information... Done
</span></span><span style=display:flex><span>The following package was automatically installed and is no longer required:
</span></span><span style=display:flex><span>  libllvm7
</span></span><span style=display:flex><span>Use <span style=color:#e6db74>&#39;sudo apt autoremove&#39;</span> to remove it.
</span></span><span style=display:flex><span>The following packages will be upgraded:
</span></span><span style=display:flex><span>  kubectl kubelet
</span></span><span style=display:flex><span><span style=color:#ae81ff>2</span> upgraded, <span style=color:#ae81ff>0</span> newly installed, <span style=color:#ae81ff>0</span> to remove and <span style=color:#ae81ff>39</span> not upgraded.
</span></span><span style=display:flex><span>Need to get 29.9 MB of archives.
</span></span><span style=display:flex><span>After this operation, <span style=color:#ae81ff>7179</span> kB of additional disk space will be used.
</span></span><span style=display:flex><span>Get:1 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubectl amd64 1.16.1-00 <span style=color:#f92672>[</span><span style=color:#ae81ff>9234</span> kB<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>Get:2 https://packages.cloud.google.com/apt kubernetes-xenial/main amd64 kubelet amd64 1.16.1-00 <span style=color:#f92672>[</span>20.7 MB<span style=color:#f92672>]</span>
</span></span><span style=display:flex><span>Fetched 29.9 MB in 6s <span style=color:#f92672>(</span><span style=color:#ae81ff>4899</span> kB/s<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span><span style=color:#f92672>(</span>Reading database ... <span style=color:#ae81ff>237550</span> files and directories currently installed.<span style=color:#f92672>)</span>
</span></span><span style=display:flex><span>Preparing to unpack .../kubectl_1.16.1-00_amd64.deb ...
</span></span><span style=display:flex><span>Unpacking kubectl <span style=color:#f92672>(</span>1.16.1-00<span style=color:#f92672>)</span> over <span style=color:#f92672>(</span>1.15.3-00<span style=color:#f92672>)</span> ...
</span></span><span style=display:flex><span>Preparing to unpack .../kubelet_1.16.1-00_amd64.deb ...
</span></span><span style=display:flex><span>Unpacking kubelet <span style=color:#f92672>(</span>1.16.1-00<span style=color:#f92672>)</span> over <span style=color:#f92672>(</span>1.15.3-00<span style=color:#f92672>)</span> ...
</span></span><span style=display:flex><span>Setting up kubelet <span style=color:#f92672>(</span>1.16.1-00<span style=color:#f92672>)</span> ...
</span></span><span style=display:flex><span>Setting up kubectl <span style=color:#f92672>(</span>1.16.1-00<span style=color:#f92672>)</span> ...
</span></span><span style=display:flex><span>kubelet set on hold.
</span></span><span style=display:flex><span>kubectl set on hold.
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>cychong@mini1:~$ sudo systemctl restart kubelet
</span></span><span style=display:flex><span>cychong@mini1:~$
</span></span></code></pre></div><h2 id=check-the-status>Check the status</h2><pre tabindex=0><code>cychong@mini1:~$ kubectl get nodes
NAME    STATUS   ROLES    AGE   VERSION
mini1   Ready    master   29d   v1.16.1
</code></pre><p>Reference</p><ul><li><a href=https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/>https://kubernetes.io/docs/tasks/administer-cluster/kubeadm/kubeadm-upgrade/</a></li></ul></content><p><a href=https://cychong47.github.io/tags/kubernetes/>#Kubernetes</a></p></main><footer>Made with <a href=https://github.com/janraasch/hugo-bearblog/>Hugo ʕ•ᴥ•ʔ Bear</a></footer></body></html>